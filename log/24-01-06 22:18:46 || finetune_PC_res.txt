Start time: 2024-01-06 22:18:46.466079
priority replay buffer is in use
batch i:1
batch i:2
batch i:3
batch i:4
batch i:5
batch i:6
learning rate: 0.0013333333333333333, loss: 2.512636661529541
batch i:7
learning rate: 0.0008888888888888888, loss: 2.1638026237487793
batch i:8
learning rate: 0.0005925925925925926, loss: 2.1908998489379883
batch i:9
learning rate: 0.0003950617283950617, loss: 2.060263156890869
batch i:10
learning rate: 0.0003950617283950617, loss: 2.3433265686035156
current self-play batch: 10
num_playouts:1000, win: 10, lose: 0, tie:0
average time: 236.5425549507141
New best policy from pure MCTS
batch i:11
learning rate: 0.0003950617283950617, loss: 2.334805488586426
batch i:12
learning rate: 0.0003950617283950617, loss: 2.4147377014160156
batch i:13
learning rate: 0.0003950617283950617, loss: 2.403907299041748
batch i:14
learning rate: 0.0003950617283950617, loss: 2.1834959983825684
batch i:15
Traceback (most recent call last):
  File "/mnt/nas/home/huangyixin/AI/train.py", line 402, in <module>
    training_pipeline.train(game_batch_num)
  File "/mnt/nas/home/huangyixin/AI/train.py", line 304, in train
    self.policy_update()
  File "/mnt/nas/home/huangyixin/AI/train.py", line 268, in policy_update
    old_probs, _, _ = self.net.eval_state(state_batch)
  File "/mnt/nas/home/huangyixin/AI/model.py", line 296, in eval_state
    policy_logits, value_logits, value = self.net(state_batch)
  File "/home/huangyixin/anaconda3/envs/gomoku/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/nas/home/huangyixin/AI/model.py", line 109, in forward
    x = self.res_blocks(x)
  File "/home/huangyixin/anaconda3/envs/gomoku/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/huangyixin/anaconda3/envs/gomoku/lib/python3.9/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/huangyixin/anaconda3/envs/gomoku/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/nas/home/huangyixin/AI/model.py", line 61, in forward
    ret = F.relu(ret)
  File "/home/huangyixin/anaconda3/envs/gomoku/lib/python3.9/site-packages/torch/nn/functional.py", line 1457, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 10.76 GiB total capacity; 9.38 GiB already allocated; 7.44 MiB free; 9.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
