Start time: 2023-12-18 01:19:19.941170
batch i:1
batch i:2
learning rate: 0.0013333333333333333, loss: 5.447202682495117
batch i:3
learning rate: 0.0008888888888888888, loss: 5.236029148101807
batch i:4
learning rate: 0.0005925925925925926, loss: 5.27301549911499
batch i:5
learning rate: 0.0008888888888888889, loss: 5.222054481506348
batch i:6
learning rate: 0.0013333333333333335, loss: 5.177064895629883
batch i:7
learning rate: 0.0013333333333333335, loss: 5.140440464019775
batch i:8
learning rate: 0.0013333333333333335, loss: 5.187992572784424
batch i:9
learning rate: 0.0013333333333333335, loss: 5.1170334815979
batch i:10
learning rate: 0.0013333333333333335, loss: 5.029115200042725
batch i:11
learning rate: 0.0013333333333333335, loss: 4.954333782196045
batch i:12
learning rate: 0.0013333333333333335, loss: 4.903995513916016
batch i:13
learning rate: 0.0013333333333333335, loss: 4.974889278411865
batch i:14
learning rate: 0.0013333333333333335, loss: 4.886072158813477
batch i:15
learning rate: 0.0013333333333333335, loss: 4.880843162536621
batch i:16
learning rate: 0.0013333333333333335, loss: 4.841334819793701
batch i:17
learning rate: 0.0013333333333333335, loss: 4.707690238952637
batch i:18
learning rate: 0.000888888888888889, loss: 4.543750286102295
batch i:19
learning rate: 0.000888888888888889, loss: 4.469705581665039
batch i:20
learning rate: 0.000888888888888889, loss: 4.430961608886719
batch i:21
learning rate: 0.000888888888888889, loss: 4.358004570007324
batch i:22
learning rate: 0.000888888888888889, loss: 4.341531276702881
batch i:23
learning rate: 0.000888888888888889, loss: 4.35336971282959
batch i:24
learning rate: 0.000888888888888889, loss: 4.409909248352051
batch i:25
learning rate: 0.000888888888888889, loss: 4.372586250305176
batch i:26
learning rate: 0.000888888888888889, loss: 4.32351541519165
batch i:27
learning rate: 0.0005925925925925927, loss: 4.336627960205078
batch i:28
learning rate: 0.0005925925925925927, loss: 4.334284782409668
batch i:29
learning rate: 0.0005925925925925927, loss: 4.417647838592529
batch i:30
learning rate: 0.0005925925925925927, loss: 4.415096282958984
batch i:31
learning rate: 0.0005925925925925927, loss: 4.34511661529541
batch i:32
learning rate: 0.0005925925925925927, loss: 4.386624336242676
batch i:33
learning rate: 0.0005925925925925927, loss: 4.380268096923828
batch i:34
learning rate: 0.0005925925925925927, loss: 4.357244968414307
batch i:35
learning rate: 0.0005925925925925927, loss: 4.425327777862549
batch i:36
learning rate: 0.0005925925925925927, loss: 4.33339786529541
batch i:37
learning rate: 0.0005925925925925927, loss: 4.3445305824279785
batch i:38
learning rate: 0.0005925925925925927, loss: 4.340442657470703
batch i:39
learning rate: 0.0005925925925925927, loss: 4.310709476470947
batch i:40
learning rate: 0.0005925925925925927, loss: 4.304815769195557
batch i:41
learning rate: 0.0005925925925925927, loss: 4.341123580932617
batch i:42
learning rate: 0.0005925925925925927, loss: 4.26345157623291
batch i:43
learning rate: 0.0005925925925925927, loss: 4.238728046417236
batch i:44
learning rate: 0.0005925925925925927, loss: 4.164638519287109
batch i:45
learning rate: 0.0005925925925925927, loss: 4.094186782836914
batch i:46
learning rate: 0.0005925925925925927, loss: 4.181056022644043
batch i:47
learning rate: 0.0005925925925925927, loss: 4.085293292999268
batch i:48
learning rate: 0.0005925925925925927, loss: 4.104768753051758
batch i:49
learning rate: 0.0005925925925925927, loss: 4.122089385986328
batch i:50
learning rate: 0.0005925925925925927, loss: 4.082512855529785
current self-play batch: 50
num_playouts:1000, win: 0, lose: 10, tie:0
average time: 89.173144698143
batch i:51
learning rate: 0.0005925925925925927, loss: 4.034726142883301
batch i:52
learning rate: 0.0005925925925925927, loss: 4.044581413269043
batch i:53
learning rate: 0.0005925925925925927, loss: 4.040020942687988
batch i:54
learning rate: 0.0005925925925925927, loss: 4.042514801025391
batch i:55
learning rate: 0.0005925925925925927, loss: 3.959900140762329
batch i:56
learning rate: 0.0005925925925925927, loss: 3.9231250286102295
batch i:57
learning rate: 0.0005925925925925927, loss: 3.967712163925171
batch i:58
learning rate: 0.0003950617283950618, loss: 4.049831867218018
batch i:59
learning rate: 0.0003950617283950618, loss: 3.976633071899414
batch i:60
learning rate: 0.0003950617283950618, loss: 4.008530616760254
batch i:61
learning rate: 0.0003950617283950618, loss: 3.9164984226226807
batch i:62
learning rate: 0.0003950617283950618, loss: 4.066864967346191
batch i:63
learning rate: 0.0003950617283950618, loss: 4.051360130310059
batch i:64
learning rate: 0.0003950617283950618, loss: 3.997619152069092
batch i:65
learning rate: 0.0003950617283950618, loss: 3.984860420227051
batch i:66
learning rate: 0.0003950617283950618, loss: 4.00909948348999
batch i:67
learning rate: 0.0003950617283950618, loss: 3.978074312210083
batch i:68
learning rate: 0.0003950617283950618, loss: 3.8844027519226074
batch i:69
learning rate: 0.0003950617283950618, loss: 3.9114127159118652
batch i:70
learning rate: 0.0003950617283950618, loss: 3.8874454498291016
batch i:71
learning rate: 0.0003950617283950618, loss: 3.89878511428833
batch i:72
learning rate: 0.0003950617283950618, loss: 3.89847731590271
batch i:73
learning rate: 0.0003950617283950618, loss: 3.819584608078003
batch i:74
learning rate: 0.0003950617283950618, loss: 3.7824320793151855
batch i:75
learning rate: 0.0003950617283950618, loss: 3.888298988342285
batch i:76
learning rate: 0.0003950617283950618, loss: 3.900336742401123
batch i:77
learning rate: 0.0003950617283950618, loss: 3.8110382556915283
batch i:78
learning rate: 0.0003950617283950618, loss: 3.8267064094543457
batch i:79
learning rate: 0.0003950617283950618, loss: 3.729329824447632
batch i:80
learning rate: 0.0003950617283950618, loss: 3.766630172729492
batch i:81
learning rate: 0.0003950617283950618, loss: 3.7672858238220215
batch i:82
learning rate: 0.0003950617283950618, loss: 3.8268990516662598
batch i:83
learning rate: 0.0003950617283950618, loss: 3.835380792617798
batch i:84
learning rate: 0.0003950617283950618, loss: 3.7827930450439453
batch i:85
learning rate: 0.0003950617283950618, loss: 3.757722854614258
batch i:86
learning rate: 0.0003950617283950618, loss: 3.827523708343506
batch i:87
learning rate: 0.0003950617283950618, loss: 3.811164617538452
batch i:88
learning rate: 0.0003950617283950618, loss: 3.7694814205169678
batch i:89
learning rate: 0.0003950617283950618, loss: 3.7076594829559326
batch i:90
learning rate: 0.0003950617283950618, loss: 3.731863260269165
batch i:91
learning rate: 0.0003950617283950618, loss: 3.6963138580322266
batch i:92
learning rate: 0.0003950617283950618, loss: 3.7507405281066895
batch i:93
learning rate: 0.0003950617283950618, loss: 3.6691150665283203
batch i:94
learning rate: 0.0003950617283950618, loss: 3.769176959991455
batch i:95
learning rate: 0.0003950617283950618, loss: 3.795637845993042
batch i:96
learning rate: 0.0003950617283950618, loss: 3.7074477672576904
batch i:97
learning rate: 0.0003950617283950618, loss: 3.7114667892456055
batch i:98
learning rate: 0.0003950617283950618, loss: 3.744813919067383
batch i:99
learning rate: 0.0003950617283950618, loss: 3.7233705520629883
batch i:100
learning rate: 0.0003950617283950618, loss: 3.7168869972229004
current self-play batch: 100
num_playouts:1000, win: 4, lose: 6, tie:0
average time: 72.21304256916046
New best policy from pure MCTS
batch i:101
learning rate: 0.0003950617283950618, loss: 3.789494752883911
batch i:102
learning rate: 0.0003950617283950618, loss: 3.6919193267822266
batch i:103
learning rate: 0.0003950617283950618, loss: 3.678171157836914
batch i:104
learning rate: 0.0003950617283950618, loss: 3.7154276371002197
batch i:105
learning rate: 0.0003950617283950618, loss: 3.6725194454193115
batch i:106
learning rate: 0.0002633744855967079, loss: 3.6536929607391357
batch i:107
learning rate: 0.00017558299039780527, loss: 3.6710453033447266
batch i:108
learning rate: 0.00017558299039780527, loss: 3.655010223388672
batch i:109
learning rate: 0.0002633744855967079, loss: 3.667365789413452
batch i:110
learning rate: 0.0002633744855967079, loss: 3.716510534286499
batch i:111
learning rate: 0.0002633744855967079, loss: 3.6952295303344727
batch i:112
learning rate: 0.0002633744855967079, loss: 3.669741630554199
batch i:113
learning rate: 0.0002633744855967079, loss: 3.619335889816284
batch i:114
learning rate: 0.0002633744855967079, loss: 3.5850038528442383
batch i:115
learning rate: 0.0002633744855967079, loss: 3.635469436645508
batch i:116
learning rate: 0.0002633744855967079, loss: 3.586599349975586
batch i:117
learning rate: 0.0002633744855967079, loss: 3.7349953651428223
batch i:118
learning rate: 0.00039506172839506187, loss: 3.6654791831970215
batch i:119
learning rate: 0.00039506172839506187, loss: 3.6656723022460938
batch i:120
learning rate: 0.00039506172839506187, loss: 3.566206455230713
batch i:121
learning rate: 0.00039506172839506187, loss: 3.646401882171631
batch i:122
learning rate: 0.00039506172839506187, loss: 3.6155765056610107
batch i:123
learning rate: 0.00039506172839506187, loss: 3.588207721710205
batch i:124
learning rate: 0.00039506172839506187, loss: 3.5782361030578613
batch i:125
learning rate: 0.0002633744855967079, loss: 3.5868890285491943
batch i:126
learning rate: 0.0002633744855967079, loss: 3.6746582984924316
batch i:127
learning rate: 0.0002633744855967079, loss: 3.6465506553649902
batch i:128
learning rate: 0.0002633744855967079, loss: 3.6082115173339844
batch i:129
learning rate: 0.00017558299039780527, loss: 3.6428093910217285
batch i:130
learning rate: 0.00017558299039780527, loss: 3.6087558269500732
batch i:131
learning rate: 0.0002633744855967079, loss: 3.625089406967163
batch i:132
learning rate: 0.0002633744855967079, loss: 3.534968376159668
batch i:133
learning rate: 0.0002633744855967079, loss: 3.5043251514434814
batch i:134
learning rate: 0.00039506172839506187, loss: 3.6351661682128906
batch i:135
learning rate: 0.00039506172839506187, loss: 3.553536891937256
batch i:136
learning rate: 0.00039506172839506187, loss: 3.5152831077575684
batch i:137
learning rate: 0.00039506172839506187, loss: 3.6123251914978027
batch i:138
learning rate: 0.00039506172839506187, loss: 3.5705885887145996
batch i:139
learning rate: 0.00039506172839506187, loss: 3.6068615913391113
batch i:140
learning rate: 0.00039506172839506187, loss: 3.552220344543457
batch i:141
learning rate: 0.0002633744855967079, loss: 3.553760051727295
batch i:142
learning rate: 0.0002633744855967079, loss: 3.609193801879883
batch i:143
learning rate: 0.0002633744855967079, loss: 3.545807123184204
batch i:144
learning rate: 0.0002633744855967079, loss: 3.5685503482818604
batch i:145
learning rate: 0.0002633744855967079, loss: 3.4831929206848145
batch i:146
learning rate: 0.0002633744855967079, loss: 3.5525450706481934
batch i:147
learning rate: 0.0002633744855967079, loss: 3.511255979537964
batch i:148
learning rate: 0.0002633744855967079, loss: 3.605961799621582
batch i:149
learning rate: 0.0002633744855967079, loss: 3.573626756668091
batch i:150
learning rate: 0.0002633744855967079, loss: 3.5377206802368164
current self-play batch: 150
num_playouts:1000, win: 3, lose: 7, tie:0
average time: 96.52532930374146
batch i:151
learning rate: 0.0002633744855967079, loss: 3.543626070022583
batch i:152
learning rate: 0.0002633744855967079, loss: 3.5410056114196777
batch i:153
learning rate: 0.0002633744855967079, loss: 3.5324878692626953
batch i:154
learning rate: 0.0002633744855967079, loss: 3.5655877590179443
batch i:155
learning rate: 0.0002633744855967079, loss: 3.472311496734619
batch i:156
learning rate: 0.0002633744855967079, loss: 3.3942465782165527
batch i:157
learning rate: 0.0002633744855967079, loss: 3.541806697845459
batch i:158
learning rate: 0.0002633744855967079, loss: 3.462639808654785
batch i:159
learning rate: 0.0002633744855967079, loss: 3.4807777404785156
batch i:160
learning rate: 0.0002633744855967079, loss: 3.469041585922241
batch i:161
learning rate: 0.0002633744855967079, loss: 3.4701156616210938
batch i:162
learning rate: 0.0002633744855967079, loss: 3.378690481185913
batch i:163
learning rate: 0.0002633744855967079, loss: 3.4788124561309814
batch i:164
learning rate: 0.0002633744855967079, loss: 3.4969630241394043
batch i:165
learning rate: 0.0002633744855967079, loss: 3.3894519805908203
batch i:166
learning rate: 0.0002633744855967079, loss: 3.390800952911377
batch i:167
learning rate: 0.0002633744855967079, loss: 3.4680089950561523
batch i:168
learning rate: 0.0002633744855967079, loss: 3.460124969482422
batch i:169
learning rate: 0.0002633744855967079, loss: 3.5271036624908447
batch i:170
learning rate: 0.0002633744855967079, loss: 3.4743857383728027
batch i:171
learning rate: 0.0002633744855967079, loss: 3.5047993659973145
batch i:172
learning rate: 0.0002633744855967079, loss: 3.4376449584960938
batch i:173
learning rate: 0.0002633744855967079, loss: 3.421342372894287
batch i:174
learning rate: 0.0002633744855967079, loss: 3.4967169761657715
batch i:175
learning rate: 0.0002633744855967079, loss: 3.452699899673462
batch i:176
learning rate: 0.0002633744855967079, loss: 3.445535659790039
batch i:177
learning rate: 0.0002633744855967079, loss: 3.613739013671875
batch i:178
learning rate: 0.0002633744855967079, loss: 3.482814073562622
batch i:179
learning rate: 0.0002633744855967079, loss: 3.4988198280334473
batch i:180
learning rate: 0.0002633744855967079, loss: 3.494060754776001
batch i:181
learning rate: 0.0002633744855967079, loss: 3.4599461555480957
batch i:182
learning rate: 0.0002633744855967079, loss: 3.460860252380371
batch i:183
learning rate: 0.0002633744855967079, loss: 3.5197277069091797
batch i:184
learning rate: 0.0002633744855967079, loss: 3.5230984687805176
batch i:185
learning rate: 0.0002633744855967079, loss: 3.4992074966430664
batch i:186
learning rate: 0.0002633744855967079, loss: 3.51120662689209
batch i:187
learning rate: 0.0002633744855967079, loss: 3.4674131870269775
batch i:188
learning rate: 0.0002633744855967079, loss: 3.524193286895752
batch i:189
learning rate: 0.0002633744855967079, loss: 3.525676965713501
batch i:190
learning rate: 0.0002633744855967079, loss: 3.4530134201049805
batch i:191
learning rate: 0.0002633744855967079, loss: 3.50301456451416
batch i:192
learning rate: 0.0002633744855967079, loss: 3.621290683746338
batch i:193
learning rate: 0.0002633744855967079, loss: 3.523688793182373
batch i:194
learning rate: 0.0002633744855967079, loss: 3.564207077026367
batch i:195
learning rate: 0.0002633744855967079, loss: 3.584275722503662
batch i:196
learning rate: 0.0002633744855967079, loss: 3.5258631706237793
batch i:197
learning rate: 0.0002633744855967079, loss: 3.528454303741455
batch i:198
learning rate: 0.0002633744855967079, loss: 3.5463643074035645
batch i:199
learning rate: 0.0002633744855967079, loss: 3.434123992919922
batch i:200
learning rate: 0.0002633744855967079, loss: 3.5481152534484863
current self-play batch: 200
num_playouts:1000, win: 3, lose: 7, tie:0
average time: 75.92318630218506
batch i:201
learning rate: 0.0002633744855967079, loss: 3.620518684387207
batch i:202
learning rate: 0.0002633744855967079, loss: 3.532369613647461
batch i:203
learning rate: 0.0002633744855967079, loss: 3.5809226036071777
batch i:204
learning rate: 0.0002633744855967079, loss: 3.4929070472717285
batch i:205
learning rate: 0.0002633744855967079, loss: 3.482726573944092
batch i:206
learning rate: 0.0002633744855967079, loss: 3.4178757667541504
batch i:207
learning rate: 0.0002633744855967079, loss: 3.54378080368042
batch i:208
learning rate: 0.0002633744855967079, loss: 3.5542092323303223
batch i:209
learning rate: 0.0002633744855967079, loss: 3.5385208129882812
batch i:210
learning rate: 0.0002633744855967079, loss: 3.5587828159332275
batch i:211
learning rate: 0.0002633744855967079, loss: 3.460911989212036
batch i:212
learning rate: 0.0002633744855967079, loss: 3.48529314994812
batch i:213
learning rate: 0.0002633744855967079, loss: 3.4443671703338623
batch i:214
learning rate: 0.0002633744855967079, loss: 3.4874396324157715
batch i:215
learning rate: 0.0002633744855967079, loss: 3.5161421298980713
batch i:216
learning rate: 0.0002633744855967079, loss: 3.4451117515563965
batch i:217
learning rate: 0.0002633744855967079, loss: 3.531498908996582
batch i:218
learning rate: 0.0002633744855967079, loss: 3.5504720211029053
batch i:219
learning rate: 0.0002633744855967079, loss: 3.5870304107666016
batch i:220
learning rate: 0.0002633744855967079, loss: 3.5699000358581543
batch i:221
learning rate: 0.0002633744855967079, loss: 3.5500285625457764
batch i:222
learning rate: 0.0002633744855967079, loss: 3.5569610595703125
batch i:223
learning rate: 0.0002633744855967079, loss: 3.44496488571167
batch i:224
learning rate: 0.0002633744855967079, loss: 3.476480484008789
batch i:225
learning rate: 0.0002633744855967079, loss: 3.3895833492279053
batch i:226
learning rate: 0.0002633744855967079, loss: 3.426331043243408
batch i:227
learning rate: 0.0002633744855967079, loss: 3.384413719177246
batch i:228
learning rate: 0.0002633744855967079, loss: 3.449582099914551
batch i:229
learning rate: 0.0002633744855967079, loss: 3.4130311012268066
batch i:230
learning rate: 0.0002633744855967079, loss: 3.349452495574951
batch i:231
learning rate: 0.0002633744855967079, loss: 3.326979875564575
batch i:232
learning rate: 0.0002633744855967079, loss: 3.3539438247680664
batch i:233
learning rate: 0.0002633744855967079, loss: 3.3845276832580566
batch i:234
learning rate: 0.0002633744855967079, loss: 3.355924367904663
batch i:235
learning rate: 0.00017558299039780527, loss: 3.384286642074585
batch i:236
learning rate: 0.00017558299039780527, loss: 3.410714864730835
batch i:237
learning rate: 0.00017558299039780527, loss: 3.386988878250122
batch i:238
learning rate: 0.00017558299039780527, loss: 3.3580756187438965
batch i:239
learning rate: 0.00017558299039780527, loss: 3.3219690322875977
batch i:240
learning rate: 0.00017558299039780527, loss: 3.251858949661255
batch i:241
learning rate: 0.00017558299039780527, loss: 3.2705178260803223
batch i:242
learning rate: 0.00017558299039780527, loss: 3.297544002532959
batch i:243
learning rate: 0.00017558299039780527, loss: 3.326566219329834
batch i:244
learning rate: 0.00017558299039780527, loss: 3.2343239784240723
batch i:245
learning rate: 0.00017558299039780527, loss: 3.2152957916259766
batch i:246
learning rate: 0.00017558299039780527, loss: 3.112027645111084
batch i:247
learning rate: 0.00017558299039780527, loss: 3.240128517150879
batch i:248
learning rate: 0.00017558299039780527, loss: 3.176536798477173
batch i:249
learning rate: 0.00017558299039780527, loss: 3.213792324066162
batch i:250
learning rate: 0.00017558299039780527, loss: 3.218022346496582
current self-play batch: 250
num_playouts:1000, win: 3, lose: 7, tie:0
average time: 85.9947987318039
batch i:251
learning rate: 0.00017558299039780527, loss: 3.212461471557617
batch i:252
learning rate: 0.00017558299039780527, loss: 3.124767303466797
batch i:253
learning rate: 0.00017558299039780527, loss: 3.1985464096069336
batch i:254
learning rate: 0.00017558299039780527, loss: 3.2326807975769043
batch i:255
learning rate: 0.00017558299039780527, loss: 3.1999504566192627
batch i:256
learning rate: 0.00017558299039780527, loss: 3.1941521167755127
batch i:257
learning rate: 0.00017558299039780527, loss: 3.1803431510925293
batch i:258
learning rate: 0.00011705532693187018, loss: 3.070457696914673
batch i:259
learning rate: 0.00011705532693187018, loss: 3.16454815864563
batch i:260
learning rate: 0.00011705532693187018, loss: 3.0952420234680176
batch i:261
learning rate: 0.00017558299039780527, loss: 3.080195903778076
batch i:262
learning rate: 0.00017558299039780527, loss: 3.132145881652832
batch i:263
learning rate: 0.00017558299039780527, loss: 3.135087728500366
batch i:264
learning rate: 0.00017558299039780527, loss: 3.1221864223480225
batch i:265
learning rate: 0.00017558299039780527, loss: 3.058173179626465
batch i:266
learning rate: 0.00017558299039780527, loss: 3.103456497192383
batch i:267
learning rate: 0.00017558299039780527, loss: 3.1176486015319824
batch i:268
learning rate: 0.00017558299039780527, loss: 3.1030712127685547
batch i:269
learning rate: 0.00017558299039780527, loss: 3.0630970001220703
batch i:270
learning rate: 0.00017558299039780527, loss: 3.0438923835754395
batch i:271
learning rate: 0.00017558299039780527, loss: 3.0180792808532715
batch i:272
learning rate: 0.00017558299039780527, loss: 3.0171031951904297
batch i:273
learning rate: 0.00017558299039780527, loss: 3.0638134479522705
batch i:274
learning rate: 0.00017558299039780527, loss: 3.015383720397949
batch i:275
learning rate: 0.00017558299039780527, loss: 2.9933531284332275
batch i:276
learning rate: 0.00017558299039780527, loss: 2.9094860553741455
batch i:277
learning rate: 0.00017558299039780527, loss: 3.00034499168396
batch i:278
learning rate: 0.00017558299039780527, loss: 2.9253783226013184
batch i:279
learning rate: 0.0002633744855967079, loss: 2.980487823486328
batch i:280
learning rate: 0.0002633744855967079, loss: 2.8790178298950195
batch i:281
learning rate: 0.0002633744855967079, loss: 2.9224796295166016
batch i:282
learning rate: 0.0002633744855967079, loss: 2.843338966369629
batch i:283
learning rate: 0.0002633744855967079, loss: 2.945237159729004
batch i:284
learning rate: 0.0002633744855967079, loss: 2.9991931915283203
batch i:285
learning rate: 0.0002633744855967079, loss: 2.910430431365967
batch i:286
learning rate: 0.0002633744855967079, loss: 3.056166172027588
batch i:287
learning rate: 0.0002633744855967079, loss: 2.966099739074707
batch i:288
learning rate: 0.0002633744855967079, loss: 2.952501058578491
batch i:289
learning rate: 0.0002633744855967079, loss: 3.046381950378418
batch i:290
learning rate: 0.0002633744855967079, loss: 2.9476823806762695
batch i:291
learning rate: 0.0002633744855967079, loss: 2.8916139602661133
batch i:292
learning rate: 0.0002633744855967079, loss: 2.9508609771728516
batch i:293
learning rate: 0.0002633744855967079, loss: 2.8410420417785645
batch i:294
learning rate: 0.0002633744855967079, loss: 2.8781914710998535
batch i:295
learning rate: 0.0002633744855967079, loss: 2.900827407836914
batch i:296
learning rate: 0.0002633744855967079, loss: 2.9171080589294434
batch i:297
learning rate: 0.0002633744855967079, loss: 2.8022003173828125
batch i:298
learning rate: 0.0002633744855967079, loss: 2.883378505706787
batch i:299
learning rate: 0.0002633744855967079, loss: 2.9324791431427
batch i:300
learning rate: 0.0002633744855967079, loss: 2.9158506393432617
current self-play batch: 300
num_playouts:1000, win: 6, lose: 4, tie:0
average time: 183.6300496339798
New best policy from pure MCTS
batch i:301
learning rate: 0.0002633744855967079, loss: 3.0016536712646484
batch i:302
learning rate: 0.00017558299039780527, loss: 2.91557240486145
batch i:303
learning rate: 0.00017558299039780527, loss: 2.895444393157959
batch i:304
learning rate: 0.00017558299039780527, loss: 2.8754448890686035
batch i:305
learning rate: 0.00017558299039780527, loss: 2.930295944213867
batch i:306
learning rate: 0.00017558299039780527, loss: 2.773320198059082
batch i:307
learning rate: 0.00017558299039780527, loss: 2.8683810234069824
batch i:308
learning rate: 0.00017558299039780527, loss: 2.891789674758911
batch i:309
learning rate: 0.00017558299039780527, loss: 2.8611900806427
batch i:310
learning rate: 0.00017558299039780527, loss: 2.785858154296875
batch i:311
learning rate: 0.00017558299039780527, loss: 2.814298152923584
batch i:312
learning rate: 0.00017558299039780527, loss: 2.8210740089416504
batch i:313
learning rate: 0.00017558299039780527, loss: 2.8127124309539795
batch i:314
learning rate: 0.00017558299039780527, loss: 2.8633675575256348
batch i:315
learning rate: 0.00017558299039780527, loss: 2.854877233505249
batch i:316
learning rate: 0.00017558299039780527, loss: 2.865446090698242
batch i:317
learning rate: 0.00017558299039780527, loss: 2.824939012527466
batch i:318
learning rate: 0.00017558299039780527, loss: 2.8502449989318848
batch i:319
learning rate: 0.00017558299039780527, loss: 2.853717803955078
batch i:320
learning rate: 0.00017558299039780527, loss: 2.879149913787842
batch i:321
learning rate: 0.00017558299039780527, loss: 2.9027481079101562
batch i:322
learning rate: 0.00017558299039780527, loss: 2.9497029781341553
batch i:323
learning rate: 0.00017558299039780527, loss: 2.983649253845215
batch i:324
learning rate: 0.00017558299039780527, loss: 2.948488235473633
batch i:325
learning rate: 0.00017558299039780527, loss: 2.956972599029541
batch i:326
learning rate: 0.00017558299039780527, loss: 2.996673583984375
batch i:327
learning rate: 0.00017558299039780527, loss: 2.900765895843506
batch i:328
learning rate: 0.00017558299039780527, loss: 2.9750938415527344
batch i:329
learning rate: 0.00017558299039780527, loss: 2.973259687423706
batch i:330
learning rate: 0.00017558299039780527, loss: 2.956918716430664
batch i:331
learning rate: 0.00017558299039780527, loss: 2.8498942852020264
batch i:332
learning rate: 0.00017558299039780527, loss: 2.9290013313293457
batch i:333
learning rate: 0.00017558299039780527, loss: 2.8972907066345215
batch i:334
learning rate: 0.00017558299039780527, loss: 2.859837055206299
batch i:335
learning rate: 0.00017558299039780527, loss: 2.906033992767334
batch i:336
learning rate: 0.00017558299039780527, loss: 2.9983649253845215
batch i:337
learning rate: 0.00017558299039780527, loss: 2.8935775756835938
batch i:338
learning rate: 0.00017558299039780527, loss: 3.044279098510742
batch i:339
learning rate: 0.00017558299039780527, loss: 3.056659460067749
batch i:340
learning rate: 0.00017558299039780527, loss: 2.9683661460876465
batch i:341
learning rate: 0.00017558299039780527, loss: 2.921558380126953
batch i:342
learning rate: 0.00017558299039780527, loss: 3.05792498588562
batch i:343
learning rate: 0.00017558299039780527, loss: 2.9202826023101807
batch i:344
learning rate: 0.00017558299039780527, loss: 2.9924874305725098
batch i:345
learning rate: 0.00017558299039780527, loss: 2.8799047470092773
batch i:346
learning rate: 0.00017558299039780527, loss: 2.847355842590332
batch i:347
learning rate: 0.00017558299039780527, loss: 2.8880934715270996
batch i:348
learning rate: 0.00017558299039780527, loss: 2.8865299224853516
batch i:349
learning rate: 0.00017558299039780527, loss: 2.8850255012512207
batch i:350
learning rate: 0.00017558299039780527, loss: 2.8690643310546875
current self-play batch: 350
num_playouts:1000, win: 5, lose: 5, tie:0
average time: 411.44489669799805
batch i:351
learning rate: 0.00017558299039780527, loss: 2.880650520324707
batch i:352
learning rate: 0.00017558299039780527, loss: 2.8028194904327393
batch i:353
learning rate: 0.00017558299039780527, loss: 2.9169678688049316
batch i:354
learning rate: 0.00017558299039780527, loss: 2.827981472015381
batch i:355
learning rate: 0.00017558299039780527, loss: 2.870267391204834
batch i:356
learning rate: 0.00017558299039780527, loss: 2.8982248306274414
batch i:357
learning rate: 0.00017558299039780527, loss: 2.8384294509887695
batch i:358
learning rate: 0.00017558299039780527, loss: 2.7967960834503174
batch i:359
learning rate: 0.00017558299039780527, loss: 2.7501323223114014
batch i:360
learning rate: 0.00017558299039780527, loss: 2.8478469848632812
batch i:361
learning rate: 0.00017558299039780527, loss: 2.982445240020752
batch i:362
learning rate: 0.00017558299039780527, loss: 2.8649978637695312
batch i:363
learning rate: 0.00017558299039780527, loss: 2.720655918121338
batch i:364
learning rate: 0.00017558299039780527, loss: 2.968048572540283
batch i:365
learning rate: 0.00017558299039780527, loss: 2.8923165798187256
batch i:366
learning rate: 0.00017558299039780527, loss: 2.8900904655456543
batch i:367
learning rate: 0.00017558299039780527, loss: 2.8688371181488037
batch i:368
learning rate: 0.00017558299039780527, loss: 2.8569083213806152
batch i:369
learning rate: 0.00017558299039780527, loss: 2.785261869430542
batch i:370
learning rate: 0.00017558299039780527, loss: 2.9143152236938477
batch i:371
learning rate: 0.00017558299039780527, loss: 2.7412967681884766
batch i:372
learning rate: 0.00017558299039780527, loss: 2.898744583129883
batch i:373
learning rate: 0.00017558299039780527, loss: 2.9229013919830322
batch i:374
learning rate: 0.00017558299039780527, loss: 2.8250012397766113
batch i:375
learning rate: 0.00017558299039780527, loss: 2.8130574226379395
batch i:376
learning rate: 0.00017558299039780527, loss: 2.872889518737793
batch i:377
learning rate: 0.00017558299039780527, loss: 2.9120192527770996
batch i:378
learning rate: 0.00017558299039780527, loss: 2.839015007019043
batch i:379
learning rate: 0.00017558299039780527, loss: 2.8388705253601074
batch i:380
learning rate: 0.00017558299039780527, loss: 2.985279083251953
batch i:381
learning rate: 0.00017558299039780527, loss: 2.827410936355591
batch i:382
learning rate: 0.00017558299039780527, loss: 2.821385383605957
batch i:383
learning rate: 0.00017558299039780527, loss: 2.8391098976135254
batch i:384
learning rate: 0.00017558299039780527, loss: 2.7975125312805176
batch i:385
learning rate: 0.00017558299039780527, loss: 2.8343029022216797
batch i:386
learning rate: 0.00017558299039780527, loss: 2.919067621231079
batch i:387
learning rate: 0.00017558299039780527, loss: 2.9166159629821777
batch i:388
learning rate: 0.00017558299039780527, loss: 2.8624367713928223
batch i:389
learning rate: 0.00017558299039780527, loss: 2.8960089683532715
batch i:390
learning rate: 0.00017558299039780527, loss: 2.8128650188446045
batch i:391
learning rate: 0.00017558299039780527, loss: 2.875134229660034
batch i:392
learning rate: 0.00017558299039780527, loss: 2.7930757999420166
batch i:393
learning rate: 0.00017558299039780527, loss: 2.8165030479431152
batch i:394
learning rate: 0.00017558299039780527, loss: 2.9858834743499756
batch i:395
learning rate: 0.00017558299039780527, loss: 2.801731586456299
batch i:396
learning rate: 0.00017558299039780527, loss: 2.912503242492676
batch i:397
learning rate: 0.00017558299039780527, loss: 2.9042673110961914
batch i:398
learning rate: 0.00017558299039780527, loss: 2.895750045776367
batch i:399
learning rate: 0.00017558299039780527, loss: 2.839102029800415
batch i:400
learning rate: 0.00017558299039780527, loss: 3.0220115184783936
current self-play batch: 400
num_playouts:1000, win: 7, lose: 3, tie:0
average time: 163.3488958597183
New best policy from pure MCTS
batch i:401
learning rate: 0.00017558299039780527, loss: 2.925086498260498
batch i:402
learning rate: 0.00017558299039780527, loss: 2.849177360534668
batch i:403
learning rate: 0.00017558299039780527, loss: 2.97300386428833
batch i:404
learning rate: 0.00017558299039780527, loss: 3.0621259212493896
batch i:405
learning rate: 0.00011705532693187018, loss: 2.941951274871826
batch i:406
learning rate: 0.00011705532693187018, loss: 2.938382625579834
batch i:407
learning rate: 0.00011705532693187018, loss: 3.0091938972473145
batch i:408
learning rate: 0.00011705532693187018, loss: 2.9870312213897705
batch i:409
learning rate: 0.00011705532693187018, loss: 2.9847373962402344
batch i:410
learning rate: 0.00011705532693187018, loss: 2.959014415740967
batch i:411
learning rate: 0.00011705532693187018, loss: 3.188774347305298
batch i:412
learning rate: 0.00011705532693187018, loss: 3.068877696990967
batch i:413
learning rate: 0.00011705532693187018, loss: 3.013888359069824
batch i:414
learning rate: 0.00011705532693187018, loss: 3.0803475379943848
batch i:415
learning rate: 0.00011705532693187018, loss: 3.1405038833618164
batch i:416
learning rate: 0.00011705532693187018, loss: 3.086984634399414
batch i:417
learning rate: 0.00011705532693187018, loss: 3.0847525596618652
batch i:418
learning rate: 0.00011705532693187018, loss: 3.161067247390747
batch i:419
learning rate: 0.00011705532693187018, loss: 3.0583581924438477
batch i:420
learning rate: 0.00011705532693187018, loss: 3.1126081943511963
batch i:421
learning rate: 0.00011705532693187018, loss: 3.1905291080474854
batch i:422
learning rate: 0.00011705532693187018, loss: 3.1724886894226074
batch i:423
learning rate: 0.00011705532693187018, loss: 3.0738606452941895
batch i:424
learning rate: 0.00011705532693187018, loss: 3.239788055419922
batch i:425
learning rate: 0.00011705532693187018, loss: 3.1259212493896484
batch i:426
learning rate: 0.00011705532693187018, loss: 3.1263108253479004
batch i:427
learning rate: 0.00011705532693187018, loss: 3.0930330753326416
batch i:428
learning rate: 0.00011705532693187018, loss: 3.2144358158111572
batch i:429
learning rate: 0.00011705532693187018, loss: 3.1535134315490723
batch i:430
learning rate: 0.00011705532693187018, loss: 3.1521825790405273
batch i:431
learning rate: 0.00011705532693187018, loss: 3.1920809745788574
batch i:432
learning rate: 0.00011705532693187018, loss: 3.044405460357666
batch i:433
learning rate: 0.00011705532693187018, loss: 3.177736520767212
batch i:434
learning rate: 0.00011705532693187018, loss: 3.1681456565856934
batch i:435
learning rate: 0.00011705532693187018, loss: 3.0934581756591797
batch i:436
learning rate: 0.00011705532693187018, loss: 3.0209662914276123
batch i:437
learning rate: 0.00011705532693187018, loss: 3.048079252243042
batch i:438
learning rate: 0.00011705532693187018, loss: 2.9871273040771484
batch i:439
learning rate: 0.00011705532693187018, loss: 3.041379451751709
batch i:440
learning rate: 0.00011705532693187018, loss: 3.02900767326355
batch i:441
learning rate: 0.00011705532693187018, loss: 3.135671615600586
batch i:442
learning rate: 0.00011705532693187018, loss: 3.179433822631836
batch i:443
learning rate: 0.00011705532693187018, loss: 3.1343064308166504
batch i:444
learning rate: 0.00011705532693187018, loss: 2.9925103187561035
batch i:445
learning rate: 0.00011705532693187018, loss: 3.037663221359253
batch i:446
learning rate: 0.00011705532693187018, loss: 3.0232272148132324
batch i:447
learning rate: 0.00011705532693187018, loss: 3.04685115814209
batch i:448
learning rate: 0.00011705532693187018, loss: 3.054109573364258
batch i:449
learning rate: 0.00011705532693187018, loss: 3.0956411361694336
batch i:450
learning rate: 0.00011705532693187018, loss: 3.0015439987182617
current self-play batch: 450
num_playouts:1000, win: 7, lose: 3, tie:0
average time: 143.09075055122375
batch i:451
learning rate: 0.00011705532693187018, loss: 3.012995958328247
batch i:452
learning rate: 0.00011705532693187018, loss: 3.023573875427246
batch i:453
learning rate: 0.00011705532693187018, loss: 3.138064384460449
batch i:454
learning rate: 0.00011705532693187018, loss: 3.037287473678589
batch i:455
learning rate: 0.00011705532693187018, loss: 3.015385866165161
batch i:456
learning rate: 0.00011705532693187018, loss: 2.9836249351501465
batch i:457
learning rate: 0.00011705532693187018, loss: 2.9815707206726074
batch i:458
learning rate: 0.00011705532693187018, loss: 2.996020793914795
batch i:459
learning rate: 0.00011705532693187018, loss: 3.02833890914917
batch i:460
learning rate: 0.00011705532693187018, loss: 3.0782604217529297
batch i:461
learning rate: 0.00011705532693187018, loss: 2.963974952697754
batch i:462
learning rate: 0.00011705532693187018, loss: 2.850404739379883
batch i:463
learning rate: 0.00011705532693187018, loss: 3.0948326587677
batch i:464
learning rate: 0.00011705532693187018, loss: 3.0339879989624023
batch i:465
learning rate: 0.00011705532693187018, loss: 2.9549307823181152
batch i:466
learning rate: 0.00011705532693187018, loss: 2.9996042251586914
batch i:467
learning rate: 0.00011705532693187018, loss: 3.149672031402588
batch i:468
learning rate: 0.00011705532693187018, loss: 3.133039712905884
batch i:469
learning rate: 0.00011705532693187018, loss: 3.133514881134033
batch i:470
learning rate: 0.00011705532693187018, loss: 3.0015296936035156
batch i:471
learning rate: 0.00011705532693187018, loss: 3.0755021572113037
batch i:472
learning rate: 0.00011705532693187018, loss: 2.9668760299682617
batch i:473
learning rate: 0.00011705532693187018, loss: 2.9358038902282715
batch i:474
learning rate: 0.00011705532693187018, loss: 3.084897756576538
batch i:475
learning rate: 0.00011705532693187018, loss: 3.000093936920166
batch i:476
learning rate: 0.00011705532693187018, loss: 3.0858840942382812
batch i:477
learning rate: 0.00011705532693187018, loss: 3.0357909202575684
batch i:478
learning rate: 0.00011705532693187018, loss: 2.9575536251068115
batch i:479
learning rate: 0.00011705532693187018, loss: 3.0688886642456055
batch i:480
learning rate: 0.00011705532693187018, loss: 3.0178792476654053
batch i:481
learning rate: 0.00011705532693187018, loss: 3.0994794368743896
batch i:482
learning rate: 0.00011705532693187018, loss: 3.0464630126953125
batch i:483
learning rate: 0.00011705532693187018, loss: 3.081925630569458
batch i:484
learning rate: 0.00011705532693187018, loss: 2.9971094131469727
batch i:485
learning rate: 0.00011705532693187018, loss: 3.1895151138305664
batch i:486
learning rate: 0.00011705532693187018, loss: 3.0769264698028564
batch i:487
learning rate: 0.00011705532693187018, loss: 3.0840353965759277
batch i:488
learning rate: 0.00011705532693187018, loss: 3.1170597076416016
batch i:489
learning rate: 0.00011705532693187018, loss: 3.135298728942871
batch i:490
learning rate: 0.00011705532693187018, loss: 3.071514368057251
batch i:491
learning rate: 0.00011705532693187018, loss: 3.2905657291412354
batch i:492
learning rate: 0.00011705532693187018, loss: 3.089770793914795
batch i:493
learning rate: 0.00011705532693187018, loss: 3.0964081287384033
batch i:494
learning rate: 0.00011705532693187018, loss: 3.106127977371216
batch i:495
learning rate: 0.00011705532693187018, loss: 2.997312068939209
batch i:496
learning rate: 0.00011705532693187018, loss: 3.1223981380462646
batch i:497
learning rate: 0.00011705532693187018, loss: 3.0817809104919434
batch i:498
learning rate: 0.00011705532693187018, loss: 3.0704379081726074
batch i:499
learning rate: 0.00011705532693187018, loss: 3.0790281295776367
batch i:500
learning rate: 0.00011705532693187018, loss: 3.0754334926605225
current self-play batch: 500
num_playouts:1000, win: 7, lose: 3, tie:0
average time: 161.6669179201126
batch i:501
learning rate: 0.00011705532693187018, loss: 3.0373926162719727
batch i:502
learning rate: 0.00011705532693187018, loss: 3.010471820831299
batch i:503
learning rate: 0.00011705532693187018, loss: 3.1137921810150146
batch i:504
learning rate: 0.00011705532693187018, loss: 3.0728869438171387
batch i:505
learning rate: 0.00011705532693187018, loss: 3.1540820598602295
batch i:506
learning rate: 0.00011705532693187018, loss: 3.131441593170166
batch i:507
learning rate: 0.00011705532693187018, loss: 3.127455949783325
batch i:508
learning rate: 0.00011705532693187018, loss: 3.062115430831909
batch i:509
learning rate: 0.00011705532693187018, loss: 3.192697286605835
batch i:510
learning rate: 0.00011705532693187018, loss: 3.0602569580078125
batch i:511
learning rate: 0.00011705532693187018, loss: 3.1654350757598877
batch i:512
learning rate: 0.00011705532693187018, loss: 3.1965408325195312
batch i:513
learning rate: 0.00011705532693187018, loss: 3.088376522064209
batch i:514
learning rate: 0.00011705532693187018, loss: 3.1226916313171387
batch i:515
learning rate: 0.00011705532693187018, loss: 3.2121434211730957
batch i:516
learning rate: 0.00011705532693187018, loss: 3.096937894821167
batch i:517
learning rate: 0.00011705532693187018, loss: 3.0449533462524414
batch i:518
learning rate: 0.00011705532693187018, loss: 3.051485300064087
batch i:519
learning rate: 0.00011705532693187018, loss: 3.071413516998291
batch i:520
learning rate: 0.00011705532693187018, loss: 3.1139707565307617
batch i:521
learning rate: 0.00011705532693187018, loss: 3.125035524368286
batch i:522
learning rate: 0.00011705532693187018, loss: 3.065659523010254
batch i:523
learning rate: 0.00011705532693187018, loss: 3.139132499694824
batch i:524
learning rate: 0.00011705532693187018, loss: 3.0814335346221924
batch i:525
learning rate: 0.00011705532693187018, loss: 3.08675479888916
batch i:526
learning rate: 0.00011705532693187018, loss: 3.1235599517822266
batch i:527
learning rate: 0.00011705532693187018, loss: 3.1247222423553467
batch i:528
learning rate: 0.00011705532693187018, loss: 3.0927767753601074
batch i:529
learning rate: 0.00011705532693187018, loss: 3.11007022857666
batch i:530
learning rate: 0.00011705532693187018, loss: 3.2076687812805176
batch i:531
learning rate: 0.00011705532693187018, loss: 3.2619686126708984
batch i:532
learning rate: 0.00011705532693187018, loss: 3.154581308364868
batch i:533
learning rate: 0.00011705532693187018, loss: 3.13456392288208
batch i:534
learning rate: 0.00011705532693187018, loss: 3.1056056022644043
batch i:535
learning rate: 0.00011705532693187018, loss: 3.0529279708862305
batch i:536
learning rate: 0.00011705532693187018, loss: 3.0830345153808594
batch i:537
learning rate: 0.00011705532693187018, loss: 3.0865163803100586
batch i:538
learning rate: 0.00011705532693187018, loss: 3.0517892837524414
batch i:539
learning rate: 0.00011705532693187018, loss: 3.0612473487854004
batch i:540
learning rate: 0.00011705532693187018, loss: 3.194727897644043
batch i:541
learning rate: 0.00011705532693187018, loss: 3.2297396659851074
batch i:542
learning rate: 0.00011705532693187018, loss: 3.1502909660339355
batch i:543
learning rate: 0.00011705532693187018, loss: 3.1207728385925293
batch i:544
learning rate: 0.00011705532693187018, loss: 3.1362743377685547
batch i:545
learning rate: 0.00011705532693187018, loss: 3.1902947425842285
batch i:546
learning rate: 0.00011705532693187018, loss: 3.1811599731445312
batch i:547
learning rate: 0.00011705532693187018, loss: 3.0114026069641113
batch i:548
learning rate: 0.00011705532693187018, loss: 3.0647428035736084
batch i:549
learning rate: 0.00011705532693187018, loss: 3.0092344284057617
batch i:550
learning rate: 0.00011705532693187018, loss: 3.1897127628326416
current self-play batch: 550
Traceback (most recent call last):
  File "/mnt/nas/home/huangyixin/AI/train.py", line 292, in <module>
    redirect_log_file(exp_name=exp_name, model_type=model_type)
  File "/mnt/nas/home/huangyixin/AI/train.py", line 259, in train
    self.net.save_model('current_policy')
  File "/mnt/nas/home/huangyixin/AI/game.py", line 243, in policy_evaluate
    winner = self.start_play(current_mcts_player,
  File "/mnt/nas/home/huangyixin/AI/game.py", line 183, in start_play
    move = player_in_turn.get_action(self.board)
  File "/mnt/nas/home/huangyixin/AI/mcts_alphaZero.py", line 201, in get_action
    moves, move_probs = self.mcts.get_move_and_probs(board, temp)
  File "/mnt/nas/home/huangyixin/AI/mcts_alphaZero.py", line 157, in get_move_and_probs
    self._playout(state_copy)
  File "/mnt/nas/home/huangyixin/AI/mcts_alphaZero.py", line 125, in _playout
    action_probs, leaf_value = self._policy(state)
  File "/mnt/nas/home/huangyixin/AI/model.py", line 300, in policy_value_fn
    act_probs = zip(legal_positions, act_probs[legal_positions])
IndexError: arrays used as indices must be of integer (or boolean) type
