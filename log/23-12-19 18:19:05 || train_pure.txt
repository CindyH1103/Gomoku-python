Start time: 2023-12-19 18:19:05.894174
batch i:1
batch i:2
batch i:3
batch i:4
batch i:5
batch i:6
batch i:7
learning rate: 0.0013333333333333333, loss: 3.291863441467285
batch i:8
learning rate: 0.0013333333333333333, loss: 2.824077606201172
batch i:9
learning rate: 0.0008888888888888888, loss: 2.8316798210144043
batch i:10
learning rate: 0.0008888888888888888, loss: 2.760148525238037
batch i:11
learning rate: 0.0008888888888888888, loss: 2.6588916778564453
batch i:12
learning rate: 0.0008888888888888888, loss: 2.6477267742156982
batch i:13
learning rate: 0.0008888888888888888, loss: 2.640350341796875
batch i:14
learning rate: 0.0013333333333333333, loss: 2.5117697715759277
batch i:15
learning rate: 0.0013333333333333333, loss: 2.489241600036621
batch i:16
learning rate: 0.0013333333333333333, loss: 2.4609873294830322
batch i:17
learning rate: 0.0013333333333333333, loss: 2.3614141941070557
batch i:18
learning rate: 0.0013333333333333333, loss: 2.3721137046813965
batch i:19
learning rate: 0.0013333333333333333, loss: 2.3006365299224854
batch i:20
learning rate: 0.0013333333333333333, loss: 2.2894716262817383
batch i:21
learning rate: 0.0013333333333333333, loss: 2.2929227352142334
batch i:22
learning rate: 0.0013333333333333333, loss: 2.2579574584960938
batch i:23
learning rate: 0.0013333333333333333, loss: 2.7778823375701904
batch i:24
learning rate: 0.0013333333333333333, loss: 2.7784934043884277
batch i:25
learning rate: 0.0013333333333333333, loss: 2.6953392028808594
batch i:26
learning rate: 0.0013333333333333333, loss: 2.5466363430023193
batch i:27
learning rate: 0.0013333333333333333, loss: 2.583980083465576
batch i:28
learning rate: 0.0013333333333333333, loss: 2.4134254455566406
batch i:29
learning rate: 0.0013333333333333333, loss: 2.728409767150879
batch i:30
learning rate: 0.0013333333333333333, loss: 2.780137062072754
batch i:31
learning rate: 0.0013333333333333333, loss: 2.8015947341918945
batch i:32
learning rate: 0.0013333333333333333, loss: 2.4975810050964355
batch i:33
learning rate: 0.0013333333333333333, loss: 2.823305368423462
batch i:34
learning rate: 0.0013333333333333333, loss: 2.6143696308135986
batch i:35
learning rate: 0.0013333333333333333, loss: 2.583587169647217
batch i:36
learning rate: 0.0013333333333333333, loss: 2.5508909225463867
batch i:37
learning rate: 0.0013333333333333333, loss: 2.521639347076416
batch i:38
learning rate: 0.0013333333333333333, loss: 2.541241407394409
batch i:39
learning rate: 0.0013333333333333333, loss: 2.508601665496826
batch i:40
learning rate: 0.0013333333333333333, loss: 2.3856709003448486
batch i:41
learning rate: 0.0013333333333333333, loss: 2.3821592330932617
batch i:42
learning rate: 0.0013333333333333333, loss: 2.5419459342956543
batch i:43
learning rate: 0.0013333333333333333, loss: 2.4042932987213135
batch i:44
learning rate: 0.0013333333333333333, loss: 2.3276638984680176
batch i:45
learning rate: 0.0013333333333333333, loss: 2.454826593399048
batch i:46
learning rate: 0.0013333333333333333, loss: 2.382436513900757
batch i:47
learning rate: 0.0013333333333333333, loss: 2.3926472663879395
batch i:48
learning rate: 0.0013333333333333333, loss: 2.3503637313842773
batch i:49
learning rate: 0.0013333333333333333, loss: 2.4296422004699707
batch i:50
learning rate: 0.0013333333333333333, loss: 2.4105780124664307
current self-play batch: 50
num_playouts:2000, win: 6, lose: 4, tie:0
average time: 408.61562497615813
New best policy from pure MCTS
batch i:51
learning rate: 0.0013333333333333333, loss: 2.4344162940979004
batch i:52
learning rate: 0.0013333333333333333, loss: 2.4587607383728027
batch i:53
learning rate: 0.0013333333333333333, loss: 2.5134737491607666
batch i:54
learning rate: 0.0013333333333333333, loss: 2.4398365020751953
batch i:55
learning rate: 0.0013333333333333333, loss: 2.4693591594696045
batch i:56
learning rate: 0.0013333333333333333, loss: 2.4834237098693848
batch i:57
learning rate: 0.0013333333333333333, loss: 2.5584306716918945
batch i:58
learning rate: 0.0013333333333333333, loss: 2.5167415142059326
batch i:59
learning rate: 0.0013333333333333333, loss: 2.5581302642822266
batch i:60
learning rate: 0.0013333333333333333, loss: 2.4404549598693848
batch i:61
learning rate: 0.0013333333333333333, loss: 2.4081733226776123
batch i:62
learning rate: 0.0013333333333333333, loss: 2.4315037727355957
batch i:63
learning rate: 0.0013333333333333333, loss: 2.457902431488037
batch i:64
learning rate: 0.0013333333333333333, loss: 2.4673023223876953
batch i:65
learning rate: 0.0013333333333333333, loss: 2.5005667209625244
batch i:66
learning rate: 0.0013333333333333333, loss: 2.5190486907958984
batch i:67
learning rate: 0.0013333333333333333, loss: 2.4946517944335938
batch i:68
learning rate: 0.0013333333333333333, loss: 2.6025538444519043
batch i:69
learning rate: 0.0013333333333333333, loss: 2.634730339050293
batch i:70
learning rate: 0.0013333333333333333, loss: 2.4086554050445557
batch i:71
learning rate: 0.0013333333333333333, loss: 2.492475748062134
batch i:72
learning rate: 0.0013333333333333333, loss: 2.479048013687134
batch i:73
learning rate: 0.0013333333333333333, loss: 2.5343918800354004
batch i:74
learning rate: 0.0013333333333333333, loss: 2.4236016273498535
batch i:75
learning rate: 0.0013333333333333333, loss: 2.513216972351074
batch i:76
learning rate: 0.0013333333333333333, loss: 2.4873733520507812
batch i:77
learning rate: 0.0013333333333333333, loss: 2.6637978553771973
batch i:78
learning rate: 0.0013333333333333333, loss: 2.4501187801361084
batch i:79
learning rate: 0.0013333333333333333, loss: 2.41849422454834
batch i:80
learning rate: 0.0013333333333333333, loss: 2.408115863800049
batch i:81
learning rate: 0.0013333333333333333, loss: 2.471738338470459
batch i:82
learning rate: 0.0013333333333333333, loss: 2.3610105514526367
batch i:83
learning rate: 0.0013333333333333333, loss: 2.368506908416748
batch i:84
learning rate: 0.0013333333333333333, loss: 2.400019645690918
batch i:85
learning rate: 0.0013333333333333333, loss: 2.5157103538513184
batch i:86
learning rate: 0.0013333333333333333, loss: 2.458752155303955
batch i:87
learning rate: 0.0013333333333333333, loss: 2.4066286087036133
batch i:88
learning rate: 0.0013333333333333333, loss: 2.407055139541626
batch i:89
learning rate: 0.0013333333333333333, loss: 2.4888758659362793
batch i:90
learning rate: 0.0013333333333333333, loss: 2.5818099975585938
batch i:91
learning rate: 0.0013333333333333333, loss: 2.4848275184631348
batch i:92
learning rate: 0.0013333333333333333, loss: 2.492215633392334
batch i:93
learning rate: 0.0013333333333333333, loss: 2.500196695327759
batch i:94
learning rate: 0.0013333333333333333, loss: 2.457846164703369
batch i:95
learning rate: 0.0013333333333333333, loss: 2.360553741455078
batch i:96
learning rate: 0.0013333333333333333, loss: 2.417117118835449
batch i:97
learning rate: 0.0013333333333333333, loss: 2.4134740829467773
batch i:98
learning rate: 0.0013333333333333333, loss: 2.433696985244751
batch i:99
learning rate: 0.0013333333333333333, loss: 2.393916606903076
batch i:100
learning rate: 0.0013333333333333333, loss: 2.320760726928711
current self-play batch: 100
num_playouts:2000, win: 6, lose: 4, tie:0
average time: 385.9004474639893
batch i:101
learning rate: 0.0013333333333333333, loss: 2.477653980255127
batch i:102
learning rate: 0.0013333333333333333, loss: 2.3426332473754883
batch i:103
learning rate: 0.0013333333333333333, loss: 2.5275654792785645
batch i:104
learning rate: 0.0013333333333333333, loss: 2.4810357093811035
batch i:105
learning rate: 0.0013333333333333333, loss: 2.4700043201446533
batch i:106
learning rate: 0.0013333333333333333, loss: 2.5159225463867188
batch i:107
learning rate: 0.0013333333333333333, loss: 2.575669527053833
batch i:108
learning rate: 0.0013333333333333333, loss: 2.539651393890381
batch i:109
learning rate: 0.0013333333333333333, loss: 2.537945032119751
batch i:110
learning rate: 0.0013333333333333333, loss: 2.4380640983581543
batch i:111
learning rate: 0.0013333333333333333, loss: 2.5024702548980713
batch i:112
learning rate: 0.0013333333333333333, loss: 2.505866050720215
batch i:113
learning rate: 0.0013333333333333333, loss: 2.5188419818878174
batch i:114
learning rate: 0.0013333333333333333, loss: 2.5241036415100098
batch i:115
learning rate: 0.0013333333333333333, loss: 2.5280895233154297
batch i:116
learning rate: 0.0013333333333333333, loss: 2.522639036178589
batch i:117
learning rate: 0.0013333333333333333, loss: 2.6205766201019287
batch i:118
learning rate: 0.0013333333333333333, loss: 2.505918502807617
batch i:119
learning rate: 0.0013333333333333333, loss: 2.574897289276123
batch i:120
learning rate: 0.0013333333333333333, loss: 2.4762325286865234
batch i:121
learning rate: 0.0013333333333333333, loss: 2.5230116844177246
batch i:122
learning rate: 0.0013333333333333333, loss: 2.499258518218994
batch i:123
learning rate: 0.0013333333333333333, loss: 2.4864537715911865
batch i:124
learning rate: 0.0013333333333333333, loss: 2.5517172813415527
batch i:125
learning rate: 0.0013333333333333333, loss: 2.395522117614746
batch i:126
learning rate: 0.0013333333333333333, loss: 2.488715648651123
batch i:127
learning rate: 0.0013333333333333333, loss: 2.5254909992218018
batch i:128
learning rate: 0.0013333333333333333, loss: 2.4444758892059326
batch i:129
learning rate: 0.0013333333333333333, loss: 2.4787135124206543
batch i:130
learning rate: 0.0013333333333333333, loss: 2.450270652770996
batch i:131
learning rate: 0.0013333333333333333, loss: 2.466052532196045
batch i:132
learning rate: 0.0013333333333333333, loss: 2.4750611782073975
batch i:133
learning rate: 0.0013333333333333333, loss: 2.426851272583008
batch i:134
learning rate: 0.0013333333333333333, loss: 2.49273681640625
batch i:135
learning rate: 0.0013333333333333333, loss: 2.5325067043304443
batch i:136
learning rate: 0.0013333333333333333, loss: 2.580369234085083
batch i:137
learning rate: 0.0013333333333333333, loss: 2.4458608627319336
batch i:138
learning rate: 0.0013333333333333333, loss: 2.5494027137756348
batch i:139
learning rate: 0.0013333333333333333, loss: 2.617455005645752
batch i:140
learning rate: 0.0013333333333333333, loss: 2.4961819648742676
batch i:141
learning rate: 0.0013333333333333333, loss: 2.579087257385254
batch i:142
learning rate: 0.0013333333333333333, loss: 2.488973379135132
batch i:143
learning rate: 0.0013333333333333333, loss: 2.5654990673065186
batch i:144
learning rate: 0.0013333333333333333, loss: 2.5047600269317627
batch i:145
learning rate: 0.0013333333333333333, loss: 2.558708667755127
batch i:146
learning rate: 0.0013333333333333333, loss: 2.3528475761413574
batch i:147
learning rate: 0.0013333333333333333, loss: 2.3922934532165527
batch i:148
learning rate: 0.0013333333333333333, loss: 2.5242061614990234
batch i:149
learning rate: 0.0013333333333333333, loss: 2.5673177242279053
batch i:150
learning rate: 0.0013333333333333333, loss: 2.5315990447998047
current self-play batch: 150
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 404.21167221069334
New best policy from pure MCTS
batch i:151
learning rate: 0.0013333333333333333, loss: 2.5544872283935547
batch i:152
learning rate: 0.0013333333333333333, loss: 2.499840259552002
batch i:153
learning rate: 0.0013333333333333333, loss: 2.5127038955688477
batch i:154
learning rate: 0.0013333333333333333, loss: 2.4948618412017822
batch i:155
learning rate: 0.0013333333333333333, loss: 2.4817094802856445
batch i:156
learning rate: 0.0013333333333333333, loss: 2.4610490798950195
batch i:157
learning rate: 0.0013333333333333333, loss: 2.4723854064941406
batch i:158
learning rate: 0.0013333333333333333, loss: 2.493396282196045
batch i:159
learning rate: 0.0013333333333333333, loss: 2.439784288406372
batch i:160
learning rate: 0.0013333333333333333, loss: 2.446737766265869
batch i:161
learning rate: 0.0013333333333333333, loss: 2.496497869491577
batch i:162
learning rate: 0.0013333333333333333, loss: 2.557950019836426
batch i:163
learning rate: 0.0013333333333333333, loss: 2.4952192306518555
batch i:164
learning rate: 0.0013333333333333333, loss: 2.6420085430145264
batch i:165
learning rate: 0.0013333333333333333, loss: 2.637714385986328
batch i:166
learning rate: 0.0013333333333333333, loss: 2.5644493103027344
batch i:167
learning rate: 0.0013333333333333333, loss: 2.594738721847534
batch i:168
learning rate: 0.0013333333333333333, loss: 2.6536471843719482
batch i:169
learning rate: 0.0013333333333333333, loss: 2.6513447761535645
batch i:170
learning rate: 0.0013333333333333333, loss: 2.53047513961792
batch i:171
learning rate: 0.0013333333333333333, loss: 2.611488103866577
batch i:172
learning rate: 0.0013333333333333333, loss: 2.5894527435302734
batch i:173
learning rate: 0.0013333333333333333, loss: 2.578584671020508
batch i:174
learning rate: 0.0013333333333333333, loss: 2.6304898262023926
batch i:175
learning rate: 0.0013333333333333333, loss: 2.501399040222168
batch i:176
learning rate: 0.0013333333333333333, loss: 2.486453056335449
batch i:177
learning rate: 0.0013333333333333333, loss: 2.575901746749878
batch i:178
learning rate: 0.0013333333333333333, loss: 2.551335334777832
batch i:179
learning rate: 0.0013333333333333333, loss: 2.5370023250579834
batch i:180
learning rate: 0.0013333333333333333, loss: 2.4922127723693848
batch i:181
learning rate: 0.0013333333333333333, loss: 2.5226995944976807
batch i:182
learning rate: 0.0013333333333333333, loss: 2.4461522102355957
batch i:183
learning rate: 0.0013333333333333333, loss: 2.5564088821411133
batch i:184
learning rate: 0.0013333333333333333, loss: 2.511212110519409
batch i:185
learning rate: 0.0013333333333333333, loss: 2.5400147438049316
batch i:186
learning rate: 0.0013333333333333333, loss: 2.4222631454467773
batch i:187
learning rate: 0.0013333333333333333, loss: 2.595912456512451
batch i:188
learning rate: 0.0013333333333333333, loss: 2.5084033012390137
batch i:189
learning rate: 0.0013333333333333333, loss: 2.594403028488159
batch i:190
learning rate: 0.0013333333333333333, loss: 2.5526347160339355
batch i:191
learning rate: 0.0013333333333333333, loss: 2.5107383728027344
batch i:192
learning rate: 0.0013333333333333333, loss: 2.4749131202697754
batch i:193
learning rate: 0.0013333333333333333, loss: 2.5025293827056885
batch i:194
learning rate: 0.0013333333333333333, loss: 2.492933750152588
batch i:195
learning rate: 0.0013333333333333333, loss: 2.58807373046875
batch i:196
learning rate: 0.0013333333333333333, loss: 2.4800896644592285
batch i:197
learning rate: 0.0013333333333333333, loss: 2.445462703704834
batch i:198
learning rate: 0.0013333333333333333, loss: 2.472553253173828
batch i:199
learning rate: 0.0013333333333333333, loss: 2.463533401489258
batch i:200
learning rate: 0.0013333333333333333, loss: 2.510439872741699
current self-play batch: 200
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 376.9815997838974
batch i:201
learning rate: 0.0013333333333333333, loss: 2.4845938682556152
batch i:202
learning rate: 0.0013333333333333333, loss: 2.514984607696533
batch i:203
learning rate: 0.0013333333333333333, loss: 2.495476722717285
batch i:204
learning rate: 0.0013333333333333333, loss: 2.471313238143921
batch i:205
learning rate: 0.0013333333333333333, loss: 2.478944778442383
batch i:206
learning rate: 0.0013333333333333333, loss: 2.421234607696533
batch i:207
learning rate: 0.0013333333333333333, loss: 2.5109262466430664
batch i:208
learning rate: 0.0013333333333333333, loss: 2.5830843448638916
batch i:209
learning rate: 0.0013333333333333333, loss: 2.5749640464782715
batch i:210
learning rate: 0.0013333333333333333, loss: 2.5691452026367188
batch i:211
learning rate: 0.0013333333333333333, loss: 2.4427223205566406
batch i:212
learning rate: 0.0013333333333333333, loss: 2.457056999206543
batch i:213
learning rate: 0.0013333333333333333, loss: 2.563187599182129
batch i:214
learning rate: 0.0013333333333333333, loss: 2.528116464614868
batch i:215
learning rate: 0.0013333333333333333, loss: 2.5038671493530273
batch i:216
learning rate: 0.0013333333333333333, loss: 2.596728801727295
batch i:217
learning rate: 0.0013333333333333333, loss: 2.569307327270508
batch i:218
learning rate: 0.0013333333333333333, loss: 2.6200549602508545
batch i:219
learning rate: 0.0013333333333333333, loss: 2.5175342559814453
batch i:220
learning rate: 0.0013333333333333333, loss: 2.6143288612365723
batch i:221
learning rate: 0.0013333333333333333, loss: 2.5470242500305176
batch i:222
learning rate: 0.0013333333333333333, loss: 2.5822911262512207
batch i:223
learning rate: 0.0013333333333333333, loss: 2.5647783279418945
batch i:224
learning rate: 0.0013333333333333333, loss: 2.482339382171631
batch i:225
learning rate: 0.0013333333333333333, loss: 2.514254093170166
batch i:226
learning rate: 0.0013333333333333333, loss: 2.5118227005004883
batch i:227
learning rate: 0.0013333333333333333, loss: 2.420353412628174
batch i:228
learning rate: 0.0013333333333333333, loss: 2.55612850189209
batch i:229
learning rate: 0.0013333333333333333, loss: 2.5507240295410156
batch i:230
learning rate: 0.0013333333333333333, loss: 2.6156182289123535
batch i:231
learning rate: 0.0013333333333333333, loss: 2.5002024173736572
batch i:232
learning rate: 0.0013333333333333333, loss: 2.5257487297058105
batch i:233
learning rate: 0.0013333333333333333, loss: 2.6031594276428223
batch i:234
learning rate: 0.0013333333333333333, loss: 2.5825858116149902
batch i:235
learning rate: 0.0013333333333333333, loss: 2.5765719413757324
batch i:236
learning rate: 0.0013333333333333333, loss: 2.582305431365967
batch i:237
learning rate: 0.0013333333333333333, loss: 2.670410394668579
batch i:238
learning rate: 0.0013333333333333333, loss: 2.7150979042053223
batch i:239
learning rate: 0.0013333333333333333, loss: 2.6270434856414795
batch i:240
learning rate: 0.0013333333333333333, loss: 2.7958850860595703
batch i:241
learning rate: 0.0013333333333333333, loss: 2.7491135597229004
batch i:242
learning rate: 0.0013333333333333333, loss: 2.6552183628082275
batch i:243
learning rate: 0.0013333333333333333, loss: 2.724423408508301
batch i:244
learning rate: 0.0013333333333333333, loss: 2.739584445953369
batch i:245
learning rate: 0.0013333333333333333, loss: 2.690152406692505
batch i:246
learning rate: 0.0013333333333333333, loss: 2.786198616027832
batch i:247
learning rate: 0.0013333333333333333, loss: 2.8110363483428955
batch i:248
learning rate: 0.0013333333333333333, loss: 2.7446041107177734
batch i:249
learning rate: 0.0013333333333333333, loss: 2.770371437072754
batch i:250
learning rate: 0.0013333333333333333, loss: 2.7959885597229004
current self-play batch: 250
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 422.0589785814285
batch i:251
learning rate: 0.0013333333333333333, loss: 2.7616865634918213
batch i:252
learning rate: 0.0013333333333333333, loss: 2.6664137840270996
batch i:253
learning rate: 0.0013333333333333333, loss: 2.759465217590332
batch i:254
learning rate: 0.0013333333333333333, loss: 2.7256054878234863
batch i:255
learning rate: 0.0013333333333333333, loss: 2.7160704135894775
batch i:256
learning rate: 0.0013333333333333333, loss: 2.6453564167022705
batch i:257
learning rate: 0.0013333333333333333, loss: 2.796975612640381
batch i:258
learning rate: 0.0013333333333333333, loss: 2.737220048904419
batch i:259
learning rate: 0.0013333333333333333, loss: 2.7469687461853027
batch i:260
learning rate: 0.0013333333333333333, loss: 2.7136917114257812
batch i:261
learning rate: 0.0013333333333333333, loss: 2.725691795349121
batch i:262
learning rate: 0.0013333333333333333, loss: 2.7750399112701416
batch i:263
learning rate: 0.0013333333333333333, loss: 2.78535795211792
batch i:264
learning rate: 0.0013333333333333333, loss: 2.712527275085449
batch i:265
learning rate: 0.0013333333333333333, loss: 2.7106292247772217
batch i:266
learning rate: 0.0013333333333333333, loss: 2.6572299003601074
batch i:267
learning rate: 0.0013333333333333333, loss: 2.769026041030884
batch i:268
learning rate: 0.0013333333333333333, loss: 2.81600022315979
batch i:269
learning rate: 0.0013333333333333333, loss: 2.7650246620178223
batch i:270
learning rate: 0.0013333333333333333, loss: 2.831925868988037
batch i:271
learning rate: 0.0013333333333333333, loss: 2.7846453189849854
batch i:272
learning rate: 0.0013333333333333333, loss: 2.6657776832580566
batch i:273
learning rate: 0.0013333333333333333, loss: 2.701786994934082
batch i:274
learning rate: 0.0013333333333333333, loss: 2.8228821754455566
batch i:275
learning rate: 0.0013333333333333333, loss: 2.6153979301452637
batch i:276
learning rate: 0.0013333333333333333, loss: 2.739588499069214
batch i:277
learning rate: 0.0013333333333333333, loss: 2.7125768661499023
batch i:278
learning rate: 0.0013333333333333333, loss: 2.8232719898223877
batch i:279
learning rate: 0.0013333333333333333, loss: 2.8716955184936523
batch i:280
learning rate: 0.0013333333333333333, loss: 2.804060459136963
batch i:281
learning rate: 0.0013333333333333333, loss: 2.839325428009033
batch i:282
learning rate: 0.0013333333333333333, loss: 2.7550716400146484
batch i:283
learning rate: 0.0013333333333333333, loss: 2.789045572280884
batch i:284
learning rate: 0.0013333333333333333, loss: 2.714540481567383
batch i:285
learning rate: 0.0013333333333333333, loss: 2.8982300758361816
batch i:286
learning rate: 0.0013333333333333333, loss: 2.7416880130767822
batch i:287
learning rate: 0.0013333333333333333, loss: 2.8398141860961914
batch i:288
learning rate: 0.0013333333333333333, loss: 2.808082342147827
batch i:289
learning rate: 0.0013333333333333333, loss: 2.791264533996582
batch i:290
learning rate: 0.0013333333333333333, loss: 2.8041858673095703
batch i:291
learning rate: 0.0013333333333333333, loss: 2.823971748352051
batch i:292
learning rate: 0.0013333333333333333, loss: 2.745600938796997
batch i:293
learning rate: 0.0013333333333333333, loss: 2.873243808746338
batch i:294
learning rate: 0.0013333333333333333, loss: 2.9871394634246826
batch i:295
learning rate: 0.0013333333333333333, loss: 2.822277545928955
batch i:296
learning rate: 0.0013333333333333333, loss: 2.7860260009765625
batch i:297
learning rate: 0.0013333333333333333, loss: 2.7327442169189453
batch i:298
learning rate: 0.0013333333333333333, loss: 2.823709011077881
batch i:299
learning rate: 0.0013333333333333333, loss: 2.7101125717163086
batch i:300
learning rate: 0.0013333333333333333, loss: 2.807563304901123
current self-play batch: 300
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 282.23031120300294
batch i:301
learning rate: 0.0013333333333333333, loss: 2.882047653198242
batch i:302
learning rate: 0.0013333333333333333, loss: 2.7034072875976562
batch i:303
learning rate: 0.0013333333333333333, loss: 2.6977410316467285
batch i:304
learning rate: 0.0013333333333333333, loss: 2.9315171241760254
batch i:305
learning rate: 0.0013333333333333333, loss: 2.7867369651794434
batch i:306
learning rate: 0.0013333333333333333, loss: 2.919078826904297
batch i:307
learning rate: 0.0013333333333333333, loss: 2.819207191467285
batch i:308
learning rate: 0.0013333333333333333, loss: 2.7794675827026367
batch i:309
learning rate: 0.0013333333333333333, loss: 2.778477668762207
batch i:310
learning rate: 0.0013333333333333333, loss: 2.8660712242126465
batch i:311
learning rate: 0.0013333333333333333, loss: 2.8717243671417236
batch i:312
learning rate: 0.0013333333333333333, loss: 2.8361093997955322
batch i:313
learning rate: 0.0013333333333333333, loss: 2.9334068298339844
batch i:314
learning rate: 0.0013333333333333333, loss: 2.947340488433838
batch i:315
learning rate: 0.0013333333333333333, loss: 2.9483563899993896
batch i:316
learning rate: 0.0013333333333333333, loss: 2.904484272003174
batch i:317
learning rate: 0.0013333333333333333, loss: 2.8945727348327637
batch i:318
learning rate: 0.0013333333333333333, loss: 2.813401222229004
batch i:319
learning rate: 0.0013333333333333333, loss: 2.8637924194335938
batch i:320
learning rate: 0.0013333333333333333, loss: 2.8734850883483887
batch i:321
learning rate: 0.0013333333333333333, loss: 2.891956329345703
batch i:322
learning rate: 0.0013333333333333333, loss: 2.835963249206543
batch i:323
learning rate: 0.0013333333333333333, loss: 2.7924516201019287
batch i:324
learning rate: 0.0013333333333333333, loss: 2.857278347015381
batch i:325
learning rate: 0.0013333333333333333, loss: 2.853449821472168
batch i:326
learning rate: 0.0013333333333333333, loss: 2.835452079772949
batch i:327
learning rate: 0.0013333333333333333, loss: 2.833102226257324
batch i:328
learning rate: 0.0013333333333333333, loss: 2.7176461219787598
batch i:329
learning rate: 0.0013333333333333333, loss: 2.8019094467163086
batch i:330
learning rate: 0.0013333333333333333, loss: 2.8386662006378174
batch i:331
learning rate: 0.0013333333333333333, loss: 2.837198257446289
batch i:332
learning rate: 0.0013333333333333333, loss: 2.8069262504577637
batch i:333
learning rate: 0.0013333333333333333, loss: 2.706836700439453
batch i:334
learning rate: 0.0013333333333333333, loss: 2.8415825366973877
batch i:335
learning rate: 0.0013333333333333333, loss: 2.7222914695739746
batch i:336
learning rate: 0.0013333333333333333, loss: 2.772830009460449
batch i:337
learning rate: 0.0013333333333333333, loss: 2.6794304847717285
batch i:338
learning rate: 0.0013333333333333333, loss: 2.704164743423462
batch i:339
learning rate: 0.0013333333333333333, loss: 2.738896608352661
batch i:340
learning rate: 0.0013333333333333333, loss: 2.846876621246338
batch i:341
learning rate: 0.0013333333333333333, loss: 2.86368465423584
batch i:342
learning rate: 0.0013333333333333333, loss: 2.8002030849456787
batch i:343
learning rate: 0.0013333333333333333, loss: 2.8459599018096924
batch i:344
learning rate: 0.0013333333333333333, loss: 2.7945141792297363
batch i:345
learning rate: 0.0013333333333333333, loss: 2.7542073726654053
batch i:346
learning rate: 0.0013333333333333333, loss: 2.86027455329895
batch i:347
learning rate: 0.0013333333333333333, loss: 2.7882535457611084
batch i:348
learning rate: 0.0013333333333333333, loss: 2.730910301208496
batch i:349
learning rate: 0.0013333333333333333, loss: 2.7406418323516846
batch i:350
learning rate: 0.0013333333333333333, loss: 2.8517813682556152
current self-play batch: 350
num_playouts:2000, win: 6, lose: 4, tie:0
average time: 275.05164909362793
batch i:351
learning rate: 0.0013333333333333333, loss: 2.776686906814575
batch i:352
learning rate: 0.0013333333333333333, loss: 2.828051805496216
batch i:353
learning rate: 0.0013333333333333333, loss: 2.7954211235046387
batch i:354
learning rate: 0.0013333333333333333, loss: 2.7888872623443604
batch i:355
learning rate: 0.0013333333333333333, loss: 2.8643009662628174
batch i:356
learning rate: 0.0013333333333333333, loss: 2.7413389682769775
batch i:357
learning rate: 0.0013333333333333333, loss: 2.8017160892486572
batch i:358
learning rate: 0.0013333333333333333, loss: 2.7770841121673584
batch i:359
learning rate: 0.0013333333333333333, loss: 2.8384342193603516
batch i:360
learning rate: 0.0013333333333333333, loss: 2.782501697540283
batch i:361
learning rate: 0.0013333333333333333, loss: 2.7480647563934326
batch i:362
learning rate: 0.0013333333333333333, loss: 2.85345458984375
batch i:363
learning rate: 0.0013333333333333333, loss: 2.8204784393310547
batch i:364
learning rate: 0.0013333333333333333, loss: 2.79976749420166
batch i:365
learning rate: 0.0013333333333333333, loss: 2.7486138343811035
batch i:366
learning rate: 0.0013333333333333333, loss: 2.71787428855896
batch i:367
learning rate: 0.0013333333333333333, loss: 2.8114702701568604
batch i:368
learning rate: 0.0013333333333333333, loss: 2.7459864616394043
batch i:369
learning rate: 0.0013333333333333333, loss: 2.751946210861206
batch i:370
learning rate: 0.0013333333333333333, loss: 2.736626148223877
batch i:371
learning rate: 0.0013333333333333333, loss: 2.7408738136291504
batch i:372
learning rate: 0.0013333333333333333, loss: 2.648247241973877
batch i:373
learning rate: 0.0013333333333333333, loss: 2.799173355102539
batch i:374
learning rate: 0.0013333333333333333, loss: 2.762803077697754
batch i:375
learning rate: 0.0013333333333333333, loss: 2.7662816047668457
batch i:376
learning rate: 0.0013333333333333333, loss: 2.6479883193969727
batch i:377
learning rate: 0.0013333333333333333, loss: 2.7579290866851807
batch i:378
learning rate: 0.0013333333333333333, loss: 2.841726779937744
batch i:379
learning rate: 0.0013333333333333333, loss: 2.849759817123413
batch i:380
learning rate: 0.0013333333333333333, loss: 2.788658857345581
batch i:381
learning rate: 0.0013333333333333333, loss: 2.723236560821533
batch i:382
learning rate: 0.0013333333333333333, loss: 2.663862705230713
batch i:383
learning rate: 0.0013333333333333333, loss: 2.7827272415161133
batch i:384
learning rate: 0.0013333333333333333, loss: 2.7391276359558105
batch i:385
learning rate: 0.0013333333333333333, loss: 2.774378538131714
batch i:386
learning rate: 0.0013333333333333333, loss: 2.834908962249756
batch i:387
learning rate: 0.0013333333333333333, loss: 2.796566963195801
batch i:388
learning rate: 0.0013333333333333333, loss: 2.8105244636535645
batch i:389
learning rate: 0.0013333333333333333, loss: 2.8397953510284424
batch i:390
learning rate: 0.0013333333333333333, loss: 2.7846784591674805
batch i:391
learning rate: 0.0013333333333333333, loss: 2.71463942527771
batch i:392
learning rate: 0.0013333333333333333, loss: 2.7837839126586914
batch i:393
learning rate: 0.0013333333333333333, loss: 2.748805284500122
batch i:394
learning rate: 0.0013333333333333333, loss: 2.8129563331604004
batch i:395
learning rate: 0.0013333333333333333, loss: 2.8784475326538086
batch i:396
learning rate: 0.0013333333333333333, loss: 2.837153434753418
batch i:397
learning rate: 0.0013333333333333333, loss: 2.8659276962280273
batch i:398
learning rate: 0.0013333333333333333, loss: 2.819446086883545
batch i:399
learning rate: 0.0013333333333333333, loss: 2.803046703338623
batch i:400
learning rate: 0.0013333333333333333, loss: 2.8250036239624023
current self-play batch: 400
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 308.7448604106903
batch i:401
learning rate: 0.0013333333333333333, loss: 2.84127140045166
batch i:402
learning rate: 0.0013333333333333333, loss: 2.8939130306243896
batch i:403
learning rate: 0.0013333333333333333, loss: 2.8659281730651855
batch i:404
learning rate: 0.0013333333333333333, loss: 2.7382497787475586
batch i:405
learning rate: 0.0013333333333333333, loss: 2.762436866760254
batch i:406
learning rate: 0.0013333333333333333, loss: 2.837576389312744
batch i:407
learning rate: 0.0013333333333333333, loss: 2.7908835411071777
batch i:408
learning rate: 0.0013333333333333333, loss: 2.7962803840637207
batch i:409
learning rate: 0.0013333333333333333, loss: 2.784992218017578
batch i:410
learning rate: 0.0013333333333333333, loss: 2.666597843170166
batch i:411
learning rate: 0.0013333333333333333, loss: 2.7344233989715576
batch i:412
learning rate: 0.0013333333333333333, loss: 2.698699712753296
batch i:413
learning rate: 0.0013333333333333333, loss: 2.723557472229004
batch i:414
learning rate: 0.0013333333333333333, loss: 2.714313268661499
batch i:415
learning rate: 0.0013333333333333333, loss: 2.7325754165649414
batch i:416
learning rate: 0.0013333333333333333, loss: 2.7322280406951904
batch i:417
learning rate: 0.0013333333333333333, loss: 2.7240681648254395
batch i:418
learning rate: 0.0013333333333333333, loss: 2.7409486770629883
batch i:419
learning rate: 0.0013333333333333333, loss: 2.718357801437378
batch i:420
learning rate: 0.0013333333333333333, loss: 2.7389988899230957
batch i:421
learning rate: 0.0013333333333333333, loss: 2.7828609943389893
batch i:422
learning rate: 0.0013333333333333333, loss: 2.8064205646514893
batch i:423
learning rate: 0.0013333333333333333, loss: 2.725538730621338
batch i:424
learning rate: 0.0013333333333333333, loss: 2.6550698280334473
batch i:425
learning rate: 0.0013333333333333333, loss: 2.669003486633301
batch i:426
learning rate: 0.0013333333333333333, loss: 2.7096173763275146
batch i:427
learning rate: 0.0013333333333333333, loss: 2.773772716522217
batch i:428
learning rate: 0.0013333333333333333, loss: 2.740004539489746
batch i:429
learning rate: 0.0013333333333333333, loss: 2.689685344696045
batch i:430
learning rate: 0.0013333333333333333, loss: 2.8342950344085693
batch i:431
learning rate: 0.0013333333333333333, loss: 2.703155279159546
batch i:432
learning rate: 0.0013333333333333333, loss: 2.6861751079559326
batch i:433
learning rate: 0.0013333333333333333, loss: 2.7802367210388184
batch i:434
learning rate: 0.0013333333333333333, loss: 2.7816381454467773
batch i:435
learning rate: 0.0013333333333333333, loss: 2.712367296218872
batch i:436
learning rate: 0.0013333333333333333, loss: 2.805379867553711
batch i:437
learning rate: 0.0013333333333333333, loss: 2.770291328430176
batch i:438
learning rate: 0.0013333333333333333, loss: 2.79504656791687
batch i:439
learning rate: 0.0013333333333333333, loss: 2.74155592918396
batch i:440
learning rate: 0.0013333333333333333, loss: 2.6771509647369385
batch i:441
learning rate: 0.0013333333333333333, loss: 2.7944233417510986
batch i:442
learning rate: 0.0013333333333333333, loss: 2.7810535430908203
batch i:443
learning rate: 0.0013333333333333333, loss: 2.7615177631378174
batch i:444
learning rate: 0.0013333333333333333, loss: 2.6422345638275146
batch i:445
learning rate: 0.0013333333333333333, loss: 2.65807843208313
batch i:446
learning rate: 0.0013333333333333333, loss: 2.7463583946228027
batch i:447
learning rate: 0.0013333333333333333, loss: 2.6128015518188477
batch i:448
learning rate: 0.0013333333333333333, loss: 2.5260958671569824
batch i:449
learning rate: 0.0013333333333333333, loss: 2.7248427867889404
batch i:450
learning rate: 0.0013333333333333333, loss: 2.614114284515381
current self-play batch: 450
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 357.54171857833865
batch i:451
learning rate: 0.0013333333333333333, loss: 2.6028828620910645
batch i:452
learning rate: 0.0013333333333333333, loss: 2.665329933166504
batch i:453
learning rate: 0.0013333333333333333, loss: 2.716063976287842
batch i:454
learning rate: 0.0013333333333333333, loss: 2.6376712322235107
batch i:455
learning rate: 0.0013333333333333333, loss: 2.671609401702881
batch i:456
learning rate: 0.0013333333333333333, loss: 2.698694944381714
batch i:457
learning rate: 0.0013333333333333333, loss: 2.666985034942627
batch i:458
learning rate: 0.0013333333333333333, loss: 2.6744000911712646
batch i:459
learning rate: 0.0013333333333333333, loss: 2.6529343128204346
batch i:460
learning rate: 0.0013333333333333333, loss: 2.6812376976013184
batch i:461
learning rate: 0.0013333333333333333, loss: 2.6485941410064697
batch i:462
learning rate: 0.0013333333333333333, loss: 2.626706838607788
batch i:463
learning rate: 0.0013333333333333333, loss: 2.6524789333343506
batch i:464
learning rate: 0.0013333333333333333, loss: 2.6536970138549805
batch i:465
learning rate: 0.0013333333333333333, loss: 2.5986313819885254
batch i:466
learning rate: 0.0013333333333333333, loss: 2.605231285095215
batch i:467
learning rate: 0.0013333333333333333, loss: 2.756309986114502
batch i:468
learning rate: 0.0013333333333333333, loss: 2.6872172355651855
batch i:469
learning rate: 0.0013333333333333333, loss: 2.704629898071289
batch i:470
learning rate: 0.0013333333333333333, loss: 2.6838455200195312
batch i:471
learning rate: 0.0013333333333333333, loss: 2.6674113273620605
batch i:472
learning rate: 0.0013333333333333333, loss: 2.6801395416259766
batch i:473
learning rate: 0.0013333333333333333, loss: 2.692265510559082
batch i:474
learning rate: 0.0013333333333333333, loss: 2.678316593170166
batch i:475
learning rate: 0.0013333333333333333, loss: 2.7701735496520996
batch i:476
learning rate: 0.0013333333333333333, loss: 2.7757151126861572
batch i:477
learning rate: 0.0013333333333333333, loss: 2.779811382293701
batch i:478
learning rate: 0.0013333333333333333, loss: 2.6678545475006104
batch i:479
learning rate: 0.0013333333333333333, loss: 2.7331736087799072
batch i:480
learning rate: 0.0013333333333333333, loss: 2.734862804412842
batch i:481
learning rate: 0.0013333333333333333, loss: 2.832806348800659
batch i:482
learning rate: 0.0013333333333333333, loss: 2.7757668495178223
batch i:483
learning rate: 0.0013333333333333333, loss: 2.702342987060547
batch i:484
learning rate: 0.0013333333333333333, loss: 2.8044400215148926
batch i:485
learning rate: 0.0013333333333333333, loss: 2.744968891143799
batch i:486
learning rate: 0.0013333333333333333, loss: 2.755270004272461
batch i:487
learning rate: 0.0013333333333333333, loss: 2.613919734954834
batch i:488
learning rate: 0.0013333333333333333, loss: 2.668438673019409
batch i:489
learning rate: 0.0013333333333333333, loss: 2.6581315994262695
batch i:490
learning rate: 0.0013333333333333333, loss: 2.715117931365967
batch i:491
learning rate: 0.0013333333333333333, loss: 2.7029619216918945
batch i:492
learning rate: 0.0013333333333333333, loss: 2.6512463092803955
batch i:493
learning rate: 0.0013333333333333333, loss: 2.7093238830566406
batch i:494
learning rate: 0.0013333333333333333, loss: 2.664043426513672
batch i:495
learning rate: 0.0013333333333333333, loss: 2.6369266510009766
batch i:496
learning rate: 0.0013333333333333333, loss: 2.602647542953491
batch i:497
learning rate: 0.0013333333333333333, loss: 2.731428384780884
batch i:498
learning rate: 0.0013333333333333333, loss: 2.617312431335449
batch i:499
learning rate: 0.0013333333333333333, loss: 2.5414812564849854
batch i:500
learning rate: 0.0013333333333333333, loss: 2.532186985015869
current self-play batch: 500
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 366.216148853302
batch i:501
learning rate: 0.0013333333333333333, loss: 2.573378562927246
batch i:502
learning rate: 0.0013333333333333333, loss: 2.582080602645874
batch i:503
learning rate: 0.0013333333333333333, loss: 2.566349506378174
batch i:504
learning rate: 0.0013333333333333333, loss: 2.5738983154296875
batch i:505
learning rate: 0.0013333333333333333, loss: 2.5401864051818848
batch i:506
learning rate: 0.0013333333333333333, loss: 2.6553244590759277
batch i:507
learning rate: 0.0013333333333333333, loss: 2.650467872619629
batch i:508
learning rate: 0.0013333333333333333, loss: 2.7085814476013184
batch i:509
learning rate: 0.0013333333333333333, loss: 2.6133358478546143
batch i:510
learning rate: 0.0013333333333333333, loss: 2.6017298698425293
batch i:511
learning rate: 0.0013333333333333333, loss: 2.6825661659240723
batch i:512
learning rate: 0.0013333333333333333, loss: 2.663065195083618
batch i:513
learning rate: 0.0013333333333333333, loss: 2.659444808959961
batch i:514
learning rate: 0.0013333333333333333, loss: 2.6123454570770264
batch i:515
learning rate: 0.0013333333333333333, loss: 2.7514874935150146
batch i:516
learning rate: 0.0013333333333333333, loss: 2.578634262084961
batch i:517
learning rate: 0.0013333333333333333, loss: 2.630923271179199
batch i:518
learning rate: 0.0013333333333333333, loss: 2.522602081298828
batch i:519
learning rate: 0.0013333333333333333, loss: 2.5941948890686035
batch i:520
learning rate: 0.0013333333333333333, loss: 2.661986827850342
batch i:521
learning rate: 0.0013333333333333333, loss: 2.6572725772857666
batch i:522
learning rate: 0.0013333333333333333, loss: 2.785830020904541
batch i:523
learning rate: 0.0013333333333333333, loss: 2.7389769554138184
batch i:524
learning rate: 0.0013333333333333333, loss: 2.67830753326416
batch i:525
learning rate: 0.0013333333333333333, loss: 2.714871883392334
batch i:526
learning rate: 0.0013333333333333333, loss: 2.7603182792663574
batch i:527
learning rate: 0.0013333333333333333, loss: 2.6912472248077393
batch i:528
learning rate: 0.0013333333333333333, loss: 2.6337075233459473
batch i:529
learning rate: 0.0013333333333333333, loss: 2.6597208976745605
batch i:530
learning rate: 0.0013333333333333333, loss: 2.692422389984131
batch i:531
learning rate: 0.0013333333333333333, loss: 2.6504364013671875
batch i:532
learning rate: 0.0013333333333333333, loss: 2.6860976219177246
batch i:533
learning rate: 0.0013333333333333333, loss: 2.7150182723999023
batch i:534
learning rate: 0.0013333333333333333, loss: 2.6893510818481445
batch i:535
learning rate: 0.0013333333333333333, loss: 2.7401790618896484
batch i:536
learning rate: 0.0013333333333333333, loss: 2.7292518615722656
batch i:537
learning rate: 0.0013333333333333333, loss: 2.6286349296569824
batch i:538
learning rate: 0.0013333333333333333, loss: 2.8066024780273438
batch i:539
learning rate: 0.0013333333333333333, loss: 2.738071918487549
batch i:540
learning rate: 0.0013333333333333333, loss: 2.702789783477783
batch i:541
learning rate: 0.0013333333333333333, loss: 2.7913975715637207
batch i:542
learning rate: 0.0013333333333333333, loss: 2.802705764770508
batch i:543
learning rate: 0.0013333333333333333, loss: 2.7750580310821533
batch i:544
learning rate: 0.0013333333333333333, loss: 2.6795554161071777
batch i:545
learning rate: 0.0013333333333333333, loss: 2.8290605545043945
batch i:546
learning rate: 0.0013333333333333333, loss: 2.7548162937164307
batch i:547
learning rate: 0.0013333333333333333, loss: 2.76442289352417
batch i:548
learning rate: 0.0013333333333333333, loss: 2.845353603363037
batch i:549
learning rate: 0.0013333333333333333, loss: 2.8918046951293945
batch i:550
learning rate: 0.0013333333333333333, loss: 2.900559902191162
current self-play batch: 550
num_playouts:2000, win: 5, lose: 5, tie:0
average time: 637.2308354139328
batch i:551
learning rate: 0.0013333333333333333, loss: 2.9634337425231934
batch i:552
learning rate: 0.0013333333333333333, loss: 2.8559908866882324
batch i:553
learning rate: 0.0013333333333333333, loss: 2.7503581047058105
batch i:554
learning rate: 0.0013333333333333333, loss: 2.8220248222351074
batch i:555
learning rate: 0.0013333333333333333, loss: 2.7674520015716553
batch i:556
learning rate: 0.0013333333333333333, loss: 2.812378406524658
batch i:557
learning rate: 0.0013333333333333333, loss: 2.7379391193389893
batch i:558
learning rate: 0.0013333333333333333, loss: 2.872783660888672
batch i:559
learning rate: 0.0013333333333333333, loss: 2.7715210914611816
batch i:560
learning rate: 0.0013333333333333333, loss: 2.755945920944214
batch i:561
learning rate: 0.0013333333333333333, loss: 2.8294105529785156
batch i:562
learning rate: 0.0013333333333333333, loss: 2.7051286697387695
batch i:563
learning rate: 0.0013333333333333333, loss: 2.7549588680267334
batch i:564
learning rate: 0.0013333333333333333, loss: 2.846644163131714
batch i:565
learning rate: 0.0013333333333333333, loss: 2.6983726024627686
batch i:566
learning rate: 0.0013333333333333333, loss: 2.635329246520996
batch i:567
learning rate: 0.0013333333333333333, loss: 2.7976903915405273
batch i:568
learning rate: 0.0013333333333333333, loss: 2.862308979034424
batch i:569
learning rate: 0.0013333333333333333, loss: 2.708887815475464
batch i:570
learning rate: 0.0013333333333333333, loss: 2.7377185821533203
batch i:571
learning rate: 0.0013333333333333333, loss: 2.836519718170166
batch i:572
learning rate: 0.0013333333333333333, loss: 2.732203483581543
batch i:573
learning rate: 0.0013333333333333333, loss: 2.62557315826416
batch i:574
learning rate: 0.0013333333333333333, loss: 2.724269151687622
batch i:575
learning rate: 0.0013333333333333333, loss: 2.6768906116485596
batch i:576
learning rate: 0.0013333333333333333, loss: 2.6471853256225586
batch i:577
learning rate: 0.0013333333333333333, loss: 2.7605810165405273
batch i:578
learning rate: 0.0013333333333333333, loss: 2.7695353031158447
batch i:579
learning rate: 0.0013333333333333333, loss: 2.765897274017334
batch i:580
learning rate: 0.0013333333333333333, loss: 2.653799533843994
batch i:581
learning rate: 0.0013333333333333333, loss: 2.7322635650634766
batch i:582
learning rate: 0.0013333333333333333, loss: 2.7699432373046875
batch i:583
learning rate: 0.0013333333333333333, loss: 2.7323756217956543
batch i:584
learning rate: 0.0013333333333333333, loss: 2.7080986499786377
batch i:585
learning rate: 0.0013333333333333333, loss: 2.7667951583862305
batch i:586
learning rate: 0.0013333333333333333, loss: 2.6921496391296387
batch i:587
learning rate: 0.0013333333333333333, loss: 2.7531113624572754
batch i:588
learning rate: 0.0013333333333333333, loss: 2.7195796966552734
batch i:589
learning rate: 0.0013333333333333333, loss: 2.6611268520355225
batch i:590
learning rate: 0.0013333333333333333, loss: 2.814509868621826
batch i:591
learning rate: 0.0013333333333333333, loss: 2.644944667816162
batch i:592
learning rate: 0.0013333333333333333, loss: 2.6512575149536133
batch i:593
learning rate: 0.0013333333333333333, loss: 2.7005040645599365
batch i:594
learning rate: 0.0013333333333333333, loss: 2.656721591949463
batch i:595
learning rate: 0.0013333333333333333, loss: 2.617636203765869
batch i:596
learning rate: 0.0013333333333333333, loss: 2.6517128944396973
batch i:597
learning rate: 0.0013333333333333333, loss: 2.6334950923919678
batch i:598
learning rate: 0.0013333333333333333, loss: 2.670620918273926
batch i:599
learning rate: 0.0013333333333333333, loss: 2.5885210037231445
batch i:600
learning rate: 0.0013333333333333333, loss: 2.6499645709991455
current self-play batch: 600
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 295.9421085834503
batch i:601
learning rate: 0.0013333333333333333, loss: 2.6712865829467773
batch i:602
learning rate: 0.0013333333333333333, loss: 2.601611852645874
batch i:603
learning rate: 0.0013333333333333333, loss: 2.6202902793884277
batch i:604
learning rate: 0.0013333333333333333, loss: 2.701035976409912
batch i:605
learning rate: 0.0013333333333333333, loss: 2.709064483642578
batch i:606
learning rate: 0.0013333333333333333, loss: 2.6402206420898438
batch i:607
learning rate: 0.0013333333333333333, loss: 2.6114344596862793
batch i:608
learning rate: 0.0013333333333333333, loss: 2.5514607429504395
batch i:609
learning rate: 0.0013333333333333333, loss: 2.6860313415527344
batch i:610
learning rate: 0.0013333333333333333, loss: 2.6560440063476562
batch i:611
learning rate: 0.0013333333333333333, loss: 2.7358832359313965
batch i:612
learning rate: 0.0013333333333333333, loss: 2.643648862838745
batch i:613
learning rate: 0.0013333333333333333, loss: 2.6028685569763184
batch i:614
learning rate: 0.0013333333333333333, loss: 2.7657814025878906
batch i:615
learning rate: 0.0013333333333333333, loss: 2.6834661960601807
batch i:616
learning rate: 0.0013333333333333333, loss: 2.680386781692505
batch i:617
learning rate: 0.0013333333333333333, loss: 2.6578376293182373
batch i:618
learning rate: 0.0013333333333333333, loss: 2.7566120624542236
batch i:619
learning rate: 0.0013333333333333333, loss: 2.8100650310516357
batch i:620
learning rate: 0.0013333333333333333, loss: 2.728342294692993
batch i:621
learning rate: 0.0013333333333333333, loss: 2.747180461883545
batch i:622
learning rate: 0.0013333333333333333, loss: 2.762098789215088
batch i:623
learning rate: 0.0013333333333333333, loss: 2.7820382118225098
batch i:624
learning rate: 0.0013333333333333333, loss: 2.7696352005004883
batch i:625
learning rate: 0.0013333333333333333, loss: 2.6857423782348633
batch i:626
learning rate: 0.0013333333333333333, loss: 2.753758192062378
batch i:627
learning rate: 0.0013333333333333333, loss: 2.7472448348999023
batch i:628
learning rate: 0.0013333333333333333, loss: 2.6934971809387207
batch i:629
learning rate: 0.0013333333333333333, loss: 2.7048866748809814
batch i:630
learning rate: 0.0013333333333333333, loss: 2.7302777767181396
batch i:631
learning rate: 0.0013333333333333333, loss: 2.7113685607910156
batch i:632
learning rate: 0.0013333333333333333, loss: 2.857367753982544
batch i:633
learning rate: 0.0013333333333333333, loss: 2.775872230529785
batch i:634
learning rate: 0.0013333333333333333, loss: 2.6337575912475586
batch i:635
learning rate: 0.0013333333333333333, loss: 2.664344549179077
batch i:636
learning rate: 0.0013333333333333333, loss: 2.6432642936706543
batch i:637
learning rate: 0.0013333333333333333, loss: 2.5893144607543945
batch i:638
learning rate: 0.0013333333333333333, loss: 2.6322038173675537
batch i:639
learning rate: 0.0013333333333333333, loss: 2.6654014587402344
batch i:640
learning rate: 0.0013333333333333333, loss: 2.642690896987915
batch i:641
learning rate: 0.0013333333333333333, loss: 2.7061386108398438
batch i:642
learning rate: 0.0013333333333333333, loss: 2.7774953842163086
batch i:643
learning rate: 0.0013333333333333333, loss: 2.7301032543182373
batch i:644
learning rate: 0.0013333333333333333, loss: 2.677913188934326
batch i:645
learning rate: 0.0013333333333333333, loss: 2.6784634590148926
batch i:646
learning rate: 0.0013333333333333333, loss: 2.69083833694458
batch i:647
learning rate: 0.0013333333333333333, loss: 2.7090659141540527
batch i:648
learning rate: 0.0013333333333333333, loss: 2.7175979614257812
batch i:649
learning rate: 0.0013333333333333333, loss: 2.6166152954101562
batch i:650
learning rate: 0.0013333333333333333, loss: 2.7834644317626953
current self-play batch: 650
num_playouts:2000, win: 10, lose: 0, tie:0
average time: 1107.4681706905365
New best policy by beating the previous best
batch i:651
learning rate: 0.0013333333333333333, loss: 2.7051825523376465
batch i:652
learning rate: 0.0013333333333333333, loss: 2.7185263633728027
batch i:653
learning rate: 0.0013333333333333333, loss: 2.7565925121307373
batch i:654
learning rate: 0.0013333333333333333, loss: 2.6460797786712646
batch i:655
learning rate: 0.0013333333333333333, loss: 2.6980810165405273
batch i:656
learning rate: 0.0013333333333333333, loss: 2.6385817527770996
batch i:657
learning rate: 0.0013333333333333333, loss: 2.7270267009735107
batch i:658
learning rate: 0.0013333333333333333, loss: 2.6928958892822266
batch i:659
learning rate: 0.0013333333333333333, loss: 2.7236406803131104
batch i:660
learning rate: 0.0013333333333333333, loss: 2.6723623275756836
batch i:661
learning rate: 0.0013333333333333333, loss: 2.743563175201416
batch i:662
learning rate: 0.0013333333333333333, loss: 2.7635200023651123
batch i:663
learning rate: 0.0013333333333333333, loss: 2.7450499534606934
batch i:664
learning rate: 0.0013333333333333333, loss: 2.7256669998168945
batch i:665
learning rate: 0.0013333333333333333, loss: 2.734286308288574
batch i:666
learning rate: 0.0013333333333333333, loss: 2.709442615509033
batch i:667
learning rate: 0.0013333333333333333, loss: 2.689019203186035
batch i:668
learning rate: 0.0013333333333333333, loss: 2.6997313499450684
batch i:669
learning rate: 0.0013333333333333333, loss: 2.7516236305236816
batch i:670
learning rate: 0.0013333333333333333, loss: 2.710648536682129
batch i:671
learning rate: 0.0013333333333333333, loss: 2.7474770545959473
batch i:672
learning rate: 0.0013333333333333333, loss: 2.785914659500122
batch i:673
learning rate: 0.0013333333333333333, loss: 2.9090232849121094
batch i:674
learning rate: 0.0013333333333333333, loss: 2.822207450866699
batch i:675
learning rate: 0.0013333333333333333, loss: 2.727867603302002
batch i:676
learning rate: 0.0013333333333333333, loss: 2.7643227577209473
batch i:677
learning rate: 0.0013333333333333333, loss: 2.7386398315429688
batch i:678
learning rate: 0.0013333333333333333, loss: 2.7217841148376465
batch i:679
learning rate: 0.0013333333333333333, loss: 2.744255542755127
batch i:680
learning rate: 0.0013333333333333333, loss: 2.757993698120117
batch i:681
learning rate: 0.0013333333333333333, loss: 2.7315285205841064
batch i:682
learning rate: 0.0013333333333333333, loss: 2.7770347595214844
batch i:683
learning rate: 0.0013333333333333333, loss: 2.7086400985717773
batch i:684
learning rate: 0.0013333333333333333, loss: 2.6840591430664062
batch i:685
learning rate: 0.0013333333333333333, loss: 2.6344046592712402
batch i:686
learning rate: 0.0013333333333333333, loss: 2.652435064315796
batch i:687
learning rate: 0.0013333333333333333, loss: 2.7305541038513184
batch i:688
learning rate: 0.0013333333333333333, loss: 2.7970547676086426
batch i:689
learning rate: 0.0013333333333333333, loss: 2.678126811981201
batch i:690
learning rate: 0.0013333333333333333, loss: 2.6594371795654297
batch i:691
learning rate: 0.0013333333333333333, loss: 2.6473405361175537
batch i:692
learning rate: 0.0013333333333333333, loss: 2.575409412384033
batch i:693
learning rate: 0.0013333333333333333, loss: 2.6583776473999023
batch i:694
learning rate: 0.0013333333333333333, loss: 2.729508399963379
batch i:695
learning rate: 0.0013333333333333333, loss: 2.707913875579834
batch i:696
learning rate: 0.0013333333333333333, loss: 2.719066858291626
batch i:697
learning rate: 0.0013333333333333333, loss: 2.6048035621643066
batch i:698
learning rate: 0.0013333333333333333, loss: 2.6466689109802246
batch i:699
learning rate: 0.0013333333333333333, loss: 2.6775383949279785
batch i:700
learning rate: 0.0013333333333333333, loss: 2.677821159362793
current self-play batch: 700
num_playouts:2000, win: 6, lose: 4, tie:0
average time: 398.8723602294922
batch i:701
learning rate: 0.0013333333333333333, loss: 2.5968494415283203
batch i:702
learning rate: 0.0013333333333333333, loss: 2.6285154819488525
batch i:703
learning rate: 0.0013333333333333333, loss: 2.6614065170288086
batch i:704
learning rate: 0.0013333333333333333, loss: 2.6476354598999023
batch i:705
learning rate: 0.0013333333333333333, loss: 2.6225080490112305
batch i:706
learning rate: 0.0013333333333333333, loss: 2.6062891483306885
batch i:707
learning rate: 0.0013333333333333333, loss: 2.6866555213928223
batch i:708
learning rate: 0.0013333333333333333, loss: 2.6021194458007812
batch i:709
learning rate: 0.0013333333333333333, loss: 2.7181529998779297
batch i:710
learning rate: 0.0013333333333333333, loss: 2.685976505279541
batch i:711
learning rate: 0.0013333333333333333, loss: 2.6484806537628174
batch i:712
learning rate: 0.0013333333333333333, loss: 2.7527694702148438
batch i:713
learning rate: 0.0013333333333333333, loss: 2.7208127975463867
batch i:714
learning rate: 0.0013333333333333333, loss: 2.5880188941955566
batch i:715
learning rate: 0.0013333333333333333, loss: 2.6006665229797363
batch i:716
learning rate: 0.0013333333333333333, loss: 2.5931427478790283
batch i:717
learning rate: 0.0013333333333333333, loss: 2.565363645553589
batch i:718
learning rate: 0.0013333333333333333, loss: 2.5624914169311523
batch i:719
learning rate: 0.0013333333333333333, loss: 2.6752734184265137
batch i:720
learning rate: 0.0013333333333333333, loss: 2.683749198913574
batch i:721
learning rate: 0.0013333333333333333, loss: 2.684051513671875
batch i:722
learning rate: 0.0013333333333333333, loss: 2.6726198196411133
batch i:723
learning rate: 0.0013333333333333333, loss: 2.7388851642608643
batch i:724
learning rate: 0.0013333333333333333, loss: 2.7068819999694824
batch i:725
learning rate: 0.0013333333333333333, loss: 2.784050703048706
batch i:726
learning rate: 0.0013333333333333333, loss: 2.7082338333129883
batch i:727
learning rate: 0.0013333333333333333, loss: 2.6560606956481934
batch i:728
learning rate: 0.0013333333333333333, loss: 2.758378744125366
batch i:729
learning rate: 0.0013333333333333333, loss: 2.7060141563415527
batch i:730
learning rate: 0.0013333333333333333, loss: 2.600200653076172
batch i:731
learning rate: 0.0013333333333333333, loss: 2.654181480407715
batch i:732
learning rate: 0.0013333333333333333, loss: 2.7395622730255127
batch i:733
learning rate: 0.0013333333333333333, loss: 2.7295141220092773
batch i:734
learning rate: 0.0013333333333333333, loss: 2.639718532562256
batch i:735
learning rate: 0.0013333333333333333, loss: 2.7104849815368652
batch i:736
learning rate: 0.0013333333333333333, loss: 2.696504592895508
batch i:737
learning rate: 0.0013333333333333333, loss: 2.6330974102020264
batch i:738
learning rate: 0.0013333333333333333, loss: 2.6517534255981445
batch i:739
learning rate: 0.0013333333333333333, loss: 2.6802024841308594
batch i:740
learning rate: 0.0013333333333333333, loss: 2.696650981903076
batch i:741
learning rate: 0.0013333333333333333, loss: 2.5840439796447754
batch i:742
learning rate: 0.0013333333333333333, loss: 2.646228790283203
batch i:743
learning rate: 0.0013333333333333333, loss: 2.5494942665100098
batch i:744
learning rate: 0.0013333333333333333, loss: 2.704092502593994
batch i:745
learning rate: 0.0013333333333333333, loss: 2.735471248626709
batch i:746
learning rate: 0.0013333333333333333, loss: 2.747389078140259
batch i:747
learning rate: 0.0013333333333333333, loss: 2.711440086364746
batch i:748
learning rate: 0.0013333333333333333, loss: 2.7474279403686523
batch i:749
learning rate: 0.0013333333333333333, loss: 2.6636316776275635
batch i:750
learning rate: 0.0013333333333333333, loss: 2.6411209106445312
current self-play batch: 750
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 313.652973151207
batch i:751
learning rate: 0.0013333333333333333, loss: 2.723849296569824
batch i:752
learning rate: 0.0013333333333333333, loss: 2.6817867755889893
batch i:753
learning rate: 0.0013333333333333333, loss: 2.719019889831543
batch i:754
learning rate: 0.0013333333333333333, loss: 2.67950177192688
batch i:755
learning rate: 0.0013333333333333333, loss: 2.7215182781219482
batch i:756
learning rate: 0.0013333333333333333, loss: 2.6515259742736816
batch i:757
learning rate: 0.0013333333333333333, loss: 2.6575770378112793
batch i:758
learning rate: 0.0013333333333333333, loss: 2.6324567794799805
batch i:759
learning rate: 0.0013333333333333333, loss: 2.679619789123535
batch i:760
learning rate: 0.0013333333333333333, loss: 2.6695284843444824
batch i:761
learning rate: 0.0013333333333333333, loss: 2.7231173515319824
batch i:762
learning rate: 0.0013333333333333333, loss: 2.572329521179199
batch i:763
learning rate: 0.0013333333333333333, loss: 2.7085907459259033
batch i:764
learning rate: 0.0013333333333333333, loss: 2.6811017990112305
batch i:765
learning rate: 0.0013333333333333333, loss: 2.6689751148223877
batch i:766
learning rate: 0.0013333333333333333, loss: 2.783095359802246
batch i:767
learning rate: 0.0013333333333333333, loss: 2.6647276878356934
batch i:768
learning rate: 0.0013333333333333333, loss: 2.669081687927246
batch i:769
learning rate: 0.0013333333333333333, loss: 2.7005932331085205
batch i:770
learning rate: 0.0013333333333333333, loss: 2.7957239151000977
batch i:771
learning rate: 0.0013333333333333333, loss: 2.653658628463745
batch i:772
learning rate: 0.0013333333333333333, loss: 2.6805622577667236
batch i:773
learning rate: 0.0013333333333333333, loss: 2.6958532333374023
batch i:774
learning rate: 0.0013333333333333333, loss: 2.720078945159912
batch i:775
learning rate: 0.0013333333333333333, loss: 2.7371292114257812
batch i:776
learning rate: 0.0013333333333333333, loss: 2.7229621410369873
batch i:777
learning rate: 0.0013333333333333333, loss: 2.7170896530151367
batch i:778
learning rate: 0.0013333333333333333, loss: 2.6537673473358154
batch i:779
learning rate: 0.0013333333333333333, loss: 2.672743082046509
batch i:780
learning rate: 0.0013333333333333333, loss: 2.6855437755584717
batch i:781
learning rate: 0.0013333333333333333, loss: 2.6876518726348877
batch i:782
learning rate: 0.0013333333333333333, loss: 2.6860928535461426
batch i:783
learning rate: 0.0013333333333333333, loss: 2.656423568725586
batch i:784
learning rate: 0.0013333333333333333, loss: 2.706264019012451
batch i:785
learning rate: 0.0013333333333333333, loss: 2.692944049835205
batch i:786
learning rate: 0.0013333333333333333, loss: 2.6448230743408203
batch i:787
learning rate: 0.0013333333333333333, loss: 2.7195873260498047
batch i:788
learning rate: 0.0013333333333333333, loss: 2.7492833137512207
batch i:789
learning rate: 0.0013333333333333333, loss: 2.654520034790039
batch i:790
learning rate: 0.0013333333333333333, loss: 2.6286299228668213
batch i:791
learning rate: 0.0013333333333333333, loss: 2.7013161182403564
batch i:792
learning rate: 0.0013333333333333333, loss: 2.774949550628662
batch i:793
learning rate: 0.0013333333333333333, loss: 2.5539731979370117
batch i:794
learning rate: 0.0013333333333333333, loss: 2.612086296081543
batch i:795
learning rate: 0.0013333333333333333, loss: 2.6592986583709717
batch i:796
learning rate: 0.0013333333333333333, loss: 2.666531801223755
batch i:797
learning rate: 0.0013333333333333333, loss: 2.6286492347717285
batch i:798
learning rate: 0.0013333333333333333, loss: 2.713972806930542
batch i:799
learning rate: 0.0013333333333333333, loss: 2.6400246620178223
batch i:800
learning rate: 0.0013333333333333333, loss: 2.623800039291382
current self-play batch: 800
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 362.09197359085084
batch i:801
learning rate: 0.0013333333333333333, loss: 2.5741539001464844
batch i:802
learning rate: 0.0013333333333333333, loss: 2.7243010997772217
batch i:803
learning rate: 0.0013333333333333333, loss: 2.649369955062866
batch i:804
learning rate: 0.0013333333333333333, loss: 2.714682102203369
batch i:805
learning rate: 0.0013333333333333333, loss: 2.5953176021575928
batch i:806
learning rate: 0.0013333333333333333, loss: 2.6717801094055176
batch i:807
learning rate: 0.0013333333333333333, loss: 2.7027029991149902
batch i:808
learning rate: 0.0013333333333333333, loss: 2.5693845748901367
batch i:809
learning rate: 0.0013333333333333333, loss: 2.620914936065674
batch i:810
learning rate: 0.0013333333333333333, loss: 2.5376100540161133
batch i:811
learning rate: 0.0013333333333333333, loss: 2.6533925533294678
batch i:812
learning rate: 0.0013333333333333333, loss: 2.607170581817627
batch i:813
learning rate: 0.0013333333333333333, loss: 2.6040358543395996
batch i:814
learning rate: 0.0013333333333333333, loss: 2.6558001041412354
batch i:815
learning rate: 0.0013333333333333333, loss: 2.593177318572998
batch i:816
learning rate: 0.0013333333333333333, loss: 2.6930532455444336
batch i:817
learning rate: 0.0013333333333333333, loss: 2.5826897621154785
batch i:818
learning rate: 0.0013333333333333333, loss: 2.50667667388916
batch i:819
learning rate: 0.0013333333333333333, loss: 2.6017470359802246
batch i:820
learning rate: 0.0013333333333333333, loss: 2.5287511348724365
batch i:821
learning rate: 0.0013333333333333333, loss: 2.6289491653442383
batch i:822
learning rate: 0.0013333333333333333, loss: 2.6377453804016113
batch i:823
learning rate: 0.0013333333333333333, loss: 2.655735492706299
batch i:824
learning rate: 0.0013333333333333333, loss: 2.6405930519104004
batch i:825
learning rate: 0.0013333333333333333, loss: 2.6623992919921875
batch i:826
learning rate: 0.0013333333333333333, loss: 2.6233696937561035
batch i:827
learning rate: 0.0013333333333333333, loss: 2.6538619995117188
batch i:828
learning rate: 0.0013333333333333333, loss: 2.638380765914917
batch i:829
learning rate: 0.0013333333333333333, loss: 2.6618857383728027
batch i:830
learning rate: 0.0013333333333333333, loss: 2.6534531116485596
batch i:831
learning rate: 0.0013333333333333333, loss: 2.653498649597168
batch i:832
learning rate: 0.0013333333333333333, loss: 2.5866799354553223
batch i:833
learning rate: 0.0013333333333333333, loss: 2.7094357013702393
batch i:834
learning rate: 0.0013333333333333333, loss: 2.6414005756378174
batch i:835
learning rate: 0.0013333333333333333, loss: 2.65075421333313
batch i:836
learning rate: 0.0013333333333333333, loss: 2.656684398651123
batch i:837
learning rate: 0.0013333333333333333, loss: 2.667379140853882
batch i:838
learning rate: 0.0013333333333333333, loss: 2.6119203567504883
batch i:839
learning rate: 0.0013333333333333333, loss: 2.7070164680480957
batch i:840
learning rate: 0.0013333333333333333, loss: 2.6828346252441406
batch i:841
learning rate: 0.0013333333333333333, loss: 2.572068452835083
batch i:842
learning rate: 0.0013333333333333333, loss: 2.7709484100341797
batch i:843
learning rate: 0.0013333333333333333, loss: 2.6378579139709473
batch i:844
learning rate: 0.0013333333333333333, loss: 2.724470615386963
batch i:845
learning rate: 0.0013333333333333333, loss: 2.7695655822753906
batch i:846
learning rate: 0.0013333333333333333, loss: 2.7974109649658203
batch i:847
learning rate: 0.0013333333333333333, loss: 2.7419159412384033
batch i:848
learning rate: 0.0013333333333333333, loss: 2.7085940837860107
batch i:849
learning rate: 0.0013333333333333333, loss: 2.697033166885376
batch i:850
learning rate: 0.0013333333333333333, loss: 2.7770791053771973
current self-play batch: 850
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 349.1128022909164
batch i:851
learning rate: 0.0013333333333333333, loss: 2.823591709136963
batch i:852
learning rate: 0.0013333333333333333, loss: 2.7376790046691895
batch i:853
learning rate: 0.0013333333333333333, loss: 2.762220621109009
batch i:854
learning rate: 0.0013333333333333333, loss: 2.6399550437927246
batch i:855
learning rate: 0.0013333333333333333, loss: 2.72574782371521
batch i:856
learning rate: 0.0013333333333333333, loss: 2.7030911445617676
batch i:857
learning rate: 0.0013333333333333333, loss: 2.7396748065948486
batch i:858
learning rate: 0.0013333333333333333, loss: 2.6986875534057617
batch i:859
learning rate: 0.0013333333333333333, loss: 2.7196640968322754
batch i:860
learning rate: 0.0013333333333333333, loss: 2.679896354675293
batch i:861
learning rate: 0.0013333333333333333, loss: 2.680567741394043
batch i:862
learning rate: 0.0013333333333333333, loss: 2.6331419944763184
batch i:863
learning rate: 0.0013333333333333333, loss: 2.683030366897583
batch i:864
learning rate: 0.0013333333333333333, loss: 2.6838932037353516
batch i:865
learning rate: 0.0013333333333333333, loss: 2.61961030960083
batch i:866
learning rate: 0.0013333333333333333, loss: 2.6048293113708496
batch i:867
learning rate: 0.0013333333333333333, loss: 2.689060926437378
batch i:868
learning rate: 0.0013333333333333333, loss: 2.594508171081543
batch i:869
learning rate: 0.0013333333333333333, loss: 2.7054152488708496
batch i:870
learning rate: 0.0013333333333333333, loss: 2.6132895946502686
batch i:871
learning rate: 0.0013333333333333333, loss: 2.54600191116333
batch i:872
learning rate: 0.0013333333333333333, loss: 2.674842357635498
batch i:873
learning rate: 0.0013333333333333333, loss: 2.6121420860290527
batch i:874
learning rate: 0.0013333333333333333, loss: 2.7570571899414062
batch i:875
learning rate: 0.0013333333333333333, loss: 2.562392234802246
batch i:876
learning rate: 0.0013333333333333333, loss: 2.627932071685791
batch i:877
learning rate: 0.0013333333333333333, loss: 2.5573339462280273
batch i:878
learning rate: 0.0013333333333333333, loss: 2.5604660511016846
batch i:879
learning rate: 0.0013333333333333333, loss: 2.6479439735412598
batch i:880
learning rate: 0.0013333333333333333, loss: 2.5979795455932617
batch i:881
learning rate: 0.0013333333333333333, loss: 2.6284050941467285
batch i:882
learning rate: 0.0013333333333333333, loss: 2.634859561920166
batch i:883
learning rate: 0.0013333333333333333, loss: 2.745993137359619
batch i:884
learning rate: 0.0013333333333333333, loss: 2.725086212158203
batch i:885
learning rate: 0.0013333333333333333, loss: 2.6873083114624023
batch i:886
learning rate: 0.0013333333333333333, loss: 2.642889976501465
batch i:887
learning rate: 0.0013333333333333333, loss: 2.661496877670288
batch i:888
learning rate: 0.0013333333333333333, loss: 2.6523513793945312
batch i:889
learning rate: 0.0013333333333333333, loss: 2.599797248840332
batch i:890
learning rate: 0.0013333333333333333, loss: 2.597177267074585
batch i:891
learning rate: 0.0013333333333333333, loss: 2.6288647651672363
batch i:892
learning rate: 0.0013333333333333333, loss: 2.6057753562927246
batch i:893
learning rate: 0.0013333333333333333, loss: 2.645552635192871
batch i:894
learning rate: 0.0013333333333333333, loss: 2.6002345085144043
batch i:895
learning rate: 0.0013333333333333333, loss: 2.6910643577575684
batch i:896
learning rate: 0.0013333333333333333, loss: 2.72900128364563
batch i:897
learning rate: 0.0013333333333333333, loss: 2.58213472366333
batch i:898
learning rate: 0.0013333333333333333, loss: 2.6293351650238037
batch i:899
learning rate: 0.0013333333333333333, loss: 2.691436290740967
batch i:900
learning rate: 0.0013333333333333333, loss: 2.6065053939819336
current self-play batch: 900
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 218.8449109315872
batch i:901
learning rate: 0.0013333333333333333, loss: 2.704157829284668
batch i:902
learning rate: 0.0013333333333333333, loss: 2.5849685668945312
batch i:903
learning rate: 0.0013333333333333333, loss: 2.623311996459961
batch i:904
learning rate: 0.0013333333333333333, loss: 2.6871328353881836
batch i:905
learning rate: 0.0013333333333333333, loss: 2.617603302001953
batch i:906
learning rate: 0.0013333333333333333, loss: 2.6812117099761963
batch i:907
learning rate: 0.0013333333333333333, loss: 2.6026599407196045
batch i:908
learning rate: 0.0013333333333333333, loss: 2.6594130992889404
batch i:909
learning rate: 0.0013333333333333333, loss: 2.6431267261505127
batch i:910
learning rate: 0.0013333333333333333, loss: 2.510438919067383
batch i:911
learning rate: 0.0013333333333333333, loss: 2.663567543029785
batch i:912
learning rate: 0.0013333333333333333, loss: 2.790395736694336
batch i:913
learning rate: 0.0013333333333333333, loss: 2.794156789779663
batch i:914
learning rate: 0.0013333333333333333, loss: 2.7228341102600098
batch i:915
learning rate: 0.0013333333333333333, loss: 2.671907663345337
batch i:916
learning rate: 0.0013333333333333333, loss: 2.6131927967071533
batch i:917
learning rate: 0.0013333333333333333, loss: 2.668728828430176
batch i:918
learning rate: 0.0013333333333333333, loss: 2.6390509605407715
batch i:919
learning rate: 0.0013333333333333333, loss: 2.647614002227783
batch i:920
learning rate: 0.0013333333333333333, loss: 2.6861929893493652
batch i:921
learning rate: 0.0013333333333333333, loss: 2.7185211181640625
batch i:922
learning rate: 0.0013333333333333333, loss: 2.6494498252868652
batch i:923
learning rate: 0.0013333333333333333, loss: 2.7327356338500977
batch i:924
learning rate: 0.0013333333333333333, loss: 2.7017745971679688
batch i:925
learning rate: 0.0013333333333333333, loss: 2.6873579025268555
batch i:926
learning rate: 0.0013333333333333333, loss: 2.6423592567443848
batch i:927
learning rate: 0.0013333333333333333, loss: 2.6383719444274902
batch i:928
learning rate: 0.0013333333333333333, loss: 2.6816868782043457
batch i:929
learning rate: 0.0013333333333333333, loss: 2.6809701919555664
batch i:930
learning rate: 0.0013333333333333333, loss: 2.711120367050171
batch i:931
learning rate: 0.0013333333333333333, loss: 2.622783899307251
batch i:932
learning rate: 0.0013333333333333333, loss: 2.605924606323242
batch i:933
learning rate: 0.0013333333333333333, loss: 2.70119047164917
batch i:934
learning rate: 0.0013333333333333333, loss: 2.630908966064453
batch i:935
learning rate: 0.0013333333333333333, loss: 2.652876377105713
batch i:936
learning rate: 0.0013333333333333333, loss: 2.68048095703125
batch i:937
learning rate: 0.0013333333333333333, loss: 2.632683277130127
batch i:938
learning rate: 0.0013333333333333333, loss: 2.6183736324310303
batch i:939
learning rate: 0.0013333333333333333, loss: 2.662844181060791
batch i:940
learning rate: 0.0013333333333333333, loss: 2.6685428619384766
batch i:941
learning rate: 0.0013333333333333333, loss: 2.8048911094665527
batch i:942
learning rate: 0.0013333333333333333, loss: 2.682387590408325
batch i:943
learning rate: 0.0013333333333333333, loss: 2.745894432067871
batch i:944
learning rate: 0.0013333333333333333, loss: 2.6854891777038574
batch i:945
learning rate: 0.0013333333333333333, loss: 2.7139086723327637
batch i:946
learning rate: 0.0013333333333333333, loss: 2.7315280437469482
batch i:947
learning rate: 0.0013333333333333333, loss: 2.707765579223633
batch i:948
learning rate: 0.0013333333333333333, loss: 2.7117223739624023
batch i:949
learning rate: 0.0013333333333333333, loss: 2.751509666442871
batch i:950
learning rate: 0.0013333333333333333, loss: 2.772508144378662
current self-play batch: 950
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 187.19789872169494
batch i:951
learning rate: 0.0013333333333333333, loss: 2.789409637451172
batch i:952
learning rate: 0.0013333333333333333, loss: 2.8382363319396973
batch i:953
learning rate: 0.0013333333333333333, loss: 2.7946367263793945
batch i:954
learning rate: 0.0013333333333333333, loss: 2.7767527103424072
batch i:955
learning rate: 0.0013333333333333333, loss: 2.7299652099609375
batch i:956
learning rate: 0.0013333333333333333, loss: 2.6678109169006348
batch i:957
learning rate: 0.0013333333333333333, loss: 2.7018191814422607
batch i:958
learning rate: 0.0013333333333333333, loss: 2.724789619445801
batch i:959
learning rate: 0.0013333333333333333, loss: 2.668795108795166
batch i:960
learning rate: 0.0013333333333333333, loss: 2.6618809700012207
batch i:961
learning rate: 0.0013333333333333333, loss: 2.7711331844329834
batch i:962
learning rate: 0.0013333333333333333, loss: 2.7241365909576416
batch i:963
learning rate: 0.0013333333333333333, loss: 2.7366535663604736
batch i:964
learning rate: 0.0013333333333333333, loss: 2.7992310523986816
batch i:965
learning rate: 0.0013333333333333333, loss: 2.748792886734009
batch i:966
learning rate: 0.0013333333333333333, loss: 2.7085604667663574
batch i:967
learning rate: 0.0013333333333333333, loss: 2.6796956062316895
batch i:968
learning rate: 0.0013333333333333333, loss: 2.8352255821228027
batch i:969
learning rate: 0.0013333333333333333, loss: 2.802981376647949
batch i:970
learning rate: 0.0013333333333333333, loss: 2.7798337936401367
batch i:971
learning rate: 0.0013333333333333333, loss: 2.6757781505584717
batch i:972
learning rate: 0.0013333333333333333, loss: 2.6642212867736816
batch i:973
learning rate: 0.0013333333333333333, loss: 2.8160459995269775
batch i:974
learning rate: 0.0013333333333333333, loss: 2.7819502353668213
batch i:975
learning rate: 0.0013333333333333333, loss: 2.798079252243042
batch i:976
learning rate: 0.0013333333333333333, loss: 2.797734498977661
batch i:977
learning rate: 0.0013333333333333333, loss: 2.744551420211792
batch i:978
learning rate: 0.0013333333333333333, loss: 2.745239734649658
batch i:979
learning rate: 0.0013333333333333333, loss: 2.836256265640259
batch i:980
learning rate: 0.0013333333333333333, loss: 2.7955780029296875
batch i:981
learning rate: 0.0013333333333333333, loss: 2.825272560119629
batch i:982
learning rate: 0.0013333333333333333, loss: 2.835909843444824
batch i:983
learning rate: 0.0013333333333333333, loss: 2.811842441558838
batch i:984
learning rate: 0.0013333333333333333, loss: 2.859375
batch i:985
learning rate: 0.0013333333333333333, loss: 2.841325044631958
batch i:986
learning rate: 0.0013333333333333333, loss: 2.7727713584899902
batch i:987
learning rate: 0.0013333333333333333, loss: 2.728036880493164
batch i:988
learning rate: 0.0013333333333333333, loss: 2.788989543914795
batch i:989
learning rate: 0.0013333333333333333, loss: 2.7551631927490234
batch i:990
learning rate: 0.0013333333333333333, loss: 2.8546204566955566
batch i:991
learning rate: 0.0013333333333333333, loss: 2.793508291244507
batch i:992
learning rate: 0.0013333333333333333, loss: 2.7368545532226562
batch i:993
learning rate: 0.0013333333333333333, loss: 2.7218329906463623
batch i:994
learning rate: 0.0013333333333333333, loss: 2.6197259426116943
batch i:995
learning rate: 0.0013333333333333333, loss: 2.7715654373168945
batch i:996
learning rate: 0.0013333333333333333, loss: 2.7991890907287598
batch i:997
learning rate: 0.0013333333333333333, loss: 2.7475295066833496
batch i:998
learning rate: 0.0013333333333333333, loss: 2.729872941970825
batch i:999
learning rate: 0.0013333333333333333, loss: 2.873430013656616
batch i:1000
learning rate: 0.0013333333333333333, loss: 2.8258607387542725
current self-play batch: 1000
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 162.62329466342925
batch i:1001
learning rate: 0.0013333333333333333, loss: 2.7125158309936523
batch i:1002
learning rate: 0.0013333333333333333, loss: 2.6816015243530273
batch i:1003
learning rate: 0.0013333333333333333, loss: 2.748645544052124
batch i:1004
learning rate: 0.0013333333333333333, loss: 2.8099749088287354
batch i:1005
learning rate: 0.0013333333333333333, loss: 2.6618242263793945
batch i:1006
learning rate: 0.0013333333333333333, loss: 2.6831741333007812
batch i:1007
learning rate: 0.0013333333333333333, loss: 2.6925950050354004
batch i:1008
learning rate: 0.0013333333333333333, loss: 2.8615055084228516
batch i:1009
learning rate: 0.0013333333333333333, loss: 2.717414140701294
batch i:1010
learning rate: 0.0013333333333333333, loss: 2.6374659538269043
batch i:1011
learning rate: 0.0013333333333333333, loss: 2.758528232574463
batch i:1012
learning rate: 0.0013333333333333333, loss: 2.7290735244750977
batch i:1013
learning rate: 0.0013333333333333333, loss: 2.7814838886260986
batch i:1014
learning rate: 0.0013333333333333333, loss: 2.6801819801330566
batch i:1015
learning rate: 0.0013333333333333333, loss: 2.725126266479492
batch i:1016
learning rate: 0.0013333333333333333, loss: 2.655949354171753
batch i:1017
learning rate: 0.0013333333333333333, loss: 2.7589330673217773
batch i:1018
learning rate: 0.0013333333333333333, loss: 2.659857749938965
batch i:1019
learning rate: 0.0013333333333333333, loss: 2.653282880783081
batch i:1020
learning rate: 0.0013333333333333333, loss: 2.7299537658691406
batch i:1021
learning rate: 0.0013333333333333333, loss: 2.6736249923706055
batch i:1022
learning rate: 0.0013333333333333333, loss: 2.6189775466918945
batch i:1023
learning rate: 0.0013333333333333333, loss: 2.7053985595703125
batch i:1024
learning rate: 0.0013333333333333333, loss: 2.724867105484009
batch i:1025
learning rate: 0.0013333333333333333, loss: 2.7208468914031982
batch i:1026
learning rate: 0.0013333333333333333, loss: 2.8293938636779785
batch i:1027
learning rate: 0.0013333333333333333, loss: 2.716252565383911
batch i:1028
learning rate: 0.0013333333333333333, loss: 2.791914224624634
batch i:1029
learning rate: 0.0013333333333333333, loss: 2.787616491317749
batch i:1030
learning rate: 0.0013333333333333333, loss: 2.7402825355529785
batch i:1031
learning rate: 0.0013333333333333333, loss: 2.703350067138672
batch i:1032
learning rate: 0.0013333333333333333, loss: 2.855966567993164
batch i:1033
learning rate: 0.0013333333333333333, loss: 2.7496352195739746
batch i:1034
learning rate: 0.0013333333333333333, loss: 2.6922671794891357
batch i:1035
learning rate: 0.0013333333333333333, loss: 2.8191943168640137
batch i:1036
learning rate: 0.0013333333333333333, loss: 2.708312749862671
batch i:1037
learning rate: 0.0013333333333333333, loss: 2.717881679534912
batch i:1038
learning rate: 0.0013333333333333333, loss: 2.769202470779419
batch i:1039
learning rate: 0.0013333333333333333, loss: 2.7233223915100098
batch i:1040
learning rate: 0.0013333333333333333, loss: 2.818432331085205
batch i:1041
learning rate: 0.0013333333333333333, loss: 2.6808371543884277
batch i:1042
learning rate: 0.0013333333333333333, loss: 2.7055749893188477
batch i:1043
learning rate: 0.0013333333333333333, loss: 2.679044246673584
batch i:1044
learning rate: 0.0013333333333333333, loss: 2.769087791442871
batch i:1045
learning rate: 0.0013333333333333333, loss: 2.7284770011901855
batch i:1046
learning rate: 0.0013333333333333333, loss: 2.6885056495666504
batch i:1047
learning rate: 0.0013333333333333333, loss: 2.711832046508789
batch i:1048
learning rate: 0.0013333333333333333, loss: 2.7057607173919678
batch i:1049
learning rate: 0.0013333333333333333, loss: 2.7030909061431885
batch i:1050
learning rate: 0.0013333333333333333, loss: 2.728013038635254
current self-play batch: 1050
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 174.13858304023742
batch i:1051
learning rate: 0.0013333333333333333, loss: 2.7795279026031494
batch i:1052
learning rate: 0.0013333333333333333, loss: 2.8057405948638916
batch i:1053
learning rate: 0.0013333333333333333, loss: 2.8646774291992188
batch i:1054
learning rate: 0.0013333333333333333, loss: 2.8893985748291016
batch i:1055
learning rate: 0.0013333333333333333, loss: 2.7220282554626465
batch i:1056
learning rate: 0.0013333333333333333, loss: 2.7718944549560547
batch i:1057
learning rate: 0.0013333333333333333, loss: 2.685150623321533
batch i:1058
learning rate: 0.0013333333333333333, loss: 2.734123706817627
batch i:1059
learning rate: 0.0013333333333333333, loss: 2.7272138595581055
batch i:1060
learning rate: 0.0013333333333333333, loss: 2.75895357131958
batch i:1061
learning rate: 0.0013333333333333333, loss: 2.7753186225891113
batch i:1062
learning rate: 0.0013333333333333333, loss: 2.717985153198242
batch i:1063
learning rate: 0.0013333333333333333, loss: 2.797398328781128
batch i:1064
learning rate: 0.0013333333333333333, loss: 2.807478427886963
batch i:1065
learning rate: 0.0013333333333333333, loss: 2.793665885925293
batch i:1066
learning rate: 0.0013333333333333333, loss: 2.804363250732422
batch i:1067
learning rate: 0.0013333333333333333, loss: 2.7439327239990234
batch i:1068
learning rate: 0.0013333333333333333, loss: 2.7706687450408936
batch i:1069
learning rate: 0.0013333333333333333, loss: 2.6994056701660156
batch i:1070
learning rate: 0.0013333333333333333, loss: 2.6292877197265625
batch i:1071
learning rate: 0.0013333333333333333, loss: 2.796433925628662
batch i:1072
learning rate: 0.0013333333333333333, loss: 2.662872314453125
batch i:1073
learning rate: 0.0013333333333333333, loss: 2.699368953704834
batch i:1074
learning rate: 0.0013333333333333333, loss: 2.744476795196533
batch i:1075
learning rate: 0.0013333333333333333, loss: 2.7433905601501465
batch i:1076
learning rate: 0.0013333333333333333, loss: 2.724573850631714
batch i:1077
learning rate: 0.0013333333333333333, loss: 2.7308549880981445
batch i:1078
learning rate: 0.0013333333333333333, loss: 2.7875657081604004
batch i:1079
learning rate: 0.0013333333333333333, loss: 2.775742292404175
batch i:1080
learning rate: 0.0013333333333333333, loss: 2.791597843170166
batch i:1081
learning rate: 0.0013333333333333333, loss: 2.719228982925415
batch i:1082
learning rate: 0.0013333333333333333, loss: 2.7484302520751953
batch i:1083
learning rate: 0.0013333333333333333, loss: 2.778238296508789
batch i:1084
learning rate: 0.0013333333333333333, loss: 2.5934414863586426
batch i:1085
learning rate: 0.0013333333333333333, loss: 2.7543511390686035
batch i:1086
learning rate: 0.0013333333333333333, loss: 2.7139735221862793
batch i:1087
learning rate: 0.0013333333333333333, loss: 2.684967517852783
batch i:1088
learning rate: 0.0013333333333333333, loss: 2.7716028690338135
batch i:1089
learning rate: 0.0013333333333333333, loss: 2.7338979244232178
batch i:1090
learning rate: 0.0013333333333333333, loss: 2.6635890007019043
batch i:1091
learning rate: 0.0013333333333333333, loss: 2.708308219909668
batch i:1092
learning rate: 0.0013333333333333333, loss: 2.578400135040283
batch i:1093
learning rate: 0.0013333333333333333, loss: 2.7261428833007812
batch i:1094
learning rate: 0.0013333333333333333, loss: 2.6953272819519043
batch i:1095
learning rate: 0.0013333333333333333, loss: 2.717381238937378
batch i:1096
learning rate: 0.0013333333333333333, loss: 2.7427420616149902
batch i:1097
learning rate: 0.0013333333333333333, loss: 2.6187093257904053
batch i:1098
learning rate: 0.0013333333333333333, loss: 2.654320478439331
batch i:1099
learning rate: 0.0013333333333333333, loss: 2.6522085666656494
batch i:1100
learning rate: 0.0013333333333333333, loss: 2.72986102104187
current self-play batch: 1100
num_playouts:2000, win: 6, lose: 4, tie:0
average time: 200.34288799762726
batch i:1101
learning rate: 0.0013333333333333333, loss: 2.7383790016174316
batch i:1102
learning rate: 0.0013333333333333333, loss: 2.7154946327209473
batch i:1103
learning rate: 0.0013333333333333333, loss: 2.744175434112549
batch i:1104
learning rate: 0.0013333333333333333, loss: 2.6638946533203125
batch i:1105
learning rate: 0.0013333333333333333, loss: 2.739164352416992
batch i:1106
learning rate: 0.0013333333333333333, loss: 2.6739606857299805
batch i:1107
learning rate: 0.0013333333333333333, loss: 2.7729549407958984
batch i:1108
learning rate: 0.0013333333333333333, loss: 2.6217360496520996
batch i:1109
learning rate: 0.0013333333333333333, loss: 2.6616034507751465
batch i:1110
learning rate: 0.0013333333333333333, loss: 2.7328765392303467
batch i:1111
learning rate: 0.0013333333333333333, loss: 2.7064995765686035
batch i:1112
learning rate: 0.0013333333333333333, loss: 2.6664843559265137
batch i:1113
learning rate: 0.0013333333333333333, loss: 2.7029473781585693
batch i:1114
learning rate: 0.0013333333333333333, loss: 2.7324893474578857
batch i:1115
learning rate: 0.0013333333333333333, loss: 2.753608465194702
batch i:1116
learning rate: 0.0013333333333333333, loss: 2.6597137451171875
batch i:1117
learning rate: 0.0013333333333333333, loss: 2.6291232109069824
batch i:1118
learning rate: 0.0013333333333333333, loss: 2.741450071334839
batch i:1119
learning rate: 0.0013333333333333333, loss: 2.7508950233459473
batch i:1120
learning rate: 0.0013333333333333333, loss: 2.6043548583984375
batch i:1121
learning rate: 0.0013333333333333333, loss: 2.7138006687164307
batch i:1122
learning rate: 0.0013333333333333333, loss: 2.731931447982788
batch i:1123
learning rate: 0.0013333333333333333, loss: 2.7271735668182373
batch i:1124
learning rate: 0.0013333333333333333, loss: 2.7081940174102783
batch i:1125
learning rate: 0.0013333333333333333, loss: 2.618102550506592
batch i:1126
learning rate: 0.0013333333333333333, loss: 2.716028928756714
batch i:1127
learning rate: 0.0013333333333333333, loss: 2.727339029312134
batch i:1128
learning rate: 0.0013333333333333333, loss: 2.7092366218566895
batch i:1129
learning rate: 0.0013333333333333333, loss: 2.6826672554016113
batch i:1130
learning rate: 0.0013333333333333333, loss: 2.7060885429382324
batch i:1131
learning rate: 0.0013333333333333333, loss: 2.6988651752471924
batch i:1132
learning rate: 0.0013333333333333333, loss: 2.668543815612793
batch i:1133
learning rate: 0.0013333333333333333, loss: 2.760030746459961
batch i:1134
learning rate: 0.0013333333333333333, loss: 2.732637882232666
batch i:1135
learning rate: 0.0013333333333333333, loss: 2.634401321411133
batch i:1136
learning rate: 0.0013333333333333333, loss: 2.7177255153656006
batch i:1137
learning rate: 0.0013333333333333333, loss: 2.6232829093933105
batch i:1138
learning rate: 0.0013333333333333333, loss: 2.683598041534424
batch i:1139
learning rate: 0.0013333333333333333, loss: 2.5812039375305176
batch i:1140
learning rate: 0.0013333333333333333, loss: 2.621394157409668
batch i:1141
learning rate: 0.0013333333333333333, loss: 2.642578125
batch i:1142
learning rate: 0.0013333333333333333, loss: 2.5910911560058594
batch i:1143
learning rate: 0.0013333333333333333, loss: 2.606727123260498
batch i:1144
learning rate: 0.0013333333333333333, loss: 2.7484023571014404
batch i:1145
learning rate: 0.0013333333333333333, loss: 2.613456964492798
batch i:1146
learning rate: 0.0013333333333333333, loss: 2.618523359298706
batch i:1147
learning rate: 0.0013333333333333333, loss: 2.6134374141693115
batch i:1148
learning rate: 0.0013333333333333333, loss: 2.71395206451416
batch i:1149
learning rate: 0.0013333333333333333, loss: 2.6932101249694824
batch i:1150
learning rate: 0.0013333333333333333, loss: 2.6163172721862793
current self-play batch: 1150
num_playouts:2000, win: 6, lose: 4, tie:0
average time: 221.3990786075592
batch i:1151
learning rate: 0.0013333333333333333, loss: 2.6810710430145264
batch i:1152
learning rate: 0.0013333333333333333, loss: 2.6546223163604736
batch i:1153
learning rate: 0.0013333333333333333, loss: 2.6403560638427734
batch i:1154
learning rate: 0.0013333333333333333, loss: 2.658310651779175
batch i:1155
learning rate: 0.0013333333333333333, loss: 2.7244374752044678
batch i:1156
learning rate: 0.0013333333333333333, loss: 2.63385272026062
batch i:1157
learning rate: 0.0013333333333333333, loss: 2.620453357696533
batch i:1158
learning rate: 0.0013333333333333333, loss: 2.686239719390869
batch i:1159
learning rate: 0.0013333333333333333, loss: 2.66510009765625
batch i:1160
learning rate: 0.0013333333333333333, loss: 2.7166531085968018
batch i:1161
learning rate: 0.0013333333333333333, loss: 2.6890573501586914
batch i:1162
learning rate: 0.0013333333333333333, loss: 2.692628860473633
batch i:1163
learning rate: 0.0013333333333333333, loss: 2.7081196308135986
batch i:1164
learning rate: 0.0013333333333333333, loss: 2.697409152984619
batch i:1165
learning rate: 0.0013333333333333333, loss: 2.806760311126709
batch i:1166
learning rate: 0.0013333333333333333, loss: 2.676471710205078
batch i:1167
learning rate: 0.0013333333333333333, loss: 2.6664047241210938
batch i:1168
learning rate: 0.0013333333333333333, loss: 2.68314528465271
batch i:1169
learning rate: 0.0013333333333333333, loss: 2.7397313117980957
batch i:1170
learning rate: 0.0013333333333333333, loss: 2.7171411514282227
batch i:1171
learning rate: 0.0013333333333333333, loss: 2.7205066680908203
batch i:1172
learning rate: 0.0013333333333333333, loss: 2.833652973175049
batch i:1173
learning rate: 0.0013333333333333333, loss: 2.7598795890808105
batch i:1174
learning rate: 0.0013333333333333333, loss: 2.74037504196167
batch i:1175
learning rate: 0.0013333333333333333, loss: 2.644975185394287
batch i:1176
learning rate: 0.0013333333333333333, loss: 2.705531120300293
batch i:1177
learning rate: 0.0013333333333333333, loss: 2.6965689659118652
batch i:1178
learning rate: 0.0013333333333333333, loss: 2.6811485290527344
batch i:1179
learning rate: 0.0013333333333333333, loss: 2.5951833724975586
batch i:1180
learning rate: 0.0013333333333333333, loss: 2.706573963165283
batch i:1181
learning rate: 0.0013333333333333333, loss: 2.755770206451416
batch i:1182
learning rate: 0.0013333333333333333, loss: 2.763916015625
batch i:1183
learning rate: 0.0013333333333333333, loss: 2.716869592666626
batch i:1184
learning rate: 0.0013333333333333333, loss: 2.6281824111938477
batch i:1185
learning rate: 0.0013333333333333333, loss: 2.8135666847229004
batch i:1186
learning rate: 0.0013333333333333333, loss: 2.611833333969116
batch i:1187
learning rate: 0.0013333333333333333, loss: 2.632817268371582
batch i:1188
learning rate: 0.0013333333333333333, loss: 2.7004289627075195
batch i:1189
learning rate: 0.0013333333333333333, loss: 2.6130261421203613
batch i:1190
learning rate: 0.0013333333333333333, loss: 2.6741738319396973
batch i:1191
learning rate: 0.0013333333333333333, loss: 2.6924052238464355
batch i:1192
learning rate: 0.0013333333333333333, loss: 2.693331480026245
batch i:1193
learning rate: 0.0013333333333333333, loss: 2.6215646266937256
batch i:1194
learning rate: 0.0013333333333333333, loss: 2.717162847518921
batch i:1195
learning rate: 0.0013333333333333333, loss: 2.750904083251953
batch i:1196
learning rate: 0.0013333333333333333, loss: 2.8163819313049316
batch i:1197
learning rate: 0.0013333333333333333, loss: 2.757509708404541
batch i:1198
learning rate: 0.0013333333333333333, loss: 2.74933123588562
batch i:1199
learning rate: 0.0013333333333333333, loss: 2.7186131477355957
batch i:1200
learning rate: 0.0013333333333333333, loss: 2.7531027793884277
current self-play batch: 1200
num_playouts:2000, win: 5, lose: 5, tie:0
average time: 267.0320177078247
batch i:1201
learning rate: 0.0013333333333333333, loss: 2.624955654144287
batch i:1202
learning rate: 0.0013333333333333333, loss: 2.7244415283203125
batch i:1203
learning rate: 0.0013333333333333333, loss: 2.5968711376190186
batch i:1204
learning rate: 0.0013333333333333333, loss: 2.7530012130737305
batch i:1205
learning rate: 0.0013333333333333333, loss: 2.6686596870422363
batch i:1206
learning rate: 0.0013333333333333333, loss: 2.587402820587158
batch i:1207
learning rate: 0.0013333333333333333, loss: 2.616940498352051
batch i:1208
learning rate: 0.0013333333333333333, loss: 2.7293777465820312
batch i:1209
learning rate: 0.0013333333333333333, loss: 2.73439884185791
batch i:1210
learning rate: 0.0013333333333333333, loss: 2.6791388988494873
batch i:1211
learning rate: 0.0013333333333333333, loss: 2.590331554412842
batch i:1212
learning rate: 0.0013333333333333333, loss: 2.6523983478546143
batch i:1213
learning rate: 0.0013333333333333333, loss: 2.6627190113067627
batch i:1214
learning rate: 0.0013333333333333333, loss: 2.702331066131592
batch i:1215
learning rate: 0.0013333333333333333, loss: 2.6322498321533203
batch i:1216
learning rate: 0.0013333333333333333, loss: 2.6246392726898193
batch i:1217
learning rate: 0.0013333333333333333, loss: 2.6663620471954346
batch i:1218
learning rate: 0.0013333333333333333, loss: 2.700704574584961
batch i:1219
learning rate: 0.0013333333333333333, loss: 2.714155673980713
batch i:1220
learning rate: 0.0013333333333333333, loss: 2.668375015258789
batch i:1221
learning rate: 0.0013333333333333333, loss: 2.6531338691711426
batch i:1222
learning rate: 0.0013333333333333333, loss: 2.6949398517608643
batch i:1223
learning rate: 0.0013333333333333333, loss: 2.6888585090637207
batch i:1224
learning rate: 0.0013333333333333333, loss: 2.761594772338867
batch i:1225
learning rate: 0.0013333333333333333, loss: 2.755265474319458
batch i:1226
learning rate: 0.0013333333333333333, loss: 2.7464728355407715
batch i:1227
learning rate: 0.0013333333333333333, loss: 2.701002597808838
batch i:1228
learning rate: 0.0013333333333333333, loss: 2.577859401702881
batch i:1229
learning rate: 0.0013333333333333333, loss: 2.596931219100952
batch i:1230
learning rate: 0.0013333333333333333, loss: 2.642220973968506
batch i:1231
learning rate: 0.0013333333333333333, loss: 2.785569190979004
batch i:1232
learning rate: 0.0013333333333333333, loss: 2.70284366607666
batch i:1233
learning rate: 0.0013333333333333333, loss: 2.7385802268981934
batch i:1234
learning rate: 0.0013333333333333333, loss: 2.767721652984619
batch i:1235
learning rate: 0.0013333333333333333, loss: 2.6191329956054688
batch i:1236
learning rate: 0.0013333333333333333, loss: 2.643840789794922
batch i:1237
learning rate: 0.0013333333333333333, loss: 2.7877490520477295
batch i:1238
learning rate: 0.0013333333333333333, loss: 2.6781253814697266
batch i:1239
learning rate: 0.0013333333333333333, loss: 2.751659393310547
batch i:1240
learning rate: 0.0013333333333333333, loss: 2.678715229034424
batch i:1241
learning rate: 0.0013333333333333333, loss: 2.8210482597351074
batch i:1242
learning rate: 0.0013333333333333333, loss: 2.771836280822754
batch i:1243
learning rate: 0.0013333333333333333, loss: 2.716266632080078
batch i:1244
learning rate: 0.0013333333333333333, loss: 2.6983938217163086
batch i:1245
learning rate: 0.0013333333333333333, loss: 2.656291961669922
batch i:1246
learning rate: 0.0013333333333333333, loss: 2.7190561294555664
batch i:1247
learning rate: 0.0013333333333333333, loss: 2.727700710296631
batch i:1248
learning rate: 0.0013333333333333333, loss: 2.69456148147583
batch i:1249
learning rate: 0.0013333333333333333, loss: 2.77439546585083
batch i:1250
learning rate: 0.0013333333333333333, loss: 2.7817015647888184
current self-play batch: 1250
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 224.26291484832763
batch i:1251
learning rate: 0.0013333333333333333, loss: 2.7708640098571777
batch i:1252
learning rate: 0.0013333333333333333, loss: 2.7638936042785645
batch i:1253
learning rate: 0.0013333333333333333, loss: 2.749239444732666
batch i:1254
learning rate: 0.0013333333333333333, loss: 2.6478874683380127
batch i:1255
learning rate: 0.0013333333333333333, loss: 2.7017321586608887
batch i:1256
learning rate: 0.0013333333333333333, loss: 2.6824874877929688
batch i:1257
learning rate: 0.0013333333333333333, loss: 2.66062068939209
batch i:1258
learning rate: 0.0013333333333333333, loss: 2.7351858615875244
batch i:1259
learning rate: 0.0013333333333333333, loss: 2.7246603965759277
batch i:1260
learning rate: 0.0013333333333333333, loss: 2.563634157180786
batch i:1261
learning rate: 0.0013333333333333333, loss: 2.7651028633117676
batch i:1262
learning rate: 0.0013333333333333333, loss: 2.7164974212646484
batch i:1263
learning rate: 0.0013333333333333333, loss: 2.675874948501587
batch i:1264
learning rate: 0.0013333333333333333, loss: 2.7703747749328613
batch i:1265
learning rate: 0.0013333333333333333, loss: 2.623028516769409
batch i:1266
learning rate: 0.0013333333333333333, loss: 2.6268889904022217
batch i:1267
learning rate: 0.0013333333333333333, loss: 2.6596832275390625
batch i:1268
learning rate: 0.0013333333333333333, loss: 2.6110482215881348
batch i:1269
learning rate: 0.0013333333333333333, loss: 2.6849164962768555
batch i:1270
learning rate: 0.0013333333333333333, loss: 2.748203754425049
batch i:1271
learning rate: 0.0013333333333333333, loss: 2.6640496253967285
batch i:1272
learning rate: 0.0013333333333333333, loss: 2.69626784324646
batch i:1273
learning rate: 0.0013333333333333333, loss: 2.691497802734375
batch i:1274
learning rate: 0.0013333333333333333, loss: 2.747926712036133
batch i:1275
learning rate: 0.0013333333333333333, loss: 2.630913496017456
batch i:1276
learning rate: 0.0013333333333333333, loss: 2.6402409076690674
batch i:1277
learning rate: 0.0013333333333333333, loss: 2.6995604038238525
batch i:1278
learning rate: 0.0013333333333333333, loss: 2.603236675262451
batch i:1279
learning rate: 0.0013333333333333333, loss: 2.63931941986084
batch i:1280
learning rate: 0.0013333333333333333, loss: 2.671224355697632
batch i:1281
learning rate: 0.0013333333333333333, loss: 2.681751251220703
batch i:1282
learning rate: 0.0013333333333333333, loss: 2.6586546897888184
batch i:1283
learning rate: 0.0013333333333333333, loss: 2.6645541191101074
batch i:1284
learning rate: 0.0013333333333333333, loss: 2.687276840209961
batch i:1285
learning rate: 0.0013333333333333333, loss: 2.6234471797943115
batch i:1286
learning rate: 0.0013333333333333333, loss: 2.733638286590576
batch i:1287
learning rate: 0.0013333333333333333, loss: 2.764148712158203
batch i:1288
learning rate: 0.0013333333333333333, loss: 2.716810941696167
batch i:1289
learning rate: 0.0013333333333333333, loss: 2.7196125984191895
batch i:1290
learning rate: 0.0013333333333333333, loss: 2.6293230056762695
batch i:1291
learning rate: 0.0013333333333333333, loss: 2.737121105194092
batch i:1292
learning rate: 0.0013333333333333333, loss: 2.680964946746826
batch i:1293
learning rate: 0.0013333333333333333, loss: 2.697500228881836
batch i:1294
learning rate: 0.0013333333333333333, loss: 2.7293357849121094
batch i:1295
learning rate: 0.0013333333333333333, loss: 2.5866806507110596
batch i:1296
learning rate: 0.0013333333333333333, loss: 2.695301055908203
batch i:1297
learning rate: 0.0013333333333333333, loss: 2.6097049713134766
batch i:1298
learning rate: 0.0013333333333333333, loss: 2.695110321044922
batch i:1299
learning rate: 0.0013333333333333333, loss: 2.6662912368774414
batch i:1300
learning rate: 0.0013333333333333333, loss: 2.691784143447876
current self-play batch: 1300
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 164.76237332820892
batch i:1301
learning rate: 0.0013333333333333333, loss: 2.7277538776397705
batch i:1302
learning rate: 0.0013333333333333333, loss: 2.796785593032837
batch i:1303
learning rate: 0.0013333333333333333, loss: 2.7425856590270996
batch i:1304
learning rate: 0.0013333333333333333, loss: 2.6751580238342285
batch i:1305
learning rate: 0.0013333333333333333, loss: 2.774174690246582
batch i:1306
learning rate: 0.0013333333333333333, loss: 2.6963372230529785
batch i:1307
learning rate: 0.0013333333333333333, loss: 2.724865436553955
batch i:1308
learning rate: 0.0013333333333333333, loss: 2.668768882751465
batch i:1309
learning rate: 0.0013333333333333333, loss: 2.663407325744629
batch i:1310
learning rate: 0.0013333333333333333, loss: 2.6868114471435547
batch i:1311
learning rate: 0.0013333333333333333, loss: 2.7459399700164795
batch i:1312
learning rate: 0.0013333333333333333, loss: 2.7633702754974365
batch i:1313
learning rate: 0.0013333333333333333, loss: 2.732222080230713
batch i:1314
learning rate: 0.0013333333333333333, loss: 2.7750091552734375
batch i:1315
learning rate: 0.0013333333333333333, loss: 2.790266513824463
batch i:1316
learning rate: 0.0013333333333333333, loss: 2.727914333343506
batch i:1317
learning rate: 0.0013333333333333333, loss: 2.7398438453674316
batch i:1318
learning rate: 0.0013333333333333333, loss: 2.7925829887390137
batch i:1319
learning rate: 0.0013333333333333333, loss: 2.835073947906494
batch i:1320
learning rate: 0.0013333333333333333, loss: 2.8413562774658203
batch i:1321
learning rate: 0.0013333333333333333, loss: 2.790809154510498
batch i:1322
learning rate: 0.0013333333333333333, loss: 2.805412769317627
batch i:1323
learning rate: 0.0013333333333333333, loss: 2.7841107845306396
batch i:1324
learning rate: 0.0013333333333333333, loss: 2.711686372756958
batch i:1325
learning rate: 0.0013333333333333333, loss: 2.7655811309814453
batch i:1326
learning rate: 0.0013333333333333333, loss: 2.7767958641052246
batch i:1327
learning rate: 0.0013333333333333333, loss: 2.811675548553467
batch i:1328
learning rate: 0.0013333333333333333, loss: 2.8188018798828125
batch i:1329
learning rate: 0.0013333333333333333, loss: 2.8059520721435547
batch i:1330
learning rate: 0.0013333333333333333, loss: 2.843423843383789
batch i:1331
learning rate: 0.0013333333333333333, loss: 2.828533172607422
batch i:1332
learning rate: 0.0013333333333333333, loss: 2.844853401184082
batch i:1333
learning rate: 0.0013333333333333333, loss: 2.7849087715148926
batch i:1334
learning rate: 0.0013333333333333333, loss: 2.768785238265991
batch i:1335
learning rate: 0.0013333333333333333, loss: 2.786611557006836
batch i:1336
learning rate: 0.0013333333333333333, loss: 2.7375760078430176
batch i:1337
learning rate: 0.0013333333333333333, loss: 2.7477543354034424
batch i:1338
learning rate: 0.0013333333333333333, loss: 2.695714235305786
batch i:1339
learning rate: 0.0013333333333333333, loss: 2.760530948638916
batch i:1340
learning rate: 0.0013333333333333333, loss: 2.7472901344299316
batch i:1341
learning rate: 0.0013333333333333333, loss: 2.6686596870422363
batch i:1342
learning rate: 0.0013333333333333333, loss: 2.7384982109069824
batch i:1343
learning rate: 0.0013333333333333333, loss: 2.676279067993164
batch i:1344
learning rate: 0.0013333333333333333, loss: 2.7601075172424316
batch i:1345
learning rate: 0.0013333333333333333, loss: 2.657707452774048
batch i:1346
learning rate: 0.0013333333333333333, loss: 2.859442710876465
batch i:1347
learning rate: 0.0013333333333333333, loss: 2.6994097232818604
batch i:1348
learning rate: 0.0013333333333333333, loss: 2.7057836055755615
batch i:1349
learning rate: 0.0013333333333333333, loss: 2.706864356994629
batch i:1350
learning rate: 0.0013333333333333333, loss: 2.7503433227539062
current self-play batch: 1350
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 170.7787181377411
batch i:1351
learning rate: 0.0013333333333333333, loss: 2.6065845489501953
batch i:1352
learning rate: 0.0013333333333333333, loss: 2.6335771083831787
batch i:1353
learning rate: 0.0013333333333333333, loss: 2.5229597091674805
batch i:1354
learning rate: 0.0013333333333333333, loss: 2.7058892250061035
batch i:1355
learning rate: 0.0013333333333333333, loss: 2.6931095123291016
batch i:1356
learning rate: 0.0013333333333333333, loss: 2.675685405731201
batch i:1357
learning rate: 0.0013333333333333333, loss: 2.7015604972839355
batch i:1358
learning rate: 0.0013333333333333333, loss: 2.7570979595184326
batch i:1359
learning rate: 0.0013333333333333333, loss: 2.7043228149414062
batch i:1360
learning rate: 0.0013333333333333333, loss: 2.743370532989502
batch i:1361
learning rate: 0.0013333333333333333, loss: 2.780696392059326
batch i:1362
learning rate: 0.0013333333333333333, loss: 2.6634931564331055
batch i:1363
learning rate: 0.0013333333333333333, loss: 2.6836256980895996
batch i:1364
learning rate: 0.0013333333333333333, loss: 2.680842638015747
batch i:1365
learning rate: 0.0013333333333333333, loss: 2.6537857055664062
batch i:1366
learning rate: 0.0013333333333333333, loss: 2.6378426551818848
batch i:1367
learning rate: 0.0013333333333333333, loss: 2.6927618980407715
batch i:1368
learning rate: 0.0013333333333333333, loss: 2.790767192840576
batch i:1369
learning rate: 0.0013333333333333333, loss: 2.6421303749084473
batch i:1370
learning rate: 0.0013333333333333333, loss: 2.7122445106506348
batch i:1371
learning rate: 0.0013333333333333333, loss: 2.6964111328125
batch i:1372
learning rate: 0.0013333333333333333, loss: 2.6786842346191406
batch i:1373
learning rate: 0.0013333333333333333, loss: 2.7090535163879395
batch i:1374
learning rate: 0.0013333333333333333, loss: 2.6256027221679688
batch i:1375
learning rate: 0.0013333333333333333, loss: 2.793437957763672
batch i:1376
learning rate: 0.0013333333333333333, loss: 2.7488043308258057
batch i:1377
learning rate: 0.0013333333333333333, loss: 2.588935136795044
batch i:1378
learning rate: 0.0013333333333333333, loss: 2.727992057800293
batch i:1379
learning rate: 0.0013333333333333333, loss: 2.821659564971924
batch i:1380
learning rate: 0.0013333333333333333, loss: 2.67465877532959
batch i:1381
learning rate: 0.0013333333333333333, loss: 2.7270381450653076
batch i:1382
learning rate: 0.0013333333333333333, loss: 2.7005841732025146
batch i:1383
learning rate: 0.0013333333333333333, loss: 2.714688777923584
batch i:1384
learning rate: 0.0013333333333333333, loss: 2.6133780479431152
batch i:1385
learning rate: 0.0013333333333333333, loss: 2.6728272438049316
batch i:1386
learning rate: 0.0013333333333333333, loss: 2.7125062942504883
batch i:1387
learning rate: 0.0013333333333333333, loss: 2.723228931427002
batch i:1388
learning rate: 0.0013333333333333333, loss: 2.6820931434631348
batch i:1389
learning rate: 0.0013333333333333333, loss: 2.671848773956299
batch i:1390
learning rate: 0.0013333333333333333, loss: 2.718837261199951
batch i:1391
learning rate: 0.0013333333333333333, loss: 2.7391016483306885
batch i:1392
learning rate: 0.0013333333333333333, loss: 2.7426154613494873
batch i:1393
learning rate: 0.0013333333333333333, loss: 2.7468061447143555
batch i:1394
learning rate: 0.0013333333333333333, loss: 2.7413763999938965
batch i:1395
learning rate: 0.0013333333333333333, loss: 2.693241596221924
batch i:1396
learning rate: 0.0013333333333333333, loss: 2.649437427520752
batch i:1397
learning rate: 0.0013333333333333333, loss: 2.5678586959838867
batch i:1398
learning rate: 0.0013333333333333333, loss: 2.718756914138794
batch i:1399
learning rate: 0.0013333333333333333, loss: 2.6937942504882812
batch i:1400
learning rate: 0.0013333333333333333, loss: 2.712543249130249
current self-play batch: 1400
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 174.0401356935501
batch i:1401
learning rate: 0.0013333333333333333, loss: 2.738892078399658
batch i:1402
learning rate: 0.0013333333333333333, loss: 2.718059539794922
batch i:1403
learning rate: 0.0013333333333333333, loss: 2.753763198852539
batch i:1404
learning rate: 0.0013333333333333333, loss: 2.7295236587524414
batch i:1405
learning rate: 0.0013333333333333333, loss: 2.824552059173584
batch i:1406
learning rate: 0.0013333333333333333, loss: 2.8049981594085693
batch i:1407
learning rate: 0.0013333333333333333, loss: 2.9211459159851074
batch i:1408
learning rate: 0.0013333333333333333, loss: 2.893946886062622
batch i:1409
learning rate: 0.0013333333333333333, loss: 2.7157583236694336
batch i:1410
learning rate: 0.0013333333333333333, loss: 2.852980136871338
batch i:1411
learning rate: 0.0013333333333333333, loss: 2.7974817752838135
batch i:1412
learning rate: 0.0013333333333333333, loss: 2.720731735229492
batch i:1413
learning rate: 0.0013333333333333333, loss: 2.8274316787719727
batch i:1414
learning rate: 0.0013333333333333333, loss: 2.705153465270996
batch i:1415
learning rate: 0.0013333333333333333, loss: 2.7919254302978516
batch i:1416
learning rate: 0.0013333333333333333, loss: 2.726337194442749
batch i:1417
learning rate: 0.0013333333333333333, loss: 2.8961901664733887
batch i:1418
learning rate: 0.0013333333333333333, loss: 2.7884151935577393
batch i:1419
learning rate: 0.0013333333333333333, loss: 2.8431644439697266
batch i:1420
learning rate: 0.0013333333333333333, loss: 2.8303840160369873
batch i:1421
learning rate: 0.0013333333333333333, loss: 2.9090757369995117
batch i:1422
learning rate: 0.0013333333333333333, loss: 2.893437385559082
batch i:1423
learning rate: 0.0013333333333333333, loss: 2.8304309844970703
batch i:1424
learning rate: 0.0013333333333333333, loss: 2.8862664699554443
batch i:1425
learning rate: 0.0013333333333333333, loss: 2.744579553604126
batch i:1426
learning rate: 0.0013333333333333333, loss: 2.8522849082946777
batch i:1427
learning rate: 0.0013333333333333333, loss: 2.880195379257202
batch i:1428
learning rate: 0.0013333333333333333, loss: 2.77313232421875
batch i:1429
learning rate: 0.0013333333333333333, loss: 2.719545841217041
batch i:1430
learning rate: 0.0013333333333333333, loss: 2.871443271636963
batch i:1431
learning rate: 0.0013333333333333333, loss: 2.7845191955566406
batch i:1432
learning rate: 0.0013333333333333333, loss: 2.830639600753784
batch i:1433
learning rate: 0.0013333333333333333, loss: 2.837372303009033
batch i:1434
learning rate: 0.0013333333333333333, loss: 2.7129924297332764
batch i:1435
learning rate: 0.0013333333333333333, loss: 2.8089733123779297
batch i:1436
learning rate: 0.0013333333333333333, loss: 2.890619993209839
batch i:1437
learning rate: 0.0013333333333333333, loss: 2.8617382049560547
batch i:1438
learning rate: 0.0013333333333333333, loss: 2.825303077697754
batch i:1439
learning rate: 0.0013333333333333333, loss: 2.7583823204040527
batch i:1440
learning rate: 0.0013333333333333333, loss: 2.8272387981414795
batch i:1441
learning rate: 0.0013333333333333333, loss: 2.7823588848114014
batch i:1442
learning rate: 0.0013333333333333333, loss: 2.90818452835083
batch i:1443
learning rate: 0.0013333333333333333, loss: 2.747605323791504
batch i:1444
learning rate: 0.0013333333333333333, loss: 2.6790425777435303
batch i:1445
learning rate: 0.0013333333333333333, loss: 2.7776966094970703
batch i:1446
learning rate: 0.0013333333333333333, loss: 2.7832188606262207
batch i:1447
learning rate: 0.0013333333333333333, loss: 2.811807155609131
batch i:1448
learning rate: 0.0013333333333333333, loss: 2.7599291801452637
batch i:1449
learning rate: 0.0013333333333333333, loss: 2.827366352081299
batch i:1450
learning rate: 0.0013333333333333333, loss: 2.7835853099823
current self-play batch: 1450
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 202.8316555738449
batch i:1451
learning rate: 0.0013333333333333333, loss: 2.9267826080322266
batch i:1452
learning rate: 0.0013333333333333333, loss: 2.790052890777588
batch i:1453
learning rate: 0.0013333333333333333, loss: 2.844289779663086
batch i:1454
learning rate: 0.0013333333333333333, loss: 2.923027753829956
batch i:1455
learning rate: 0.0013333333333333333, loss: 2.83294939994812
batch i:1456
learning rate: 0.0013333333333333333, loss: 2.7670793533325195
batch i:1457
learning rate: 0.0013333333333333333, loss: 3.0153849124908447
batch i:1458
learning rate: 0.0013333333333333333, loss: 2.8471012115478516
batch i:1459
learning rate: 0.0013333333333333333, loss: 2.8303298950195312
batch i:1460
learning rate: 0.0013333333333333333, loss: 2.8525123596191406
batch i:1461
learning rate: 0.0013333333333333333, loss: 2.8862338066101074
batch i:1462
learning rate: 0.0013333333333333333, loss: 2.769619941711426
batch i:1463
learning rate: 0.0013333333333333333, loss: 2.980698585510254
batch i:1464
learning rate: 0.0013333333333333333, loss: 2.8224222660064697
batch i:1465
learning rate: 0.0013333333333333333, loss: 2.9756321907043457
batch i:1466
learning rate: 0.0013333333333333333, loss: 2.9222965240478516
batch i:1467
learning rate: 0.0013333333333333333, loss: 2.8190081119537354
batch i:1468
learning rate: 0.0013333333333333333, loss: 2.9276559352874756
batch i:1469
learning rate: 0.0013333333333333333, loss: 2.8901326656341553
batch i:1470
learning rate: 0.0013333333333333333, loss: 2.9213128089904785
batch i:1471
learning rate: 0.0013333333333333333, loss: 2.989170789718628
batch i:1472
learning rate: 0.0013333333333333333, loss: 2.8527026176452637
batch i:1473
learning rate: 0.0013333333333333333, loss: 2.9386091232299805
batch i:1474
learning rate: 0.0013333333333333333, loss: 2.9152379035949707
batch i:1475
learning rate: 0.0013333333333333333, loss: 2.9206595420837402
batch i:1476
learning rate: 0.0013333333333333333, loss: 2.9060921669006348
batch i:1477
learning rate: 0.0013333333333333333, loss: 2.9038991928100586
batch i:1478
learning rate: 0.0013333333333333333, loss: 2.952030658721924
batch i:1479
learning rate: 0.0013333333333333333, loss: 2.9707870483398438
batch i:1480
learning rate: 0.0013333333333333333, loss: 2.9573135375976562
batch i:1481
learning rate: 0.0013333333333333333, loss: 2.976937770843506
batch i:1482
learning rate: 0.0013333333333333333, loss: 2.88948392868042
batch i:1483
learning rate: 0.0013333333333333333, loss: 2.895382881164551
batch i:1484
learning rate: 0.0013333333333333333, loss: 2.9970645904541016
batch i:1485
learning rate: 0.0013333333333333333, loss: 2.8858554363250732
batch i:1486
learning rate: 0.0013333333333333333, loss: 2.9747703075408936
batch i:1487
learning rate: 0.0013333333333333333, loss: 2.9005649089813232
batch i:1488
learning rate: 0.0013333333333333333, loss: 2.8488192558288574
batch i:1489
learning rate: 0.0013333333333333333, loss: 2.9392096996307373
batch i:1490
learning rate: 0.0013333333333333333, loss: 2.8396849632263184
batch i:1491
learning rate: 0.0013333333333333333, loss: 2.936540126800537
batch i:1492
learning rate: 0.0013333333333333333, loss: 2.9475936889648438
batch i:1493
learning rate: 0.0013333333333333333, loss: 2.9912209510803223
batch i:1494
learning rate: 0.0013333333333333333, loss: 3.0099411010742188
batch i:1495
learning rate: 0.0013333333333333333, loss: 2.861051559448242
batch i:1496
learning rate: 0.0013333333333333333, loss: 2.880296230316162
batch i:1497
learning rate: 0.0013333333333333333, loss: 2.908597707748413
batch i:1498
learning rate: 0.0013333333333333333, loss: 2.9872899055480957
batch i:1499
learning rate: 0.0013333333333333333, loss: 2.9155588150024414
batch i:1500
learning rate: 0.0013333333333333333, loss: 2.8442835807800293
current self-play batch: 1500
num_playouts:2000, win: 6, lose: 4, tie:0
average time: 223.4985142469406
