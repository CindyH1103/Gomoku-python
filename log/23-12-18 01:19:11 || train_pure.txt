Start time: 2023-12-18 01:19:11.655464
batch i:1
batch i:2
learning rate: 0.0013333333333333333, loss: 5.120057106018066
batch i:3
learning rate: 0.0013333333333333333, loss: 4.801865577697754
batch i:4
learning rate: 0.0013333333333333333, loss: 4.577478885650635
batch i:5
learning rate: 0.0013333333333333333, loss: 4.81395149230957
batch i:6
learning rate: 0.0013333333333333333, loss: 4.640916347503662
batch i:7
learning rate: 0.0013333333333333333, loss: 4.550732612609863
batch i:8
learning rate: 0.0013333333333333333, loss: 4.483900547027588
batch i:9
learning rate: 0.0013333333333333333, loss: 4.419816970825195
batch i:10
learning rate: 0.0013333333333333333, loss: 4.54135274887085
batch i:11
learning rate: 0.0013333333333333333, loss: 4.372568130493164
batch i:12
learning rate: 0.0013333333333333333, loss: 4.307879447937012
batch i:13
learning rate: 0.0013333333333333333, loss: 4.254246234893799
batch i:14
learning rate: 0.0013333333333333333, loss: 4.260138511657715
batch i:15
learning rate: 0.0013333333333333333, loss: 4.209688663482666
batch i:16
learning rate: 0.0013333333333333333, loss: 4.168247222900391
batch i:17
learning rate: 0.0013333333333333333, loss: 4.226917743682861
batch i:18
learning rate: 0.0013333333333333333, loss: 4.197384834289551
batch i:19
learning rate: 0.0013333333333333333, loss: 4.241661548614502
batch i:20
learning rate: 0.0013333333333333333, loss: 4.305401802062988
batch i:21
learning rate: 0.0013333333333333333, loss: 4.271612167358398
batch i:22
learning rate: 0.0013333333333333333, loss: 4.324099063873291
batch i:23
learning rate: 0.0013333333333333333, loss: 4.376982688903809
batch i:24
learning rate: 0.0013333333333333333, loss: 4.416996479034424
batch i:25
learning rate: 0.0013333333333333333, loss: 4.406494140625
batch i:26
learning rate: 0.0013333333333333333, loss: 4.480975151062012
batch i:27
learning rate: 0.0013333333333333333, loss: 4.435567855834961
batch i:28
learning rate: 0.0013333333333333333, loss: 4.292816638946533
batch i:29
learning rate: 0.0013333333333333333, loss: 4.33174991607666
batch i:30
learning rate: 0.0013333333333333333, loss: 4.303942680358887
batch i:31
learning rate: 0.0013333333333333333, loss: 4.244166374206543
batch i:32
learning rate: 0.0013333333333333333, loss: 4.194809436798096
batch i:33
learning rate: 0.0013333333333333333, loss: 4.181917667388916
batch i:34
learning rate: 0.0013333333333333333, loss: 4.154172897338867
batch i:35
learning rate: 0.0013333333333333333, loss: 4.166619300842285
batch i:36
learning rate: 0.0008888888888888888, loss: 4.082424163818359
batch i:37
learning rate: 0.0008888888888888888, loss: 4.2366437911987305
batch i:38
learning rate: 0.0008888888888888888, loss: 4.136139869689941
batch i:39
learning rate: 0.0008888888888888888, loss: 4.171473503112793
batch i:40
learning rate: 0.0008888888888888888, loss: 4.160950660705566
batch i:41
learning rate: 0.0013333333333333333, loss: 4.17601203918457
batch i:42
learning rate: 0.0013333333333333333, loss: 4.180452346801758
batch i:43
learning rate: 0.0013333333333333333, loss: 4.077179908752441
batch i:44
learning rate: 0.0013333333333333333, loss: 4.074921607971191
batch i:45
learning rate: 0.0013333333333333333, loss: 4.047722339630127
batch i:46
learning rate: 0.0013333333333333333, loss: 4.009234428405762
batch i:47
learning rate: 0.0013333333333333333, loss: 3.926840305328369
batch i:48
learning rate: 0.0013333333333333333, loss: 4.088152885437012
batch i:49
learning rate: 0.0013333333333333333, loss: 3.9931466579437256
batch i:50
learning rate: 0.0013333333333333333, loss: 3.9697999954223633
current self-play batch: 50
num_playouts:1000, win: 1, lose: 9, tie:0
average time: 61.870863342285155
New best policy from pure MCTS
batch i:51
learning rate: 0.0013333333333333333, loss: 4.017056465148926
batch i:52
learning rate: 0.0013333333333333333, loss: 4.037642478942871
batch i:53
learning rate: 0.0013333333333333333, loss: 4.041121482849121
batch i:54
learning rate: 0.0013333333333333333, loss: 3.932313919067383
batch i:55
learning rate: 0.0013333333333333333, loss: 3.905670166015625
batch i:56
learning rate: 0.0013333333333333333, loss: 4.061697006225586
batch i:57
learning rate: 0.0013333333333333333, loss: 4.012535095214844
batch i:58
learning rate: 0.0013333333333333333, loss: 3.891989231109619
batch i:59
learning rate: 0.0013333333333333333, loss: 3.9600346088409424
batch i:60
learning rate: 0.0013333333333333333, loss: 3.872288227081299
batch i:61
learning rate: 0.0013333333333333333, loss: 3.9548962116241455
batch i:62
learning rate: 0.0013333333333333333, loss: 3.953361988067627
batch i:63
learning rate: 0.0013333333333333333, loss: 3.8721749782562256
batch i:64
learning rate: 0.0013333333333333333, loss: 3.9273505210876465
batch i:65
learning rate: 0.0013333333333333333, loss: 3.9456284046173096
batch i:66
learning rate: 0.0013333333333333333, loss: 3.870365619659424
batch i:67
learning rate: 0.0013333333333333333, loss: 3.976778268814087
batch i:68
learning rate: 0.0013333333333333333, loss: 3.938634157180786
batch i:69
learning rate: 0.0013333333333333333, loss: 4.031315326690674
batch i:70
learning rate: 0.0013333333333333333, loss: 3.9980125427246094
batch i:71
learning rate: 0.0013333333333333333, loss: 4.009713172912598
batch i:72
learning rate: 0.0013333333333333333, loss: 4.035759449005127
batch i:73
learning rate: 0.0013333333333333333, loss: 4.020333766937256
batch i:74
learning rate: 0.0013333333333333333, loss: 3.9831838607788086
batch i:75
learning rate: 0.0013333333333333333, loss: 4.036488056182861
batch i:76
learning rate: 0.0013333333333333333, loss: 3.997957229614258
batch i:77
learning rate: 0.0013333333333333333, loss: 4.030857086181641
batch i:78
learning rate: 0.0013333333333333333, loss: 4.059552192687988
batch i:79
learning rate: 0.0013333333333333333, loss: 3.9902119636535645
batch i:80
learning rate: 0.0013333333333333333, loss: 3.960111141204834
batch i:81
learning rate: 0.0013333333333333333, loss: 3.9233145713806152
batch i:82
learning rate: 0.0013333333333333333, loss: 3.933293342590332
batch i:83
learning rate: 0.0013333333333333333, loss: 3.9278008937835693
batch i:84
learning rate: 0.0013333333333333333, loss: 3.895735025405884
batch i:85
learning rate: 0.0013333333333333333, loss: 3.8624606132507324
batch i:86
learning rate: 0.0013333333333333333, loss: 3.8283278942108154
batch i:87
learning rate: 0.0013333333333333333, loss: 3.968336820602417
batch i:88
learning rate: 0.0013333333333333333, loss: 3.900573253631592
batch i:89
learning rate: 0.0013333333333333333, loss: 3.902251958847046
batch i:90
learning rate: 0.0013333333333333333, loss: 3.852146625518799
batch i:91
learning rate: 0.0013333333333333333, loss: 3.827784538269043
batch i:92
learning rate: 0.0013333333333333333, loss: 3.826298236846924
batch i:93
learning rate: 0.0013333333333333333, loss: 3.8319995403289795
batch i:94
learning rate: 0.0013333333333333333, loss: 3.862438917160034
batch i:95
learning rate: 0.0013333333333333333, loss: 3.8228654861450195
batch i:96
learning rate: 0.0013333333333333333, loss: 3.8163530826568604
batch i:97
learning rate: 0.0013333333333333333, loss: 3.7781877517700195
batch i:98
learning rate: 0.0013333333333333333, loss: 3.7184090614318848
batch i:99
learning rate: 0.0013333333333333333, loss: 3.783994197845459
batch i:100
learning rate: 0.0013333333333333333, loss: 3.7751851081848145
current self-play batch: 100
num_playouts:1000, win: 6, lose: 4, tie:0
average time: 79.33055245876312
New best policy from pure MCTS
batch i:101
learning rate: 0.0013333333333333333, loss: 3.7637462615966797
batch i:102
learning rate: 0.0013333333333333333, loss: 3.6907472610473633
batch i:103
learning rate: 0.0013333333333333333, loss: 3.7325356006622314
batch i:104
learning rate: 0.0013333333333333333, loss: 3.7689757347106934
batch i:105
learning rate: 0.0013333333333333333, loss: 3.6654584407806396
batch i:106
learning rate: 0.0013333333333333333, loss: 3.668822765350342
batch i:107
learning rate: 0.0013333333333333333, loss: 3.6894218921661377
batch i:108
learning rate: 0.0013333333333333333, loss: 3.659137725830078
batch i:109
learning rate: 0.0013333333333333333, loss: 3.824954032897949
batch i:110
learning rate: 0.0013333333333333333, loss: 3.785592555999756
batch i:111
learning rate: 0.0013333333333333333, loss: 3.7123961448669434
batch i:112
learning rate: 0.0013333333333333333, loss: 3.755317211151123
batch i:113
learning rate: 0.0013333333333333333, loss: 3.7089362144470215
batch i:114
learning rate: 0.0013333333333333333, loss: 3.698760509490967
batch i:115
learning rate: 0.0013333333333333333, loss: 3.669590473175049
batch i:116
learning rate: 0.0013333333333333333, loss: 3.640103816986084
batch i:117
learning rate: 0.0013333333333333333, loss: 3.765761613845825
batch i:118
learning rate: 0.0013333333333333333, loss: 3.6404738426208496
batch i:119
learning rate: 0.0013333333333333333, loss: 3.5595855712890625
batch i:120
learning rate: 0.0013333333333333333, loss: 3.5631628036499023
batch i:121
learning rate: 0.0013333333333333333, loss: 3.5458946228027344
batch i:122
learning rate: 0.0013333333333333333, loss: 3.5819787979125977
batch i:123
learning rate: 0.0013333333333333333, loss: 3.588606595993042
batch i:124
learning rate: 0.0013333333333333333, loss: 3.471393585205078
batch i:125
learning rate: 0.0013333333333333333, loss: 3.5113234519958496
batch i:126
learning rate: 0.0013333333333333333, loss: 3.438145637512207
batch i:127
learning rate: 0.0013333333333333333, loss: 3.340329170227051
batch i:128
learning rate: 0.0013333333333333333, loss: 3.3889079093933105
batch i:129
learning rate: 0.0013333333333333333, loss: 3.3797168731689453
batch i:130
learning rate: 0.0013333333333333333, loss: 3.393075466156006
batch i:131
learning rate: 0.0013333333333333333, loss: 3.3546013832092285
batch i:132
learning rate: 0.0013333333333333333, loss: 3.3839383125305176
batch i:133
learning rate: 0.0013333333333333333, loss: 3.395301342010498
batch i:134
learning rate: 0.0013333333333333333, loss: 3.353027105331421
batch i:135
learning rate: 0.0013333333333333333, loss: 3.370652437210083
batch i:136
learning rate: 0.0013333333333333333, loss: 3.2297983169555664
batch i:137
learning rate: 0.0013333333333333333, loss: 3.3305716514587402
batch i:138
learning rate: 0.0013333333333333333, loss: 3.4153690338134766
batch i:139
learning rate: 0.0013333333333333333, loss: 3.334836483001709
batch i:140
learning rate: 0.0013333333333333333, loss: 3.403545618057251
batch i:141
learning rate: 0.0013333333333333333, loss: 3.4166178703308105
batch i:142
learning rate: 0.0013333333333333333, loss: 3.364861249923706
batch i:143
learning rate: 0.0013333333333333333, loss: 3.3227436542510986
batch i:144
learning rate: 0.0013333333333333333, loss: 3.38993501663208
batch i:145
learning rate: 0.0013333333333333333, loss: 3.33953595161438
batch i:146
learning rate: 0.0013333333333333333, loss: 3.3945446014404297
batch i:147
learning rate: 0.0013333333333333333, loss: 3.3234598636627197
batch i:148
learning rate: 0.0013333333333333333, loss: 3.2986574172973633
batch i:149
learning rate: 0.0013333333333333333, loss: 3.325880765914917
batch i:150
learning rate: 0.0013333333333333333, loss: 3.390815258026123
current self-play batch: 150
num_playouts:1000, win: 6, lose: 4, tie:0
average time: 71.2391685962677
batch i:151
learning rate: 0.0013333333333333333, loss: 3.391585350036621
batch i:152
learning rate: 0.0013333333333333333, loss: 3.470227003097534
batch i:153
learning rate: 0.0013333333333333333, loss: 3.377531051635742
batch i:154
learning rate: 0.0013333333333333333, loss: 3.340174913406372
batch i:155
learning rate: 0.0013333333333333333, loss: 3.447904348373413
batch i:156
learning rate: 0.0013333333333333333, loss: 3.394667148590088
batch i:157
learning rate: 0.0013333333333333333, loss: 3.4289169311523438
batch i:158
learning rate: 0.0013333333333333333, loss: 3.412762403488159
batch i:159
learning rate: 0.0013333333333333333, loss: 3.476675510406494
batch i:160
learning rate: 0.0013333333333333333, loss: 3.4878218173980713
batch i:161
learning rate: 0.0013333333333333333, loss: 3.4250571727752686
batch i:162
learning rate: 0.0013333333333333333, loss: 3.4909470081329346
batch i:163
learning rate: 0.0013333333333333333, loss: 3.5832388401031494
batch i:164
learning rate: 0.0013333333333333333, loss: 3.5544276237487793
batch i:165
learning rate: 0.0013333333333333333, loss: 3.635192394256592
batch i:166
learning rate: 0.0013333333333333333, loss: 3.6288979053497314
batch i:167
learning rate: 0.0013333333333333333, loss: 3.5415425300598145
batch i:168
learning rate: 0.0013333333333333333, loss: 3.549008846282959
batch i:169
learning rate: 0.0013333333333333333, loss: 3.483604907989502
batch i:170
learning rate: 0.0013333333333333333, loss: 3.4853172302246094
batch i:171
learning rate: 0.0013333333333333333, loss: 3.515619993209839
batch i:172
learning rate: 0.0013333333333333333, loss: 3.471342086791992
batch i:173
learning rate: 0.0013333333333333333, loss: 3.5284554958343506
batch i:174
learning rate: 0.0013333333333333333, loss: 3.481985092163086
batch i:175
learning rate: 0.0013333333333333333, loss: 3.422240972518921
batch i:176
learning rate: 0.0013333333333333333, loss: 3.4787065982818604
batch i:177
learning rate: 0.0013333333333333333, loss: 3.510709762573242
batch i:178
learning rate: 0.0013333333333333333, loss: 3.4204795360565186
batch i:179
learning rate: 0.0013333333333333333, loss: 3.422529697418213
batch i:180
learning rate: 0.0013333333333333333, loss: 3.4588537216186523
batch i:181
learning rate: 0.0013333333333333333, loss: 3.331275463104248
batch i:182
learning rate: 0.0013333333333333333, loss: 3.385310649871826
batch i:183
learning rate: 0.0013333333333333333, loss: 3.450171709060669
batch i:184
learning rate: 0.0013333333333333333, loss: 3.4911084175109863
batch i:185
learning rate: 0.0013333333333333333, loss: 3.4063668251037598
batch i:186
learning rate: 0.0013333333333333333, loss: 3.451809883117676
batch i:187
learning rate: 0.0013333333333333333, loss: 3.434812545776367
batch i:188
learning rate: 0.0013333333333333333, loss: 3.3638081550598145
batch i:189
learning rate: 0.0013333333333333333, loss: 3.4346704483032227
batch i:190
learning rate: 0.0013333333333333333, loss: 3.461412191390991
batch i:191
learning rate: 0.0013333333333333333, loss: 3.3829784393310547
batch i:192
learning rate: 0.0013333333333333333, loss: 3.4253430366516113
batch i:193
learning rate: 0.0013333333333333333, loss: 3.4469351768493652
batch i:194
learning rate: 0.0013333333333333333, loss: 3.3911526203155518
batch i:195
learning rate: 0.0013333333333333333, loss: 3.537970542907715
batch i:196
learning rate: 0.0013333333333333333, loss: 3.438720464706421
batch i:197
learning rate: 0.0013333333333333333, loss: 3.4676766395568848
batch i:198
learning rate: 0.0013333333333333333, loss: 3.509521484375
batch i:199
learning rate: 0.0013333333333333333, loss: 3.510112762451172
batch i:200
learning rate: 0.0013333333333333333, loss: 3.5186564922332764
current self-play batch: 200
num_playouts:1000, win: 3, lose: 7, tie:0
average time: 75.37699594497681
batch i:201
learning rate: 0.0013333333333333333, loss: 3.5326051712036133
batch i:202
learning rate: 0.0013333333333333333, loss: 3.4766359329223633
batch i:203
learning rate: 0.0013333333333333333, loss: 3.4287495613098145
batch i:204
learning rate: 0.0013333333333333333, loss: 3.4697012901306152
batch i:205
learning rate: 0.0013333333333333333, loss: 3.467132091522217
batch i:206
learning rate: 0.0013333333333333333, loss: 3.432047128677368
batch i:207
learning rate: 0.0013333333333333333, loss: 3.482707977294922
batch i:208
learning rate: 0.0013333333333333333, loss: 3.5219247341156006
batch i:209
learning rate: 0.0013333333333333333, loss: 3.5191397666931152
batch i:210
learning rate: 0.0013333333333333333, loss: 3.518094778060913
batch i:211
learning rate: 0.0013333333333333333, loss: 3.5032050609588623
batch i:212
learning rate: 0.0013333333333333333, loss: 3.4026436805725098
batch i:213
learning rate: 0.0013333333333333333, loss: 3.363865852355957
batch i:214
learning rate: 0.0013333333333333333, loss: 3.4490315914154053
batch i:215
learning rate: 0.0013333333333333333, loss: 3.423323154449463
batch i:216
learning rate: 0.0013333333333333333, loss: 3.4189555644989014
batch i:217
learning rate: 0.0013333333333333333, loss: 3.358184814453125
batch i:218
learning rate: 0.0013333333333333333, loss: 3.29620361328125
batch i:219
learning rate: 0.0013333333333333333, loss: 3.3529534339904785
batch i:220
learning rate: 0.0013333333333333333, loss: 3.360252857208252
batch i:221
learning rate: 0.0013333333333333333, loss: 3.3850884437561035
batch i:222
learning rate: 0.0013333333333333333, loss: 3.424287796020508
batch i:223
learning rate: 0.0013333333333333333, loss: 3.4736151695251465
batch i:224
learning rate: 0.0013333333333333333, loss: 3.3913021087646484
batch i:225
learning rate: 0.0013333333333333333, loss: 3.3572914600372314
batch i:226
learning rate: 0.0013333333333333333, loss: 3.3862226009368896
batch i:227
learning rate: 0.0013333333333333333, loss: 3.4128599166870117
batch i:228
learning rate: 0.0013333333333333333, loss: 3.3624236583709717
batch i:229
learning rate: 0.0013333333333333333, loss: 3.3561177253723145
batch i:230
learning rate: 0.0013333333333333333, loss: 3.323801040649414
batch i:231
learning rate: 0.0013333333333333333, loss: 3.3836793899536133
batch i:232
learning rate: 0.0013333333333333333, loss: 3.40976619720459
batch i:233
learning rate: 0.0013333333333333333, loss: 3.3413939476013184
batch i:234
learning rate: 0.0013333333333333333, loss: 3.3191819190979004
batch i:235
learning rate: 0.0013333333333333333, loss: 3.276301622390747
batch i:236
learning rate: 0.0013333333333333333, loss: 3.27962064743042
batch i:237
learning rate: 0.0013333333333333333, loss: 3.3613436222076416
batch i:238
learning rate: 0.0013333333333333333, loss: 3.3021655082702637
batch i:239
learning rate: 0.0013333333333333333, loss: 3.360576629638672
batch i:240
learning rate: 0.0013333333333333333, loss: 3.305088996887207
batch i:241
learning rate: 0.0013333333333333333, loss: 3.3433003425598145
batch i:242
learning rate: 0.0013333333333333333, loss: 3.410529375076294
batch i:243
learning rate: 0.0013333333333333333, loss: 3.4324827194213867
batch i:244
learning rate: 0.0013333333333333333, loss: 3.436798572540283
batch i:245
learning rate: 0.0013333333333333333, loss: 3.4430155754089355
batch i:246
learning rate: 0.0013333333333333333, loss: 3.4575564861297607
batch i:247
learning rate: 0.0013333333333333333, loss: 3.4063000679016113
batch i:248
learning rate: 0.0013333333333333333, loss: 3.419436454772949
batch i:249
learning rate: 0.0013333333333333333, loss: 3.4715089797973633
batch i:250
learning rate: 0.0013333333333333333, loss: 3.480600357055664
current self-play batch: 250
num_playouts:1000, win: 4, lose: 6, tie:0
average time: 81.55930571556091
batch i:251
learning rate: 0.0013333333333333333, loss: 3.3790106773376465
batch i:252
learning rate: 0.0013333333333333333, loss: 3.372990846633911
batch i:253
learning rate: 0.0013333333333333333, loss: 3.4324073791503906
batch i:254
learning rate: 0.0013333333333333333, loss: 3.394404888153076
batch i:255
learning rate: 0.0013333333333333333, loss: 3.330087900161743
batch i:256
learning rate: 0.0013333333333333333, loss: 3.4970922470092773
batch i:257
learning rate: 0.0013333333333333333, loss: 3.4502310752868652
batch i:258
learning rate: 0.0013333333333333333, loss: 3.474942684173584
batch i:259
learning rate: 0.0013333333333333333, loss: 3.3955023288726807
batch i:260
learning rate: 0.0013333333333333333, loss: 3.420811414718628
batch i:261
learning rate: 0.0013333333333333333, loss: 3.445725440979004
batch i:262
learning rate: 0.0013333333333333333, loss: 3.414254665374756
batch i:263
learning rate: 0.0013333333333333333, loss: 3.4160656929016113
batch i:264
learning rate: 0.0013333333333333333, loss: 3.464524745941162
batch i:265
learning rate: 0.0013333333333333333, loss: 3.4778800010681152
batch i:266
learning rate: 0.0013333333333333333, loss: 3.40478777885437
batch i:267
learning rate: 0.0013333333333333333, loss: 3.495218515396118
batch i:268
learning rate: 0.0013333333333333333, loss: 3.408566951751709
batch i:269
learning rate: 0.0013333333333333333, loss: 3.497781753540039
batch i:270
learning rate: 0.0013333333333333333, loss: 3.5375866889953613
batch i:271
learning rate: 0.0013333333333333333, loss: 3.402629852294922
batch i:272
learning rate: 0.0013333333333333333, loss: 3.47001576423645
batch i:273
learning rate: 0.0013333333333333333, loss: 3.3643929958343506
batch i:274
learning rate: 0.0013333333333333333, loss: 3.3891868591308594
batch i:275
learning rate: 0.0013333333333333333, loss: 3.387599468231201
batch i:276
learning rate: 0.0013333333333333333, loss: 3.496009349822998
batch i:277
learning rate: 0.0013333333333333333, loss: 3.526474952697754
batch i:278
learning rate: 0.0013333333333333333, loss: 3.421980381011963
batch i:279
learning rate: 0.0013333333333333333, loss: 3.466663360595703
batch i:280
learning rate: 0.0013333333333333333, loss: 3.4782819747924805
batch i:281
learning rate: 0.0013333333333333333, loss: 3.487837076187134
batch i:282
learning rate: 0.0013333333333333333, loss: 3.4043657779693604
batch i:283
learning rate: 0.0013333333333333333, loss: 3.3783130645751953
batch i:284
learning rate: 0.0013333333333333333, loss: 3.5009288787841797
batch i:285
learning rate: 0.0013333333333333333, loss: 3.514420747756958
batch i:286
learning rate: 0.0013333333333333333, loss: 3.4284427165985107
batch i:287
learning rate: 0.0013333333333333333, loss: 3.470438003540039
batch i:288
learning rate: 0.0013333333333333333, loss: 3.5245280265808105
batch i:289
learning rate: 0.0013333333333333333, loss: 3.4011435508728027
batch i:290
learning rate: 0.0013333333333333333, loss: 3.467899799346924
batch i:291
learning rate: 0.0013333333333333333, loss: 3.3958723545074463
batch i:292
learning rate: 0.0013333333333333333, loss: 3.300210952758789
batch i:293
learning rate: 0.0013333333333333333, loss: 3.3600611686706543
batch i:294
learning rate: 0.0013333333333333333, loss: 3.3178329467773438
batch i:295
learning rate: 0.0013333333333333333, loss: 3.3679206371307373
batch i:296
learning rate: 0.0013333333333333333, loss: 3.3503170013427734
batch i:297
learning rate: 0.0013333333333333333, loss: 3.331058979034424
batch i:298
learning rate: 0.0013333333333333333, loss: 3.3362135887145996
batch i:299
learning rate: 0.0013333333333333333, loss: 3.324345827102661
batch i:300
learning rate: 0.0013333333333333333, loss: 3.384213924407959
current self-play batch: 300
num_playouts:1000, win: 4, lose: 6, tie:0
average time: 75.2700584411621
batch i:301
learning rate: 0.0013333333333333333, loss: 3.4166531562805176
batch i:302
learning rate: 0.0013333333333333333, loss: 3.3435397148132324
batch i:303
learning rate: 0.0013333333333333333, loss: 3.412193775177002
batch i:304
learning rate: 0.0013333333333333333, loss: 3.340430736541748
batch i:305
learning rate: 0.0013333333333333333, loss: 3.4845333099365234
batch i:306
learning rate: 0.0013333333333333333, loss: 3.4291136264801025
batch i:307
learning rate: 0.0013333333333333333, loss: 3.3807191848754883
batch i:308
learning rate: 0.0013333333333333333, loss: 3.419412136077881
batch i:309
learning rate: 0.0013333333333333333, loss: 3.411923885345459
batch i:310
learning rate: 0.0013333333333333333, loss: 3.3681588172912598
batch i:311
learning rate: 0.0013333333333333333, loss: 3.574646472930908
batch i:312
learning rate: 0.0013333333333333333, loss: 3.4531450271606445
batch i:313
learning rate: 0.0013333333333333333, loss: 3.374216079711914
batch i:314
learning rate: 0.0013333333333333333, loss: 3.3882408142089844
batch i:315
learning rate: 0.0013333333333333333, loss: 3.441957950592041
batch i:316
learning rate: 0.0013333333333333333, loss: 3.3803722858428955
batch i:317
learning rate: 0.0013333333333333333, loss: 3.3414790630340576
batch i:318
learning rate: 0.0013333333333333333, loss: 3.312007427215576
batch i:319
learning rate: 0.0013333333333333333, loss: 3.3092188835144043
batch i:320
learning rate: 0.0013333333333333333, loss: 3.2448675632476807
batch i:321
learning rate: 0.0013333333333333333, loss: 3.3035292625427246
batch i:322
learning rate: 0.0013333333333333333, loss: 3.4077744483947754
batch i:323
learning rate: 0.0013333333333333333, loss: 3.333378791809082
batch i:324
learning rate: 0.0013333333333333333, loss: 3.3430166244506836
batch i:325
learning rate: 0.0013333333333333333, loss: 3.320751667022705
batch i:326
learning rate: 0.0013333333333333333, loss: 3.3453903198242188
batch i:327
learning rate: 0.0013333333333333333, loss: 3.3506827354431152
batch i:328
learning rate: 0.0013333333333333333, loss: 3.3664817810058594
batch i:329
learning rate: 0.0013333333333333333, loss: 3.404301166534424
batch i:330
learning rate: 0.0013333333333333333, loss: 3.376206159591675
batch i:331
learning rate: 0.0013333333333333333, loss: 3.3484764099121094
batch i:332
learning rate: 0.0013333333333333333, loss: 3.338308334350586
batch i:333
learning rate: 0.0013333333333333333, loss: 3.34200382232666
batch i:334
learning rate: 0.0013333333333333333, loss: 3.4133706092834473
batch i:335
learning rate: 0.0013333333333333333, loss: 3.328129291534424
batch i:336
learning rate: 0.0013333333333333333, loss: 3.296935558319092
batch i:337
learning rate: 0.0013333333333333333, loss: 3.407907485961914
batch i:338
learning rate: 0.0013333333333333333, loss: 3.3860368728637695
batch i:339
learning rate: 0.0013333333333333333, loss: 3.2920053005218506
batch i:340
learning rate: 0.0013333333333333333, loss: 3.2647604942321777
batch i:341
learning rate: 0.0013333333333333333, loss: 3.316479206085205
batch i:342
learning rate: 0.0013333333333333333, loss: 3.2868852615356445
batch i:343
learning rate: 0.0013333333333333333, loss: 3.350904941558838
batch i:344
learning rate: 0.0013333333333333333, loss: 3.250009536743164
batch i:345
learning rate: 0.0013333333333333333, loss: 3.1982858180999756
batch i:346
learning rate: 0.0013333333333333333, loss: 3.226752758026123
batch i:347
learning rate: 0.0013333333333333333, loss: 3.331258773803711
batch i:348
learning rate: 0.0013333333333333333, loss: 3.2856216430664062
batch i:349
learning rate: 0.0013333333333333333, loss: 3.362931966781616
batch i:350
learning rate: 0.0013333333333333333, loss: 3.1593689918518066
current self-play batch: 350
num_playouts:1000, win: 4, lose: 6, tie:0
average time: 68.77306258678436
batch i:351
learning rate: 0.0013333333333333333, loss: 3.2145423889160156
batch i:352
learning rate: 0.0013333333333333333, loss: 3.2979350090026855
Traceback (most recent call last):
  File "/mnt/nas/home/huangyixin/AI/train.py", line 292, in <module>
    training_pipeline.train()
  File "/mnt/nas/home/huangyixin/AI/train.py", line 249, in train
    self.collect_selfplay_data(play_batch_size)
  File "/mnt/nas/home/huangyixin/AI/train.py", line 199, in collect_selfplay_data
    _, play_data = self.game.start_self_play(self.mcts_player,
  File "/mnt/nas/home/huangyixin/AI/game.py", line 204, in start_self_play
    move, move_probs = player.get_action(self.board,
  File "/mnt/nas/home/huangyixin/AI/mcts_alphaZero.py", line 201, in get_action
    moves, move_probs = self.mcts.get_move_and_probs(board, temp)
  File "/mnt/nas/home/huangyixin/AI/mcts_alphaZero.py", line 157, in get_move_and_probs
    self._playout(state_copy)
  File "/mnt/nas/home/huangyixin/AI/mcts_alphaZero.py", line 125, in _playout
    action_probs, leaf_value = self._policy(state)
  File "/mnt/nas/home/huangyixin/AI/model.py", line 300, in policy_value_fn
    act_probs = zip(legal_positions, act_probs[legal_positions])
IndexError: arrays used as indices must be of integer (or boolean) type
