Start time: 2023-12-23 22:22:35.499827
batch i:1
batch i:2
batch i:3
batch i:4
batch i:5
batch i:6
learning rate0.0013333333333333333, loss:4.54918098449707
batch i:7
learning rate0.0008888888888888888, loss:4.595069885253906
batch i:8
learning rate0.0005925925925925926, loss:4.72577428817749
batch i:9
learning rate0.0003950617283950617, loss:4.285395622253418
batch i:10
learning rate0.0002633744855967078, loss:4.1097211837768555
batch i:11
learning rate0.0001755829903978052, loss:3.8286147117614746
batch i:12
learning rate0.0001755829903978052, loss:3.723862648010254
batch i:13
learning rate0.0001755829903978052, loss:3.57120680809021
batch i:14
learning rate0.0001755829903978052, loss:3.5629048347473145
batch i:15
learning rate0.0001755829903978052, loss:3.445953130722046
batch i:16
learning rate0.0001755829903978052, loss:3.3706865310668945
batch i:17
learning rate0.0001755829903978052, loss:3.352797508239746
batch i:18
learning rate0.0001755829903978052, loss:3.4950225353240967
batch i:19
learning rate0.0001755829903978052, loss:3.346890449523926
batch i:20
learning rate0.0001755829903978052, loss:3.4017505645751953
batch i:21
learning rate0.0002633744855967078, loss:3.3534862995147705
batch i:22
learning rate0.0002633744855967078, loss:3.36098575592041
batch i:23
learning rate0.0002633744855967078, loss:3.2910330295562744
batch i:24
learning rate0.0002633744855967078, loss:3.232822895050049
batch i:25
learning rate0.0002633744855967078, loss:3.1973440647125244
batch i:26
learning rate0.0002633744855967078, loss:3.1665143966674805
batch i:27
learning rate0.0002633744855967078, loss:3.1281564235687256
batch i:28
learning rate0.0002633744855967078, loss:3.238373041152954
batch i:29
learning rate0.0002633744855967078, loss:3.119727373123169
batch i:30
learning rate0.0002633744855967078, loss:3.1207666397094727
batch i:31
learning rate0.0002633744855967078, loss:3.1271467208862305
batch i:32
learning rate0.0002633744855967078, loss:3.158456802368164
batch i:33
learning rate0.0002633744855967078, loss:3.0927515029907227
batch i:34
learning rate0.0002633744855967078, loss:3.140606641769409
batch i:35
learning rate0.0002633744855967078, loss:3.097702980041504
batch i:36
learning rate0.0002633744855967078, loss:3.0517706871032715
batch i:37
learning rate0.0002633744855967078, loss:3.086881160736084
batch i:38
learning rate0.0002633744855967078, loss:3.1357736587524414
batch i:39
learning rate0.0002633744855967078, loss:3.0191187858581543
batch i:40
learning rate0.0002633744855967078, loss:3.0715267658233643
batch i:41
learning rate0.0002633744855967078, loss:3.134765625
batch i:42
learning rate0.0002633744855967078, loss:3.1064887046813965
batch i:43
learning rate0.0002633744855967078, loss:3.10764741897583
batch i:44
learning rate0.0002633744855967078, loss:3.1049280166625977
batch i:45
learning rate0.0002633744855967078, loss:3.061195135116577
batch i:46
learning rate0.0002633744855967078, loss:3.0523524284362793
batch i:47
learning rate0.0002633744855967078, loss:3.0272529125213623
batch i:48
learning rate0.0002633744855967078, loss:3.0402019023895264
batch i:49
learning rate0.0002633744855967078, loss:3.018134355545044
batch i:50
learning rate0.0002633744855967078, loss:3.106065273284912
current self-play batch: 50
num_playouts:1000, win: 10, lose: 0, tie:0
average time: 280.6009988307953
New best policy from pure MCTS
batch i:51
learning rate0.0002633744855967078, loss:3.1540603637695312
batch i:52
learning rate0.0002633744855967078, loss:3.0463311672210693
batch i:53
learning rate0.0002633744855967078, loss:3.078258991241455
batch i:54
learning rate0.0002633744855967078, loss:3.0221192836761475
batch i:55
learning rate0.0002633744855967078, loss:3.103360176086426
batch i:56
learning rate0.0002633744855967078, loss:3.1473217010498047
batch i:57
learning rate0.0002633744855967078, loss:3.050058603286743
batch i:58
learning rate0.0002633744855967078, loss:3.0466208457946777
batch i:59
learning rate0.0002633744855967078, loss:3.0059914588928223
batch i:60
learning rate0.0002633744855967078, loss:3.018456220626831
batch i:61
learning rate0.0002633744855967078, loss:3.0551047325134277
batch i:62
learning rate0.0002633744855967078, loss:2.987692356109619
batch i:63
learning rate0.0002633744855967078, loss:3.1015055179595947
batch i:64
learning rate0.0002633744855967078, loss:3.091386079788208
batch i:65
learning rate0.0002633744855967078, loss:3.125770330429077
batch i:66
learning rate0.0002633744855967078, loss:3.079467296600342
batch i:67
learning rate0.0002633744855967078, loss:3.0433099269866943
batch i:68
learning rate0.0002633744855967078, loss:3.0905189514160156
batch i:69
learning rate0.0002633744855967078, loss:3.0896530151367188
batch i:70
learning rate0.0002633744855967078, loss:3.06173038482666
batch i:71
learning rate0.0002633744855967078, loss:3.0984606742858887
batch i:72
learning rate0.0002633744855967078, loss:3.090729236602783
batch i:73
learning rate0.0002633744855967078, loss:3.029118776321411
batch i:74
learning rate0.0002633744855967078, loss:3.1258928775787354
batch i:75
learning rate0.0002633744855967078, loss:3.1498031616210938
batch i:76
learning rate0.0002633744855967078, loss:3.0931358337402344
batch i:77
learning rate0.0002633744855967078, loss:3.04630708694458
batch i:78
learning rate0.0002633744855967078, loss:3.0757617950439453
batch i:79
learning rate0.0002633744855967078, loss:3.151932716369629
batch i:80
learning rate0.0002633744855967078, loss:3.0874533653259277
batch i:81
learning rate0.0002633744855967078, loss:3.1254682540893555
batch i:82
learning rate0.0002633744855967078, loss:3.122373104095459
batch i:83
learning rate0.0002633744855967078, loss:3.0334296226501465
batch i:84
learning rate0.0002633744855967078, loss:3.103496789932251
batch i:85
learning rate0.0002633744855967078, loss:3.119046926498413
batch i:86
learning rate0.0002633744855967078, loss:3.097970962524414
batch i:87
learning rate0.0002633744855967078, loss:3.0083272457122803
batch i:88
learning rate0.0002633744855967078, loss:3.1153478622436523
batch i:89
learning rate0.0002633744855967078, loss:3.1014275550842285
batch i:90
learning rate0.0002633744855967078, loss:3.0645666122436523
batch i:91
learning rate0.0002633744855967078, loss:3.0775327682495117
batch i:92
learning rate0.0002633744855967078, loss:3.0238146781921387
batch i:93
learning rate0.0002633744855967078, loss:3.067704200744629
batch i:94
learning rate0.0002633744855967078, loss:3.0123603343963623
batch i:95
learning rate0.0002633744855967078, loss:3.0669806003570557
batch i:96
learning rate0.0002633744855967078, loss:3.0504565238952637
batch i:97
learning rate0.0002633744855967078, loss:3.040160655975342
batch i:98
learning rate0.0002633744855967078, loss:3.0293431282043457
batch i:99
learning rate0.0002633744855967078, loss:3.0697665214538574
batch i:100
learning rate0.0002633744855967078, loss:3.030322313308716
current self-play batch: 100
num_playouts:2000, win: 10, lose: 0, tie:0
average time: 540.4606219053269
New best policy from pure MCTS
batch i:101
learning rate0.0002633744855967078, loss:3.0279746055603027
batch i:102
learning rate0.0002633744855967078, loss:3.002119541168213
batch i:103
learning rate0.0002633744855967078, loss:3.012873649597168
batch i:104
learning rate0.0002633744855967078, loss:2.954432964324951
batch i:105
learning rate0.0002633744855967078, loss:3.060303211212158
batch i:106
learning rate0.0002633744855967078, loss:2.9773359298706055
batch i:107
learning rate0.0002633744855967078, loss:2.940899133682251
batch i:108
learning rate0.0002633744855967078, loss:3.039137363433838
batch i:109
learning rate0.0002633744855967078, loss:2.9887290000915527
batch i:110
learning rate0.0002633744855967078, loss:2.9736742973327637
batch i:111
learning rate0.0002633744855967078, loss:2.9653072357177734
batch i:112
learning rate0.0002633744855967078, loss:2.9716947078704834
batch i:113
learning rate0.0002633744855967078, loss:2.9637508392333984
batch i:114
learning rate0.0002633744855967078, loss:2.9918079376220703
batch i:115
learning rate0.0002633744855967078, loss:2.994713306427002
batch i:116
learning rate0.0002633744855967078, loss:2.999709129333496
batch i:117
learning rate0.0002633744855967078, loss:2.9658889770507812
batch i:118
learning rate0.0002633744855967078, loss:2.9387600421905518
batch i:119
learning rate0.0002633744855967078, loss:3.01576828956604
batch i:120
learning rate0.0002633744855967078, loss:2.919971466064453
batch i:121
learning rate0.0002633744855967078, loss:3.0245161056518555
batch i:122
learning rate0.0002633744855967078, loss:2.9263734817504883
batch i:123
learning rate0.0002633744855967078, loss:3.034658432006836
batch i:124
learning rate0.0002633744855967078, loss:3.004039764404297
batch i:125
learning rate0.0002633744855967078, loss:2.981503963470459
batch i:126
learning rate0.0002633744855967078, loss:2.970482349395752
batch i:127
learning rate0.0002633744855967078, loss:2.987269163131714
batch i:128
learning rate0.0002633744855967078, loss:2.868290901184082
batch i:129
learning rate0.0002633744855967078, loss:2.9235386848449707
batch i:130
learning rate0.0002633744855967078, loss:2.9428658485412598
batch i:131
learning rate0.0002633744855967078, loss:2.976205348968506
batch i:132
learning rate0.0002633744855967078, loss:2.9094386100769043
batch i:133
learning rate0.0002633744855967078, loss:3.0303590297698975
batch i:134
learning rate0.0002633744855967078, loss:2.898789882659912
batch i:135
learning rate0.0002633744855967078, loss:2.9536988735198975
batch i:136
learning rate0.0002633744855967078, loss:2.9120595455169678
batch i:137
learning rate0.0002633744855967078, loss:2.9435510635375977
batch i:138
learning rate0.0002633744855967078, loss:2.9148526191711426
batch i:139
learning rate0.0002633744855967078, loss:2.9767556190490723
batch i:140
learning rate0.0002633744855967078, loss:2.9345550537109375
batch i:141
learning rate0.0002633744855967078, loss:2.9380674362182617
batch i:142
learning rate0.0002633744855967078, loss:2.914552688598633
batch i:143
learning rate0.0002633744855967078, loss:2.9647648334503174
batch i:144
learning rate0.0002633744855967078, loss:2.925797939300537
batch i:145
learning rate0.0002633744855967078, loss:2.997356414794922
batch i:146
learning rate0.0002633744855967078, loss:2.848144054412842
batch i:147
learning rate0.0002633744855967078, loss:2.9067611694335938
batch i:148
learning rate0.0002633744855967078, loss:2.949343204498291
batch i:149
learning rate0.0002633744855967078, loss:2.9503321647644043
batch i:150
learning rate0.0002633744855967078, loss:2.9450011253356934
current self-play batch: 150
num_playouts:3000, win: 9, lose: 1, tie:0
average time: 867.9159523963929
New best policy from pure MCTS
batch i:151
learning rate0.0002633744855967078, loss:2.9545822143554688
batch i:152
learning rate0.0002633744855967078, loss:2.953847885131836
batch i:153
learning rate0.0002633744855967078, loss:2.7793314456939697
batch i:154
learning rate0.0002633744855967078, loss:2.8713085651397705
batch i:155
learning rate0.0002633744855967078, loss:2.9600601196289062
batch i:156
learning rate0.0002633744855967078, loss:2.8945436477661133
batch i:157
learning rate0.0002633744855967078, loss:2.9768271446228027
batch i:158
learning rate0.0002633744855967078, loss:2.919663906097412
batch i:159
learning rate0.0002633744855967078, loss:2.8993160724639893
batch i:160
learning rate0.0002633744855967078, loss:2.9285500049591064
batch i:161
learning rate0.0002633744855967078, loss:2.8684210777282715
batch i:162
learning rate0.0002633744855967078, loss:2.8839120864868164
batch i:163
learning rate0.0002633744855967078, loss:2.886359691619873
batch i:164
learning rate0.0002633744855967078, loss:2.8437657356262207
batch i:165
learning rate0.0002633744855967078, loss:2.832178831100464
batch i:166
learning rate0.0002633744855967078, loss:2.870914936065674
batch i:167
learning rate0.0002633744855967078, loss:2.8322951793670654
batch i:168
learning rate0.0002633744855967078, loss:2.9322433471679688
batch i:169
learning rate0.0002633744855967078, loss:2.896519660949707
batch i:170
learning rate0.0002633744855967078, loss:2.8844969272613525
batch i:171
learning rate0.0002633744855967078, loss:2.856933832168579
batch i:172
learning rate0.0002633744855967078, loss:2.931980609893799
batch i:173
learning rate0.0002633744855967078, loss:2.887669086456299
batch i:174
learning rate0.0002633744855967078, loss:2.8475005626678467
batch i:175
learning rate0.0002633744855967078, loss:2.977534294128418
batch i:176
learning rate0.0002633744855967078, loss:2.874354839324951
batch i:177
learning rate0.0002633744855967078, loss:2.876941680908203
batch i:178
learning rate0.0002633744855967078, loss:2.873840808868408
batch i:179
learning rate0.0002633744855967078, loss:2.9293713569641113
batch i:180
learning rate0.0002633744855967078, loss:2.873314380645752
batch i:181
learning rate0.0002633744855967078, loss:2.827630043029785
batch i:182
learning rate0.0002633744855967078, loss:2.9984331130981445
batch i:183
learning rate0.0002633744855967078, loss:2.9394736289978027
batch i:184
learning rate0.0002633744855967078, loss:2.975187301635742
batch i:185
learning rate0.0002633744855967078, loss:2.7964789867401123
batch i:186
learning rate0.0002633744855967078, loss:2.9215240478515625
batch i:187
learning rate0.0002633744855967078, loss:2.913808822631836
batch i:188
learning rate0.0002633744855967078, loss:2.84822940826416
batch i:189
learning rate0.0002633744855967078, loss:2.8583321571350098
batch i:190
learning rate0.0002633744855967078, loss:2.8628756999969482
batch i:191
learning rate0.0002633744855967078, loss:2.896247386932373
batch i:192
learning rate0.0002633744855967078, loss:2.8293344974517822
batch i:193
learning rate0.0002633744855967078, loss:2.852283000946045
batch i:194
learning rate0.0002633744855967078, loss:2.9174602031707764
batch i:195
learning rate0.0002633744855967078, loss:2.82057785987854
batch i:196
learning rate0.0002633744855967078, loss:2.9179389476776123
batch i:197
learning rate0.0002633744855967078, loss:2.898613452911377
batch i:198
learning rate0.0002633744855967078, loss:2.8089146614074707
batch i:199
learning rate0.0002633744855967078, loss:2.9109039306640625
batch i:200
learning rate0.0002633744855967078, loss:2.9204912185668945
current self-play batch: 200
num_playouts:3000, win: 7, lose: 3, tie:0
average time: 1381.428052997589
batch i:201
learning rate0.0002633744855967078, loss:2.859128475189209
batch i:202
learning rate0.0001755829903978052, loss:2.8081068992614746
batch i:203
learning rate0.0001755829903978052, loss:2.9462499618530273
batch i:204
learning rate0.0001755829903978052, loss:2.8779096603393555
batch i:205
learning rate0.0001755829903978052, loss:2.904151678085327
batch i:206
learning rate0.0001755829903978052, loss:2.804370880126953
batch i:207
learning rate0.0001755829903978052, loss:2.7698302268981934
batch i:208
learning rate0.0001755829903978052, loss:2.83846116065979
batch i:209
learning rate0.0001755829903978052, loss:2.7369236946105957
batch i:210
learning rate0.0001755829903978052, loss:2.85605525970459
batch i:211
learning rate0.0001755829903978052, loss:2.888688325881958
batch i:212
learning rate0.0001755829903978052, loss:2.8283181190490723
batch i:213
learning rate0.0001755829903978052, loss:2.843869209289551
batch i:214
learning rate0.0001755829903978052, loss:2.842564105987549
batch i:215
learning rate0.0001755829903978052, loss:2.832510232925415
batch i:216
learning rate0.0001755829903978052, loss:2.814802885055542
batch i:217
learning rate0.0001755829903978052, loss:2.8608291149139404
batch i:218
learning rate0.0001755829903978052, loss:2.854912519454956
batch i:219
learning rate0.0001755829903978052, loss:2.84733510017395
batch i:220
learning rate0.0001755829903978052, loss:2.843446969985962
batch i:221
learning rate0.0001755829903978052, loss:2.8346686363220215
batch i:222
learning rate0.0001755829903978052, loss:2.8176140785217285
batch i:223
learning rate0.0001755829903978052, loss:2.8710126876831055
batch i:224
learning rate0.0001755829903978052, loss:2.89506196975708
batch i:225
learning rate0.0002633744855967078, loss:2.825749397277832
batch i:226
learning rate0.0002633744855967078, loss:2.891810894012451
batch i:227
learning rate0.0002633744855967078, loss:2.7990596294403076
batch i:228
learning rate0.0002633744855967078, loss:2.8552703857421875
batch i:229
learning rate0.0002633744855967078, loss:2.796128749847412
batch i:230
learning rate0.0002633744855967078, loss:2.783143997192383
batch i:231
learning rate0.0002633744855967078, loss:2.792459011077881
batch i:232
learning rate0.0002633744855967078, loss:2.7674875259399414
batch i:233
learning rate0.0002633744855967078, loss:2.845848798751831
batch i:234
learning rate0.0002633744855967078, loss:2.8950748443603516
batch i:235
learning rate0.0002633744855967078, loss:2.7833166122436523
batch i:236
learning rate0.0002633744855967078, loss:2.8019707202911377
batch i:237
learning rate0.0002633744855967078, loss:2.8223729133605957
batch i:238
learning rate0.0002633744855967078, loss:2.765498161315918
batch i:239
learning rate0.0002633744855967078, loss:2.881232738494873
batch i:240
learning rate0.0002633744855967078, loss:2.8151116371154785
batch i:241
learning rate0.0002633744855967078, loss:2.831684112548828
batch i:242
learning rate0.0002633744855967078, loss:2.7641162872314453
batch i:243
learning rate0.0002633744855967078, loss:2.819178819656372
batch i:244
learning rate0.0002633744855967078, loss:2.8176982402801514
batch i:245
learning rate0.0002633744855967078, loss:2.7915706634521484
batch i:246
learning rate0.0002633744855967078, loss:2.8376917839050293
batch i:247
learning rate0.0002633744855967078, loss:2.7854294776916504
batch i:248
learning rate0.0001755829903978052, loss:2.7855725288391113
batch i:249
learning rate0.0001755829903978052, loss:2.7924249172210693
batch i:250
learning rate0.0001755829903978052, loss:2.7947065830230713
current self-play batch: 250
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 1049.2318275928496
batch i:251
learning rate0.0001755829903978052, loss:2.778625726699829
batch i:252
learning rate0.0002633744855967078, loss:2.831110954284668
batch i:253
learning rate0.0002633744855967078, loss:2.761218547821045
batch i:254
learning rate0.0002633744855967078, loss:2.762644052505493
batch i:255
learning rate0.0002633744855967078, loss:2.8022258281707764
batch i:256
learning rate0.0002633744855967078, loss:2.779489278793335
batch i:257
learning rate0.0002633744855967078, loss:2.800935745239258
batch i:258
learning rate0.0002633744855967078, loss:2.7188923358917236
batch i:259
learning rate0.0002633744855967078, loss:2.7988829612731934
batch i:260
learning rate0.0002633744855967078, loss:2.76237416267395
batch i:261
learning rate0.0002633744855967078, loss:2.821272373199463
batch i:262
learning rate0.0002633744855967078, loss:2.7351937294006348
batch i:263
learning rate0.0002633744855967078, loss:2.806446075439453
batch i:264
learning rate0.0002633744855967078, loss:2.8117504119873047
batch i:265
learning rate0.0002633744855967078, loss:2.7157857418060303
batch i:266
learning rate0.0002633744855967078, loss:2.8184080123901367
batch i:267
learning rate0.0002633744855967078, loss:2.7121191024780273
batch i:268
learning rate0.0002633744855967078, loss:2.7963008880615234
batch i:269
learning rate0.0002633744855967078, loss:2.73616886138916
batch i:270
learning rate0.0002633744855967078, loss:2.844240665435791
batch i:271
learning rate0.0002633744855967078, loss:2.8578262329101562
batch i:272
learning rate0.0002633744855967078, loss:2.84436297416687
batch i:273
learning rate0.0002633744855967078, loss:2.8921384811401367
batch i:274
learning rate0.0002633744855967078, loss:2.7788093090057373
batch i:275
learning rate0.0002633744855967078, loss:2.8778791427612305
batch i:276
learning rate0.0002633744855967078, loss:2.8085460662841797
batch i:277
learning rate0.0002633744855967078, loss:2.9290919303894043
batch i:278
learning rate0.0002633744855967078, loss:2.843132972717285
batch i:279
learning rate0.0002633744855967078, loss:2.8461828231811523
batch i:280
learning rate0.0002633744855967078, loss:2.8003766536712646
batch i:281
learning rate0.0002633744855967078, loss:2.8218421936035156
batch i:282
learning rate0.0002633744855967078, loss:2.88021183013916
batch i:283
learning rate0.0002633744855967078, loss:2.835883140563965
batch i:284
learning rate0.0002633744855967078, loss:2.829353094100952
batch i:285
learning rate0.0002633744855967078, loss:2.793469190597534
batch i:286
learning rate0.0002633744855967078, loss:2.961082935333252
batch i:287
learning rate0.0002633744855967078, loss:2.8967514038085938
batch i:288
learning rate0.0002633744855967078, loss:2.7944488525390625
batch i:289
learning rate0.0002633744855967078, loss:2.8709278106689453
batch i:290
learning rate0.0002633744855967078, loss:2.870938777923584
batch i:291
learning rate0.0002633744855967078, loss:2.7381949424743652
batch i:292
learning rate0.0002633744855967078, loss:2.8752169609069824
batch i:293
learning rate0.0002633744855967078, loss:2.862287998199463
batch i:294
learning rate0.0002633744855967078, loss:2.8380489349365234
batch i:295
learning rate0.0002633744855967078, loss:2.7773876190185547
batch i:296
learning rate0.0002633744855967078, loss:2.78763484954834
batch i:297
learning rate0.0002633744855967078, loss:2.85087251663208
batch i:298
learning rate0.0002633744855967078, loss:2.8536086082458496
batch i:299
learning rate0.0002633744855967078, loss:2.786220073699951
batch i:300
learning rate0.0002633744855967078, loss:2.8103177547454834
current self-play batch: 300
Traceback (most recent call last):
  File "/mnt/nas/home/huangyixin/AI/train.py", line 378, in <module>
    training_pipeline.train(game_batch_num)
  File "/mnt/nas/home/huangyixin/AI/train.py", line 288, in train
    win_ratio, _, _ = self.game.policy_evaluate(filename,
  File "/mnt/nas/home/huangyixin/AI/game.py", line 402, in policy_evaluate
    winner, pos = self.start_play(current_mcts_player,
  File "/mnt/nas/home/huangyixin/AI/game.py", line 339, in start_play
    move, _ = player_in_turn.get_action(self.board)
  File "/mnt/nas/home/huangyixin/AI/mcts_alphaZero.py", line 203, in get_action
    moves, move_probs = self.mcts.get_move_and_probs(board, temp)
  File "/mnt/nas/home/huangyixin/AI/mcts_alphaZero.py", line 158, in get_move_and_probs
    self._playout(state_copy)
  File "/mnt/nas/home/huangyixin/AI/mcts_alphaZero.py", line 126, in _playout
    action_probs, leaf_value = self._policy(state)
  File "/mnt/nas/home/huangyixin/AI/model.py", line 306, in policy_value_fn
    act_probs = zip(legal_positions, act_probs[legal_positions])
IndexError: arrays used as indices must be of integer (or boolean) type
