Start time: 2023-12-19 07:46:17.652632
batch i:1
batch i:2
batch i:3
batch i:4
learning rate: 0.0013333333333333333, loss: 4.708286285400391
batch i:5
learning rate: 0.0008888888888888888, loss: 4.563907623291016
batch i:6
learning rate: 0.0005925925925925926, loss: 3.980558395385742
batch i:7
learning rate: 0.0003950617283950617, loss: 3.494326591491699
batch i:8
learning rate: 0.0002633744855967078, loss: 3.54237699508667
batch i:9
learning rate: 0.0002633744855967078, loss: 3.3579695224761963
batch i:10
learning rate: 0.0002633744855967078, loss: 3.445526361465454
batch i:11
learning rate: 0.0002633744855967078, loss: 3.5797438621520996
batch i:12
learning rate: 0.0002633744855967078, loss: 3.3884339332580566
batch i:13
learning rate: 0.0002633744855967078, loss: 3.343024253845215
batch i:14
learning rate: 0.0002633744855967078, loss: 3.272456645965576
batch i:15
learning rate: 0.0002633744855967078, loss: 3.312379837036133
batch i:16
learning rate: 0.0002633744855967078, loss: 3.3029165267944336
batch i:17
learning rate: 0.0002633744855967078, loss: 3.2695202827453613
batch i:18
learning rate: 0.0002633744855967078, loss: 3.2906174659729004
batch i:19
learning rate: 0.0002633744855967078, loss: 3.3847126960754395
batch i:20
learning rate: 0.0002633744855967078, loss: 3.28230881690979
batch i:21
learning rate: 0.0002633744855967078, loss: 3.3207294940948486
batch i:22
learning rate: 0.0002633744855967078, loss: 3.2579345703125
batch i:23
learning rate: 0.0002633744855967078, loss: 3.2150089740753174
batch i:24
learning rate: 0.0002633744855967078, loss: 3.1498961448669434
batch i:25
learning rate: 0.0002633744855967078, loss: 3.102677583694458
batch i:26
learning rate: 0.0002633744855967078, loss: 3.075378179550171
batch i:27
learning rate: 0.0002633744855967078, loss: 3.0170557498931885
batch i:28
learning rate: 0.0002633744855967078, loss: 3.057584762573242
batch i:29
learning rate: 0.0002633744855967078, loss: 3.0518558025360107
batch i:30
learning rate: 0.0002633744855967078, loss: 3.0697033405303955
batch i:31
learning rate: 0.0002633744855967078, loss: 3.137847423553467
batch i:32
learning rate: 0.0002633744855967078, loss: 3.026707887649536
batch i:33
learning rate: 0.0002633744855967078, loss: 3.069462776184082
batch i:34
learning rate: 0.0002633744855967078, loss: 3.0805680751800537
batch i:35
learning rate: 0.0002633744855967078, loss: 3.0632567405700684
batch i:36
learning rate: 0.0002633744855967078, loss: 3.027297019958496
batch i:37
learning rate: 0.0002633744855967078, loss: 3.078726291656494
batch i:38
learning rate: 0.0002633744855967078, loss: 3.0906286239624023
batch i:39
learning rate: 0.0002633744855967078, loss: 3.098806619644165
batch i:40
learning rate: 0.0002633744855967078, loss: 3.023082733154297
batch i:41
learning rate: 0.0002633744855967078, loss: 3.0178639888763428
batch i:42
learning rate: 0.0002633744855967078, loss: 3.0786590576171875
batch i:43
learning rate: 0.0002633744855967078, loss: 3.072683334350586
batch i:44
learning rate: 0.0002633744855967078, loss: 3.1334738731384277
batch i:45
learning rate: 0.0002633744855967078, loss: 3.031330108642578
batch i:46
learning rate: 0.0002633744855967078, loss: 2.926149368286133
batch i:47
learning rate: 0.0002633744855967078, loss: 3.0603489875793457
batch i:48
learning rate: 0.0002633744855967078, loss: 2.9568443298339844
batch i:49
learning rate: 0.0002633744855967078, loss: 3.07537841796875
batch i:50
learning rate: 0.0002633744855967078, loss: 3.0096120834350586
current self-play batch: 50
num_playouts:1000, win: 7, lose: 3, tie:0
average time: 84.00442612171173
New best policy from pure MCTS
batch i:51
learning rate: 0.0002633744855967078, loss: 2.9970221519470215
batch i:52
learning rate: 0.0002633744855967078, loss: 3.0241565704345703
batch i:53
learning rate: 0.0002633744855967078, loss: 3.0477874279022217
batch i:54
learning rate: 0.0002633744855967078, loss: 2.9926671981811523
batch i:55
learning rate: 0.0002633744855967078, loss: 3.0391647815704346
batch i:56
learning rate: 0.0002633744855967078, loss: 2.9304580688476562
batch i:57
learning rate: 0.0002633744855967078, loss: 2.9621479511260986
batch i:58
learning rate: 0.0002633744855967078, loss: 2.97872257232666
batch i:59
learning rate: 0.0002633744855967078, loss: 2.9779462814331055
batch i:60
learning rate: 0.0002633744855967078, loss: 2.922744035720825
batch i:61
learning rate: 0.0002633744855967078, loss: 2.9393532276153564
batch i:62
learning rate: 0.0002633744855967078, loss: 2.960071563720703
batch i:63
learning rate: 0.0002633744855967078, loss: 2.998164653778076
batch i:64
learning rate: 0.0002633744855967078, loss: 2.990412473678589
batch i:65
learning rate: 0.0002633744855967078, loss: 2.9409942626953125
batch i:66
learning rate: 0.0002633744855967078, loss: 2.9231133460998535
batch i:67
learning rate: 0.0002633744855967078, loss: 2.9674079418182373
batch i:68
learning rate: 0.0002633744855967078, loss: 3.066307783126831
batch i:69
learning rate: 0.0001755829903978052, loss: 2.914778470993042
batch i:70
learning rate: 0.0001755829903978052, loss: 3.004755735397339
batch i:71
learning rate: 0.0001755829903978052, loss: 3.0186121463775635
batch i:72
learning rate: 0.0001755829903978052, loss: 2.9959287643432617
batch i:73
learning rate: 0.0001755829903978052, loss: 2.881246566772461
batch i:74
learning rate: 0.0001755829903978052, loss: 2.8768959045410156
batch i:75
learning rate: 0.0001755829903978052, loss: 2.9360408782958984
batch i:76
learning rate: 0.0001755829903978052, loss: 2.919506072998047
batch i:77
learning rate: 0.0001755829903978052, loss: 3.012842893600464
batch i:78
learning rate: 0.0001755829903978052, loss: 2.9459075927734375
batch i:79
learning rate: 0.0001755829903978052, loss: 2.9747347831726074
batch i:80
learning rate: 0.0001755829903978052, loss: 2.9807989597320557
batch i:81
learning rate: 0.0001755829903978052, loss: 2.9424679279327393
batch i:82
learning rate: 0.0001755829903978052, loss: 2.8841686248779297
batch i:83
learning rate: 0.0001755829903978052, loss: 2.872354030609131
batch i:84
learning rate: 0.0001755829903978052, loss: 2.887861728668213
batch i:85
learning rate: 0.0001755829903978052, loss: 3.004507541656494
batch i:86
learning rate: 0.0001755829903978052, loss: 2.9577760696411133
batch i:87
learning rate: 0.0001755829903978052, loss: 2.9351038932800293
batch i:88
learning rate: 0.0001755829903978052, loss: 2.9522640705108643
batch i:89
learning rate: 0.0001755829903978052, loss: 2.814542770385742
batch i:90
learning rate: 0.0001755829903978052, loss: 2.859025001525879
batch i:91
learning rate: 0.0001755829903978052, loss: 2.8760485649108887
batch i:92
learning rate: 0.0001755829903978052, loss: 3.0095934867858887
batch i:93
learning rate: 0.0001755829903978052, loss: 2.8129043579101562
batch i:94
learning rate: 0.0001755829903978052, loss: 2.8525519371032715
batch i:95
learning rate: 0.0001755829903978052, loss: 2.9270105361938477
batch i:96
learning rate: 0.0001755829903978052, loss: 2.841693878173828
batch i:97
learning rate: 0.0001755829903978052, loss: 2.9868054389953613
batch i:98
learning rate: 0.0001755829903978052, loss: 2.8296570777893066
batch i:99
learning rate: 0.0001755829903978052, loss: 2.9830424785614014
batch i:100
learning rate: 0.0001755829903978052, loss: 2.8923840522766113
current self-play batch: 100
num_playouts:1000, win: 9, lose: 1, tie:0
average time: 66.553755068779
New best policy from pure MCTS
batch i:101
learning rate: 0.0001755829903978052, loss: 2.8652167320251465
batch i:102
learning rate: 0.0001755829903978052, loss: 2.8717708587646484
batch i:103
learning rate: 0.0001755829903978052, loss: 2.8566832542419434
batch i:104
learning rate: 0.0001755829903978052, loss: 2.8389570713043213
batch i:105
learning rate: 0.0001755829903978052, loss: 2.769474506378174
batch i:106
learning rate: 0.0001755829903978052, loss: 2.8333213329315186
batch i:107
learning rate: 0.0001755829903978052, loss: 2.770440101623535
batch i:108
learning rate: 0.0001755829903978052, loss: 2.811161994934082
batch i:109
learning rate: 0.0001755829903978052, loss: 2.799591064453125
batch i:110
learning rate: 0.0001755829903978052, loss: 2.8082823753356934
batch i:111
learning rate: 0.0001755829903978052, loss: 2.748072862625122
batch i:112
learning rate: 0.0001755829903978052, loss: 2.8715860843658447
batch i:113
learning rate: 0.0001755829903978052, loss: 2.895644187927246
batch i:114
learning rate: 0.0001755829903978052, loss: 2.8403985500335693
batch i:115
learning rate: 0.0001755829903978052, loss: 2.8706865310668945
batch i:116
learning rate: 0.0001755829903978052, loss: 2.7701258659362793
batch i:117
learning rate: 0.0001755829903978052, loss: 2.8543214797973633
batch i:118
learning rate: 0.0001755829903978052, loss: 2.890803813934326
batch i:119
learning rate: 0.0001755829903978052, loss: 2.7800099849700928
batch i:120
learning rate: 0.0001755829903978052, loss: 2.732588291168213
batch i:121
learning rate: 0.0001755829903978052, loss: 2.8584346771240234
batch i:122
learning rate: 0.0001755829903978052, loss: 2.925299644470215
batch i:123
learning rate: 0.0001755829903978052, loss: 2.850207805633545
batch i:124
learning rate: 0.0001755829903978052, loss: 2.987644672393799
batch i:125
learning rate: 0.0001755829903978052, loss: 2.853457450866699
batch i:126
learning rate: 0.0001755829903978052, loss: 2.8795385360717773
batch i:127
learning rate: 0.0001755829903978052, loss: 2.813793182373047
batch i:128
learning rate: 0.0001755829903978052, loss: 2.915783166885376
batch i:129
learning rate: 0.0001755829903978052, loss: 2.886977434158325
batch i:130
learning rate: 0.0001755829903978052, loss: 2.9688661098480225
batch i:131
learning rate: 0.0001755829903978052, loss: 2.958108901977539
batch i:132
learning rate: 0.0001755829903978052, loss: 2.896995782852173
batch i:133
learning rate: 0.0001755829903978052, loss: 2.9953644275665283
batch i:134
learning rate: 0.0001755829903978052, loss: 2.90679931640625
batch i:135
learning rate: 0.0001755829903978052, loss: 2.7650692462921143
batch i:136
learning rate: 0.0001755829903978052, loss: 2.845691680908203
batch i:137
learning rate: 0.0001755829903978052, loss: 2.873326301574707
batch i:138
learning rate: 0.0001755829903978052, loss: 2.9229350090026855
batch i:139
learning rate: 0.0001755829903978052, loss: 2.828516960144043
batch i:140
learning rate: 0.0001755829903978052, loss: 2.799576759338379
batch i:141
learning rate: 0.0001755829903978052, loss: 2.8226397037506104
batch i:142
learning rate: 0.0001755829903978052, loss: 2.8743228912353516
batch i:143
learning rate: 0.0001755829903978052, loss: 2.8324594497680664
batch i:144
learning rate: 0.0001755829903978052, loss: 2.8216514587402344
batch i:145
learning rate: 0.0001755829903978052, loss: 2.8988447189331055
batch i:146
learning rate: 0.0001755829903978052, loss: 2.776003837585449
batch i:147
learning rate: 0.0001755829903978052, loss: 2.884032726287842
batch i:148
learning rate: 0.0001755829903978052, loss: 2.7776942253112793
batch i:149
learning rate: 0.0001755829903978052, loss: 2.833893060684204
batch i:150
learning rate: 0.0001755829903978052, loss: 2.8158674240112305
current self-play batch: 150
num_playouts:1000, win: 10, lose: 0, tie:0
average time: 66.16409909725189
New best policy from pure MCTS
batch i:151
learning rate: 0.0001755829903978052, loss: 2.770160675048828
batch i:152
learning rate: 0.0001755829903978052, loss: 2.8135955333709717
batch i:153
learning rate: 0.0001755829903978052, loss: 2.7861576080322266
batch i:154
learning rate: 0.0001755829903978052, loss: 2.8659567832946777
batch i:155
learning rate: 0.0001755829903978052, loss: 2.9034643173217773
batch i:156
learning rate: 0.0001755829903978052, loss: 2.8096463680267334
batch i:157
learning rate: 0.0001755829903978052, loss: 2.782557249069214
batch i:158
learning rate: 0.00011705532693187012, loss: 2.8364570140838623
batch i:159
learning rate: 0.0001755829903978052, loss: 2.764092445373535
batch i:160
learning rate: 0.00011705532693187012, loss: 2.8454983234405518
batch i:161
learning rate: 0.00011705532693187012, loss: 2.9298596382141113
batch i:162
learning rate: 0.00011705532693187012, loss: 2.7844221591949463
batch i:163
learning rate: 0.00011705532693187012, loss: 2.901498317718506
batch i:164
learning rate: 0.00011705532693187012, loss: 2.775132894515991
batch i:165
learning rate: 0.00011705532693187012, loss: 2.805565595626831
batch i:166
learning rate: 0.00011705532693187012, loss: 2.877528190612793
batch i:167
learning rate: 0.00011705532693187012, loss: 2.8098597526550293
batch i:168
learning rate: 0.00011705532693187012, loss: 2.782193183898926
batch i:169
learning rate: 0.0001755829903978052, loss: 2.808554172515869
batch i:170
learning rate: 0.0001755829903978052, loss: 2.790583610534668
batch i:171
learning rate: 0.0001755829903978052, loss: 2.7051072120666504
batch i:172
learning rate: 0.0001755829903978052, loss: 2.6985902786254883
batch i:173
learning rate: 0.0001755829903978052, loss: 2.6785225868225098
batch i:174
learning rate: 0.0001755829903978052, loss: 2.798983097076416
batch i:175
learning rate: 0.0001755829903978052, loss: 2.6880297660827637
batch i:176
learning rate: 0.0001755829903978052, loss: 2.6480603218078613
batch i:177
learning rate: 0.0001755829903978052, loss: 2.756331443786621
batch i:178
learning rate: 0.0001755829903978052, loss: 2.6382369995117188
batch i:179
learning rate: 0.0001755829903978052, loss: 2.8075625896453857
batch i:180
learning rate: 0.0001755829903978052, loss: 2.622180461883545
batch i:181
learning rate: 0.0001755829903978052, loss: 2.685023546218872
batch i:182
learning rate: 0.0001755829903978052, loss: 2.669494867324829
batch i:183
learning rate: 0.0001755829903978052, loss: 2.7388174533843994
batch i:184
learning rate: 0.0001755829903978052, loss: 2.6501259803771973
batch i:185
learning rate: 0.0001755829903978052, loss: 2.7282280921936035
batch i:186
learning rate: 0.0001755829903978052, loss: 2.6732068061828613
batch i:187
learning rate: 0.0001755829903978052, loss: 2.7473244667053223
batch i:188
learning rate: 0.0001755829903978052, loss: 2.760514736175537
batch i:189
learning rate: 0.0001755829903978052, loss: 2.7669949531555176
batch i:190
learning rate: 0.0001755829903978052, loss: 2.799023389816284
batch i:191
learning rate: 0.0001755829903978052, loss: 2.674506187438965
batch i:192
learning rate: 0.0001755829903978052, loss: 2.6980185508728027
batch i:193
learning rate: 0.0001755829903978052, loss: 2.6434762477874756
batch i:194
learning rate: 0.0001755829903978052, loss: 2.6375064849853516
batch i:195
learning rate: 0.0001755829903978052, loss: 2.6041486263275146
batch i:196
learning rate: 0.0001755829903978052, loss: 2.671504020690918
batch i:197
learning rate: 0.0001755829903978052, loss: 2.5616812705993652
batch i:198
learning rate: 0.0001755829903978052, loss: 2.6242754459381104
batch i:199
learning rate: 0.0001755829903978052, loss: 2.677429676055908
batch i:200
learning rate: 0.0001755829903978052, loss: 2.71978759765625
current self-play batch: 200
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 190.51075065135956
New best policy from pure MCTS
batch i:201
learning rate: 0.0001755829903978052, loss: 2.71090030670166
batch i:202
learning rate: 0.0001755829903978052, loss: 2.7477383613586426
batch i:203
learning rate: 0.0001755829903978052, loss: 2.6241486072540283
batch i:204
learning rate: 0.0001755829903978052, loss: 2.6565656661987305
batch i:205
learning rate: 0.0001755829903978052, loss: 2.661625623703003
batch i:206
learning rate: 0.0001755829903978052, loss: 2.6923458576202393
batch i:207
learning rate: 0.0001755829903978052, loss: 2.679360866546631
batch i:208
learning rate: 0.0001755829903978052, loss: 2.727792978286743
batch i:209
learning rate: 0.0001755829903978052, loss: 2.6778197288513184
batch i:210
learning rate: 0.0001755829903978052, loss: 2.6859254837036133
batch i:211
learning rate: 0.0001755829903978052, loss: 2.650221109390259
batch i:212
learning rate: 0.0001755829903978052, loss: 2.7172443866729736
batch i:213
learning rate: 0.0001755829903978052, loss: 2.8253393173217773
batch i:214
learning rate: 0.0001755829903978052, loss: 2.790268898010254
batch i:215
learning rate: 0.0001755829903978052, loss: 2.7558462619781494
batch i:216
learning rate: 0.0001755829903978052, loss: 2.7574753761291504
batch i:217
learning rate: 0.0001755829903978052, loss: 2.754441738128662
batch i:218
learning rate: 0.0001755829903978052, loss: 2.726698875427246
batch i:219
learning rate: 0.0001755829903978052, loss: 2.7784156799316406
batch i:220
learning rate: 0.0001755829903978052, loss: 2.6587986946105957
batch i:221
learning rate: 0.0001755829903978052, loss: 2.685673475265503
batch i:222
learning rate: 0.0001755829903978052, loss: 2.7396187782287598
batch i:223
learning rate: 0.0001755829903978052, loss: 2.703486204147339
batch i:224
learning rate: 0.0001755829903978052, loss: 2.6578102111816406
batch i:225
learning rate: 0.0001755829903978052, loss: 2.5972323417663574
batch i:226
learning rate: 0.00011705532693187012, loss: 2.7800376415252686
batch i:227
learning rate: 0.00011705532693187012, loss: 2.8052804470062256
batch i:228
learning rate: 0.00011705532693187012, loss: 2.903038740158081
batch i:229
learning rate: 0.00011705532693187012, loss: 2.6710634231567383
batch i:230
learning rate: 0.00011705532693187012, loss: 2.6971402168273926
batch i:231
learning rate: 0.00011705532693187012, loss: 2.6549038887023926
batch i:232
learning rate: 0.00011705532693187012, loss: 2.7688846588134766
batch i:233
learning rate: 0.00011705532693187012, loss: 2.7037529945373535
batch i:234
learning rate: 0.00011705532693187012, loss: 2.681429624557495
batch i:235
learning rate: 0.00011705532693187012, loss: 2.6945042610168457
batch i:236
learning rate: 0.0001755829903978052, loss: 2.6069324016571045
batch i:237
learning rate: 0.0001755829903978052, loss: 2.6470813751220703
batch i:238
learning rate: 0.0001755829903978052, loss: 2.7295799255371094
batch i:239
learning rate: 0.0001755829903978052, loss: 2.6548705101013184
batch i:240
learning rate: 0.0001755829903978052, loss: 2.6736841201782227
batch i:241
learning rate: 0.0001755829903978052, loss: 2.621570110321045
batch i:242
learning rate: 0.0001755829903978052, loss: 2.6130075454711914
batch i:243
learning rate: 0.0001755829903978052, loss: 2.772439479827881
batch i:244
learning rate: 0.0001755829903978052, loss: 2.7270913124084473
batch i:245
learning rate: 0.0001755829903978052, loss: 2.6779985427856445
batch i:246
learning rate: 0.0001755829903978052, loss: 2.686342716217041
batch i:247
learning rate: 0.0001755829903978052, loss: 2.6487913131713867
batch i:248
learning rate: 0.00011705532693187012, loss: 2.7721145153045654
batch i:249
learning rate: 0.00011705532693187012, loss: 2.7422609329223633
batch i:250
learning rate: 0.00011705532693187012, loss: 2.752485752105713
current self-play batch: 250
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 206.26720204353333
batch i:251
learning rate: 0.00011705532693187012, loss: 2.6570005416870117
batch i:252
learning rate: 0.00011705532693187012, loss: 2.6784887313842773
batch i:253
learning rate: 0.00011705532693187012, loss: 2.654832601547241
batch i:254
learning rate: 0.00011705532693187012, loss: 2.6711959838867188
batch i:255
learning rate: 0.00011705532693187012, loss: 2.6803393363952637
batch i:256
learning rate: 0.00011705532693187012, loss: 2.779287576675415
batch i:257
learning rate: 0.00011705532693187012, loss: 2.7105610370635986
batch i:258
learning rate: 0.00011705532693187012, loss: 2.7029025554656982
batch i:259
learning rate: 0.00011705532693187012, loss: 2.7377233505249023
batch i:260
learning rate: 0.00011705532693187012, loss: 2.6402976512908936
batch i:261
learning rate: 0.00011705532693187012, loss: 2.6209936141967773
batch i:262
learning rate: 0.00011705532693187012, loss: 2.7158946990966797
batch i:263
learning rate: 0.00011705532693187012, loss: 2.7582056522369385
batch i:264
learning rate: 0.00011705532693187012, loss: 2.7210209369659424
batch i:265
learning rate: 0.00011705532693187012, loss: 2.667445421218872
batch i:266
learning rate: 0.00011705532693187012, loss: 2.707998752593994
batch i:267
learning rate: 0.00011705532693187012, loss: 2.7165613174438477
batch i:268
learning rate: 0.00011705532693187012, loss: 2.724668502807617
batch i:269
learning rate: 0.00011705532693187012, loss: 2.805805206298828
batch i:270
learning rate: 0.00011705532693187012, loss: 2.7169907093048096
batch i:271
learning rate: 0.00011705532693187012, loss: 2.7430758476257324
batch i:272
learning rate: 0.00011705532693187012, loss: 2.727832555770874
batch i:273
learning rate: 0.00011705532693187012, loss: 2.651848077774048
batch i:274
learning rate: 0.00011705532693187012, loss: 2.7597603797912598
batch i:275
learning rate: 0.00011705532693187012, loss: 2.7185628414154053
batch i:276
learning rate: 0.00011705532693187012, loss: 2.7093346118927
batch i:277
learning rate: 0.00011705532693187012, loss: 2.6858530044555664
batch i:278
learning rate: 0.00011705532693187012, loss: 2.7626190185546875
batch i:279
learning rate: 0.00011705532693187012, loss: 2.646773099899292
batch i:280
learning rate: 0.00011705532693187012, loss: 2.673916816711426
batch i:281
learning rate: 0.00011705532693187012, loss: 2.660055160522461
batch i:282
learning rate: 0.00011705532693187012, loss: 2.607431411743164
batch i:283
learning rate: 0.00011705532693187012, loss: 2.602353096008301
batch i:284
learning rate: 0.00011705532693187012, loss: 2.6488637924194336
batch i:285
learning rate: 0.00011705532693187012, loss: 2.5231399536132812
batch i:286
learning rate: 0.00011705532693187012, loss: 2.604794979095459
batch i:287
learning rate: 0.00011705532693187012, loss: 2.5866315364837646
batch i:288
learning rate: 0.00011705532693187012, loss: 2.612403631210327
batch i:289
learning rate: 0.00011705532693187012, loss: 2.6366987228393555
batch i:290
learning rate: 0.00011705532693187012, loss: 2.5805745124816895
batch i:291
learning rate: 0.00011705532693187012, loss: 2.659553050994873
batch i:292
learning rate: 0.00011705532693187012, loss: 2.680326223373413
batch i:293
learning rate: 0.00011705532693187012, loss: 2.569491386413574
batch i:294
learning rate: 0.00011705532693187012, loss: 2.575615882873535
batch i:295
learning rate: 0.00011705532693187012, loss: 2.698371410369873
batch i:296
learning rate: 0.00011705532693187012, loss: 2.5170540809631348
batch i:297
learning rate: 0.00011705532693187012, loss: 2.674621820449829
batch i:298
learning rate: 0.00011705532693187012, loss: 2.579244613647461
batch i:299
learning rate: 0.00011705532693187012, loss: 2.7047805786132812
batch i:300
learning rate: 0.00011705532693187012, loss: 2.632688283920288
current self-play batch: 300
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 141.12443001270293
New best policy from pure MCTS
batch i:301
learning rate: 0.00011705532693187012, loss: 2.5909719467163086
batch i:302
learning rate: 0.00011705532693187012, loss: 2.6217663288116455
batch i:303
learning rate: 0.00011705532693187012, loss: 2.550647735595703
batch i:304
learning rate: 0.00011705532693187012, loss: 2.563261032104492
batch i:305
learning rate: 0.00011705532693187012, loss: 2.5746281147003174
batch i:306
learning rate: 0.00011705532693187012, loss: 2.6502814292907715
batch i:307
learning rate: 0.00011705532693187012, loss: 2.5605268478393555
batch i:308
learning rate: 0.00011705532693187012, loss: 2.658841848373413
batch i:309
learning rate: 0.00011705532693187012, loss: 2.6810483932495117
batch i:310
learning rate: 0.00011705532693187012, loss: 2.565230369567871
batch i:311
learning rate: 0.00011705532693187012, loss: 2.602046012878418
batch i:312
learning rate: 0.00011705532693187012, loss: 2.597742795944214
batch i:313
learning rate: 0.00011705532693187012, loss: 2.543337106704712
batch i:314
learning rate: 0.00011705532693187012, loss: 2.630650520324707
batch i:315
learning rate: 0.00011705532693187012, loss: 2.545355796813965
batch i:316
learning rate: 0.00011705532693187012, loss: 2.5260143280029297
batch i:317
learning rate: 0.00011705532693187012, loss: 2.544003963470459
batch i:318
learning rate: 0.00011705532693187012, loss: 2.5483226776123047
batch i:319
learning rate: 0.00011705532693187012, loss: 2.680218458175659
batch i:320
learning rate: 0.00011705532693187012, loss: 2.548520088195801
batch i:321
learning rate: 0.00011705532693187012, loss: 2.509080648422241
batch i:322
learning rate: 0.00011705532693187012, loss: 2.535646915435791
batch i:323
learning rate: 0.00011705532693187012, loss: 2.584484100341797
batch i:324
learning rate: 0.00011705532693187012, loss: 2.6385226249694824
batch i:325
learning rate: 0.00011705532693187012, loss: 2.5353779792785645
batch i:326
learning rate: 0.00011705532693187012, loss: 2.447535514831543
batch i:327
learning rate: 0.00011705532693187012, loss: 2.5606231689453125
batch i:328
learning rate: 0.00011705532693187012, loss: 2.499666690826416
batch i:329
learning rate: 0.00011705532693187012, loss: 2.5855276584625244
batch i:330
learning rate: 0.00011705532693187012, loss: 2.5128750801086426
batch i:331
learning rate: 0.00011705532693187012, loss: 2.492274761199951
batch i:332
learning rate: 0.00011705532693187012, loss: 2.489375591278076
batch i:333
learning rate: 0.00011705532693187012, loss: 2.6067960262298584
batch i:334
learning rate: 0.00011705532693187012, loss: 2.6294941902160645
batch i:335
learning rate: 0.00011705532693187012, loss: 2.548482894897461
batch i:336
learning rate: 0.00011705532693187012, loss: 2.5070674419403076
batch i:337
learning rate: 0.00011705532693187012, loss: 2.5380141735076904
batch i:338
learning rate: 0.00011705532693187012, loss: 2.6188902854919434
batch i:339
learning rate: 0.00011705532693187012, loss: 2.5730557441711426
batch i:340
learning rate: 0.00011705532693187012, loss: 2.7080578804016113
batch i:341
learning rate: 0.00011705532693187012, loss: 2.602273941040039
batch i:342
learning rate: 0.00011705532693187012, loss: 2.618351936340332
batch i:343
learning rate: 0.00011705532693187012, loss: 2.548954963684082
batch i:344
learning rate: 0.00011705532693187012, loss: 2.6348190307617188
batch i:345
learning rate: 0.00011705532693187012, loss: 2.606977939605713
batch i:346
learning rate: 0.00011705532693187012, loss: 2.451627254486084
batch i:347
learning rate: 0.00011705532693187012, loss: 2.500933885574341
batch i:348
learning rate: 0.00011705532693187012, loss: 2.4441967010498047
batch i:349
learning rate: 0.00011705532693187012, loss: 2.406442403793335
batch i:350
learning rate: 0.00011705532693187012, loss: 2.4047560691833496
current self-play batch: 350
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 167.85262472629546
batch i:351
learning rate: 0.00011705532693187012, loss: 2.498476266860962
batch i:352
learning rate: 0.00011705532693187012, loss: 2.527998924255371
batch i:353
learning rate: 0.00011705532693187012, loss: 2.482513904571533
batch i:354
learning rate: 0.00011705532693187012, loss: 2.5685794353485107
batch i:355
learning rate: 0.00011705532693187012, loss: 2.618093967437744
batch i:356
learning rate: 0.00011705532693187012, loss: 2.512009620666504
batch i:357
learning rate: 0.00011705532693187012, loss: 2.5839905738830566
batch i:358
learning rate: 0.00011705532693187012, loss: 2.5557477474212646
batch i:359
learning rate: 0.00011705532693187012, loss: 2.5274152755737305
batch i:360
learning rate: 0.00011705532693187012, loss: 2.543980121612549
batch i:361
learning rate: 0.00011705532693187012, loss: 2.527456283569336
batch i:362
learning rate: 0.00011705532693187012, loss: 2.502530097961426
batch i:363
learning rate: 0.00011705532693187012, loss: 2.5533509254455566
batch i:364
learning rate: 0.00011705532693187012, loss: 2.5642921924591064
batch i:365
learning rate: 0.00011705532693187012, loss: 2.468662738800049
batch i:366
learning rate: 0.00011705532693187012, loss: 2.482081890106201
batch i:367
learning rate: 0.00011705532693187012, loss: 2.6119394302368164
batch i:368
learning rate: 0.00011705532693187012, loss: 2.504600763320923
batch i:369
learning rate: 0.00011705532693187012, loss: 2.592583656311035
batch i:370
learning rate: 0.00011705532693187012, loss: 2.675556182861328
batch i:371
learning rate: 0.00011705532693187012, loss: 2.5083911418914795
batch i:372
learning rate: 0.00011705532693187012, loss: 2.594041585922241
batch i:373
learning rate: 0.00011705532693187012, loss: 2.5771665573120117
batch i:374
learning rate: 0.00011705532693187012, loss: 2.61846923828125
batch i:375
learning rate: 0.00011705532693187012, loss: 2.4735140800476074
batch i:376
learning rate: 0.00011705532693187012, loss: 2.586980104446411
batch i:377
learning rate: 0.00011705532693187012, loss: 2.5282323360443115
batch i:378
learning rate: 0.00011705532693187012, loss: 2.5039725303649902
batch i:379
learning rate: 0.00011705532693187012, loss: 2.5841572284698486
batch i:380
learning rate: 0.00011705532693187012, loss: 2.578765869140625
batch i:381
learning rate: 0.00011705532693187012, loss: 2.5442497730255127
batch i:382
learning rate: 0.00011705532693187012, loss: 2.456907033920288
batch i:383
learning rate: 0.00011705532693187012, loss: 2.496490955352783
batch i:384
learning rate: 0.00011705532693187012, loss: 2.449382781982422
batch i:385
learning rate: 0.00011705532693187012, loss: 2.4329333305358887
batch i:386
learning rate: 0.00011705532693187012, loss: 2.4763967990875244
batch i:387
learning rate: 0.00011705532693187012, loss: 2.5049431324005127
batch i:388
learning rate: 0.00011705532693187012, loss: 2.495419502258301
batch i:389
learning rate: 0.00011705532693187012, loss: 2.687410354614258
batch i:390
learning rate: 0.00011705532693187012, loss: 2.543250322341919
batch i:391
learning rate: 0.00011705532693187012, loss: 2.596569061279297
batch i:392
learning rate: 0.00011705532693187012, loss: 2.5263795852661133
batch i:393
learning rate: 0.00011705532693187012, loss: 2.640177011489868
batch i:394
learning rate: 0.00011705532693187012, loss: 2.482550621032715
batch i:395
learning rate: 0.00011705532693187012, loss: 2.5091192722320557
batch i:396
learning rate: 0.00011705532693187012, loss: 2.5715434551239014
batch i:397
learning rate: 0.00011705532693187012, loss: 2.52181339263916
batch i:398
learning rate: 0.00011705532693187012, loss: 2.556440591812134
batch i:399
learning rate: 0.00011705532693187012, loss: 2.4796037673950195
batch i:400
learning rate: 0.00011705532693187012, loss: 2.5475168228149414
current self-play batch: 400
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 169.10455939769744
batch i:401
learning rate: 0.00011705532693187012, loss: 2.4850692749023438
batch i:402
learning rate: 0.00011705532693187012, loss: 2.4968996047973633
batch i:403
learning rate: 0.00011705532693187012, loss: 2.4963696002960205
batch i:404
learning rate: 0.00011705532693187012, loss: 2.555777072906494
batch i:405
learning rate: 0.00011705532693187012, loss: 2.595836639404297
batch i:406
learning rate: 0.00011705532693187012, loss: 2.5112931728363037
batch i:407
learning rate: 0.00011705532693187012, loss: 2.5786924362182617
batch i:408
learning rate: 0.00011705532693187012, loss: 2.5738863945007324
batch i:409
learning rate: 0.00011705532693187012, loss: 2.5307676792144775
batch i:410
learning rate: 0.00011705532693187012, loss: 2.5518460273742676
batch i:411
learning rate: 0.00011705532693187012, loss: 2.486062526702881
batch i:412
learning rate: 0.00011705532693187012, loss: 2.5693325996398926
batch i:413
learning rate: 0.00011705532693187012, loss: 2.595125198364258
batch i:414
learning rate: 0.00011705532693187012, loss: 2.6476831436157227
batch i:415
learning rate: 0.00011705532693187012, loss: 2.597961187362671
batch i:416
learning rate: 0.00011705532693187012, loss: 2.662780284881592
batch i:417
learning rate: 0.00011705532693187012, loss: 2.589728355407715
batch i:418
learning rate: 0.00011705532693187012, loss: 2.5416853427886963
batch i:419
learning rate: 0.00011705532693187012, loss: 2.613415479660034
batch i:420
learning rate: 0.00011705532693187012, loss: 2.599858283996582
batch i:421
learning rate: 0.0001755829903978052, loss: 2.669646978378296
batch i:422
learning rate: 0.0001755829903978052, loss: 2.598940372467041
batch i:423
learning rate: 0.0001755829903978052, loss: 2.6672561168670654
batch i:424
learning rate: 0.0001755829903978052, loss: 2.6493377685546875
batch i:425
learning rate: 0.0001755829903978052, loss: 2.690636157989502
batch i:426
learning rate: 0.0001755829903978052, loss: 2.6166269779205322
batch i:427
learning rate: 0.0001755829903978052, loss: 2.6143085956573486
batch i:428
learning rate: 0.0001755829903978052, loss: 2.4763193130493164
batch i:429
learning rate: 0.0001755829903978052, loss: 2.5232393741607666
batch i:430
learning rate: 0.0001755829903978052, loss: 2.567929983139038
batch i:431
learning rate: 0.00011705532693187012, loss: 2.5136260986328125
batch i:432
learning rate: 0.00011705532693187012, loss: 2.6363534927368164
batch i:433
learning rate: 0.00011705532693187012, loss: 2.6319708824157715
batch i:434
learning rate: 0.00011705532693187012, loss: 2.5696282386779785
batch i:435
learning rate: 0.00011705532693187012, loss: 2.6300368309020996
batch i:436
learning rate: 0.00011705532693187012, loss: 2.5117149353027344
batch i:437
learning rate: 0.00011705532693187012, loss: 2.557387351989746
batch i:438
learning rate: 0.00011705532693187012, loss: 2.655001640319824
batch i:439
learning rate: 0.00011705532693187012, loss: 2.614856243133545
batch i:440
learning rate: 0.00011705532693187012, loss: 2.5773160457611084
batch i:441
learning rate: 0.00011705532693187012, loss: 2.564253807067871
batch i:442
learning rate: 0.00011705532693187012, loss: 2.6225931644439697
batch i:443
learning rate: 0.00011705532693187012, loss: 2.6128897666931152
batch i:444
learning rate: 0.00011705532693187012, loss: 2.6216464042663574
batch i:445
learning rate: 0.00011705532693187012, loss: 2.4674806594848633
batch i:446
learning rate: 0.00011705532693187012, loss: 2.5251264572143555
batch i:447
learning rate: 0.00011705532693187012, loss: 2.484398365020752
batch i:448
learning rate: 0.00011705532693187012, loss: 2.590855121612549
batch i:449
learning rate: 0.00011705532693187012, loss: 2.507983446121216
batch i:450
learning rate: 0.00011705532693187012, loss: 2.486330986022949
current self-play batch: 450
num_playouts:2000, win: 8, lose: 1, tie:1
average time: 236.4481080532074
batch i:451
learning rate: 0.00011705532693187012, loss: 2.544560194015503
batch i:452
learning rate: 0.00011705532693187012, loss: 2.562443733215332
batch i:453
learning rate: 0.00011705532693187012, loss: 2.5819878578186035
batch i:454
learning rate: 0.00011705532693187012, loss: 2.565688133239746
batch i:455
learning rate: 0.00011705532693187012, loss: 2.665440559387207
batch i:456
learning rate: 0.00011705532693187012, loss: 2.7653021812438965
batch i:457
learning rate: 0.00011705532693187012, loss: 2.5337581634521484
batch i:458
learning rate: 0.00011705532693187012, loss: 2.757361888885498
batch i:459
learning rate: 0.00011705532693187012, loss: 2.5586957931518555
batch i:460
learning rate: 0.00011705532693187012, loss: 2.6488819122314453
batch i:461
learning rate: 0.00011705532693187012, loss: 2.567101001739502
batch i:462
learning rate: 0.00011705532693187012, loss: 2.490659236907959
batch i:463
learning rate: 0.00011705532693187012, loss: 2.4618334770202637
batch i:464
learning rate: 0.00011705532693187012, loss: 2.6053974628448486
batch i:465
learning rate: 0.00011705532693187012, loss: 2.6356849670410156
batch i:466
learning rate: 0.00011705532693187012, loss: 2.695291519165039
batch i:467
learning rate: 0.00011705532693187012, loss: 2.5509519577026367
batch i:468
learning rate: 0.00011705532693187012, loss: 2.609656810760498
batch i:469
learning rate: 0.00011705532693187012, loss: 2.5786709785461426
batch i:470
learning rate: 0.00011705532693187012, loss: 2.6005969047546387
batch i:471
learning rate: 0.00011705532693187012, loss: 2.590177059173584
batch i:472
learning rate: 0.00011705532693187012, loss: 2.716012477874756
batch i:473
learning rate: 0.00011705532693187012, loss: 2.601884126663208
batch i:474
learning rate: 0.00011705532693187012, loss: 2.516432046890259
batch i:475
learning rate: 0.00011705532693187012, loss: 2.649378776550293
batch i:476
learning rate: 0.00011705532693187012, loss: 2.6284451484680176
batch i:477
learning rate: 0.00011705532693187012, loss: 2.5606493949890137
batch i:478
learning rate: 0.00011705532693187012, loss: 2.576115131378174
batch i:479
learning rate: 0.00011705532693187012, loss: 2.5643303394317627
batch i:480
learning rate: 0.00011705532693187012, loss: 2.618946075439453
batch i:481
learning rate: 0.00011705532693187012, loss: 2.5742640495300293
batch i:482
learning rate: 0.00011705532693187012, loss: 2.5802128314971924
batch i:483
learning rate: 0.00011705532693187012, loss: 2.5468809604644775
batch i:484
learning rate: 0.00011705532693187012, loss: 2.5668697357177734
batch i:485
learning rate: 0.00011705532693187012, loss: 2.5077507495880127
batch i:486
learning rate: 0.00011705532693187012, loss: 2.6083016395568848
batch i:487
learning rate: 0.00011705532693187012, loss: 2.570042610168457
batch i:488
learning rate: 0.00011705532693187012, loss: 2.582258701324463
batch i:489
learning rate: 0.00011705532693187012, loss: 2.571824073791504
batch i:490
learning rate: 0.00011705532693187012, loss: 2.5662918090820312
batch i:491
learning rate: 0.00011705532693187012, loss: 2.5219614505767822
batch i:492
learning rate: 0.00011705532693187012, loss: 2.53800630569458
batch i:493
learning rate: 0.00011705532693187012, loss: 2.666172504425049
batch i:494
learning rate: 0.00011705532693187012, loss: 2.577531099319458
batch i:495
learning rate: 0.00011705532693187012, loss: 2.6368963718414307
batch i:496
learning rate: 0.00011705532693187012, loss: 2.531599760055542
batch i:497
learning rate: 0.00011705532693187012, loss: 2.4906578063964844
batch i:498
learning rate: 0.00011705532693187012, loss: 2.541043758392334
batch i:499
learning rate: 0.00011705532693187012, loss: 2.663973331451416
batch i:500
learning rate: 0.00011705532693187012, loss: 2.5902762413024902
current self-play batch: 500
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 142.3962230682373
batch i:501
learning rate: 0.00011705532693187012, loss: 2.4743194580078125
batch i:502
learning rate: 0.00011705532693187012, loss: 2.6194019317626953
batch i:503
learning rate: 0.00011705532693187012, loss: 2.619037628173828
batch i:504
learning rate: 0.00011705532693187012, loss: 2.5884437561035156
batch i:505
learning rate: 0.00011705532693187012, loss: 2.6108102798461914
batch i:506
learning rate: 0.00011705532693187012, loss: 2.6034576892852783
batch i:507
learning rate: 0.00011705532693187012, loss: 2.654998302459717
batch i:508
learning rate: 0.00011705532693187012, loss: 2.6268863677978516
batch i:509
learning rate: 0.00011705532693187012, loss: 2.7034265995025635
batch i:510
learning rate: 0.00011705532693187012, loss: 2.6037821769714355
batch i:511
learning rate: 0.00011705532693187012, loss: 2.590554714202881
batch i:512
learning rate: 0.00011705532693187012, loss: 2.748173236846924
batch i:513
learning rate: 0.00011705532693187012, loss: 2.6258764266967773
batch i:514
learning rate: 0.00011705532693187012, loss: 2.573784828186035
batch i:515
learning rate: 0.00011705532693187012, loss: 2.6363887786865234
batch i:516
learning rate: 0.00011705532693187012, loss: 2.55324125289917
batch i:517
learning rate: 0.00011705532693187012, loss: 2.6615805625915527
batch i:518
learning rate: 0.00011705532693187012, loss: 2.6135644912719727
batch i:519
learning rate: 0.00011705532693187012, loss: 2.6663084030151367
batch i:520
learning rate: 0.00011705532693187012, loss: 2.5779950618743896
batch i:521
learning rate: 0.00011705532693187012, loss: 2.6093761920928955
batch i:522
learning rate: 0.00011705532693187012, loss: 2.5908257961273193
batch i:523
learning rate: 0.00011705532693187012, loss: 2.5147452354431152
batch i:524
learning rate: 0.00011705532693187012, loss: 2.5740418434143066
batch i:525
learning rate: 0.00011705532693187012, loss: 2.4891357421875
batch i:526
learning rate: 0.00011705532693187012, loss: 2.5854976177215576
batch i:527
learning rate: 0.00011705532693187012, loss: 2.6764185428619385
batch i:528
learning rate: 0.00011705532693187012, loss: 2.677469491958618
batch i:529
learning rate: 0.00011705532693187012, loss: 2.5810089111328125
batch i:530
learning rate: 0.00011705532693187012, loss: 2.6910743713378906
batch i:531
learning rate: 0.00011705532693187012, loss: 2.6974611282348633
batch i:532
learning rate: 0.00011705532693187012, loss: 2.6804680824279785
batch i:533
learning rate: 0.00011705532693187012, loss: 2.71921968460083
batch i:534
learning rate: 0.00011705532693187012, loss: 2.6806581020355225
batch i:535
learning rate: 0.00011705532693187012, loss: 2.6733603477478027
batch i:536
learning rate: 0.00011705532693187012, loss: 2.6928505897521973
batch i:537
learning rate: 0.00011705532693187012, loss: 2.802659511566162
batch i:538
learning rate: 0.00011705532693187012, loss: 2.682840585708618
batch i:539
learning rate: 0.00011705532693187012, loss: 2.6393537521362305
batch i:540
learning rate: 0.00011705532693187012, loss: 2.653208017349243
batch i:541
learning rate: 0.00011705532693187012, loss: 2.681908369064331
batch i:542
learning rate: 0.00011705532693187012, loss: 2.652470111846924
batch i:543
learning rate: 0.00011705532693187012, loss: 2.582176446914673
batch i:544
learning rate: 0.00011705532693187012, loss: 2.650477409362793
batch i:545
learning rate: 0.00011705532693187012, loss: 2.6177163124084473
batch i:546
learning rate: 0.00011705532693187012, loss: 2.731351613998413
batch i:547
learning rate: 0.00011705532693187012, loss: 2.6958014965057373
batch i:548
learning rate: 0.00011705532693187012, loss: 2.692032814025879
batch i:549
learning rate: 0.00011705532693187012, loss: 2.6618432998657227
batch i:550
learning rate: 0.00011705532693187012, loss: 2.7093679904937744
current self-play batch: 550
num_playouts:2000, win: 7, lose: 2, tie:1
average time: 306.64019043445586
batch i:551
learning rate: 0.00011705532693187012, loss: 2.6336865425109863
batch i:552
learning rate: 0.00011705532693187012, loss: 2.7495503425598145
batch i:553
learning rate: 0.00011705532693187012, loss: 2.745373249053955
batch i:554
learning rate: 0.00011705532693187012, loss: 2.7389326095581055
batch i:555
learning rate: 0.00011705532693187012, loss: 2.7555174827575684
batch i:556
learning rate: 0.00011705532693187012, loss: 2.661247730255127
batch i:557
learning rate: 0.00011705532693187012, loss: 2.6308798789978027
batch i:558
learning rate: 0.00011705532693187012, loss: 2.7828667163848877
batch i:559
learning rate: 0.00011705532693187012, loss: 2.698610544204712
batch i:560
learning rate: 0.00011705532693187012, loss: 2.712265968322754
batch i:561
learning rate: 0.00011705532693187012, loss: 2.691689968109131
batch i:562
learning rate: 0.00011705532693187012, loss: 2.6795287132263184
batch i:563
learning rate: 0.00011705532693187012, loss: 2.770689010620117
batch i:564
learning rate: 0.00011705532693187012, loss: 2.6313862800598145
batch i:565
learning rate: 0.00011705532693187012, loss: 2.630026340484619
batch i:566
learning rate: 0.00011705532693187012, loss: 2.6887693405151367
batch i:567
learning rate: 0.00011705532693187012, loss: 2.672745943069458
batch i:568
learning rate: 0.00011705532693187012, loss: 2.698970317840576
batch i:569
learning rate: 0.00011705532693187012, loss: 2.636162281036377
batch i:570
learning rate: 0.00011705532693187012, loss: 2.576286792755127
batch i:571
learning rate: 0.00011705532693187012, loss: 2.654186248779297
batch i:572
learning rate: 0.00011705532693187012, loss: 2.584273338317871
batch i:573
learning rate: 0.00011705532693187012, loss: 2.566556930541992
batch i:574
learning rate: 0.00011705532693187012, loss: 2.6285502910614014
batch i:575
learning rate: 0.00011705532693187012, loss: 2.581753730773926
batch i:576
learning rate: 0.00011705532693187012, loss: 2.579540967941284
batch i:577
learning rate: 0.00011705532693187012, loss: 2.5346553325653076
batch i:578
learning rate: 0.00011705532693187012, loss: 2.5580623149871826
batch i:579
learning rate: 0.00011705532693187012, loss: 2.6138103008270264
batch i:580
learning rate: 0.00011705532693187012, loss: 2.5467052459716797
batch i:581
learning rate: 0.00011705532693187012, loss: 2.733097553253174
batch i:582
learning rate: 0.00011705532693187012, loss: 2.6434338092803955
batch i:583
learning rate: 0.00011705532693187012, loss: 2.618162155151367
batch i:584
learning rate: 0.00011705532693187012, loss: 2.674217939376831
batch i:585
learning rate: 0.00011705532693187012, loss: 2.5651612281799316
batch i:586
learning rate: 0.00011705532693187012, loss: 2.469820022583008
batch i:587
learning rate: 0.00011705532693187012, loss: 2.5304369926452637
batch i:588
learning rate: 0.00011705532693187012, loss: 2.5566887855529785
batch i:589
learning rate: 0.00011705532693187012, loss: 2.620579719543457
batch i:590
learning rate: 0.00011705532693187012, loss: 2.48140287399292
batch i:591
learning rate: 0.00011705532693187012, loss: 2.4851250648498535
batch i:592
learning rate: 0.00011705532693187012, loss: 2.5814614295959473
batch i:593
learning rate: 0.00011705532693187012, loss: 2.6265792846679688
batch i:594
learning rate: 0.00011705532693187012, loss: 2.6228556632995605
batch i:595
learning rate: 0.00011705532693187012, loss: 2.6013803482055664
batch i:596
learning rate: 0.00011705532693187012, loss: 2.7190165519714355
batch i:597
learning rate: 0.00011705532693187012, loss: 2.6848690509796143
batch i:598
learning rate: 0.0001755829903978052, loss: 2.6285812854766846
batch i:599
learning rate: 0.0001755829903978052, loss: 2.55430269241333
batch i:600
learning rate: 0.0001755829903978052, loss: 2.6865034103393555
current self-play batch: 600
num_playouts:2000, win: 5, lose: 0, tie:5
average time: 586.1692212343216
batch i:601
learning rate: 0.0001755829903978052, loss: 2.6601033210754395
batch i:602
learning rate: 0.0001755829903978052, loss: 2.708409070968628
batch i:603
learning rate: 0.0001755829903978052, loss: 2.7715373039245605
batch i:604
learning rate: 0.0001755829903978052, loss: 2.672095775604248
batch i:605
learning rate: 0.0001755829903978052, loss: 2.6918883323669434
batch i:606
learning rate: 0.0001755829903978052, loss: 2.643245220184326
batch i:607
learning rate: 0.0001755829903978052, loss: 2.6293444633483887
batch i:608
learning rate: 0.0001755829903978052, loss: 2.6788649559020996
batch i:609
learning rate: 0.0001755829903978052, loss: 2.684532642364502
batch i:610
learning rate: 0.0001755829903978052, loss: 2.679185390472412
batch i:611
learning rate: 0.0001755829903978052, loss: 2.6924760341644287
batch i:612
learning rate: 0.0001755829903978052, loss: 2.760303497314453
batch i:613
learning rate: 0.0001755829903978052, loss: 2.693624973297119
batch i:614
learning rate: 0.0001755829903978052, loss: 2.8948073387145996
batch i:615
learning rate: 0.0001755829903978052, loss: 2.7034668922424316
batch i:616
learning rate: 0.0001755829903978052, loss: 2.7834277153015137
batch i:617
learning rate: 0.0001755829903978052, loss: 2.8089096546173096
batch i:618
learning rate: 0.0001755829903978052, loss: 2.816073417663574
batch i:619
learning rate: 0.0001755829903978052, loss: 2.864243984222412
batch i:620
learning rate: 0.0001755829903978052, loss: 2.7804627418518066
batch i:621
learning rate: 0.0001755829903978052, loss: 2.709861993789673
batch i:622
learning rate: 0.0001755829903978052, loss: 2.7497775554656982
batch i:623
learning rate: 0.0001755829903978052, loss: 2.7091732025146484
batch i:624
learning rate: 0.0001755829903978052, loss: 2.761237621307373
batch i:625
learning rate: 0.0001755829903978052, loss: 2.6919984817504883
batch i:626
learning rate: 0.0001755829903978052, loss: 2.802438735961914
batch i:627
learning rate: 0.0001755829903978052, loss: 2.7937710285186768
batch i:628
learning rate: 0.0001755829903978052, loss: 2.700068950653076
batch i:629
learning rate: 0.0001755829903978052, loss: 2.7704977989196777
batch i:630
learning rate: 0.0001755829903978052, loss: 2.6808109283447266
batch i:631
learning rate: 0.0001755829903978052, loss: 2.7527146339416504
batch i:632
learning rate: 0.0001755829903978052, loss: 2.766857385635376
batch i:633
learning rate: 0.0001755829903978052, loss: 2.7271382808685303
batch i:634
learning rate: 0.0001755829903978052, loss: 2.7269978523254395
batch i:635
learning rate: 0.0001755829903978052, loss: 2.6250696182250977
batch i:636
learning rate: 0.0001755829903978052, loss: 2.6500649452209473
batch i:637
learning rate: 0.0001755829903978052, loss: 2.755858898162842
batch i:638
learning rate: 0.0001755829903978052, loss: 2.733516216278076
batch i:639
learning rate: 0.0001755829903978052, loss: 2.729830265045166
batch i:640
learning rate: 0.0001755829903978052, loss: 2.656463623046875
batch i:641
learning rate: 0.0001755829903978052, loss: 2.7308907508850098
batch i:642
learning rate: 0.0001755829903978052, loss: 2.712268114089966
batch i:643
learning rate: 0.0001755829903978052, loss: 2.699260711669922
batch i:644
learning rate: 0.0001755829903978052, loss: 2.68420147895813
batch i:645
learning rate: 0.0001755829903978052, loss: 2.7112958431243896
batch i:646
learning rate: 0.0001755829903978052, loss: 2.770784854888916
batch i:647
learning rate: 0.0001755829903978052, loss: 2.7593512535095215
batch i:648
learning rate: 0.0001755829903978052, loss: 2.819192886352539
batch i:649
learning rate: 0.0001755829903978052, loss: 2.7648370265960693
batch i:650
learning rate: 0.0001755829903978052, loss: 2.7120189666748047
current self-play batch: 650
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 192.32132422924042
batch i:651
learning rate: 0.0001755829903978052, loss: 2.652751922607422
batch i:652
learning rate: 0.0001755829903978052, loss: 2.7720298767089844
batch i:653
learning rate: 0.0001755829903978052, loss: 2.714287519454956
batch i:654
learning rate: 0.0001755829903978052, loss: 2.7336418628692627
batch i:655
learning rate: 0.0001755829903978052, loss: 2.868258476257324
batch i:656
learning rate: 0.0001755829903978052, loss: 2.7278378009796143
batch i:657
learning rate: 0.0001755829903978052, loss: 2.782332420349121
batch i:658
learning rate: 0.0001755829903978052, loss: 2.7619998455047607
batch i:659
learning rate: 0.0001755829903978052, loss: 2.805814266204834
batch i:660
learning rate: 0.0001755829903978052, loss: 2.6961731910705566
batch i:661
learning rate: 0.0001755829903978052, loss: 2.6613893508911133
batch i:662
learning rate: 0.0001755829903978052, loss: 2.675421953201294
batch i:663
learning rate: 0.0001755829903978052, loss: 2.757019519805908
batch i:664
learning rate: 0.0001755829903978052, loss: 2.755472183227539
batch i:665
learning rate: 0.0001755829903978052, loss: 2.7618908882141113
batch i:666
learning rate: 0.0001755829903978052, loss: 2.757331371307373
batch i:667
learning rate: 0.0001755829903978052, loss: 2.7075514793395996
batch i:668
learning rate: 0.0001755829903978052, loss: 2.7472028732299805
batch i:669
learning rate: 0.0001755829903978052, loss: 2.7197866439819336
batch i:670
learning rate: 0.0001755829903978052, loss: 2.72257661819458
batch i:671
learning rate: 0.0001755829903978052, loss: 2.7803425788879395
batch i:672
learning rate: 0.0001755829903978052, loss: 2.8142895698547363
batch i:673
learning rate: 0.0001755829903978052, loss: 2.7567076683044434
batch i:674
learning rate: 0.00011705532693187012, loss: 2.778810977935791
batch i:675
learning rate: 0.00011705532693187012, loss: 2.854409694671631
batch i:676
learning rate: 0.00011705532693187012, loss: 2.8105249404907227
batch i:677
learning rate: 0.00011705532693187012, loss: 2.7262234687805176
batch i:678
learning rate: 0.00011705532693187012, loss: 2.7527782917022705
batch i:679
learning rate: 0.00011705532693187012, loss: 2.683730363845825
batch i:680
learning rate: 0.00011705532693187012, loss: 2.7624635696411133
batch i:681
learning rate: 0.00011705532693187012, loss: 2.8115718364715576
batch i:682
learning rate: 0.00011705532693187012, loss: 2.7310335636138916
batch i:683
learning rate: 0.00011705532693187012, loss: 2.7458248138427734
batch i:684
learning rate: 0.00011705532693187012, loss: 2.6840262413024902
batch i:685
learning rate: 0.00011705532693187012, loss: 2.6397898197174072
batch i:686
learning rate: 0.0001755829903978052, loss: 2.766726016998291
batch i:687
learning rate: 0.0001755829903978052, loss: 2.8758840560913086
batch i:688
learning rate: 0.0001755829903978052, loss: 2.854473114013672
batch i:689
learning rate: 0.0001755829903978052, loss: 2.764631748199463
batch i:690
learning rate: 0.0001755829903978052, loss: 2.8144168853759766
batch i:691
learning rate: 0.0001755829903978052, loss: 2.8420960903167725
batch i:692
learning rate: 0.0001755829903978052, loss: 2.756693124771118
batch i:693
learning rate: 0.0001755829903978052, loss: 2.780822515487671
batch i:694
learning rate: 0.0001755829903978052, loss: 2.746830940246582
batch i:695
learning rate: 0.0001755829903978052, loss: 2.8602027893066406
batch i:696
learning rate: 0.0001755829903978052, loss: 2.7808094024658203
batch i:697
learning rate: 0.0001755829903978052, loss: 2.6488075256347656
batch i:698
learning rate: 0.0001755829903978052, loss: 2.885974407196045
batch i:699
learning rate: 0.0001755829903978052, loss: 2.7447926998138428
batch i:700
learning rate: 0.0001755829903978052, loss: 2.7212843894958496
current self-play batch: 700
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 152.21433370113374
batch i:701
learning rate: 0.0001755829903978052, loss: 2.8562116622924805
batch i:702
learning rate: 0.0001755829903978052, loss: 2.736910343170166
batch i:703
learning rate: 0.0001755829903978052, loss: 2.8430871963500977
batch i:704
learning rate: 0.0001755829903978052, loss: 2.8374063968658447
batch i:705
learning rate: 0.0001755829903978052, loss: 2.7821009159088135
batch i:706
learning rate: 0.0001755829903978052, loss: 2.7618443965911865
batch i:707
learning rate: 0.0001755829903978052, loss: 2.865319013595581
batch i:708
learning rate: 0.0001755829903978052, loss: 2.7579877376556396
batch i:709
learning rate: 0.0001755829903978052, loss: 2.7823824882507324
batch i:710
learning rate: 0.0001755829903978052, loss: 2.856661796569824
batch i:711
learning rate: 0.0001755829903978052, loss: 2.862863302230835
batch i:712
learning rate: 0.0001755829903978052, loss: 2.8798739910125732
batch i:713
learning rate: 0.0001755829903978052, loss: 2.9276089668273926
batch i:714
learning rate: 0.0001755829903978052, loss: 2.8334240913391113
batch i:715
learning rate: 0.0001755829903978052, loss: 2.8998360633850098
batch i:716
learning rate: 0.0001755829903978052, loss: 2.8645057678222656
batch i:717
learning rate: 0.0001755829903978052, loss: 2.9441773891448975
batch i:718
learning rate: 0.0001755829903978052, loss: 2.8765969276428223
batch i:719
learning rate: 0.0001755829903978052, loss: 2.81172513961792
batch i:720
learning rate: 0.0001755829903978052, loss: 2.9281864166259766
batch i:721
learning rate: 0.0001755829903978052, loss: 2.895211696624756
batch i:722
learning rate: 0.0001755829903978052, loss: 2.8636820316314697
batch i:723
learning rate: 0.0001755829903978052, loss: 2.998915195465088
batch i:724
learning rate: 0.0001755829903978052, loss: 2.941628932952881
batch i:725
learning rate: 0.0001755829903978052, loss: 2.959745168685913
batch i:726
learning rate: 0.0001755829903978052, loss: 3.044191360473633
batch i:727
learning rate: 0.0001755829903978052, loss: 2.9299025535583496
batch i:728
learning rate: 0.0001755829903978052, loss: 3.0970683097839355
batch i:729
learning rate: 0.0001755829903978052, loss: 2.9934005737304688
batch i:730
learning rate: 0.0001755829903978052, loss: 2.901841640472412
batch i:731
learning rate: 0.0001755829903978052, loss: 2.922104597091675
batch i:732
learning rate: 0.0001755829903978052, loss: 2.9173378944396973
batch i:733
learning rate: 0.0001755829903978052, loss: 2.953854560852051
batch i:734
learning rate: 0.0001755829903978052, loss: 2.867429494857788
batch i:735
learning rate: 0.0001755829903978052, loss: 2.9570631980895996
batch i:736
learning rate: 0.0001755829903978052, loss: 2.957021474838257
batch i:737
learning rate: 0.0001755829903978052, loss: 2.967989921569824
batch i:738
learning rate: 0.0001755829903978052, loss: 2.9223952293395996
batch i:739
learning rate: 0.0001755829903978052, loss: 2.8959813117980957
batch i:740
learning rate: 0.0001755829903978052, loss: 2.96091890335083
batch i:741
learning rate: 0.0001755829903978052, loss: 2.985433578491211
batch i:742
learning rate: 0.0001755829903978052, loss: 2.962899684906006
batch i:743
learning rate: 0.0001755829903978052, loss: 2.9167089462280273
batch i:744
learning rate: 0.0001755829903978052, loss: 3.0093278884887695
batch i:745
learning rate: 0.0001755829903978052, loss: 2.970946788787842
batch i:746
learning rate: 0.0001755829903978052, loss: 3.012138605117798
batch i:747
learning rate: 0.0001755829903978052, loss: 2.988161087036133
batch i:748
learning rate: 0.0001755829903978052, loss: 2.965322971343994
batch i:749
learning rate: 0.0001755829903978052, loss: 3.000775098800659
batch i:750
learning rate: 0.00011705532693187012, loss: 3.0122060775756836
current self-play batch: 750
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 180.99599432945251
batch i:751
learning rate: 0.00011705532693187012, loss: 3.0703907012939453
batch i:752
learning rate: 0.00011705532693187012, loss: 3.0554375648498535
batch i:753
learning rate: 0.00011705532693187012, loss: 3.1614317893981934
batch i:754
learning rate: 0.00011705532693187012, loss: 3.0374207496643066
batch i:755
learning rate: 0.00011705532693187012, loss: 3.087848663330078
batch i:756
learning rate: 0.00011705532693187012, loss: 3.056370258331299
batch i:757
learning rate: 0.00011705532693187012, loss: 3.0019795894622803
batch i:758
learning rate: 0.00011705532693187012, loss: 3.002258062362671
batch i:759
learning rate: 0.00011705532693187012, loss: 3.098761558532715
batch i:760
learning rate: 0.00011705532693187012, loss: 3.071805477142334
batch i:761
learning rate: 0.00011705532693187012, loss: 3.0835323333740234
batch i:762
learning rate: 0.00011705532693187012, loss: 3.008017063140869
batch i:763
learning rate: 0.00011705532693187012, loss: 2.9565749168395996
batch i:764
learning rate: 0.00011705532693187012, loss: 2.974848747253418
batch i:765
learning rate: 0.00011705532693187012, loss: 3.0579118728637695
batch i:766
learning rate: 0.00011705532693187012, loss: 3.0158629417419434
batch i:767
learning rate: 0.00011705532693187012, loss: 3.0495266914367676
batch i:768
learning rate: 0.00011705532693187012, loss: 3.0584492683410645
batch i:769
learning rate: 0.00011705532693187012, loss: 3.006598949432373
batch i:770
learning rate: 0.00011705532693187012, loss: 2.9919159412384033
batch i:771
learning rate: 0.00011705532693187012, loss: 3.041802406311035
batch i:772
learning rate: 0.00011705532693187012, loss: 2.925790309906006
batch i:773
learning rate: 0.00011705532693187012, loss: 3.0026113986968994
batch i:774
learning rate: 0.00011705532693187012, loss: 2.9137511253356934
batch i:775
learning rate: 0.00011705532693187012, loss: 2.854684352874756
batch i:776
learning rate: 0.00011705532693187012, loss: 2.950089454650879
batch i:777
learning rate: 0.00011705532693187012, loss: 2.8781278133392334
batch i:778
learning rate: 0.00011705532693187012, loss: 2.894216299057007
batch i:779
learning rate: 0.00011705532693187012, loss: 2.987435817718506
batch i:780
learning rate: 0.00011705532693187012, loss: 2.8772504329681396
batch i:781
learning rate: 0.00011705532693187012, loss: 2.8877882957458496
batch i:782
learning rate: 0.00011705532693187012, loss: 2.922154426574707
batch i:783
learning rate: 0.00011705532693187012, loss: 2.8370869159698486
batch i:784
learning rate: 0.00011705532693187012, loss: 2.9028406143188477
batch i:785
learning rate: 0.00011705532693187012, loss: 2.9196577072143555
batch i:786
learning rate: 0.0001755829903978052, loss: 2.9661195278167725
batch i:787
learning rate: 0.0001755829903978052, loss: 2.874974012374878
batch i:788
learning rate: 0.0001755829903978052, loss: 2.9114346504211426
batch i:789
learning rate: 0.0001755829903978052, loss: 2.905325174331665
batch i:790
learning rate: 0.0001755829903978052, loss: 2.9051380157470703
batch i:791
learning rate: 0.0001755829903978052, loss: 2.8370628356933594
batch i:792
learning rate: 0.0001755829903978052, loss: 2.97924542427063
batch i:793
learning rate: 0.0001755829903978052, loss: 2.9568684101104736
batch i:794
learning rate: 0.0001755829903978052, loss: 2.8935036659240723
batch i:795
learning rate: 0.0001755829903978052, loss: 2.832256555557251
batch i:796
learning rate: 0.0001755829903978052, loss: 2.820919990539551
batch i:797
learning rate: 0.0001755829903978052, loss: 2.8898143768310547
batch i:798
learning rate: 0.0001755829903978052, loss: 2.914742946624756
batch i:799
learning rate: 0.0001755829903978052, loss: 2.9930171966552734
batch i:800
learning rate: 0.0001755829903978052, loss: 2.9023373126983643
current self-play batch: 800
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 195.5372535943985
batch i:801
learning rate: 0.0001755829903978052, loss: 2.7987570762634277
batch i:802
learning rate: 0.0001755829903978052, loss: 2.9072208404541016
batch i:803
learning rate: 0.0001755829903978052, loss: 2.8898611068725586
batch i:804
learning rate: 0.0001755829903978052, loss: 2.863943099975586
batch i:805
learning rate: 0.0001755829903978052, loss: 2.9104080200195312
batch i:806
learning rate: 0.0001755829903978052, loss: 2.8456802368164062
batch i:807
learning rate: 0.0001755829903978052, loss: 2.78206205368042
batch i:808
learning rate: 0.0001755829903978052, loss: 2.759049415588379
batch i:809
learning rate: 0.0001755829903978052, loss: 2.7988343238830566
batch i:810
learning rate: 0.0001755829903978052, loss: 2.8720040321350098
batch i:811
learning rate: 0.0001755829903978052, loss: 2.81840443611145
batch i:812
learning rate: 0.0001755829903978052, loss: 2.839383363723755
batch i:813
learning rate: 0.0001755829903978052, loss: 2.851045608520508
batch i:814
learning rate: 0.0001755829903978052, loss: 2.8071367740631104
batch i:815
learning rate: 0.0001755829903978052, loss: 2.947226047515869
batch i:816
learning rate: 0.0001755829903978052, loss: 2.9300460815429688
batch i:817
learning rate: 0.0001755829903978052, loss: 2.8659520149230957
batch i:818
learning rate: 0.0001755829903978052, loss: 2.8651225566864014
batch i:819
learning rate: 0.00011705532693187012, loss: 2.7562098503112793
batch i:820
learning rate: 0.00011705532693187012, loss: 2.833272933959961
batch i:821
learning rate: 0.00011705532693187012, loss: 2.856318712234497
batch i:822
learning rate: 0.00011705532693187012, loss: 2.790283679962158
batch i:823
learning rate: 0.00011705532693187012, loss: 2.905988931655884
batch i:824
learning rate: 0.00011705532693187012, loss: 2.869387626647949
batch i:825
learning rate: 0.00011705532693187012, loss: 2.848961353302002
batch i:826
learning rate: 0.0001755829903978052, loss: 2.881319761276245
batch i:827
learning rate: 0.0001755829903978052, loss: 2.747680187225342
batch i:828
learning rate: 0.0001755829903978052, loss: 2.8334267139434814
batch i:829
learning rate: 0.0001755829903978052, loss: 2.889387845993042
batch i:830
learning rate: 0.0001755829903978052, loss: 2.710446834564209
batch i:831
learning rate: 0.0001755829903978052, loss: 2.788949966430664
batch i:832
learning rate: 0.0001755829903978052, loss: 2.9299588203430176
batch i:833
learning rate: 0.0001755829903978052, loss: 2.7181801795959473
batch i:834
learning rate: 0.0001755829903978052, loss: 2.738950252532959
batch i:835
learning rate: 0.0001755829903978052, loss: 2.7155263423919678
batch i:836
learning rate: 0.0001755829903978052, loss: 2.868898391723633
batch i:837
learning rate: 0.0001755829903978052, loss: 2.7531027793884277
batch i:838
learning rate: 0.0001755829903978052, loss: 2.7736167907714844
batch i:839
learning rate: 0.0001755829903978052, loss: 2.829423666000366
batch i:840
learning rate: 0.0001755829903978052, loss: 2.794290065765381
batch i:841
learning rate: 0.0001755829903978052, loss: 2.803436279296875
batch i:842
learning rate: 0.0001755829903978052, loss: 2.8622891902923584
batch i:843
learning rate: 0.0001755829903978052, loss: 2.8111438751220703
batch i:844
learning rate: 0.0001755829903978052, loss: 2.7068328857421875
batch i:845
learning rate: 0.0001755829903978052, loss: 2.7288546562194824
batch i:846
learning rate: 0.0001755829903978052, loss: 2.6862213611602783
batch i:847
learning rate: 0.0001755829903978052, loss: 2.7652761936187744
batch i:848
learning rate: 0.0001755829903978052, loss: 2.7135910987854004
batch i:849
learning rate: 0.0001755829903978052, loss: 2.845608711242676
batch i:850
learning rate: 0.0001755829903978052, loss: 2.7695491313934326
current self-play batch: 850
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 189.71913454532623
batch i:851
learning rate: 0.0001755829903978052, loss: 2.6511199474334717
batch i:852
learning rate: 0.0001755829903978052, loss: 2.6956934928894043
batch i:853
learning rate: 0.0001755829903978052, loss: 2.810518264770508
batch i:854
learning rate: 0.0001755829903978052, loss: 2.6780309677124023
batch i:855
learning rate: 0.0001755829903978052, loss: 2.684573173522949
batch i:856
learning rate: 0.0001755829903978052, loss: 2.7132248878479004
batch i:857
learning rate: 0.0001755829903978052, loss: 2.7808289527893066
batch i:858
learning rate: 0.0001755829903978052, loss: 2.7176060676574707
batch i:859
learning rate: 0.0001755829903978052, loss: 2.7329845428466797
batch i:860
learning rate: 0.0001755829903978052, loss: 2.727370023727417
batch i:861
learning rate: 0.0001755829903978052, loss: 2.6923727989196777
batch i:862
learning rate: 0.0001755829903978052, loss: 2.7315800189971924
batch i:863
learning rate: 0.0001755829903978052, loss: 2.8456053733825684
batch i:864
learning rate: 0.0001755829903978052, loss: 2.885556221008301
batch i:865
learning rate: 0.0001755829903978052, loss: 2.7475123405456543
batch i:866
learning rate: 0.0001755829903978052, loss: 2.7692201137542725
batch i:867
learning rate: 0.0001755829903978052, loss: 2.74005126953125
batch i:868
learning rate: 0.0001755829903978052, loss: 2.7327146530151367
batch i:869
learning rate: 0.0001755829903978052, loss: 2.6717376708984375
batch i:870
learning rate: 0.0001755829903978052, loss: 2.7932114601135254
batch i:871
learning rate: 0.0001755829903978052, loss: 2.68996524810791
batch i:872
learning rate: 0.0001755829903978052, loss: 2.802394151687622
batch i:873
learning rate: 0.0001755829903978052, loss: 2.77254056930542
batch i:874
learning rate: 0.0001755829903978052, loss: 2.8257412910461426
batch i:875
learning rate: 0.0001755829903978052, loss: 2.7279343605041504
batch i:876
learning rate: 0.0001755829903978052, loss: 2.777419090270996
batch i:877
learning rate: 0.0001755829903978052, loss: 2.792797327041626
batch i:878
learning rate: 0.0001755829903978052, loss: 2.812422752380371
batch i:879
learning rate: 0.0001755829903978052, loss: 2.7338452339172363
batch i:880
learning rate: 0.0001755829903978052, loss: 2.794126033782959
batch i:881
learning rate: 0.0001755829903978052, loss: 2.7303414344787598
batch i:882
learning rate: 0.0001755829903978052, loss: 2.7930691242218018
batch i:883
learning rate: 0.0001755829903978052, loss: 2.7865490913391113
batch i:884
learning rate: 0.0001755829903978052, loss: 2.7643609046936035
batch i:885
learning rate: 0.0001755829903978052, loss: 2.827434778213501
batch i:886
learning rate: 0.0001755829903978052, loss: 2.708831787109375
batch i:887
learning rate: 0.0001755829903978052, loss: 2.7066938877105713
batch i:888
learning rate: 0.0001755829903978052, loss: 2.804229736328125
batch i:889
learning rate: 0.0001755829903978052, loss: 2.746028423309326
batch i:890
learning rate: 0.00011705532693187012, loss: 2.808326244354248
batch i:891
learning rate: 0.00011705532693187012, loss: 2.7242870330810547
batch i:892
learning rate: 0.00011705532693187012, loss: 2.7255115509033203
batch i:893
learning rate: 0.00011705532693187012, loss: 2.794564723968506
batch i:894
learning rate: 0.00011705532693187012, loss: 2.9663071632385254
batch i:895
learning rate: 0.00011705532693187012, loss: 2.9135022163391113
batch i:896
learning rate: 0.00011705532693187012, loss: 2.81653094291687
batch i:897
learning rate: 0.00011705532693187012, loss: 2.8304123878479004
batch i:898
learning rate: 0.00011705532693187012, loss: 2.831141471862793
batch i:899
learning rate: 0.00011705532693187012, loss: 2.8614392280578613
batch i:900
learning rate: 0.00011705532693187012, loss: 2.7847375869750977
current self-play batch: 900
num_playouts:2000, win: 10, lose: 0, tie:0
average time: 220.9770241498947
New best policy from pure MCTS
batch i:901
learning rate: 0.00011705532693187012, loss: 2.929370403289795
batch i:902
learning rate: 0.0001755829903978052, loss: 2.843311071395874
batch i:903
learning rate: 0.0001755829903978052, loss: 2.7343273162841797
batch i:904
learning rate: 0.0001755829903978052, loss: 2.8217785358428955
batch i:905
learning rate: 0.0001755829903978052, loss: 2.783184289932251
batch i:906
learning rate: 0.0001755829903978052, loss: 2.8747262954711914
batch i:907
learning rate: 0.0001755829903978052, loss: 2.8094139099121094
batch i:908
learning rate: 0.0001755829903978052, loss: 2.8244845867156982
batch i:909
learning rate: 0.0001755829903978052, loss: 2.845445156097412
batch i:910
learning rate: 0.0001755829903978052, loss: 2.706437587738037
batch i:911
learning rate: 0.0001755829903978052, loss: 2.7111408710479736
batch i:912
learning rate: 0.0001755829903978052, loss: 2.7714099884033203
batch i:913
learning rate: 0.0001755829903978052, loss: 2.768111228942871
batch i:914
learning rate: 0.00011705532693187012, loss: 2.733903408050537
batch i:915
learning rate: 0.00011705532693187012, loss: 2.7561252117156982
batch i:916
learning rate: 0.00011705532693187012, loss: 2.7934818267822266
batch i:917
learning rate: 0.00011705532693187012, loss: 2.781766414642334
batch i:918
learning rate: 0.00011705532693187012, loss: 2.750499725341797
batch i:919
learning rate: 0.00011705532693187012, loss: 2.6869754791259766
batch i:920
learning rate: 0.00011705532693187012, loss: 2.702815532684326
batch i:921
learning rate: 0.00011705532693187012, loss: 2.719566822052002
batch i:922
learning rate: 0.00011705532693187012, loss: 2.666013717651367
batch i:923
learning rate: 0.00011705532693187012, loss: 2.7403531074523926
batch i:924
learning rate: 0.00011705532693187012, loss: 2.6078684329986572
batch i:925
learning rate: 0.00011705532693187012, loss: 2.672140121459961
batch i:926
learning rate: 0.00011705532693187012, loss: 2.6497907638549805
batch i:927
learning rate: 0.00011705532693187012, loss: 2.696467876434326
batch i:928
learning rate: 0.00011705532693187012, loss: 2.6520471572875977
batch i:929
learning rate: 0.00011705532693187012, loss: 2.6606051921844482
batch i:930
learning rate: 0.00011705532693187012, loss: 2.5182323455810547
batch i:931
learning rate: 0.00011705532693187012, loss: 2.6729393005371094
batch i:932
learning rate: 0.00011705532693187012, loss: 2.648670196533203
batch i:933
learning rate: 0.00011705532693187012, loss: 2.696765899658203
batch i:934
learning rate: 0.00011705532693187012, loss: 2.536898374557495
batch i:935
learning rate: 0.00011705532693187012, loss: 2.650277614593506
batch i:936
learning rate: 0.00011705532693187012, loss: 2.7886390686035156
batch i:937
learning rate: 0.00011705532693187012, loss: 2.6537320613861084
batch i:938
learning rate: 0.00011705532693187012, loss: 2.6935949325561523
batch i:939
learning rate: 0.00011705532693187012, loss: 2.693769931793213
batch i:940
learning rate: 0.00011705532693187012, loss: 2.7249388694763184
batch i:941
learning rate: 0.00011705532693187012, loss: 2.6695895195007324
batch i:942
learning rate: 0.00011705532693187012, loss: 2.6925344467163086
batch i:943
learning rate: 0.00011705532693187012, loss: 2.617265224456787
batch i:944
learning rate: 0.00011705532693187012, loss: 2.6921448707580566
batch i:945
learning rate: 0.00011705532693187012, loss: 2.7667665481567383
batch i:946
learning rate: 0.00011705532693187012, loss: 2.7252988815307617
batch i:947
learning rate: 0.00011705532693187012, loss: 2.8060975074768066
batch i:948
learning rate: 0.00011705532693187012, loss: 2.738807439804077
batch i:949
learning rate: 0.00011705532693187012, loss: 2.841991901397705
batch i:950
learning rate: 0.00011705532693187012, loss: 2.6524720191955566
current self-play batch: 950
num_playouts:3000, win: 9, lose: 0, tie:1
average time: 405.2022803068161
New best policy from pure MCTS
batch i:951
learning rate: 0.00011705532693187012, loss: 2.690398693084717
batch i:952
learning rate: 0.00011705532693187012, loss: 2.6219213008880615
batch i:953
learning rate: 0.00011705532693187012, loss: 2.6972153186798096
batch i:954
learning rate: 0.00011705532693187012, loss: 2.7431704998016357
batch i:955
learning rate: 0.00011705532693187012, loss: 2.7975106239318848
batch i:956
learning rate: 0.00011705532693187012, loss: 2.685802698135376
batch i:957
learning rate: 0.00011705532693187012, loss: 2.661980628967285
batch i:958
learning rate: 0.00011705532693187012, loss: 2.573051929473877
batch i:959
learning rate: 0.00011705532693187012, loss: 2.640709161758423
batch i:960
learning rate: 0.00011705532693187012, loss: 2.5624327659606934
batch i:961
learning rate: 0.00011705532693187012, loss: 2.5314230918884277
batch i:962
learning rate: 0.00011705532693187012, loss: 2.521980047225952
batch i:963
learning rate: 0.00011705532693187012, loss: 2.5984933376312256
batch i:964
learning rate: 0.00011705532693187012, loss: 2.500361919403076
batch i:965
learning rate: 0.00011705532693187012, loss: 2.6070051193237305
batch i:966
learning rate: 0.00011705532693187012, loss: 2.464519500732422
batch i:967
learning rate: 0.00011705532693187012, loss: 2.5938284397125244
batch i:968
learning rate: 0.00011705532693187012, loss: 2.4782931804656982
batch i:969
learning rate: 0.00011705532693187012, loss: 2.6068451404571533
batch i:970
learning rate: 0.00011705532693187012, loss: 2.5573201179504395
batch i:971
learning rate: 0.00011705532693187012, loss: 2.4975316524505615
batch i:972
learning rate: 0.00011705532693187012, loss: 2.350161075592041
batch i:973
learning rate: 0.00011705532693187012, loss: 2.537445545196533
batch i:974
learning rate: 0.00011705532693187012, loss: 2.578221321105957
batch i:975
learning rate: 0.00011705532693187012, loss: 2.5083847045898438
batch i:976
learning rate: 0.00011705532693187012, loss: 2.4993908405303955
batch i:977
learning rate: 0.00011705532693187012, loss: 2.5520126819610596
batch i:978
learning rate: 0.00011705532693187012, loss: 2.5032286643981934
batch i:979
learning rate: 0.00011705532693187012, loss: 2.525758743286133
batch i:980
learning rate: 0.00011705532693187012, loss: 2.5180866718292236
batch i:981
learning rate: 0.00011705532693187012, loss: 2.588776111602783
batch i:982
learning rate: 0.00011705532693187012, loss: 2.572199821472168
batch i:983
learning rate: 0.0001755829903978052, loss: 2.5868639945983887
batch i:984
learning rate: 0.0001755829903978052, loss: 2.6418094635009766
batch i:985
learning rate: 0.0001755829903978052, loss: 2.600661277770996
batch i:986
learning rate: 0.0001755829903978052, loss: 2.8233087062835693
batch i:987
learning rate: 0.0001755829903978052, loss: 2.741419553756714
batch i:988
learning rate: 0.0001755829903978052, loss: 2.727030038833618
batch i:989
learning rate: 0.0001755829903978052, loss: 2.6156229972839355
batch i:990
learning rate: 0.0001755829903978052, loss: 2.669152021408081
batch i:991
learning rate: 0.0001755829903978052, loss: 2.6031861305236816
batch i:992
learning rate: 0.0001755829903978052, loss: 2.647892713546753
batch i:993
learning rate: 0.0001755829903978052, loss: 2.6376137733459473
batch i:994
learning rate: 0.0001755829903978052, loss: 2.6844193935394287
batch i:995
learning rate: 0.0001755829903978052, loss: 2.7549843788146973
batch i:996
learning rate: 0.0001755829903978052, loss: 2.638456106185913
batch i:997
learning rate: 0.0001755829903978052, loss: 2.6385765075683594
batch i:998
learning rate: 0.0001755829903978052, loss: 2.774538516998291
batch i:999
learning rate: 0.0001755829903978052, loss: 2.6573705673217773
batch i:1000
learning rate: 0.0001755829903978052, loss: 2.6562271118164062
current self-play batch: 1000
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 359.9469621181488
batch i:1001
learning rate: 0.0001755829903978052, loss: 2.688133716583252
batch i:1002
learning rate: 0.0001755829903978052, loss: 2.641791343688965
batch i:1003
learning rate: 0.0001755829903978052, loss: 2.6730260848999023
batch i:1004
learning rate: 0.0001755829903978052, loss: 2.5952706336975098
batch i:1005
learning rate: 0.0001755829903978052, loss: 2.6016225814819336
batch i:1006
learning rate: 0.0001755829903978052, loss: 2.692838668823242
batch i:1007
learning rate: 0.0001755829903978052, loss: 2.6700572967529297
batch i:1008
learning rate: 0.0001755829903978052, loss: 2.6998538970947266
batch i:1009
learning rate: 0.0001755829903978052, loss: 2.6884279251098633
batch i:1010
learning rate: 0.0001755829903978052, loss: 2.8432486057281494
batch i:1011
learning rate: 0.0001755829903978052, loss: 2.722123384475708
batch i:1012
learning rate: 0.0001755829903978052, loss: 2.721097469329834
batch i:1013
learning rate: 0.0001755829903978052, loss: 2.687546968460083
batch i:1014
learning rate: 0.0001755829903978052, loss: 2.77510929107666
batch i:1015
learning rate: 0.0001755829903978052, loss: 2.7706170082092285
batch i:1016
learning rate: 0.0001755829903978052, loss: 2.6546528339385986
batch i:1017
learning rate: 0.0001755829903978052, loss: 2.5848681926727295
batch i:1018
learning rate: 0.0001755829903978052, loss: 2.7479920387268066
batch i:1019
learning rate: 0.0001755829903978052, loss: 2.6949145793914795
batch i:1020
learning rate: 0.0001755829903978052, loss: 2.7723472118377686
batch i:1021
learning rate: 0.0001755829903978052, loss: 2.800291061401367
batch i:1022
learning rate: 0.0001755829903978052, loss: 2.8468918800354004
batch i:1023
learning rate: 0.0001755829903978052, loss: 2.8322319984436035
batch i:1024
learning rate: 0.0001755829903978052, loss: 2.858511447906494
batch i:1025
learning rate: 0.0001755829903978052, loss: 2.8586924076080322
batch i:1026
learning rate: 0.0001755829903978052, loss: 2.7624340057373047
batch i:1027
learning rate: 0.0001755829903978052, loss: 2.9025063514709473
batch i:1028
learning rate: 0.0001755829903978052, loss: 2.8015873432159424
batch i:1029
learning rate: 0.0001755829903978052, loss: 2.7662878036499023
batch i:1030
learning rate: 0.0001755829903978052, loss: 2.8203284740448
batch i:1031
learning rate: 0.0001755829903978052, loss: 2.8744912147521973
batch i:1032
learning rate: 0.0001755829903978052, loss: 2.742516279220581
batch i:1033
learning rate: 0.0001755829903978052, loss: 2.748868942260742
batch i:1034
learning rate: 0.0001755829903978052, loss: 2.738281726837158
batch i:1035
learning rate: 0.0001755829903978052, loss: 2.8051862716674805
batch i:1036
learning rate: 0.0001755829903978052, loss: 2.7732019424438477
batch i:1037
learning rate: 0.0001755829903978052, loss: 2.790987491607666
batch i:1038
learning rate: 0.0001755829903978052, loss: 2.81120228767395
batch i:1039
learning rate: 0.0001755829903978052, loss: 2.763782262802124
batch i:1040
learning rate: 0.0001755829903978052, loss: 2.721334457397461
batch i:1041
learning rate: 0.0001755829903978052, loss: 2.730602264404297
batch i:1042
learning rate: 0.0001755829903978052, loss: 2.805428981781006
batch i:1043
learning rate: 0.0001755829903978052, loss: 2.8065338134765625
batch i:1044
learning rate: 0.0001755829903978052, loss: 2.728301525115967
batch i:1045
learning rate: 0.0001755829903978052, loss: 2.7145700454711914
batch i:1046
learning rate: 0.0001755829903978052, loss: 2.694434404373169
batch i:1047
learning rate: 0.0001755829903978052, loss: 2.7915940284729004
batch i:1048
learning rate: 0.0001755829903978052, loss: 2.807145595550537
batch i:1049
learning rate: 0.0001755829903978052, loss: 2.76273775100708
batch i:1050
learning rate: 0.0001755829903978052, loss: 2.7728524208068848
current self-play batch: 1050
num_playouts:3000, win: 5, lose: 5, tie:0
average time: 314.1879197120667
batch i:1051
learning rate: 0.0001755829903978052, loss: 2.772378444671631
batch i:1052
learning rate: 0.0001755829903978052, loss: 2.7214550971984863
batch i:1053
learning rate: 0.0001755829903978052, loss: 2.774623394012451
batch i:1054
learning rate: 0.0001755829903978052, loss: 2.8055875301361084
batch i:1055
learning rate: 0.0001755829903978052, loss: 2.6952338218688965
batch i:1056
learning rate: 0.0001755829903978052, loss: 2.8086915016174316
batch i:1057
learning rate: 0.0001755829903978052, loss: 2.7911124229431152
batch i:1058
learning rate: 0.0001755829903978052, loss: 2.705902099609375
batch i:1059
learning rate: 0.0001755829903978052, loss: 2.677920341491699
batch i:1060
learning rate: 0.0001755829903978052, loss: 2.744786500930786
batch i:1061
learning rate: 0.0001755829903978052, loss: 2.8135435581207275
batch i:1062
learning rate: 0.0001755829903978052, loss: 2.812803268432617
batch i:1063
learning rate: 0.0001755829903978052, loss: 2.727411985397339
batch i:1064
learning rate: 0.0001755829903978052, loss: 2.8474936485290527
batch i:1065
learning rate: 0.0001755829903978052, loss: 2.7777559757232666
batch i:1066
learning rate: 0.0001755829903978052, loss: 2.779385566711426
batch i:1067
learning rate: 0.0001755829903978052, loss: 2.7954769134521484
batch i:1068
learning rate: 0.0001755829903978052, loss: 2.78659725189209
batch i:1069
learning rate: 0.0001755829903978052, loss: 2.8142523765563965
batch i:1070
learning rate: 0.0001755829903978052, loss: 2.6397805213928223
batch i:1071
learning rate: 0.0001755829903978052, loss: 2.7518138885498047
batch i:1072
learning rate: 0.0001755829903978052, loss: 2.771084785461426
batch i:1073
learning rate: 0.0001755829903978052, loss: 2.796046018600464
batch i:1074
learning rate: 0.0001755829903978052, loss: 2.7662267684936523
batch i:1075
learning rate: 0.0001755829903978052, loss: 2.790881395339966
batch i:1076
learning rate: 0.0001755829903978052, loss: 2.868391990661621
batch i:1077
learning rate: 0.0001755829903978052, loss: 2.814831256866455
batch i:1078
learning rate: 0.0001755829903978052, loss: 2.721848726272583
batch i:1079
learning rate: 0.0001755829903978052, loss: 2.8710906505584717
batch i:1080
learning rate: 0.0001755829903978052, loss: 2.686392307281494
batch i:1081
learning rate: 0.0001755829903978052, loss: 2.684779644012451
batch i:1082
learning rate: 0.0001755829903978052, loss: 2.797457218170166
batch i:1083
learning rate: 0.0001755829903978052, loss: 2.697005271911621
batch i:1084
learning rate: 0.0001755829903978052, loss: 2.706541061401367
batch i:1085
learning rate: 0.0001755829903978052, loss: 2.8290836811065674
batch i:1086
learning rate: 0.0001755829903978052, loss: 2.9040355682373047
batch i:1087
learning rate: 0.0001755829903978052, loss: 2.8915598392486572
batch i:1088
learning rate: 0.0001755829903978052, loss: 2.73262357711792
batch i:1089
learning rate: 0.0001755829903978052, loss: 2.9468231201171875
batch i:1090
learning rate: 0.0001755829903978052, loss: 2.859935998916626
batch i:1091
learning rate: 0.0001755829903978052, loss: 2.747030258178711
batch i:1092
learning rate: 0.0001755829903978052, loss: 2.7641119956970215
batch i:1093
learning rate: 0.0001755829903978052, loss: 2.7430734634399414
batch i:1094
learning rate: 0.0001755829903978052, loss: 2.832519054412842
batch i:1095
learning rate: 0.0001755829903978052, loss: 2.870242118835449
batch i:1096
learning rate: 0.0001755829903978052, loss: 2.8923423290252686
batch i:1097
learning rate: 0.0001755829903978052, loss: 2.9182915687561035
batch i:1098
learning rate: 0.0001755829903978052, loss: 2.8755035400390625
batch i:1099
learning rate: 0.0001755829903978052, loss: 2.8788161277770996
batch i:1100
learning rate: 0.0001755829903978052, loss: 2.884032726287842
current self-play batch: 1100
num_playouts:3000, win: 5, lose: 5, tie:0
average time: 401.88464970588683
batch i:1101
learning rate: 0.0001755829903978052, loss: 2.9054203033447266
batch i:1102
learning rate: 0.0001755829903978052, loss: 2.8852739334106445
batch i:1103
learning rate: 0.0001755829903978052, loss: 2.9541501998901367
batch i:1104
learning rate: 0.0001755829903978052, loss: 2.8754279613494873
batch i:1105
learning rate: 0.0001755829903978052, loss: 2.905991554260254
batch i:1106
learning rate: 0.0001755829903978052, loss: 2.8385252952575684
batch i:1107
learning rate: 0.0001755829903978052, loss: 2.8058085441589355
batch i:1108
learning rate: 0.0001755829903978052, loss: 2.8624162673950195
batch i:1109
learning rate: 0.0001755829903978052, loss: 2.7936322689056396
batch i:1110
learning rate: 0.0001755829903978052, loss: 2.7741990089416504
batch i:1111
learning rate: 0.0001755829903978052, loss: 2.801151752471924
batch i:1112
learning rate: 0.0001755829903978052, loss: 2.775515079498291
batch i:1113
learning rate: 0.0001755829903978052, loss: 2.8977880477905273
batch i:1114
learning rate: 0.0001755829903978052, loss: 2.83313250541687
batch i:1115
learning rate: 0.0001755829903978052, loss: 2.8279128074645996
batch i:1116
learning rate: 0.0001755829903978052, loss: 2.8209404945373535
batch i:1117
learning rate: 0.0001755829903978052, loss: 2.7480015754699707
batch i:1118
learning rate: 0.0001755829903978052, loss: 2.7763595581054688
batch i:1119
learning rate: 0.0001755829903978052, loss: 2.7463107109069824
batch i:1120
learning rate: 0.0001755829903978052, loss: 2.847809314727783
batch i:1121
learning rate: 0.0001755829903978052, loss: 2.8116023540496826
batch i:1122
learning rate: 0.0001755829903978052, loss: 2.7288472652435303
batch i:1123
learning rate: 0.0001755829903978052, loss: 2.8239190578460693
batch i:1124
learning rate: 0.0001755829903978052, loss: 2.7688915729522705
batch i:1125
learning rate: 0.0001755829903978052, loss: 2.8025693893432617
batch i:1126
learning rate: 0.0001755829903978052, loss: 2.7608847618103027
batch i:1127
learning rate: 0.0001755829903978052, loss: 2.820647716522217
batch i:1128
learning rate: 0.0001755829903978052, loss: 2.903416395187378
batch i:1129
learning rate: 0.0001755829903978052, loss: 2.8368821144104004
batch i:1130
learning rate: 0.0001755829903978052, loss: 2.8463234901428223
batch i:1131
learning rate: 0.0001755829903978052, loss: 2.874774217605591
batch i:1132
learning rate: 0.0001755829903978052, loss: 2.888575553894043
batch i:1133
learning rate: 0.0001755829903978052, loss: 2.76108980178833
batch i:1134
learning rate: 0.0001755829903978052, loss: 2.94777774810791
batch i:1135
learning rate: 0.0001755829903978052, loss: 2.949021577835083
batch i:1136
learning rate: 0.0001755829903978052, loss: 3.0206775665283203
batch i:1137
learning rate: 0.0001755829903978052, loss: 2.990133762359619
batch i:1138
learning rate: 0.0001755829903978052, loss: 2.8756842613220215
batch i:1139
learning rate: 0.0001755829903978052, loss: 2.8486669063568115
batch i:1140
learning rate: 0.0001755829903978052, loss: 2.9059605598449707
batch i:1141
learning rate: 0.0001755829903978052, loss: 2.989469289779663
batch i:1142
learning rate: 0.0001755829903978052, loss: 2.9697132110595703
batch i:1143
learning rate: 0.0001755829903978052, loss: 2.927614212036133
batch i:1144
learning rate: 0.0001755829903978052, loss: 2.8850457668304443
batch i:1145
learning rate: 0.0001755829903978052, loss: 2.9176220893859863
batch i:1146
learning rate: 0.0001755829903978052, loss: 2.8707189559936523
batch i:1147
learning rate: 0.0001755829903978052, loss: 2.7934420108795166
batch i:1148
learning rate: 0.0001755829903978052, loss: 2.849569320678711
batch i:1149
learning rate: 0.0001755829903978052, loss: 3.0468599796295166
batch i:1150
learning rate: 0.0001755829903978052, loss: 2.910858631134033
current self-play batch: 1150
num_playouts:3000, win: 3, lose: 7, tie:0
average time: 1170.5464542150498
batch i:1151
learning rate: 0.0001755829903978052, loss: 2.95493221282959
batch i:1152
learning rate: 0.0001755829903978052, loss: 2.9165544509887695
batch i:1153
learning rate: 0.0001755829903978052, loss: 3.0028820037841797
batch i:1154
learning rate: 0.0001755829903978052, loss: 2.9054784774780273
batch i:1155
learning rate: 0.0001755829903978052, loss: 2.902688980102539
batch i:1156
learning rate: 0.0001755829903978052, loss: 2.8758766651153564
batch i:1157
learning rate: 0.0001755829903978052, loss: 2.9070873260498047
batch i:1158
learning rate: 0.0001755829903978052, loss: 2.809187889099121
batch i:1159
learning rate: 0.0001755829903978052, loss: 2.8498945236206055
batch i:1160
learning rate: 0.0001755829903978052, loss: 2.963465929031372
batch i:1161
learning rate: 0.0001755829903978052, loss: 2.929058074951172
batch i:1162
learning rate: 0.0001755829903978052, loss: 2.982323169708252
batch i:1163
learning rate: 0.0001755829903978052, loss: 2.9710566997528076
batch i:1164
learning rate: 0.0001755829903978052, loss: 2.9146957397460938
batch i:1165
learning rate: 0.0001755829903978052, loss: 2.9525747299194336
batch i:1166
learning rate: 0.0001755829903978052, loss: 2.9561142921447754
batch i:1167
learning rate: 0.0001755829903978052, loss: 2.911365032196045
batch i:1168
learning rate: 0.0001755829903978052, loss: 2.839047908782959
batch i:1169
learning rate: 0.0001755829903978052, loss: 3.0348777770996094
batch i:1170
learning rate: 0.0001755829903978052, loss: 2.883514881134033
batch i:1171
learning rate: 0.0001755829903978052, loss: 2.964500665664673
batch i:1172
learning rate: 0.0001755829903978052, loss: 2.9224162101745605
batch i:1173
learning rate: 0.0001755829903978052, loss: 2.8626761436462402
batch i:1174
learning rate: 0.0001755829903978052, loss: 2.9138102531433105
batch i:1175
learning rate: 0.0001755829903978052, loss: 2.9696364402770996
batch i:1176
learning rate: 0.0001755829903978052, loss: 3.006166458129883
batch i:1177
learning rate: 0.0001755829903978052, loss: 2.8936920166015625
batch i:1178
learning rate: 0.0001755829903978052, loss: 2.9489498138427734
batch i:1179
learning rate: 0.0001755829903978052, loss: 2.8743832111358643
batch i:1180
learning rate: 0.0001755829903978052, loss: 2.885195732116699
batch i:1181
learning rate: 0.0001755829903978052, loss: 2.8828463554382324
batch i:1182
learning rate: 0.0001755829903978052, loss: 2.896928310394287
batch i:1183
learning rate: 0.0001755829903978052, loss: 2.9543118476867676
batch i:1184
learning rate: 0.0001755829903978052, loss: 2.95862078666687
batch i:1185
learning rate: 0.0001755829903978052, loss: 2.9135994911193848
batch i:1186
learning rate: 0.0001755829903978052, loss: 2.8337209224700928
batch i:1187
learning rate: 0.0001755829903978052, loss: 2.899965763092041
batch i:1188
learning rate: 0.0001755829903978052, loss: 2.9388465881347656
batch i:1189
learning rate: 0.0001755829903978052, loss: 2.8645997047424316
batch i:1190
learning rate: 0.0001755829903978052, loss: 2.964986801147461
batch i:1191
learning rate: 0.0001755829903978052, loss: 2.8542544841766357
batch i:1192
learning rate: 0.0001755829903978052, loss: 2.874833106994629
batch i:1193
learning rate: 0.0001755829903978052, loss: 2.916760206222534
batch i:1194
learning rate: 0.0001755829903978052, loss: 2.8501410484313965
batch i:1195
learning rate: 0.0001755829903978052, loss: 3.002803325653076
batch i:1196
learning rate: 0.0001755829903978052, loss: 3.008699893951416
batch i:1197
learning rate: 0.0001755829903978052, loss: 2.9612231254577637
batch i:1198
learning rate: 0.0001755829903978052, loss: 2.865631103515625
batch i:1199
learning rate: 0.0001755829903978052, loss: 2.901089906692505
batch i:1200
learning rate: 0.0001755829903978052, loss: 2.954946756362915
current self-play batch: 1200
num_playouts:3000, win: 4, lose: 5, tie:1
average time: 691.1952935695648
batch i:1201
learning rate: 0.0001755829903978052, loss: 2.879844903945923
batch i:1202
learning rate: 0.0001755829903978052, loss: 2.9470300674438477
batch i:1203
learning rate: 0.0001755829903978052, loss: 2.9491777420043945
batch i:1204
learning rate: 0.0001755829903978052, loss: 2.9212450981140137
batch i:1205
learning rate: 0.0001755829903978052, loss: 2.883244037628174
batch i:1206
learning rate: 0.0001755829903978052, loss: 2.9412384033203125
batch i:1207
learning rate: 0.0001755829903978052, loss: 2.902900218963623
batch i:1208
learning rate: 0.0001755829903978052, loss: 2.902710437774658
batch i:1209
learning rate: 0.0001755829903978052, loss: 2.9531164169311523
batch i:1210
learning rate: 0.0001755829903978052, loss: 2.8304553031921387
batch i:1211
learning rate: 0.0001755829903978052, loss: 2.785910129547119
batch i:1212
learning rate: 0.0001755829903978052, loss: 2.9007272720336914
batch i:1213
learning rate: 0.0001755829903978052, loss: 2.8765881061553955
batch i:1214
learning rate: 0.0001755829903978052, loss: 2.9594507217407227
batch i:1215
learning rate: 0.0001755829903978052, loss: 2.8013012409210205
batch i:1216
learning rate: 0.0001755829903978052, loss: 2.7936816215515137
batch i:1217
learning rate: 0.0001755829903978052, loss: 2.913651704788208
batch i:1218
learning rate: 0.0001755829903978052, loss: 2.9012646675109863
batch i:1219
learning rate: 0.0001755829903978052, loss: 2.940028190612793
batch i:1220
learning rate: 0.0001755829903978052, loss: 2.92910099029541
batch i:1221
learning rate: 0.0001755829903978052, loss: 2.9111857414245605
batch i:1222
learning rate: 0.0001755829903978052, loss: 2.877068519592285
batch i:1223
learning rate: 0.0001755829903978052, loss: 2.8863027095794678
batch i:1224
learning rate: 0.0001755829903978052, loss: 2.8229804039001465
batch i:1225
learning rate: 0.0001755829903978052, loss: 2.7855350971221924
batch i:1226
learning rate: 0.0001755829903978052, loss: 2.8081469535827637
batch i:1227
learning rate: 0.0001755829903978052, loss: 2.704378128051758
batch i:1228
learning rate: 0.0001755829903978052, loss: 2.713935375213623
batch i:1229
learning rate: 0.0001755829903978052, loss: 2.7014272212982178
batch i:1230
learning rate: 0.0001755829903978052, loss: 2.7601089477539062
batch i:1231
learning rate: 0.0001755829903978052, loss: 2.795255422592163
batch i:1232
learning rate: 0.0001755829903978052, loss: 2.8881983757019043
batch i:1233
learning rate: 0.0001755829903978052, loss: 2.829508066177368
batch i:1234
learning rate: 0.0001755829903978052, loss: 2.7960195541381836
batch i:1235
learning rate: 0.0001755829903978052, loss: 2.852328300476074
batch i:1236
learning rate: 0.0001755829903978052, loss: 2.816073179244995
batch i:1237
learning rate: 0.0001755829903978052, loss: 2.8627047538757324
batch i:1238
learning rate: 0.0001755829903978052, loss: 2.8813648223876953
batch i:1239
learning rate: 0.0001755829903978052, loss: 2.9689249992370605
batch i:1240
learning rate: 0.0001755829903978052, loss: 2.899454116821289
batch i:1241
learning rate: 0.0001755829903978052, loss: 2.910492181777954
batch i:1242
learning rate: 0.0001755829903978052, loss: 2.878854751586914
batch i:1243
learning rate: 0.0001755829903978052, loss: 2.8738014698028564
batch i:1244
learning rate: 0.0001755829903978052, loss: 2.7132625579833984
batch i:1245
learning rate: 0.0001755829903978052, loss: 2.8519186973571777
batch i:1246
learning rate: 0.0001755829903978052, loss: 2.839557647705078
batch i:1247
learning rate: 0.0001755829903978052, loss: 2.7400870323181152
batch i:1248
learning rate: 0.0001755829903978052, loss: 2.771779775619507
batch i:1249
learning rate: 0.0001755829903978052, loss: 2.760171890258789
batch i:1250
learning rate: 0.0001755829903978052, loss: 2.791785717010498
current self-play batch: 1250
num_playouts:3000, win: 4, lose: 6, tie:0
average time: 978.6825932502746
batch i:1251
learning rate: 0.0001755829903978052, loss: 2.8119916915893555
batch i:1252
learning rate: 0.0001755829903978052, loss: 2.8595657348632812
batch i:1253
learning rate: 0.0001755829903978052, loss: 2.8528690338134766
batch i:1254
learning rate: 0.0001755829903978052, loss: 2.781986951828003
batch i:1255
learning rate: 0.0001755829903978052, loss: 2.7469165325164795
batch i:1256
learning rate: 0.0001755829903978052, loss: 2.9105288982391357
batch i:1257
learning rate: 0.0001755829903978052, loss: 2.8180289268493652
batch i:1258
learning rate: 0.0001755829903978052, loss: 2.8791184425354004
batch i:1259
learning rate: 0.0001755829903978052, loss: 2.8660924434661865
batch i:1260
learning rate: 0.0001755829903978052, loss: 2.95054292678833
batch i:1261
learning rate: 0.0001755829903978052, loss: 2.8038206100463867
batch i:1262
learning rate: 0.0001755829903978052, loss: 2.7842068672180176
batch i:1263
learning rate: 0.0001755829903978052, loss: 3.0004355907440186
batch i:1264
learning rate: 0.0001755829903978052, loss: 2.9467215538024902
batch i:1265
learning rate: 0.0001755829903978052, loss: 2.8425612449645996
batch i:1266
learning rate: 0.0001755829903978052, loss: 2.884878396987915
batch i:1267
learning rate: 0.0001755829903978052, loss: 2.920111656188965
batch i:1268
learning rate: 0.0001755829903978052, loss: 2.8535919189453125
batch i:1269
learning rate: 0.0001755829903978052, loss: 2.8278610706329346
batch i:1270
learning rate: 0.0001755829903978052, loss: 2.8683528900146484
batch i:1271
learning rate: 0.0001755829903978052, loss: 2.8384757041931152
batch i:1272
learning rate: 0.0001755829903978052, loss: 2.9111151695251465
batch i:1273
learning rate: 0.0001755829903978052, loss: 2.9205474853515625
batch i:1274
learning rate: 0.0001755829903978052, loss: 2.8464293479919434
batch i:1275
learning rate: 0.0001755829903978052, loss: 2.865426540374756
batch i:1276
learning rate: 0.0001755829903978052, loss: 2.742058515548706
batch i:1277
learning rate: 0.0001755829903978052, loss: 2.7822318077087402
batch i:1278
learning rate: 0.0001755829903978052, loss: 2.822699785232544
batch i:1279
learning rate: 0.0001755829903978052, loss: 2.835855007171631
batch i:1280
learning rate: 0.0001755829903978052, loss: 2.9042649269104004
batch i:1281
learning rate: 0.0001755829903978052, loss: 2.7937257289886475
batch i:1282
learning rate: 0.0001755829903978052, loss: 2.771540641784668
batch i:1283
learning rate: 0.0001755829903978052, loss: 2.906132221221924
batch i:1284
learning rate: 0.0001755829903978052, loss: 2.8118066787719727
batch i:1285
learning rate: 0.0001755829903978052, loss: 2.973928451538086
batch i:1286
learning rate: 0.0001755829903978052, loss: 2.7630484104156494
batch i:1287
learning rate: 0.0001755829903978052, loss: 2.847813129425049
batch i:1288
learning rate: 0.0001755829903978052, loss: 2.99025297164917
batch i:1289
learning rate: 0.0001755829903978052, loss: 2.958455801010132
batch i:1290
learning rate: 0.0001755829903978052, loss: 2.8074307441711426
batch i:1291
learning rate: 0.0001755829903978052, loss: 2.813511371612549
batch i:1292
learning rate: 0.0001755829903978052, loss: 2.9758052825927734
batch i:1293
learning rate: 0.0001755829903978052, loss: 2.8187944889068604
batch i:1294
learning rate: 0.0001755829903978052, loss: 2.941073417663574
batch i:1295
learning rate: 0.0001755829903978052, loss: 2.988309383392334
batch i:1296
learning rate: 0.0001755829903978052, loss: 2.803123950958252
batch i:1297
learning rate: 0.0001755829903978052, loss: 2.863882541656494
batch i:1298
learning rate: 0.0001755829903978052, loss: 2.8900294303894043
batch i:1299
learning rate: 0.0001755829903978052, loss: 2.812417984008789
batch i:1300
learning rate: 0.0001755829903978052, loss: 2.8266210556030273
current self-play batch: 1300
num_playouts:3000, win: 5, lose: 5, tie:0
average time: 1035.5623121500016
batch i:1301
learning rate: 0.0001755829903978052, loss: 2.809567928314209
batch i:1302
learning rate: 0.0001755829903978052, loss: 2.7805843353271484
batch i:1303
learning rate: 0.0001755829903978052, loss: 2.943925142288208
batch i:1304
learning rate: 0.0001755829903978052, loss: 2.8629701137542725
batch i:1305
learning rate: 0.0001755829903978052, loss: 2.8921656608581543
batch i:1306
learning rate: 0.0001755829903978052, loss: 2.9278311729431152
batch i:1307
learning rate: 0.0001755829903978052, loss: 2.8765625953674316
batch i:1308
learning rate: 0.0001755829903978052, loss: 2.9446449279785156
batch i:1309
learning rate: 0.0001755829903978052, loss: 2.8114256858825684
batch i:1310
learning rate: 0.0001755829903978052, loss: 2.76511549949646
batch i:1311
learning rate: 0.0001755829903978052, loss: 2.722172498703003
batch i:1312
learning rate: 0.0001755829903978052, loss: 2.832371234893799
batch i:1313
learning rate: 0.0001755829903978052, loss: 2.8622236251831055
batch i:1314
learning rate: 0.0001755829903978052, loss: 2.8632092475891113
batch i:1315
learning rate: 0.0001755829903978052, loss: 2.8703646659851074
batch i:1316
learning rate: 0.0001755829903978052, loss: 2.824909210205078
batch i:1317
learning rate: 0.0001755829903978052, loss: 2.811502456665039
batch i:1318
learning rate: 0.0001755829903978052, loss: 2.727299928665161
batch i:1319
learning rate: 0.0001755829903978052, loss: 2.821842670440674
batch i:1320
learning rate: 0.0001755829903978052, loss: 2.9083218574523926
batch i:1321
learning rate: 0.0001755829903978052, loss: 2.818586826324463
batch i:1322
learning rate: 0.0001755829903978052, loss: 2.741450548171997
batch i:1323
learning rate: 0.0001755829903978052, loss: 2.751725196838379
batch i:1324
learning rate: 0.0001755829903978052, loss: 2.794059991836548
batch i:1325
learning rate: 0.0001755829903978052, loss: 2.67665958404541
batch i:1326
learning rate: 0.0001755829903978052, loss: 2.6891415119171143
batch i:1327
learning rate: 0.0001755829903978052, loss: 2.797718048095703
batch i:1328
learning rate: 0.0001755829903978052, loss: 2.7883715629577637
batch i:1329
learning rate: 0.0001755829903978052, loss: 2.7915496826171875
batch i:1330
learning rate: 0.0001755829903978052, loss: 2.788369655609131
batch i:1331
learning rate: 0.0001755829903978052, loss: 2.792360782623291
batch i:1332
learning rate: 0.0001755829903978052, loss: 2.9825539588928223
batch i:1333
learning rate: 0.0001755829903978052, loss: 2.807102680206299
batch i:1334
learning rate: 0.0001755829903978052, loss: 2.8369624614715576
batch i:1335
learning rate: 0.0001755829903978052, loss: 2.7873802185058594
batch i:1336
learning rate: 0.0001755829903978052, loss: 2.889369010925293
batch i:1337
learning rate: 0.0001755829903978052, loss: 2.7535881996154785
batch i:1338
learning rate: 0.0001755829903978052, loss: 2.8512532711029053
batch i:1339
learning rate: 0.0001755829903978052, loss: 2.959646224975586
batch i:1340
learning rate: 0.0001755829903978052, loss: 2.8696131706237793
batch i:1341
learning rate: 0.0001755829903978052, loss: 2.8523130416870117
batch i:1342
learning rate: 0.0001755829903978052, loss: 2.854306221008301
batch i:1343
learning rate: 0.0001755829903978052, loss: 2.7873663902282715
batch i:1344
learning rate: 0.0001755829903978052, loss: 2.8332555294036865
batch i:1345
learning rate: 0.0001755829903978052, loss: 2.9167585372924805
batch i:1346
learning rate: 0.0001755829903978052, loss: 2.7666726112365723
batch i:1347
learning rate: 0.0001755829903978052, loss: 2.9388420581817627
batch i:1348
learning rate: 0.0001755829903978052, loss: 2.894305467605591
batch i:1349
learning rate: 0.0001755829903978052, loss: 2.8523805141448975
batch i:1350
learning rate: 0.0001755829903978052, loss: 2.831929922103882
current self-play batch: 1350
num_playouts:3000, win: 8, lose: 1, tie:1
average time: 452.16218280792236
batch i:1351
learning rate: 0.0001755829903978052, loss: 2.8916525840759277
batch i:1352
learning rate: 0.0001755829903978052, loss: 2.7198033332824707
batch i:1353
learning rate: 0.0001755829903978052, loss: 2.89546275138855
batch i:1354
learning rate: 0.0001755829903978052, loss: 2.826442241668701
batch i:1355
learning rate: 0.0001755829903978052, loss: 2.867119550704956
batch i:1356
learning rate: 0.0001755829903978052, loss: 2.892216205596924
batch i:1357
learning rate: 0.0001755829903978052, loss: 2.8449461460113525
batch i:1358
learning rate: 0.0001755829903978052, loss: 2.8141441345214844
batch i:1359
learning rate: 0.0001755829903978052, loss: 2.859893798828125
batch i:1360
learning rate: 0.0001755829903978052, loss: 2.8492908477783203
batch i:1361
learning rate: 0.0001755829903978052, loss: 2.9580187797546387
batch i:1362
learning rate: 0.0001755829903978052, loss: 2.84228253364563
batch i:1363
learning rate: 0.0001755829903978052, loss: 2.812904119491577
batch i:1364
learning rate: 0.0001755829903978052, loss: 2.8031249046325684
batch i:1365
learning rate: 0.0001755829903978052, loss: 2.8163812160491943
batch i:1366
learning rate: 0.0001755829903978052, loss: 2.8796095848083496
batch i:1367
learning rate: 0.0001755829903978052, loss: 2.811431884765625
batch i:1368
learning rate: 0.0001755829903978052, loss: 2.802973747253418
batch i:1369
learning rate: 0.0001755829903978052, loss: 2.8406970500946045
batch i:1370
learning rate: 0.0001755829903978052, loss: 2.8500356674194336
batch i:1371
learning rate: 0.0001755829903978052, loss: 2.949838876724243
batch i:1372
learning rate: 0.0001755829903978052, loss: 2.929978847503662
batch i:1373
learning rate: 0.0001755829903978052, loss: 3.027815818786621
batch i:1374
learning rate: 0.0001755829903978052, loss: 2.9250705242156982
batch i:1375
learning rate: 0.0001755829903978052, loss: 3.0330352783203125
batch i:1376
learning rate: 0.0001755829903978052, loss: 2.960089683532715
batch i:1377
learning rate: 0.0001755829903978052, loss: 2.862989902496338
batch i:1378
learning rate: 0.0001755829903978052, loss: 2.9602460861206055
batch i:1379
learning rate: 0.0001755829903978052, loss: 2.83856201171875
batch i:1380
learning rate: 0.0001755829903978052, loss: 2.9495317935943604
batch i:1381
learning rate: 0.0001755829903978052, loss: 2.949477195739746
batch i:1382
learning rate: 0.0001755829903978052, loss: 2.943387031555176
batch i:1383
learning rate: 0.0001755829903978052, loss: 3.0153980255126953
batch i:1384
learning rate: 0.0001755829903978052, loss: 2.9314403533935547
batch i:1385
learning rate: 0.0001755829903978052, loss: 2.9892122745513916
batch i:1386
learning rate: 0.0001755829903978052, loss: 2.9289002418518066
batch i:1387
learning rate: 0.0001755829903978052, loss: 2.8469676971435547
batch i:1388
learning rate: 0.0001755829903978052, loss: 2.7672181129455566
batch i:1389
learning rate: 0.0001755829903978052, loss: 2.9051342010498047
batch i:1390
learning rate: 0.0001755829903978052, loss: 2.985443115234375
batch i:1391
learning rate: 0.0001755829903978052, loss: 2.9358181953430176
batch i:1392
learning rate: 0.0001755829903978052, loss: 2.895662307739258
batch i:1393
learning rate: 0.0001755829903978052, loss: 2.834635019302368
batch i:1394
learning rate: 0.0001755829903978052, loss: 2.8907129764556885
batch i:1395
learning rate: 0.0001755829903978052, loss: 2.939845323562622
batch i:1396
learning rate: 0.0001755829903978052, loss: 2.8922948837280273
batch i:1397
learning rate: 0.0001755829903978052, loss: 2.799372911453247
batch i:1398
learning rate: 0.0001755829903978052, loss: 2.8687903881073
batch i:1399
learning rate: 0.0001755829903978052, loss: 2.9360103607177734
batch i:1400
learning rate: 0.0001755829903978052, loss: 2.9305419921875
current self-play batch: 1400
num_playouts:3000, win: 8, lose: 1, tie:1
average time: 425.5091566324234
batch i:1401
learning rate: 0.0001755829903978052, loss: 2.928467273712158
batch i:1402
learning rate: 0.0001755829903978052, loss: 2.9215986728668213
batch i:1403
learning rate: 0.0001755829903978052, loss: 3.044412612915039
batch i:1404
learning rate: 0.0001755829903978052, loss: 2.9323339462280273
batch i:1405
learning rate: 0.0001755829903978052, loss: 2.951798439025879
batch i:1406
learning rate: 0.0001755829903978052, loss: 2.928208827972412
batch i:1407
learning rate: 0.0001755829903978052, loss: 2.9087746143341064
batch i:1408
learning rate: 0.0001755829903978052, loss: 2.8770902156829834
batch i:1409
learning rate: 0.0001755829903978052, loss: 2.9622609615325928
batch i:1410
learning rate: 0.0001755829903978052, loss: 2.8359460830688477
batch i:1411
learning rate: 0.0001755829903978052, loss: 2.8811187744140625
batch i:1412
learning rate: 0.0001755829903978052, loss: 2.865657091140747
batch i:1413
learning rate: 0.0001755829903978052, loss: 2.868077278137207
batch i:1414
learning rate: 0.0001755829903978052, loss: 2.9139013290405273
batch i:1415
learning rate: 0.0001755829903978052, loss: 2.8085591793060303
batch i:1416
learning rate: 0.0001755829903978052, loss: 2.903744697570801
batch i:1417
learning rate: 0.0001755829903978052, loss: 2.801957607269287
batch i:1418
learning rate: 0.0001755829903978052, loss: 2.812497615814209
batch i:1419
learning rate: 0.0001755829903978052, loss: 2.884453296661377
batch i:1420
learning rate: 0.0001755829903978052, loss: 2.819380760192871
batch i:1421
learning rate: 0.0001755829903978052, loss: 2.8674726486206055
batch i:1422
learning rate: 0.0001755829903978052, loss: 2.8509645462036133
batch i:1423
learning rate: 0.0001755829903978052, loss: 2.871018886566162
batch i:1424
learning rate: 0.0001755829903978052, loss: 2.738476514816284
batch i:1425
learning rate: 0.0001755829903978052, loss: 2.86118745803833
batch i:1426
learning rate: 0.0001755829903978052, loss: 2.847989320755005
batch i:1427
learning rate: 0.0001755829903978052, loss: 2.774505853652954
batch i:1428
learning rate: 0.0001755829903978052, loss: 2.806950569152832
batch i:1429
learning rate: 0.0001755829903978052, loss: 2.763082504272461
batch i:1430
learning rate: 0.0001755829903978052, loss: 2.9004223346710205
batch i:1431
learning rate: 0.0001755829903978052, loss: 2.943235158920288
batch i:1432
learning rate: 0.0001755829903978052, loss: 2.84743332862854
batch i:1433
learning rate: 0.0001755829903978052, loss: 2.907341718673706
batch i:1434
learning rate: 0.0001755829903978052, loss: 2.9069528579711914
batch i:1435
learning rate: 0.0001755829903978052, loss: 2.8187193870544434
batch i:1436
learning rate: 0.0001755829903978052, loss: 2.938941240310669
batch i:1437
learning rate: 0.0001755829903978052, loss: 2.8084282875061035
batch i:1438
learning rate: 0.0001755829903978052, loss: 2.9510257244110107
batch i:1439
learning rate: 0.0001755829903978052, loss: 2.8900318145751953
batch i:1440
learning rate: 0.0001755829903978052, loss: 2.8782339096069336
batch i:1441
learning rate: 0.0001755829903978052, loss: 2.808335065841675
batch i:1442
learning rate: 0.0001755829903978052, loss: 2.822906255722046
batch i:1443
learning rate: 0.0001755829903978052, loss: 2.8512699604034424
batch i:1444
learning rate: 0.0001755829903978052, loss: 2.7618443965911865
batch i:1445
learning rate: 0.0001755829903978052, loss: 2.7887988090515137
batch i:1446
learning rate: 0.0001755829903978052, loss: 2.8739001750946045
batch i:1447
learning rate: 0.0001755829903978052, loss: 2.816965103149414
batch i:1448
learning rate: 0.0001755829903978052, loss: 2.79899525642395
batch i:1449
learning rate: 0.0001755829903978052, loss: 2.9407763481140137
batch i:1450
learning rate: 0.0001755829903978052, loss: 2.6847176551818848
current self-play batch: 1450
num_playouts:3000, win: 3, lose: 6, tie:1
average time: 474.19033579826356
batch i:1451
learning rate: 0.0001755829903978052, loss: 2.840203285217285
batch i:1452
learning rate: 0.0001755829903978052, loss: 2.776688575744629
batch i:1453
learning rate: 0.0001755829903978052, loss: 2.7605631351470947
batch i:1454
learning rate: 0.0001755829903978052, loss: 2.850295066833496
batch i:1455
learning rate: 0.0001755829903978052, loss: 2.7920820713043213
batch i:1456
learning rate: 0.0001755829903978052, loss: 2.750761032104492
batch i:1457
learning rate: 0.0001755829903978052, loss: 2.6732981204986572
batch i:1458
learning rate: 0.0001755829903978052, loss: 2.745023250579834
batch i:1459
learning rate: 0.0001755829903978052, loss: 2.719625949859619
batch i:1460
learning rate: 0.0001755829903978052, loss: 2.7177464962005615
batch i:1461
learning rate: 0.0001755829903978052, loss: 2.7833096981048584
batch i:1462
learning rate: 0.0001755829903978052, loss: 2.7981152534484863
batch i:1463
learning rate: 0.0001755829903978052, loss: 2.7840797901153564
batch i:1464
learning rate: 0.0001755829903978052, loss: 2.7231688499450684
batch i:1465
learning rate: 0.0001755829903978052, loss: 2.789031505584717
batch i:1466
learning rate: 0.0001755829903978052, loss: 2.8643221855163574
batch i:1467
learning rate: 0.0001755829903978052, loss: 2.8256120681762695
batch i:1468
learning rate: 0.0001755829903978052, loss: 2.6941990852355957
batch i:1469
learning rate: 0.0001755829903978052, loss: 2.6648805141448975
batch i:1470
learning rate: 0.00011705532693187012, loss: 2.6702120304107666
batch i:1471
learning rate: 0.00011705532693187012, loss: 2.723052501678467
batch i:1472
learning rate: 0.00011705532693187012, loss: 2.666908025741577
batch i:1473
learning rate: 0.00011705532693187012, loss: 2.670231819152832
batch i:1474
learning rate: 0.00011705532693187012, loss: 2.6921463012695312
batch i:1475
learning rate: 0.00011705532693187012, loss: 2.6401913166046143
batch i:1476
learning rate: 0.00011705532693187012, loss: 2.6462631225585938
batch i:1477
learning rate: 0.00011705532693187012, loss: 2.6787068843841553
batch i:1478
learning rate: 0.00011705532693187012, loss: 2.6370649337768555
batch i:1479
learning rate: 0.0001755829903978052, loss: 2.732245922088623
batch i:1480
learning rate: 0.0001755829903978052, loss: 2.7000741958618164
batch i:1481
learning rate: 0.0001755829903978052, loss: 2.6668496131896973
batch i:1482
learning rate: 0.0001755829903978052, loss: 2.7077863216400146
batch i:1483
learning rate: 0.0001755829903978052, loss: 2.6905922889709473
batch i:1484
learning rate: 0.0001755829903978052, loss: 2.7369954586029053
batch i:1485
learning rate: 0.0001755829903978052, loss: 2.807130813598633
batch i:1486
learning rate: 0.0001755829903978052, loss: 2.749281883239746
batch i:1487
learning rate: 0.0001755829903978052, loss: 2.6652588844299316
batch i:1488
learning rate: 0.0001755829903978052, loss: 2.71433162689209
batch i:1489
learning rate: 0.0001755829903978052, loss: 2.729541301727295
batch i:1490
learning rate: 0.0001755829903978052, loss: 2.8123369216918945
batch i:1491
learning rate: 0.0001755829903978052, loss: 2.6642885208129883
batch i:1492
learning rate: 0.0001755829903978052, loss: 2.710388660430908
batch i:1493
learning rate: 0.0001755829903978052, loss: 2.611403465270996
batch i:1494
learning rate: 0.0001755829903978052, loss: 2.659705638885498
batch i:1495
learning rate: 0.0001755829903978052, loss: 2.61728835105896
batch i:1496
learning rate: 0.0001755829903978052, loss: 2.753864288330078
batch i:1497
learning rate: 0.0001755829903978052, loss: 2.545100688934326
batch i:1498
learning rate: 0.0001755829903978052, loss: 2.7116923332214355
batch i:1499
learning rate: 0.0001755829903978052, loss: 2.63283371925354
batch i:1500
learning rate: 0.0001755829903978052, loss: 2.602477550506592
current self-play batch: 1500
num_playouts:3000, win: 4, lose: 5, tie:1
average time: 455.7117653608322
