Start time: 2023-12-23 09:21:56.621408
batch i:1
batch i:2
batch i:3
batch i:4
batch i:5
learning rate0.0013333333333333333, loss:3.7563159465789795
batch i:6
learning rate0.0013333333333333333, loss:3.6081857681274414
batch i:7
learning rate0.0013333333333333333, loss:3.506568431854248
batch i:8
learning rate0.0013333333333333333, loss:3.4319419860839844
batch i:9
learning rate0.0013333333333333333, loss:3.2601051330566406
batch i:10
learning rate0.0013333333333333333, loss:3.1387429237365723
batch i:11
learning rate0.0013333333333333333, loss:3.30086088180542
batch i:12
learning rate0.0013333333333333333, loss:3.15325927734375
batch i:13
learning rate0.0013333333333333333, loss:3.123983860015869
batch i:14
learning rate0.0013333333333333333, loss:3.210355758666992
batch i:15
learning rate0.0013333333333333333, loss:3.126154899597168
batch i:16
learning rate0.0013333333333333333, loss:3.1698145866394043
batch i:17
learning rate0.0013333333333333333, loss:3.130965232849121
batch i:18
learning rate0.0013333333333333333, loss:3.145928382873535
batch i:19
learning rate0.0013333333333333333, loss:3.1035385131835938
batch i:20
learning rate0.0013333333333333333, loss:3.1296191215515137
batch i:21
learning rate0.0013333333333333333, loss:3.1714894771575928
batch i:22
learning rate0.0013333333333333333, loss:3.019958972930908
batch i:23
learning rate0.0013333333333333333, loss:3.094207763671875
batch i:24
learning rate0.0013333333333333333, loss:3.1053357124328613
batch i:25
learning rate0.0013333333333333333, loss:3.1066415309906006
batch i:26
learning rate0.0013333333333333333, loss:3.110426664352417
batch i:27
learning rate0.0013333333333333333, loss:3.103732109069824
batch i:28
learning rate0.0013333333333333333, loss:3.153393268585205
batch i:29
learning rate0.0013333333333333333, loss:3.1837544441223145
batch i:30
learning rate0.0013333333333333333, loss:3.1068756580352783
batch i:31
learning rate0.0013333333333333333, loss:3.116933822631836
batch i:32
learning rate0.0013333333333333333, loss:3.130624771118164
batch i:33
learning rate0.0013333333333333333, loss:3.1475582122802734
batch i:34
learning rate0.0013333333333333333, loss:3.06817889213562
batch i:35
learning rate0.0013333333333333333, loss:3.086817741394043
batch i:36
learning rate0.0013333333333333333, loss:3.0841941833496094
batch i:37
learning rate0.0013333333333333333, loss:3.057682752609253
batch i:38
learning rate0.0013333333333333333, loss:3.0657577514648438
batch i:39
learning rate0.0013333333333333333, loss:3.1709256172180176
batch i:40
learning rate0.0013333333333333333, loss:3.077805280685425
batch i:41
learning rate0.0013333333333333333, loss:3.1118485927581787
batch i:42
learning rate0.0013333333333333333, loss:3.1267683506011963
batch i:43
learning rate0.0013333333333333333, loss:3.0197501182556152
batch i:44
learning rate0.0013333333333333333, loss:3.043346405029297
batch i:45
learning rate0.0013333333333333333, loss:3.043487548828125
batch i:46
learning rate0.0013333333333333333, loss:3.0605177879333496
batch i:47
learning rate0.0013333333333333333, loss:3.1044793128967285
batch i:48
learning rate0.0013333333333333333, loss:3.1602492332458496
batch i:49
learning rate0.0013333333333333333, loss:3.035128116607666
batch i:50
learning rate0.0013333333333333333, loss:3.057511806488037
current self-play batch: 50
num_playouts:1000, win: 9, lose: 1, tie:0
average time: 144.4565668106079
New best policy from pure MCTS
batch i:51
learning rate0.0013333333333333333, loss:3.059765577316284
batch i:52
learning rate0.0013333333333333333, loss:2.9725992679595947
batch i:53
learning rate0.0013333333333333333, loss:3.112137794494629
batch i:54
learning rate0.0013333333333333333, loss:3.13057279586792
batch i:55
learning rate0.0013333333333333333, loss:3.0506935119628906
batch i:56
learning rate0.0013333333333333333, loss:3.0891714096069336
batch i:57
learning rate0.0013333333333333333, loss:3.047335147857666
batch i:58
learning rate0.0013333333333333333, loss:3.1535520553588867
batch i:59
learning rate0.0013333333333333333, loss:3.138688564300537
batch i:60
learning rate0.0013333333333333333, loss:3.1128034591674805
batch i:61
learning rate0.0013333333333333333, loss:3.1293416023254395
batch i:62
learning rate0.0013333333333333333, loss:3.140623092651367
batch i:63
learning rate0.0013333333333333333, loss:3.1142592430114746
batch i:64
learning rate0.0013333333333333333, loss:3.0986239910125732
batch i:65
learning rate0.0013333333333333333, loss:3.1901566982269287
batch i:66
learning rate0.0013333333333333333, loss:3.0958781242370605
batch i:67
learning rate0.0013333333333333333, loss:3.1024036407470703
batch i:68
learning rate0.0013333333333333333, loss:3.0481200218200684
batch i:69
learning rate0.0013333333333333333, loss:3.0533664226531982
batch i:70
learning rate0.0013333333333333333, loss:3.086672306060791
batch i:71
learning rate0.0013333333333333333, loss:3.133185863494873
batch i:72
learning rate0.0013333333333333333, loss:3.08060359954834
batch i:73
learning rate0.0013333333333333333, loss:3.0926361083984375
batch i:74
learning rate0.0013333333333333333, loss:3.0737485885620117
batch i:75
learning rate0.0013333333333333333, loss:3.1508166790008545
batch i:76
learning rate0.0013333333333333333, loss:3.009458065032959
batch i:77
learning rate0.0013333333333333333, loss:3.0678293704986572
batch i:78
learning rate0.0013333333333333333, loss:2.986745595932007
batch i:79
learning rate0.0013333333333333333, loss:3.0555713176727295
batch i:80
learning rate0.0013333333333333333, loss:3.043776750564575
batch i:81
learning rate0.0013333333333333333, loss:3.0827813148498535
batch i:82
learning rate0.0013333333333333333, loss:3.1483047008514404
batch i:83
learning rate0.0013333333333333333, loss:3.0469508171081543
batch i:84
learning rate0.0013333333333333333, loss:3.056180715560913
batch i:85
learning rate0.0013333333333333333, loss:3.0533738136291504
batch i:86
learning rate0.0013333333333333333, loss:3.009241819381714
batch i:87
learning rate0.0013333333333333333, loss:3.046888589859009
batch i:88
learning rate0.0013333333333333333, loss:3.1061267852783203
batch i:89
learning rate0.0013333333333333333, loss:3.1077630519866943
batch i:90
learning rate0.0013333333333333333, loss:3.0488193035125732
batch i:91
learning rate0.0013333333333333333, loss:3.0585803985595703
batch i:92
learning rate0.0013333333333333333, loss:3.179841995239258
batch i:93
learning rate0.0013333333333333333, loss:3.044297933578491
batch i:94
learning rate0.0013333333333333333, loss:3.1034281253814697
batch i:95
learning rate0.0013333333333333333, loss:3.049767017364502
batch i:96
learning rate0.0013333333333333333, loss:3.033743143081665
batch i:97
learning rate0.0013333333333333333, loss:3.040472984313965
batch i:98
learning rate0.0013333333333333333, loss:3.002899169921875
batch i:99
learning rate0.0013333333333333333, loss:3.0508556365966797
batch i:100
learning rate0.0013333333333333333, loss:3.0254602432250977
current self-play batch: 100
num_playouts:1000, win: 8, lose: 2, tie:0
average time: 169.11507253646852
batch i:101
learning rate0.0013333333333333333, loss:3.056583881378174
batch i:102
learning rate0.0013333333333333333, loss:2.9888229370117188
batch i:103
learning rate0.0013333333333333333, loss:3.0877909660339355
batch i:104
learning rate0.0013333333333333333, loss:3.010824203491211
batch i:105
learning rate0.0013333333333333333, loss:3.003213882446289
batch i:106
learning rate0.0013333333333333333, loss:3.0236873626708984
batch i:107
learning rate0.0013333333333333333, loss:3.096320629119873
batch i:108
learning rate0.0013333333333333333, loss:2.945124864578247
batch i:109
learning rate0.0013333333333333333, loss:3.0211753845214844
batch i:110
learning rate0.0013333333333333333, loss:3.0513744354248047
batch i:111
learning rate0.0013333333333333333, loss:2.9467830657958984
batch i:112
learning rate0.0013333333333333333, loss:2.9658470153808594
batch i:113
learning rate0.0013333333333333333, loss:2.9569549560546875
batch i:114
learning rate0.0013333333333333333, loss:3.01051664352417
batch i:115
learning rate0.0013333333333333333, loss:3.0414671897888184
batch i:116
learning rate0.0013333333333333333, loss:3.088902235031128
batch i:117
learning rate0.0013333333333333333, loss:3.0811800956726074
batch i:118
learning rate0.0013333333333333333, loss:2.9928808212280273
batch i:119
learning rate0.0013333333333333333, loss:3.036496162414551
batch i:120
learning rate0.0013333333333333333, loss:3.041395664215088
batch i:121
learning rate0.0013333333333333333, loss:3.1037447452545166
batch i:122
learning rate0.0013333333333333333, loss:3.0229177474975586
batch i:123
learning rate0.0013333333333333333, loss:3.0392343997955322
batch i:124
learning rate0.0013333333333333333, loss:3.0502073764801025
batch i:125
learning rate0.0013333333333333333, loss:2.9595131874084473
batch i:126
learning rate0.0013333333333333333, loss:2.9854953289031982
batch i:127
learning rate0.0013333333333333333, loss:3.055919885635376
batch i:128
learning rate0.0013333333333333333, loss:3.0537877082824707
batch i:129
learning rate0.0013333333333333333, loss:2.9908525943756104
batch i:130
learning rate0.0013333333333333333, loss:2.996384620666504
batch i:131
learning rate0.0013333333333333333, loss:3.1163933277130127
batch i:132
learning rate0.0013333333333333333, loss:2.9780497550964355
batch i:133
learning rate0.0013333333333333333, loss:3.0941290855407715
batch i:134
learning rate0.0013333333333333333, loss:3.0710153579711914
batch i:135
learning rate0.0013333333333333333, loss:3.080589771270752
batch i:136
learning rate0.0013333333333333333, loss:3.013305187225342
batch i:137
learning rate0.0013333333333333333, loss:3.081696033477783
batch i:138
learning rate0.0013333333333333333, loss:3.0006520748138428
batch i:139
learning rate0.0013333333333333333, loss:3.034334659576416
batch i:140
learning rate0.0013333333333333333, loss:3.0407230854034424
batch i:141
learning rate0.0013333333333333333, loss:2.9972124099731445
batch i:142
learning rate0.0013333333333333333, loss:3.0165188312530518
batch i:143
learning rate0.0013333333333333333, loss:3.005319595336914
batch i:144
learning rate0.0013333333333333333, loss:3.055722713470459
batch i:145
learning rate0.0013333333333333333, loss:3.0230636596679688
batch i:146
learning rate0.0013333333333333333, loss:2.98154354095459
batch i:147
learning rate0.0013333333333333333, loss:3.000966787338257
batch i:148
learning rate0.0013333333333333333, loss:2.9742469787597656
batch i:149
learning rate0.0013333333333333333, loss:3.0624501705169678
batch i:150
learning rate0.0013333333333333333, loss:2.958441734313965
current self-play batch: 150
num_playouts:1000, win: 10, lose: 0, tie:0
average time: 146.2564291715622
New best policy from pure MCTS
batch i:151
learning rate0.0013333333333333333, loss:2.970428466796875
batch i:152
learning rate0.0013333333333333333, loss:2.9987337589263916
batch i:153
learning rate0.0013333333333333333, loss:2.8898439407348633
batch i:154
learning rate0.0013333333333333333, loss:2.959099292755127
batch i:155
learning rate0.0013333333333333333, loss:2.9706978797912598
batch i:156
learning rate0.0013333333333333333, loss:2.9373373985290527
batch i:157
learning rate0.0013333333333333333, loss:2.8951327800750732
batch i:158
learning rate0.0013333333333333333, loss:2.904473304748535
batch i:159
learning rate0.0013333333333333333, loss:2.8530502319335938
batch i:160
learning rate0.0013333333333333333, loss:2.9445838928222656
batch i:161
learning rate0.0013333333333333333, loss:2.962071657180786
batch i:162
learning rate0.0013333333333333333, loss:2.9088032245635986
batch i:163
learning rate0.0013333333333333333, loss:2.9708797931671143
batch i:164
learning rate0.0013333333333333333, loss:2.9495320320129395
batch i:165
learning rate0.0013333333333333333, loss:2.994964599609375
batch i:166
learning rate0.0013333333333333333, loss:2.9419853687286377
batch i:167
learning rate0.0013333333333333333, loss:2.9075541496276855
batch i:168
learning rate0.0013333333333333333, loss:2.9911837577819824
batch i:169
learning rate0.0013333333333333333, loss:2.8586812019348145
batch i:170
learning rate0.0013333333333333333, loss:2.938072919845581
batch i:171
learning rate0.0013333333333333333, loss:2.888042449951172
batch i:172
learning rate0.0013333333333333333, loss:2.9388210773468018
batch i:173
learning rate0.0013333333333333333, loss:2.8755781650543213
batch i:174
learning rate0.0013333333333333333, loss:2.8623600006103516
batch i:175
learning rate0.0013333333333333333, loss:2.9607319831848145
batch i:176
learning rate0.0013333333333333333, loss:2.904202938079834
batch i:177
learning rate0.0013333333333333333, loss:2.9298174381256104
batch i:178
learning rate0.0013333333333333333, loss:2.9446306228637695
batch i:179
learning rate0.0013333333333333333, loss:2.943441867828369
batch i:180
learning rate0.0013333333333333333, loss:2.9722704887390137
batch i:181
learning rate0.0013333333333333333, loss:2.9989371299743652
batch i:182
learning rate0.0013333333333333333, loss:2.941819906234741
batch i:183
learning rate0.0013333333333333333, loss:2.9924497604370117
batch i:184
learning rate0.0013333333333333333, loss:2.8737456798553467
batch i:185
learning rate0.0013333333333333333, loss:2.983030319213867
batch i:186
learning rate0.0013333333333333333, loss:2.909776210784912
batch i:187
learning rate0.0013333333333333333, loss:2.924137592315674
batch i:188
learning rate0.0013333333333333333, loss:2.910926342010498
batch i:189
learning rate0.0013333333333333333, loss:2.9362950325012207
batch i:190
learning rate0.0013333333333333333, loss:2.9829177856445312
batch i:191
learning rate0.0013333333333333333, loss:2.8883628845214844
batch i:192
learning rate0.0013333333333333333, loss:2.90905499458313
batch i:193
learning rate0.0013333333333333333, loss:2.9262192249298096
batch i:194
learning rate0.0013333333333333333, loss:2.9929637908935547
batch i:195
learning rate0.0013333333333333333, loss:2.8607521057128906
batch i:196
learning rate0.0013333333333333333, loss:2.9313244819641113
batch i:197
learning rate0.0013333333333333333, loss:2.90436053276062
batch i:198
learning rate0.0013333333333333333, loss:2.9284539222717285
batch i:199
learning rate0.0013333333333333333, loss:2.9162228107452393
batch i:200
learning rate0.0013333333333333333, loss:2.980196714401245
current self-play batch: 200
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 406.5715215206146
New best policy from pure MCTS
batch i:201
learning rate0.0013333333333333333, loss:2.9198760986328125
batch i:202
learning rate0.0013333333333333333, loss:2.8816871643066406
batch i:203
learning rate0.0013333333333333333, loss:2.9445316791534424
batch i:204
learning rate0.0013333333333333333, loss:2.8991949558258057
batch i:205
learning rate0.0013333333333333333, loss:2.867518663406372
batch i:206
learning rate0.0013333333333333333, loss:3.049865245819092
batch i:207
learning rate0.0013333333333333333, loss:2.952688694000244
batch i:208
learning rate0.0013333333333333333, loss:2.9180331230163574
batch i:209
learning rate0.0013333333333333333, loss:2.9413230419158936
batch i:210
learning rate0.0013333333333333333, loss:2.9943559169769287
batch i:211
learning rate0.0013333333333333333, loss:2.906606674194336
batch i:212
learning rate0.0013333333333333333, loss:2.851008892059326
batch i:213
learning rate0.0013333333333333333, loss:3.005955219268799
batch i:214
learning rate0.0013333333333333333, loss:2.905252695083618
batch i:215
learning rate0.0013333333333333333, loss:2.9692137241363525
batch i:216
learning rate0.0013333333333333333, loss:2.8974647521972656
batch i:217
learning rate0.0013333333333333333, loss:2.9047622680664062
batch i:218
learning rate0.0013333333333333333, loss:2.969102144241333
batch i:219
learning rate0.0013333333333333333, loss:2.8831119537353516
batch i:220
learning rate0.0013333333333333333, loss:2.909935474395752
batch i:221
learning rate0.0013333333333333333, loss:2.937988042831421
batch i:222
learning rate0.0013333333333333333, loss:2.9173030853271484
batch i:223
learning rate0.0013333333333333333, loss:2.9532933235168457
batch i:224
learning rate0.0013333333333333333, loss:2.965488910675049
batch i:225
learning rate0.0013333333333333333, loss:2.9042351245880127
batch i:226
learning rate0.0013333333333333333, loss:2.916630268096924
batch i:227
learning rate0.0013333333333333333, loss:2.9503350257873535
batch i:228
learning rate0.0013333333333333333, loss:2.908639907836914
batch i:229
learning rate0.0013333333333333333, loss:2.9118216037750244
batch i:230
learning rate0.0013333333333333333, loss:2.8928933143615723
batch i:231
learning rate0.0013333333333333333, loss:2.8702731132507324
batch i:232
learning rate0.0013333333333333333, loss:3.0186893939971924
batch i:233
learning rate0.0013333333333333333, loss:2.9268441200256348
batch i:234
learning rate0.0013333333333333333, loss:2.8751373291015625
batch i:235
learning rate0.0013333333333333333, loss:2.8449387550354004
batch i:236
learning rate0.0013333333333333333, loss:2.923633575439453
batch i:237
learning rate0.0013333333333333333, loss:3.0135021209716797
batch i:238
learning rate0.0013333333333333333, loss:2.9111697673797607
batch i:239
learning rate0.0013333333333333333, loss:2.9022297859191895
batch i:240
learning rate0.0013333333333333333, loss:2.9482316970825195
batch i:241
learning rate0.0013333333333333333, loss:2.9668359756469727
batch i:242
learning rate0.0013333333333333333, loss:2.865511417388916
batch i:243
learning rate0.0013333333333333333, loss:2.9278922080993652
batch i:244
learning rate0.0013333333333333333, loss:3.003535270690918
batch i:245
learning rate0.0013333333333333333, loss:2.9870264530181885
batch i:246
learning rate0.0013333333333333333, loss:2.931300640106201
batch i:247
learning rate0.0013333333333333333, loss:2.893324136734009
batch i:248
learning rate0.0013333333333333333, loss:2.873753070831299
batch i:249
learning rate0.0013333333333333333, loss:2.912193536758423
batch i:250
learning rate0.0013333333333333333, loss:2.9241037368774414
current self-play batch: 250
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 349.4440176010132
batch i:251
learning rate0.0013333333333333333, loss:2.9667043685913086
batch i:252
learning rate0.0013333333333333333, loss:2.933542013168335
batch i:253
learning rate0.0013333333333333333, loss:2.9116134643554688
batch i:254
learning rate0.0013333333333333333, loss:2.9981799125671387
batch i:255
learning rate0.0013333333333333333, loss:2.9518239498138428
batch i:256
learning rate0.0013333333333333333, loss:2.976034164428711
batch i:257
learning rate0.0013333333333333333, loss:2.967897415161133
batch i:258
learning rate0.0013333333333333333, loss:2.944883346557617
batch i:259
learning rate0.0013333333333333333, loss:2.8984880447387695
batch i:260
learning rate0.0013333333333333333, loss:2.932722568511963
batch i:261
learning rate0.0013333333333333333, loss:2.946033477783203
batch i:262
learning rate0.0013333333333333333, loss:2.9827938079833984
batch i:263
learning rate0.0013333333333333333, loss:3.0100138187408447
batch i:264
learning rate0.0013333333333333333, loss:2.933884382247925
batch i:265
learning rate0.0013333333333333333, loss:2.9185476303100586
batch i:266
learning rate0.0013333333333333333, loss:3.054264545440674
batch i:267
learning rate0.0013333333333333333, loss:2.975412130355835
batch i:268
learning rate0.0013333333333333333, loss:2.9496588706970215
batch i:269
learning rate0.0013333333333333333, loss:2.9251837730407715
batch i:270
learning rate0.0013333333333333333, loss:2.936603546142578
batch i:271
learning rate0.0013333333333333333, loss:2.8312268257141113
batch i:272
learning rate0.0013333333333333333, loss:2.92374324798584
batch i:273
learning rate0.0013333333333333333, loss:2.87797212600708
batch i:274
learning rate0.0013333333333333333, loss:2.9567956924438477
batch i:275
learning rate0.0013333333333333333, loss:2.9365952014923096
batch i:276
learning rate0.0013333333333333333, loss:2.9150795936584473
batch i:277
learning rate0.0013333333333333333, loss:2.8732309341430664
batch i:278
learning rate0.0013333333333333333, loss:2.8740923404693604
batch i:279
learning rate0.0013333333333333333, loss:2.9802565574645996
batch i:280
learning rate0.0013333333333333333, loss:3.0082221031188965
batch i:281
learning rate0.0013333333333333333, loss:2.938586950302124
batch i:282
learning rate0.0013333333333333333, loss:2.901069164276123
batch i:283
learning rate0.0013333333333333333, loss:2.947777032852173
batch i:284
learning rate0.0013333333333333333, loss:2.91369366645813
batch i:285
learning rate0.0013333333333333333, loss:2.9500060081481934
batch i:286
learning rate0.0013333333333333333, loss:2.873539924621582
batch i:287
learning rate0.0013333333333333333, loss:2.9053807258605957
batch i:288
learning rate0.0013333333333333333, loss:2.945112705230713
batch i:289
learning rate0.0013333333333333333, loss:2.9938111305236816
batch i:290
learning rate0.0013333333333333333, loss:2.828056812286377
batch i:291
learning rate0.0013333333333333333, loss:2.914104461669922
batch i:292
learning rate0.0013333333333333333, loss:2.954957962036133
batch i:293
learning rate0.0013333333333333333, loss:2.9945268630981445
batch i:294
learning rate0.0013333333333333333, loss:2.9803600311279297
batch i:295
learning rate0.0013333333333333333, loss:2.9709620475769043
batch i:296
learning rate0.0013333333333333333, loss:2.8880863189697266
batch i:297
learning rate0.0013333333333333333, loss:2.961526393890381
batch i:298
learning rate0.0013333333333333333, loss:2.935488700866699
batch i:299
learning rate0.0013333333333333333, loss:2.913722038269043
batch i:300
learning rate0.0013333333333333333, loss:2.9052157402038574
current self-play batch: 300
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 464.4127056360245
batch i:301
learning rate0.0013333333333333333, loss:2.965744733810425
batch i:302
learning rate0.0013333333333333333, loss:2.994205951690674
batch i:303
learning rate0.0013333333333333333, loss:2.924915313720703
batch i:304
learning rate0.0013333333333333333, loss:2.9051642417907715
batch i:305
learning rate0.0013333333333333333, loss:2.9377973079681396
batch i:306
learning rate0.0013333333333333333, loss:3.0169858932495117
batch i:307
learning rate0.0013333333333333333, loss:2.923219680786133
batch i:308
learning rate0.0013333333333333333, loss:2.8734219074249268
batch i:309
learning rate0.0013333333333333333, loss:3.0038394927978516
batch i:310
learning rate0.0013333333333333333, loss:2.9661343097686768
batch i:311
learning rate0.0013333333333333333, loss:3.0087127685546875
batch i:312
learning rate0.0013333333333333333, loss:2.92437744140625
batch i:313
learning rate0.0013333333333333333, loss:2.9521396160125732
batch i:314
learning rate0.0013333333333333333, loss:2.9190573692321777
batch i:315
learning rate0.0013333333333333333, loss:2.94260835647583
batch i:316
learning rate0.0013333333333333333, loss:2.964186429977417
batch i:317
learning rate0.0013333333333333333, loss:2.887982130050659
batch i:318
learning rate0.0013333333333333333, loss:2.9585866928100586
batch i:319
learning rate0.0013333333333333333, loss:2.843273878097534
batch i:320
learning rate0.0013333333333333333, loss:2.987172842025757
batch i:321
learning rate0.0013333333333333333, loss:3.0007097721099854
batch i:322
learning rate0.0013333333333333333, loss:2.903059959411621
batch i:323
learning rate0.0013333333333333333, loss:2.8867430686950684
batch i:324
learning rate0.0013333333333333333, loss:2.9184234142303467
batch i:325
learning rate0.0013333333333333333, loss:3.0079238414764404
batch i:326
learning rate0.0013333333333333333, loss:2.931386947631836
batch i:327
learning rate0.0013333333333333333, loss:2.911484718322754
batch i:328
learning rate0.0013333333333333333, loss:2.9037022590637207
batch i:329
learning rate0.0013333333333333333, loss:2.9448082447052
batch i:330
learning rate0.0013333333333333333, loss:2.967301368713379
batch i:331
learning rate0.0013333333333333333, loss:2.9770150184631348
batch i:332
learning rate0.0013333333333333333, loss:2.9111146926879883
batch i:333
learning rate0.0013333333333333333, loss:2.96903133392334
batch i:334
learning rate0.0013333333333333333, loss:3.0166308879852295
batch i:335
learning rate0.0013333333333333333, loss:3.010040283203125
batch i:336
learning rate0.0013333333333333333, loss:2.9306087493896484
batch i:337
learning rate0.0013333333333333333, loss:2.9293746948242188
batch i:338
learning rate0.0013333333333333333, loss:2.9070167541503906
batch i:339
learning rate0.0013333333333333333, loss:2.917992353439331
batch i:340
learning rate0.0013333333333333333, loss:2.878429412841797
batch i:341
learning rate0.0013333333333333333, loss:2.872737169265747
batch i:342
learning rate0.0013333333333333333, loss:2.999573230743408
batch i:343
learning rate0.0013333333333333333, loss:2.960787057876587
batch i:344
learning rate0.0013333333333333333, loss:2.9161806106567383
batch i:345
learning rate0.0013333333333333333, loss:2.9099793434143066
batch i:346
learning rate0.0013333333333333333, loss:2.967506170272827
batch i:347
learning rate0.0013333333333333333, loss:2.87396240234375
batch i:348
learning rate0.0013333333333333333, loss:2.88582181930542
batch i:349
learning rate0.0013333333333333333, loss:2.8919806480407715
batch i:350
learning rate0.0013333333333333333, loss:2.924194812774658
current self-play batch: 350
num_playouts:2000, win: 10, lose: 0, tie:0
average time: 316.9608734607697
New best policy from pure MCTS
batch i:351
learning rate0.0013333333333333333, loss:2.885441780090332
batch i:352
learning rate0.0013333333333333333, loss:2.8239338397979736
batch i:353
learning rate0.0013333333333333333, loss:2.881564140319824
batch i:354
learning rate0.0013333333333333333, loss:2.889003038406372
batch i:355
learning rate0.0013333333333333333, loss:2.919403076171875
batch i:356
learning rate0.0013333333333333333, loss:2.9005279541015625
batch i:357
learning rate0.0013333333333333333, loss:2.942716598510742
batch i:358
learning rate0.0013333333333333333, loss:2.9105820655822754
batch i:359
learning rate0.0013333333333333333, loss:2.9218733310699463
batch i:360
learning rate0.0013333333333333333, loss:2.947239398956299
batch i:361
learning rate0.0013333333333333333, loss:2.9180917739868164
batch i:362
learning rate0.0013333333333333333, loss:2.908538818359375
batch i:363
learning rate0.0013333333333333333, loss:2.9418156147003174
batch i:364
learning rate0.0013333333333333333, loss:2.9305648803710938
batch i:365
learning rate0.0013333333333333333, loss:2.8972911834716797
batch i:366
learning rate0.0013333333333333333, loss:2.924691677093506
batch i:367
learning rate0.0013333333333333333, loss:2.8080878257751465
batch i:368
learning rate0.0013333333333333333, loss:2.818213701248169
batch i:369
learning rate0.0013333333333333333, loss:2.8527002334594727
batch i:370
learning rate0.0013333333333333333, loss:2.8845162391662598
batch i:371
learning rate0.0013333333333333333, loss:2.8654067516326904
batch i:372
learning rate0.0013333333333333333, loss:2.901785373687744
batch i:373
learning rate0.0013333333333333333, loss:2.8461263179779053
batch i:374
learning rate0.0013333333333333333, loss:2.9783897399902344
batch i:375
learning rate0.0013333333333333333, loss:2.9097683429718018
batch i:376
learning rate0.0013333333333333333, loss:2.9473891258239746
batch i:377
learning rate0.0013333333333333333, loss:2.8638246059417725
batch i:378
learning rate0.0013333333333333333, loss:2.943267583847046
batch i:379
learning rate0.0013333333333333333, loss:2.963379144668579
batch i:380
learning rate0.0013333333333333333, loss:2.8573861122131348
batch i:381
learning rate0.0013333333333333333, loss:2.8359434604644775
batch i:382
learning rate0.0013333333333333333, loss:2.9130167961120605
batch i:383
learning rate0.0013333333333333333, loss:2.849384307861328
batch i:384
learning rate0.0013333333333333333, loss:2.8805198669433594
batch i:385
learning rate0.0013333333333333333, loss:2.8727152347564697
batch i:386
learning rate0.0013333333333333333, loss:2.883111000061035
batch i:387
learning rate0.0013333333333333333, loss:2.9377994537353516
batch i:388
learning rate0.0013333333333333333, loss:2.8713674545288086
batch i:389
learning rate0.0013333333333333333, loss:2.819707155227661
batch i:390
learning rate0.0013333333333333333, loss:2.8096327781677246
batch i:391
learning rate0.0013333333333333333, loss:2.8818259239196777
batch i:392
learning rate0.0013333333333333333, loss:2.8605294227600098
batch i:393
learning rate0.0013333333333333333, loss:2.868191957473755
batch i:394
learning rate0.0013333333333333333, loss:2.859260082244873
batch i:395
learning rate0.0013333333333333333, loss:2.8471484184265137
batch i:396
learning rate0.0013333333333333333, loss:2.915329933166504
batch i:397
learning rate0.0013333333333333333, loss:2.983987331390381
batch i:398
learning rate0.0013333333333333333, loss:2.852799654006958
batch i:399
learning rate0.0013333333333333333, loss:2.8794641494750977
batch i:400
learning rate0.0013333333333333333, loss:2.81426739692688
current self-play batch: 400
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 622.1420346260071
New best policy from pure MCTS
batch i:401
learning rate0.0013333333333333333, loss:2.8046703338623047
batch i:402
learning rate0.0013333333333333333, loss:2.7975971698760986
batch i:403
learning rate0.0013333333333333333, loss:2.885406732559204
batch i:404
learning rate0.0013333333333333333, loss:2.870718240737915
batch i:405
learning rate0.0013333333333333333, loss:2.8707728385925293
batch i:406
learning rate0.0013333333333333333, loss:2.7951207160949707
batch i:407
learning rate0.0013333333333333333, loss:2.933516025543213
batch i:408
learning rate0.0013333333333333333, loss:2.8589067459106445
batch i:409
learning rate0.0013333333333333333, loss:2.8208889961242676
batch i:410
learning rate0.0013333333333333333, loss:2.847320556640625
batch i:411
learning rate0.0013333333333333333, loss:2.8197126388549805
batch i:412
learning rate0.0013333333333333333, loss:2.817991256713867
batch i:413
learning rate0.0013333333333333333, loss:2.8894901275634766
batch i:414
learning rate0.0013333333333333333, loss:2.798593044281006
batch i:415
learning rate0.0013333333333333333, loss:2.835205078125
batch i:416
learning rate0.0013333333333333333, loss:2.836534261703491
batch i:417
learning rate0.0013333333333333333, loss:2.7944204807281494
batch i:418
learning rate0.0013333333333333333, loss:2.7960593700408936
batch i:419
learning rate0.0013333333333333333, loss:2.922370195388794
batch i:420
learning rate0.0013333333333333333, loss:2.916041851043701
batch i:421
learning rate0.0013333333333333333, loss:2.908025026321411
batch i:422
learning rate0.0013333333333333333, loss:2.8448009490966797
batch i:423
learning rate0.0013333333333333333, loss:2.9136500358581543
batch i:424
learning rate0.0013333333333333333, loss:2.820314884185791
batch i:425
learning rate0.0013333333333333333, loss:2.8306655883789062
batch i:426
learning rate0.0013333333333333333, loss:2.9318859577178955
batch i:427
learning rate0.0013333333333333333, loss:2.865150213241577
batch i:428
learning rate0.0013333333333333333, loss:2.8607125282287598
batch i:429
learning rate0.0013333333333333333, loss:2.922049045562744
batch i:430
learning rate0.0013333333333333333, loss:2.910292148590088
batch i:431
learning rate0.0013333333333333333, loss:2.84197998046875
batch i:432
learning rate0.0013333333333333333, loss:2.8764195442199707
batch i:433
learning rate0.0013333333333333333, loss:2.8807225227355957
batch i:434
learning rate0.0013333333333333333, loss:2.8171157836914062
batch i:435
learning rate0.0013333333333333333, loss:2.875413417816162
batch i:436
learning rate0.0013333333333333333, loss:2.838771343231201
batch i:437
learning rate0.0013333333333333333, loss:2.832939386367798
batch i:438
learning rate0.0013333333333333333, loss:2.8126437664031982
batch i:439
learning rate0.0013333333333333333, loss:2.818934440612793
batch i:440
learning rate0.0013333333333333333, loss:2.8823628425598145
batch i:441
learning rate0.0013333333333333333, loss:2.852389335632324
batch i:442
learning rate0.0013333333333333333, loss:2.835768699645996
batch i:443
learning rate0.0013333333333333333, loss:2.7737045288085938
batch i:444
learning rate0.0013333333333333333, loss:2.8961455821990967
batch i:445
learning rate0.0013333333333333333, loss:2.856527328491211
batch i:446
learning rate0.0013333333333333333, loss:2.852731943130493
batch i:447
learning rate0.0013333333333333333, loss:2.9081361293792725
batch i:448
learning rate0.0013333333333333333, loss:2.9117860794067383
batch i:449
learning rate0.0013333333333333333, loss:2.8506288528442383
batch i:450
learning rate0.0013333333333333333, loss:2.7967917919158936
current self-play batch: 450
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 850.914357471466
batch i:451
learning rate0.0013333333333333333, loss:2.8585238456726074
batch i:452
learning rate0.0013333333333333333, loss:2.847546100616455
batch i:453
learning rate0.0013333333333333333, loss:2.9090280532836914
batch i:454
learning rate0.0013333333333333333, loss:2.8503611087799072
batch i:455
learning rate0.0013333333333333333, loss:2.805757522583008
batch i:456
learning rate0.0013333333333333333, loss:2.841642141342163
batch i:457
learning rate0.0013333333333333333, loss:2.885652542114258
batch i:458
learning rate0.0013333333333333333, loss:2.850597381591797
batch i:459
learning rate0.0013333333333333333, loss:2.8569717407226562
batch i:460
learning rate0.0013333333333333333, loss:2.882469654083252
batch i:461
learning rate0.0013333333333333333, loss:2.915100574493408
batch i:462
learning rate0.0013333333333333333, loss:2.863743782043457
batch i:463
learning rate0.0013333333333333333, loss:2.79384708404541
batch i:464
learning rate0.0013333333333333333, loss:2.937448024749756
batch i:465
learning rate0.0013333333333333333, loss:2.791938543319702
batch i:466
learning rate0.0013333333333333333, loss:2.8433728218078613
batch i:467
learning rate0.0013333333333333333, loss:2.880889892578125
batch i:468
learning rate0.0013333333333333333, loss:2.783564329147339
batch i:469
learning rate0.0013333333333333333, loss:2.8064067363739014
batch i:470
learning rate0.0013333333333333333, loss:2.9015839099884033
batch i:471
learning rate0.0013333333333333333, loss:2.9201855659484863
batch i:472
learning rate0.0013333333333333333, loss:2.8941986560821533
batch i:473
learning rate0.0013333333333333333, loss:2.8720028400421143
batch i:474
learning rate0.0013333333333333333, loss:2.8833816051483154
batch i:475
learning rate0.0013333333333333333, loss:2.8692212104797363
batch i:476
learning rate0.0013333333333333333, loss:2.827284097671509
batch i:477
learning rate0.0013333333333333333, loss:2.879082679748535
batch i:478
learning rate0.0013333333333333333, loss:2.932234287261963
batch i:479
learning rate0.0013333333333333333, loss:2.8538196086883545
batch i:480
learning rate0.0013333333333333333, loss:2.802595853805542
batch i:481
learning rate0.0013333333333333333, loss:2.847625970840454
batch i:482
learning rate0.0013333333333333333, loss:2.8846511840820312
batch i:483
learning rate0.0013333333333333333, loss:2.885830879211426
batch i:484
learning rate0.0013333333333333333, loss:2.8255887031555176
batch i:485
learning rate0.0013333333333333333, loss:2.886657476425171
batch i:486
learning rate0.0013333333333333333, loss:2.929323673248291
batch i:487
learning rate0.0013333333333333333, loss:2.914517879486084
batch i:488
learning rate0.0013333333333333333, loss:2.8448898792266846
batch i:489
learning rate0.0013333333333333333, loss:2.8824100494384766
batch i:490
learning rate0.0013333333333333333, loss:2.8877758979797363
batch i:491
learning rate0.0013333333333333333, loss:2.8255605697631836
batch i:492
learning rate0.0013333333333333333, loss:2.864834785461426
batch i:493
learning rate0.0013333333333333333, loss:2.881099224090576
batch i:494
learning rate0.0013333333333333333, loss:2.8562583923339844
batch i:495
learning rate0.0013333333333333333, loss:2.9130983352661133
batch i:496
learning rate0.0013333333333333333, loss:2.869462728500366
batch i:497
learning rate0.0013333333333333333, loss:2.9654932022094727
batch i:498
learning rate0.0013333333333333333, loss:2.898488998413086
batch i:499
learning rate0.0013333333333333333, loss:2.9017210006713867
batch i:500
learning rate0.0013333333333333333, loss:2.8560571670532227
current self-play batch: 500
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 646.8412524223328
batch i:501
learning rate0.0013333333333333333, loss:2.929161548614502
batch i:502
learning rate0.0013333333333333333, loss:2.914625644683838
batch i:503
learning rate0.0013333333333333333, loss:2.9009549617767334
batch i:504
learning rate0.0013333333333333333, loss:2.8858654499053955
batch i:505
learning rate0.0013333333333333333, loss:2.8498945236206055
batch i:506
learning rate0.0013333333333333333, loss:2.9050540924072266
batch i:507
learning rate0.0013333333333333333, loss:2.8995213508605957
batch i:508
learning rate0.0013333333333333333, loss:2.8550474643707275
batch i:509
learning rate0.0013333333333333333, loss:2.940011501312256
batch i:510
learning rate0.0013333333333333333, loss:2.9438204765319824
batch i:511
learning rate0.0013333333333333333, loss:2.9114344120025635
batch i:512
learning rate0.0013333333333333333, loss:2.8629634380340576
batch i:513
learning rate0.0013333333333333333, loss:2.8980093002319336
batch i:514
learning rate0.0013333333333333333, loss:2.9840266704559326
batch i:515
learning rate0.0013333333333333333, loss:2.9174556732177734
batch i:516
learning rate0.0013333333333333333, loss:2.866208553314209
batch i:517
learning rate0.0013333333333333333, loss:2.775251626968384
batch i:518
learning rate0.0013333333333333333, loss:2.881939649581909
batch i:519
learning rate0.0013333333333333333, loss:2.8998517990112305
batch i:520
learning rate0.0013333333333333333, loss:2.9680838584899902
batch i:521
learning rate0.0013333333333333333, loss:2.8461947441101074
batch i:522
learning rate0.0013333333333333333, loss:2.879261016845703
batch i:523
learning rate0.0013333333333333333, loss:2.859185218811035
batch i:524
learning rate0.0013333333333333333, loss:2.9098682403564453
batch i:525
learning rate0.0013333333333333333, loss:2.9062325954437256
batch i:526
learning rate0.0013333333333333333, loss:2.894127607345581
batch i:527
learning rate0.0013333333333333333, loss:2.8401966094970703
batch i:528
learning rate0.0013333333333333333, loss:3.037454128265381
batch i:529
learning rate0.0013333333333333333, loss:2.987501621246338
batch i:530
learning rate0.0013333333333333333, loss:2.8814749717712402
batch i:531
learning rate0.0013333333333333333, loss:2.944300651550293
batch i:532
learning rate0.0013333333333333333, loss:2.933539867401123
batch i:533
learning rate0.0013333333333333333, loss:2.881899356842041
batch i:534
learning rate0.0013333333333333333, loss:2.9469411373138428
batch i:535
learning rate0.0013333333333333333, loss:2.888051748275757
batch i:536
learning rate0.0013333333333333333, loss:2.9585747718811035
batch i:537
learning rate0.0013333333333333333, loss:2.9616358280181885
batch i:538
learning rate0.0013333333333333333, loss:2.9405579566955566
batch i:539
learning rate0.0013333333333333333, loss:2.9428536891937256
batch i:540
learning rate0.0013333333333333333, loss:2.9802560806274414
batch i:541
learning rate0.0013333333333333333, loss:2.9828882217407227
batch i:542
learning rate0.0013333333333333333, loss:2.977930784225464
batch i:543
learning rate0.0013333333333333333, loss:2.9222512245178223
batch i:544
learning rate0.0013333333333333333, loss:2.925820827484131
batch i:545
learning rate0.0013333333333333333, loss:2.9755361080169678
batch i:546
learning rate0.0013333333333333333, loss:2.9646127223968506
batch i:547
learning rate0.0013333333333333333, loss:2.9020466804504395
batch i:548
learning rate0.0013333333333333333, loss:2.9861252307891846
batch i:549
learning rate0.0013333333333333333, loss:3.1215462684631348
batch i:550
learning rate0.0013333333333333333, loss:2.9788949489593506
current self-play batch: 550
num_playouts:3000, win: 9, lose: 1, tie:0
average time: 508.3966372013092
New best policy from pure MCTS
batch i:551
learning rate0.0013333333333333333, loss:2.8094563484191895
batch i:552
learning rate0.0013333333333333333, loss:2.9794976711273193
batch i:553
learning rate0.0013333333333333333, loss:2.890676975250244
batch i:554
learning rate0.0013333333333333333, loss:3.041792392730713
batch i:555
learning rate0.0013333333333333333, loss:2.957658529281616
batch i:556
learning rate0.0013333333333333333, loss:2.996734142303467
batch i:557
learning rate0.0013333333333333333, loss:2.8659048080444336
batch i:558
learning rate0.0013333333333333333, loss:2.9607582092285156
batch i:559
learning rate0.0013333333333333333, loss:3.003087282180786
batch i:560
learning rate0.0013333333333333333, loss:2.8814244270324707
batch i:561
learning rate0.0013333333333333333, loss:2.970773935317993
batch i:562
learning rate0.0013333333333333333, loss:2.993577003479004
batch i:563
learning rate0.0013333333333333333, loss:2.9926633834838867
batch i:564
learning rate0.0013333333333333333, loss:2.984309196472168
batch i:565
learning rate0.0013333333333333333, loss:3.0487101078033447
batch i:566
learning rate0.0013333333333333333, loss:3.0045886039733887
batch i:567
learning rate0.0013333333333333333, loss:2.9496469497680664
batch i:568
learning rate0.0013333333333333333, loss:2.9422850608825684
batch i:569
learning rate0.0013333333333333333, loss:3.0399527549743652
batch i:570
learning rate0.0013333333333333333, loss:3.0924830436706543
batch i:571
learning rate0.0013333333333333333, loss:2.977673292160034
batch i:572
learning rate0.0013333333333333333, loss:3.033627510070801
batch i:573
learning rate0.0013333333333333333, loss:3.039641857147217
batch i:574
learning rate0.0013333333333333333, loss:2.9452624320983887
batch i:575
learning rate0.0013333333333333333, loss:3.051347255706787
batch i:576
learning rate0.0013333333333333333, loss:2.9035863876342773
batch i:577
learning rate0.0013333333333333333, loss:2.9517955780029297
batch i:578
learning rate0.0013333333333333333, loss:2.9763026237487793
batch i:579
learning rate0.0013333333333333333, loss:2.967796802520752
batch i:580
learning rate0.0013333333333333333, loss:3.0070626735687256
batch i:581
learning rate0.0013333333333333333, loss:3.0386061668395996
batch i:582
learning rate0.0013333333333333333, loss:2.965723752975464
batch i:583
learning rate0.0013333333333333333, loss:3.0436553955078125
batch i:584
learning rate0.0013333333333333333, loss:3.0320396423339844
batch i:585
learning rate0.0013333333333333333, loss:3.000810146331787
batch i:586
learning rate0.0013333333333333333, loss:2.9194750785827637
batch i:587
learning rate0.0013333333333333333, loss:2.927855968475342
batch i:588
learning rate0.0013333333333333333, loss:2.9686522483825684
batch i:589
learning rate0.0013333333333333333, loss:2.9994988441467285
batch i:590
learning rate0.0013333333333333333, loss:2.8994438648223877
batch i:591
learning rate0.0013333333333333333, loss:3.0142416954040527
batch i:592
learning rate0.0013333333333333333, loss:3.035724401473999
batch i:593
learning rate0.0013333333333333333, loss:2.971498966217041
batch i:594
learning rate0.0013333333333333333, loss:3.008934497833252
batch i:595
learning rate0.0013333333333333333, loss:2.9346299171447754
batch i:596
learning rate0.0013333333333333333, loss:2.9566800594329834
batch i:597
learning rate0.0013333333333333333, loss:2.9714174270629883
batch i:598
learning rate0.0013333333333333333, loss:2.9909372329711914
batch i:599
learning rate0.0013333333333333333, loss:3.008033037185669
batch i:600
learning rate0.0013333333333333333, loss:2.9613475799560547
current self-play batch: 600
num_playouts:3000, win: 6, lose: 4, tie:0
average time: 692.8920066356659
batch i:601
learning rate0.0013333333333333333, loss:2.970489025115967
batch i:602
learning rate0.0013333333333333333, loss:2.8741281032562256
batch i:603
learning rate0.0013333333333333333, loss:2.9610443115234375
batch i:604
learning rate0.0013333333333333333, loss:3.0100514888763428
batch i:605
learning rate0.0013333333333333333, loss:3.016493082046509
batch i:606
learning rate0.0013333333333333333, loss:2.928196430206299
batch i:607
learning rate0.0013333333333333333, loss:3.0768966674804688
batch i:608
learning rate0.0013333333333333333, loss:2.914896249771118
batch i:609
learning rate0.0013333333333333333, loss:2.9475550651550293
batch i:610
learning rate0.0013333333333333333, loss:2.9802873134613037
batch i:611
learning rate0.0013333333333333333, loss:2.9449996948242188
batch i:612
learning rate0.0013333333333333333, loss:2.906980514526367
batch i:613
learning rate0.0013333333333333333, loss:2.9085450172424316
batch i:614
learning rate0.0013333333333333333, loss:2.9573302268981934
batch i:615
learning rate0.0013333333333333333, loss:2.9459829330444336
batch i:616
learning rate0.0013333333333333333, loss:2.9917287826538086
batch i:617
learning rate0.0013333333333333333, loss:2.904384136199951
batch i:618
learning rate0.0013333333333333333, loss:2.8537721633911133
batch i:619
learning rate0.0013333333333333333, loss:2.959080696105957
batch i:620
learning rate0.0013333333333333333, loss:2.8717823028564453
batch i:621
learning rate0.0013333333333333333, loss:2.931441307067871
batch i:622
learning rate0.0013333333333333333, loss:2.9787583351135254
batch i:623
learning rate0.0013333333333333333, loss:3.010645866394043
batch i:624
learning rate0.0013333333333333333, loss:2.881753444671631
batch i:625
learning rate0.0013333333333333333, loss:3.0416157245635986
batch i:626
learning rate0.0013333333333333333, loss:3.0020439624786377
batch i:627
learning rate0.0013333333333333333, loss:2.875518560409546
batch i:628
learning rate0.0013333333333333333, loss:2.8929200172424316
batch i:629
learning rate0.0013333333333333333, loss:2.967970848083496
batch i:630
learning rate0.0013333333333333333, loss:2.9077703952789307
batch i:631
learning rate0.0013333333333333333, loss:2.9168386459350586
batch i:632
learning rate0.0013333333333333333, loss:2.9096059799194336
batch i:633
learning rate0.0013333333333333333, loss:2.936615228652954
batch i:634
learning rate0.0013333333333333333, loss:2.9632256031036377
batch i:635
learning rate0.0013333333333333333, loss:2.988210439682007
batch i:636
learning rate0.0013333333333333333, loss:3.0883617401123047
batch i:637
learning rate0.0013333333333333333, loss:2.982067823410034
batch i:638
learning rate0.0013333333333333333, loss:3.009298801422119
batch i:639
learning rate0.0013333333333333333, loss:2.9799060821533203
batch i:640
learning rate0.0013333333333333333, loss:3.0142979621887207
batch i:641
learning rate0.0013333333333333333, loss:2.9874355792999268
batch i:642
learning rate0.0013333333333333333, loss:3.04276704788208
batch i:643
learning rate0.0013333333333333333, loss:2.9221558570861816
batch i:644
learning rate0.0013333333333333333, loss:2.9206581115722656
batch i:645
learning rate0.0013333333333333333, loss:2.919978141784668
batch i:646
learning rate0.0013333333333333333, loss:3.063015937805176
batch i:647
learning rate0.0013333333333333333, loss:2.9049034118652344
batch i:648
learning rate0.0013333333333333333, loss:2.8921568393707275
batch i:649
learning rate0.0013333333333333333, loss:2.862588882446289
batch i:650
learning rate0.0013333333333333333, loss:2.879857063293457
current self-play batch: 650
num_playouts:3000, win: 9, lose: 1, tie:0
average time: 795.8126969099045
batch i:651
learning rate0.0013333333333333333, loss:2.902327060699463
batch i:652
learning rate0.0013333333333333333, loss:2.9207916259765625
batch i:653
learning rate0.0013333333333333333, loss:2.9681341648101807
batch i:654
learning rate0.0013333333333333333, loss:2.9703757762908936
batch i:655
learning rate0.0013333333333333333, loss:2.8954198360443115
batch i:656
learning rate0.0013333333333333333, loss:2.880242347717285
batch i:657
learning rate0.0013333333333333333, loss:2.922311782836914
batch i:658
learning rate0.0013333333333333333, loss:2.8341879844665527
batch i:659
learning rate0.0013333333333333333, loss:2.946528911590576
batch i:660
learning rate0.0013333333333333333, loss:2.8457095623016357
batch i:661
learning rate0.0013333333333333333, loss:2.893101215362549
batch i:662
learning rate0.0013333333333333333, loss:2.936185121536255
batch i:663
learning rate0.0013333333333333333, loss:2.98288631439209
batch i:664
learning rate0.0013333333333333333, loss:2.970796585083008
batch i:665
learning rate0.0013333333333333333, loss:2.9290099143981934
batch i:666
learning rate0.0013333333333333333, loss:2.956815719604492
batch i:667
learning rate0.0013333333333333333, loss:2.9599545001983643
batch i:668
learning rate0.0013333333333333333, loss:3.0107014179229736
batch i:669
learning rate0.0013333333333333333, loss:2.93868350982666
batch i:670
learning rate0.0013333333333333333, loss:2.8778271675109863
batch i:671
learning rate0.0013333333333333333, loss:2.9204745292663574
batch i:672
learning rate0.0013333333333333333, loss:2.9053454399108887
batch i:673
learning rate0.0013333333333333333, loss:2.992384910583496
batch i:674
learning rate0.0013333333333333333, loss:2.9156599044799805
batch i:675
learning rate0.0013333333333333333, loss:2.922224998474121
batch i:676
learning rate0.0013333333333333333, loss:2.9181125164031982
batch i:677
learning rate0.0013333333333333333, loss:2.8805713653564453
batch i:678
learning rate0.0013333333333333333, loss:2.884742498397827
batch i:679
learning rate0.0013333333333333333, loss:2.9719579219818115
batch i:680
learning rate0.0013333333333333333, loss:2.939751625061035
batch i:681
learning rate0.0013333333333333333, loss:2.9536609649658203
batch i:682
learning rate0.0013333333333333333, loss:2.925854206085205
batch i:683
learning rate0.0013333333333333333, loss:3.0080504417419434
batch i:684
learning rate0.0013333333333333333, loss:2.9714460372924805
batch i:685
learning rate0.0013333333333333333, loss:2.96943998336792
batch i:686
learning rate0.0013333333333333333, loss:2.9846410751342773
batch i:687
learning rate0.0013333333333333333, loss:2.962958574295044
batch i:688
learning rate0.0013333333333333333, loss:2.9366049766540527
batch i:689
learning rate0.0013333333333333333, loss:2.922027587890625
batch i:690
learning rate0.0013333333333333333, loss:2.8579702377319336
batch i:691
learning rate0.0013333333333333333, loss:2.9470701217651367
batch i:692
learning rate0.0013333333333333333, loss:2.9861552715301514
batch i:693
learning rate0.0013333333333333333, loss:2.9170851707458496
batch i:694
learning rate0.0013333333333333333, loss:2.9386472702026367
batch i:695
learning rate0.0013333333333333333, loss:2.9659910202026367
batch i:696
learning rate0.0013333333333333333, loss:2.952317237854004
batch i:697
learning rate0.0013333333333333333, loss:2.868347644805908
batch i:698
learning rate0.0013333333333333333, loss:2.8438925743103027
batch i:699
learning rate0.0013333333333333333, loss:2.969744920730591
batch i:700
learning rate0.0013333333333333333, loss:2.874691963195801
current self-play batch: 700
num_playouts:3000, win: 9, lose: 1, tie:0
average time: 681.6767610788345
batch i:701
learning rate0.0013333333333333333, loss:2.945673704147339
batch i:702
learning rate0.0013333333333333333, loss:2.955209255218506
batch i:703
learning rate0.0013333333333333333, loss:2.803630828857422
batch i:704
learning rate0.0013333333333333333, loss:2.9085135459899902
batch i:705
learning rate0.0013333333333333333, loss:2.8997933864593506
batch i:706
learning rate0.0013333333333333333, loss:2.8962278366088867
batch i:707
learning rate0.0013333333333333333, loss:2.936702013015747
batch i:708
learning rate0.0013333333333333333, loss:2.8978958129882812
batch i:709
learning rate0.0013333333333333333, loss:2.8868274688720703
batch i:710
learning rate0.0013333333333333333, loss:2.847115993499756
batch i:711
learning rate0.0013333333333333333, loss:2.7693593502044678
batch i:712
learning rate0.0013333333333333333, loss:2.8707668781280518
batch i:713
learning rate0.0013333333333333333, loss:2.884554862976074
batch i:714
learning rate0.0013333333333333333, loss:2.904592990875244
batch i:715
learning rate0.0013333333333333333, loss:2.900371551513672
batch i:716
learning rate0.0013333333333333333, loss:2.9542088508605957
batch i:717
learning rate0.0013333333333333333, loss:2.8802649974823
batch i:718
learning rate0.0013333333333333333, loss:2.8596463203430176
batch i:719
learning rate0.0013333333333333333, loss:2.92934513092041
batch i:720
learning rate0.0013333333333333333, loss:2.875638484954834
batch i:721
learning rate0.0013333333333333333, loss:2.897167205810547
batch i:722
learning rate0.0013333333333333333, loss:2.9401042461395264
batch i:723
learning rate0.0013333333333333333, loss:2.88017201423645
batch i:724
learning rate0.0013333333333333333, loss:2.979907512664795
batch i:725
learning rate0.0013333333333333333, loss:2.8618812561035156
batch i:726
learning rate0.0013333333333333333, loss:2.8631649017333984
batch i:727
learning rate0.0013333333333333333, loss:2.8900985717773438
batch i:728
learning rate0.0013333333333333333, loss:2.8299436569213867
batch i:729
learning rate0.0013333333333333333, loss:2.846297264099121
batch i:730
learning rate0.0013333333333333333, loss:2.906928062438965
batch i:731
learning rate0.0013333333333333333, loss:2.900622844696045
batch i:732
learning rate0.0013333333333333333, loss:2.8537864685058594
batch i:733
learning rate0.0013333333333333333, loss:2.826389789581299
batch i:734
learning rate0.0013333333333333333, loss:2.9537172317504883
batch i:735
learning rate0.0013333333333333333, loss:2.7372069358825684
batch i:736
learning rate0.0013333333333333333, loss:2.901886463165283
batch i:737
learning rate0.0013333333333333333, loss:2.771488904953003
batch i:738
learning rate0.0013333333333333333, loss:2.911635160446167
batch i:739
learning rate0.0013333333333333333, loss:2.888810157775879
batch i:740
learning rate0.0013333333333333333, loss:2.8676493167877197
batch i:741
learning rate0.0013333333333333333, loss:2.788391351699829
batch i:742
learning rate0.0013333333333333333, loss:2.82157564163208
batch i:743
learning rate0.0013333333333333333, loss:2.8569819927215576
batch i:744
learning rate0.0013333333333333333, loss:2.8065786361694336
batch i:745
learning rate0.0013333333333333333, loss:2.8726749420166016
batch i:746
learning rate0.0013333333333333333, loss:2.8589987754821777
batch i:747
learning rate0.0013333333333333333, loss:2.7948131561279297
batch i:748
learning rate0.0013333333333333333, loss:2.839369058609009
batch i:749
learning rate0.0013333333333333333, loss:2.772805690765381
batch i:750
learning rate0.0013333333333333333, loss:2.8581936359405518
current self-play batch: 750
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 529.0272125005722
batch i:751
learning rate0.0013333333333333333, loss:2.8666629791259766
batch i:752
learning rate0.0013333333333333333, loss:2.7723875045776367
batch i:753
learning rate0.0013333333333333333, loss:2.8762459754943848
batch i:754
learning rate0.0013333333333333333, loss:2.8514859676361084
batch i:755
learning rate0.0013333333333333333, loss:2.8493714332580566
batch i:756
learning rate0.0013333333333333333, loss:2.846290111541748
batch i:757
learning rate0.0013333333333333333, loss:2.749964952468872
batch i:758
learning rate0.0013333333333333333, loss:2.879016399383545
batch i:759
learning rate0.0013333333333333333, loss:2.7844905853271484
batch i:760
learning rate0.0013333333333333333, loss:2.8178248405456543
batch i:761
learning rate0.0013333333333333333, loss:2.908555030822754
batch i:762
learning rate0.0013333333333333333, loss:2.8841090202331543
batch i:763
learning rate0.0013333333333333333, loss:2.7613468170166016
batch i:764
learning rate0.0013333333333333333, loss:2.8162097930908203
batch i:765
learning rate0.0013333333333333333, loss:2.8164329528808594
batch i:766
learning rate0.0013333333333333333, loss:2.7569332122802734
batch i:767
learning rate0.0013333333333333333, loss:2.8080153465270996
batch i:768
learning rate0.0013333333333333333, loss:2.831754207611084
batch i:769
learning rate0.0013333333333333333, loss:2.7817587852478027
batch i:770
learning rate0.0013333333333333333, loss:2.8112740516662598
batch i:771
learning rate0.0013333333333333333, loss:2.914804458618164
batch i:772
learning rate0.0013333333333333333, loss:2.8657004833221436
batch i:773
learning rate0.0013333333333333333, loss:2.7224857807159424
batch i:774
learning rate0.0013333333333333333, loss:2.8393466472625732
batch i:775
learning rate0.0013333333333333333, loss:2.860935926437378
batch i:776
learning rate0.0013333333333333333, loss:2.8339295387268066
batch i:777
learning rate0.0013333333333333333, loss:2.7897706031799316
batch i:778
learning rate0.0013333333333333333, loss:2.840202569961548
batch i:779
learning rate0.0013333333333333333, loss:2.791415214538574
batch i:780
learning rate0.0013333333333333333, loss:2.8236780166625977
batch i:781
learning rate0.0013333333333333333, loss:2.9437496662139893
batch i:782
learning rate0.0013333333333333333, loss:2.8717336654663086
batch i:783
learning rate0.0013333333333333333, loss:2.8182437419891357
batch i:784
learning rate0.0013333333333333333, loss:2.804807186126709
batch i:785
learning rate0.0013333333333333333, loss:2.7195165157318115
batch i:786
learning rate0.0013333333333333333, loss:2.8303256034851074
batch i:787
learning rate0.0013333333333333333, loss:2.7389698028564453
batch i:788
learning rate0.0013333333333333333, loss:2.8639256954193115
batch i:789
learning rate0.0013333333333333333, loss:2.7940988540649414
batch i:790
learning rate0.0013333333333333333, loss:2.8300514221191406
batch i:791
learning rate0.0013333333333333333, loss:2.7772068977355957
batch i:792
learning rate0.0013333333333333333, loss:2.8752784729003906
batch i:793
learning rate0.0013333333333333333, loss:2.8240163326263428
batch i:794
learning rate0.0013333333333333333, loss:2.8734400272369385
batch i:795
learning rate0.0013333333333333333, loss:2.807870626449585
batch i:796
learning rate0.0013333333333333333, loss:2.8129801750183105
batch i:797
learning rate0.0013333333333333333, loss:2.716015577316284
batch i:798
learning rate0.0013333333333333333, loss:2.787313938140869
batch i:799
learning rate0.0013333333333333333, loss:2.884361505508423
batch i:800
learning rate0.0013333333333333333, loss:2.7250943183898926
current self-play batch: 800
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 497.34161653518674
batch i:801
learning rate0.0013333333333333333, loss:2.8071813583374023
batch i:802
learning rate0.0013333333333333333, loss:2.8352861404418945
batch i:803
learning rate0.0013333333333333333, loss:2.853424549102783
batch i:804
learning rate0.0013333333333333333, loss:2.8057548999786377
batch i:805
learning rate0.0013333333333333333, loss:2.783034324645996
batch i:806
learning rate0.0013333333333333333, loss:2.7795093059539795
batch i:807
learning rate0.0013333333333333333, loss:2.7866296768188477
batch i:808
learning rate0.0013333333333333333, loss:2.8168301582336426
batch i:809
learning rate0.0013333333333333333, loss:2.8284358978271484
batch i:810
learning rate0.0013333333333333333, loss:2.8154296875
batch i:811
learning rate0.0013333333333333333, loss:2.7687573432922363
batch i:812
learning rate0.0013333333333333333, loss:2.877398729324341
batch i:813
learning rate0.0013333333333333333, loss:2.809612512588501
batch i:814
learning rate0.0013333333333333333, loss:2.822187900543213
batch i:815
learning rate0.0013333333333333333, loss:2.7860169410705566
batch i:816
learning rate0.0013333333333333333, loss:2.858147621154785
batch i:817
learning rate0.0013333333333333333, loss:2.8206381797790527
batch i:818
learning rate0.0013333333333333333, loss:2.725590705871582
batch i:819
learning rate0.0013333333333333333, loss:2.806262493133545
batch i:820
learning rate0.0013333333333333333, loss:2.8466203212738037
batch i:821
learning rate0.0013333333333333333, loss:2.8793883323669434
batch i:822
learning rate0.0013333333333333333, loss:2.765122413635254
batch i:823
learning rate0.0013333333333333333, loss:2.8772716522216797
batch i:824
learning rate0.0013333333333333333, loss:2.742945432662964
batch i:825
learning rate0.0013333333333333333, loss:2.805995464324951
batch i:826
learning rate0.0013333333333333333, loss:2.81024169921875
batch i:827
learning rate0.0013333333333333333, loss:2.7384157180786133
batch i:828
learning rate0.0013333333333333333, loss:2.7720484733581543
batch i:829
learning rate0.0013333333333333333, loss:2.8097128868103027
batch i:830
learning rate0.0013333333333333333, loss:2.8436625003814697
batch i:831
learning rate0.0013333333333333333, loss:2.771204948425293
batch i:832
learning rate0.0013333333333333333, loss:2.795997142791748
batch i:833
learning rate0.0013333333333333333, loss:2.801563024520874
batch i:834
learning rate0.0013333333333333333, loss:2.792513370513916
batch i:835
learning rate0.0013333333333333333, loss:2.841461658477783
batch i:836
learning rate0.0013333333333333333, loss:2.830833911895752
batch i:837
learning rate0.0013333333333333333, loss:2.773892402648926
batch i:838
learning rate0.0013333333333333333, loss:2.839996099472046
batch i:839
learning rate0.0013333333333333333, loss:2.823179244995117
batch i:840
learning rate0.0013333333333333333, loss:2.87571382522583
batch i:841
learning rate0.0013333333333333333, loss:2.7994332313537598
batch i:842
learning rate0.0013333333333333333, loss:2.763044834136963
batch i:843
learning rate0.0013333333333333333, loss:2.801088333129883
batch i:844
learning rate0.0013333333333333333, loss:2.7457337379455566
batch i:845
learning rate0.0013333333333333333, loss:2.772805690765381
batch i:846
learning rate0.0013333333333333333, loss:2.8506598472595215
batch i:847
learning rate0.0013333333333333333, loss:2.951024055480957
batch i:848
learning rate0.0013333333333333333, loss:2.791517972946167
batch i:849
learning rate0.0013333333333333333, loss:2.818159580230713
batch i:850
learning rate0.0013333333333333333, loss:2.8989241123199463
current self-play batch: 850
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 699.9712810039521
batch i:851
learning rate0.0013333333333333333, loss:2.7534596920013428
batch i:852
learning rate0.0013333333333333333, loss:2.9026551246643066
batch i:853
learning rate0.0013333333333333333, loss:2.946545362472534
batch i:854
learning rate0.0013333333333333333, loss:2.846538782119751
batch i:855
learning rate0.0013333333333333333, loss:2.879859209060669
batch i:856
learning rate0.0013333333333333333, loss:2.856308937072754
batch i:857
learning rate0.0013333333333333333, loss:2.907503604888916
batch i:858
learning rate0.0013333333333333333, loss:2.838576316833496
batch i:859
learning rate0.0013333333333333333, loss:2.8360650539398193
batch i:860
learning rate0.0013333333333333333, loss:2.7417421340942383
batch i:861
learning rate0.0013333333333333333, loss:2.903899669647217
batch i:862
learning rate0.0013333333333333333, loss:2.873985767364502
batch i:863
learning rate0.0013333333333333333, loss:2.882441520690918
batch i:864
learning rate0.0013333333333333333, loss:2.8442955017089844
batch i:865
learning rate0.0013333333333333333, loss:2.7914247512817383
batch i:866
learning rate0.0013333333333333333, loss:2.7715539932250977
batch i:867
learning rate0.0013333333333333333, loss:2.920969009399414
batch i:868
learning rate0.0013333333333333333, loss:2.7925872802734375
batch i:869
learning rate0.0013333333333333333, loss:2.792919397354126
batch i:870
learning rate0.0013333333333333333, loss:2.8292036056518555
batch i:871
learning rate0.0013333333333333333, loss:2.8774049282073975
batch i:872
learning rate0.0013333333333333333, loss:2.680652141571045
batch i:873
learning rate0.0013333333333333333, loss:2.7794647216796875
batch i:874
learning rate0.0013333333333333333, loss:2.8594157695770264
batch i:875
learning rate0.0013333333333333333, loss:2.8591039180755615
batch i:876
learning rate0.0013333333333333333, loss:2.87294602394104
batch i:877
learning rate0.0013333333333333333, loss:2.83447265625
batch i:878
learning rate0.0013333333333333333, loss:2.8473777770996094
batch i:879
learning rate0.0013333333333333333, loss:2.8993778228759766
batch i:880
learning rate0.0013333333333333333, loss:2.866687774658203
batch i:881
learning rate0.0013333333333333333, loss:2.898723602294922
batch i:882
learning rate0.0013333333333333333, loss:2.8926889896392822
batch i:883
learning rate0.0013333333333333333, loss:2.854173421859741
batch i:884
learning rate0.0013333333333333333, loss:2.8166418075561523
batch i:885
learning rate0.0013333333333333333, loss:2.760737895965576
batch i:886
learning rate0.0013333333333333333, loss:2.845264434814453
batch i:887
learning rate0.0013333333333333333, loss:2.833981513977051
batch i:888
learning rate0.0013333333333333333, loss:2.849665403366089
batch i:889
learning rate0.0013333333333333333, loss:2.902883291244507
batch i:890
learning rate0.0013333333333333333, loss:2.8462681770324707
batch i:891
learning rate0.0013333333333333333, loss:2.8323593139648438
batch i:892
learning rate0.0013333333333333333, loss:2.851858615875244
batch i:893
learning rate0.0013333333333333333, loss:2.8135483264923096
batch i:894
learning rate0.0013333333333333333, loss:2.8510217666625977
batch i:895
learning rate0.0013333333333333333, loss:2.8587069511413574
batch i:896
learning rate0.0013333333333333333, loss:2.834571361541748
batch i:897
learning rate0.0013333333333333333, loss:2.8405094146728516
batch i:898
learning rate0.0013333333333333333, loss:2.8074989318847656
batch i:899
learning rate0.0013333333333333333, loss:2.9603641033172607
batch i:900
learning rate0.0013333333333333333, loss:2.8775155544281006
current self-play batch: 900
num_playouts:3000, win: 9, lose: 1, tie:0
average time: 915.4770009994506
batch i:901
learning rate0.0013333333333333333, loss:2.8278374671936035
batch i:902
learning rate0.0013333333333333333, loss:2.85138201713562
batch i:903
learning rate0.0013333333333333333, loss:2.858116626739502
batch i:904
learning rate0.0013333333333333333, loss:2.833815813064575
batch i:905
learning rate0.0013333333333333333, loss:2.831472396850586
batch i:906
learning rate0.0013333333333333333, loss:2.834263801574707
batch i:907
learning rate0.0013333333333333333, loss:2.8258256912231445
batch i:908
learning rate0.0013333333333333333, loss:2.909465789794922
batch i:909
learning rate0.0013333333333333333, loss:2.93328857421875
batch i:910
learning rate0.0013333333333333333, loss:2.8219828605651855
batch i:911
learning rate0.0013333333333333333, loss:2.81620192527771
batch i:912
learning rate0.0013333333333333333, loss:2.846320152282715
batch i:913
learning rate0.0013333333333333333, loss:2.8598361015319824
batch i:914
learning rate0.0013333333333333333, loss:2.809091806411743
batch i:915
learning rate0.0013333333333333333, loss:2.863232374191284
batch i:916
learning rate0.0013333333333333333, loss:2.8945014476776123
batch i:917
learning rate0.0013333333333333333, loss:2.769767999649048
batch i:918
learning rate0.0013333333333333333, loss:2.8229551315307617
batch i:919
learning rate0.0013333333333333333, loss:2.851914405822754
batch i:920
learning rate0.0013333333333333333, loss:2.844942092895508
batch i:921
learning rate0.0013333333333333333, loss:2.86417293548584
batch i:922
learning rate0.0013333333333333333, loss:2.909393072128296
batch i:923
learning rate0.0013333333333333333, loss:2.8608438968658447
batch i:924
learning rate0.0013333333333333333, loss:2.814805507659912
batch i:925
learning rate0.0013333333333333333, loss:2.8361170291900635
batch i:926
learning rate0.0013333333333333333, loss:2.9297640323638916
batch i:927
learning rate0.0013333333333333333, loss:2.902099609375
batch i:928
learning rate0.0013333333333333333, loss:2.854691743850708
batch i:929
learning rate0.0013333333333333333, loss:2.837975263595581
batch i:930
learning rate0.0013333333333333333, loss:2.9786505699157715
batch i:931
learning rate0.0013333333333333333, loss:2.8502187728881836
batch i:932
learning rate0.0013333333333333333, loss:2.7618823051452637
batch i:933
learning rate0.0013333333333333333, loss:2.893394947052002
batch i:934
learning rate0.0013333333333333333, loss:2.886775493621826
batch i:935
learning rate0.0013333333333333333, loss:2.89320707321167
batch i:936
learning rate0.0013333333333333333, loss:2.8243978023529053
batch i:937
learning rate0.0013333333333333333, loss:2.90714430809021
batch i:938
learning rate0.0013333333333333333, loss:2.867262840270996
batch i:939
learning rate0.0013333333333333333, loss:2.9403257369995117
batch i:940
learning rate0.0013333333333333333, loss:2.928485155105591
batch i:941
learning rate0.0013333333333333333, loss:2.8790769577026367
batch i:942
learning rate0.0013333333333333333, loss:2.793442726135254
batch i:943
learning rate0.0013333333333333333, loss:2.914207935333252
batch i:944
learning rate0.0013333333333333333, loss:2.8752341270446777
batch i:945
learning rate0.0013333333333333333, loss:2.808265447616577
batch i:946
learning rate0.0013333333333333333, loss:2.8211991786956787
batch i:947
learning rate0.0013333333333333333, loss:2.811821937561035
batch i:948
learning rate0.0013333333333333333, loss:2.816962480545044
batch i:949
learning rate0.0013333333333333333, loss:2.948786735534668
batch i:950
learning rate0.0013333333333333333, loss:2.834442377090454
current self-play batch: 950
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 1052.828309249878
batch i:951
learning rate0.0013333333333333333, loss:2.870514392852783
batch i:952
learning rate0.0013333333333333333, loss:2.7483160495758057
batch i:953
learning rate0.0013333333333333333, loss:2.870384454727173
batch i:954
learning rate0.0013333333333333333, loss:2.843994140625
batch i:955
learning rate0.0013333333333333333, loss:2.7820987701416016
batch i:956
learning rate0.0013333333333333333, loss:2.852659225463867
batch i:957
learning rate0.0013333333333333333, loss:2.904689311981201
batch i:958
learning rate0.0013333333333333333, loss:2.810166358947754
batch i:959
learning rate0.0013333333333333333, loss:2.8405277729034424
batch i:960
learning rate0.0013333333333333333, loss:2.8836193084716797
batch i:961
learning rate0.0013333333333333333, loss:2.853668212890625
batch i:962
learning rate0.0013333333333333333, loss:2.7984657287597656
batch i:963
learning rate0.0013333333333333333, loss:2.7872426509857178
batch i:964
learning rate0.0013333333333333333, loss:2.9258570671081543
batch i:965
learning rate0.0013333333333333333, loss:2.8460774421691895
batch i:966
learning rate0.0013333333333333333, loss:2.901167154312134
batch i:967
learning rate0.0013333333333333333, loss:2.8156673908233643
batch i:968
learning rate0.0013333333333333333, loss:2.906825542449951
batch i:969
learning rate0.0013333333333333333, loss:2.8536460399627686
batch i:970
learning rate0.0013333333333333333, loss:2.889606237411499
batch i:971
learning rate0.0013333333333333333, loss:2.935889959335327
batch i:972
learning rate0.0013333333333333333, loss:2.8820080757141113
batch i:973
learning rate0.0013333333333333333, loss:2.9313273429870605
batch i:974
learning rate0.0013333333333333333, loss:2.820904016494751
batch i:975
learning rate0.0013333333333333333, loss:2.9313578605651855
batch i:976
learning rate0.0013333333333333333, loss:2.862703561782837
batch i:977
learning rate0.0013333333333333333, loss:2.947714328765869
batch i:978
learning rate0.0013333333333333333, loss:2.8138537406921387
batch i:979
learning rate0.0013333333333333333, loss:2.8500452041625977
batch i:980
learning rate0.0013333333333333333, loss:2.7974963188171387
batch i:981
learning rate0.0013333333333333333, loss:2.884685516357422
batch i:982
learning rate0.0013333333333333333, loss:2.8309407234191895
batch i:983
learning rate0.0013333333333333333, loss:2.876556873321533
batch i:984
learning rate0.0013333333333333333, loss:2.869706630706787
batch i:985
learning rate0.0013333333333333333, loss:2.874760389328003
batch i:986
learning rate0.0013333333333333333, loss:2.9302563667297363
batch i:987
learning rate0.0013333333333333333, loss:2.914914131164551
batch i:988
learning rate0.0013333333333333333, loss:2.95149564743042
batch i:989
learning rate0.0013333333333333333, loss:2.8999204635620117
batch i:990
learning rate0.0013333333333333333, loss:2.9195802211761475
batch i:991
learning rate0.0013333333333333333, loss:2.918224811553955
batch i:992
learning rate0.0013333333333333333, loss:2.901660680770874
batch i:993
learning rate0.0013333333333333333, loss:2.8259265422821045
batch i:994
learning rate0.0013333333333333333, loss:2.807203769683838
batch i:995
learning rate0.0013333333333333333, loss:2.870103597640991
batch i:996
learning rate0.0013333333333333333, loss:2.841660499572754
batch i:997
learning rate0.0013333333333333333, loss:2.8277664184570312
batch i:998
learning rate0.0013333333333333333, loss:2.8668594360351562
batch i:999
learning rate0.0013333333333333333, loss:2.889162063598633
batch i:1000
learning rate0.0013333333333333333, loss:2.8668298721313477
current self-play batch: 1000
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 529.6547430753708
batch i:1001
learning rate0.0013333333333333333, loss:2.8860700130462646
batch i:1002
learning rate0.0013333333333333333, loss:2.809708595275879
batch i:1003
learning rate0.0013333333333333333, loss:2.8552486896514893
batch i:1004
learning rate0.0013333333333333333, loss:2.891476631164551
batch i:1005
learning rate0.0013333333333333333, loss:2.825089693069458
batch i:1006
learning rate0.0013333333333333333, loss:2.818512201309204
batch i:1007
learning rate0.0013333333333333333, loss:2.8162169456481934
batch i:1008
learning rate0.0013333333333333333, loss:2.8788084983825684
batch i:1009
learning rate0.0013333333333333333, loss:2.8637354373931885
batch i:1010
learning rate0.0013333333333333333, loss:2.8217525482177734
batch i:1011
learning rate0.0013333333333333333, loss:2.9058785438537598
batch i:1012
learning rate0.0013333333333333333, loss:2.8701515197753906
batch i:1013
learning rate0.0013333333333333333, loss:2.928070545196533
batch i:1014
learning rate0.0013333333333333333, loss:2.9342880249023438
batch i:1015
learning rate0.0013333333333333333, loss:2.912248134613037
batch i:1016
learning rate0.0013333333333333333, loss:2.8081183433532715
batch i:1017
learning rate0.0013333333333333333, loss:2.8583412170410156
batch i:1018
learning rate0.0013333333333333333, loss:2.8904309272766113
batch i:1019
learning rate0.0013333333333333333, loss:2.826632022857666
batch i:1020
learning rate0.0013333333333333333, loss:2.9225096702575684
batch i:1021
learning rate0.0013333333333333333, loss:2.8938779830932617
batch i:1022
learning rate0.0013333333333333333, loss:2.803834915161133
batch i:1023
learning rate0.0013333333333333333, loss:2.8853368759155273
batch i:1024
learning rate0.0013333333333333333, loss:2.864999294281006
batch i:1025
learning rate0.0013333333333333333, loss:2.8387343883514404
batch i:1026
learning rate0.0013333333333333333, loss:2.8018441200256348
batch i:1027
learning rate0.0013333333333333333, loss:2.868572235107422
batch i:1028
learning rate0.0013333333333333333, loss:2.8788809776306152
batch i:1029
learning rate0.0013333333333333333, loss:2.918433666229248
batch i:1030
learning rate0.0013333333333333333, loss:2.8391714096069336
batch i:1031
learning rate0.0013333333333333333, loss:2.8701767921447754
batch i:1032
learning rate0.0013333333333333333, loss:2.909067153930664
batch i:1033
learning rate0.0013333333333333333, loss:2.8696417808532715
batch i:1034
learning rate0.0013333333333333333, loss:2.9406685829162598
batch i:1035
learning rate0.0013333333333333333, loss:2.780839204788208
batch i:1036
learning rate0.0013333333333333333, loss:2.9369020462036133
batch i:1037
learning rate0.0013333333333333333, loss:2.87756609916687
batch i:1038
learning rate0.0013333333333333333, loss:2.8754427433013916
batch i:1039
learning rate0.0013333333333333333, loss:2.8742403984069824
batch i:1040
learning rate0.0013333333333333333, loss:2.8586413860321045
batch i:1041
learning rate0.0013333333333333333, loss:2.8600850105285645
batch i:1042
learning rate0.0013333333333333333, loss:2.869138479232788
batch i:1043
learning rate0.0013333333333333333, loss:2.857974052429199
batch i:1044
learning rate0.0013333333333333333, loss:2.919426918029785
batch i:1045
learning rate0.0013333333333333333, loss:2.8648552894592285
batch i:1046
learning rate0.0013333333333333333, loss:2.8155059814453125
batch i:1047
learning rate0.0013333333333333333, loss:2.7720530033111572
batch i:1048
learning rate0.0013333333333333333, loss:2.9084300994873047
batch i:1049
learning rate0.0013333333333333333, loss:2.906609535217285
batch i:1050
learning rate0.0013333333333333333, loss:2.865553855895996
current self-play batch: 1050
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 1155.9572005748748
batch i:1051
learning rate0.0013333333333333333, loss:2.88740873336792
batch i:1052
learning rate0.0013333333333333333, loss:2.8746261596679688
batch i:1053
learning rate0.0013333333333333333, loss:2.8699235916137695
batch i:1054
learning rate0.0013333333333333333, loss:2.82289981842041
batch i:1055
learning rate0.0013333333333333333, loss:2.8202459812164307
batch i:1056
learning rate0.0013333333333333333, loss:2.9310598373413086
batch i:1057
learning rate0.0013333333333333333, loss:2.8288774490356445
batch i:1058
learning rate0.0013333333333333333, loss:2.7803478240966797
batch i:1059
learning rate0.0013333333333333333, loss:2.833954334259033
batch i:1060
learning rate0.0013333333333333333, loss:2.8504464626312256
batch i:1061
learning rate0.0013333333333333333, loss:2.8379952907562256
batch i:1062
learning rate0.0013333333333333333, loss:2.8012685775756836
batch i:1063
learning rate0.0013333333333333333, loss:2.885514736175537
batch i:1064
learning rate0.0013333333333333333, loss:2.94439959526062
batch i:1065
learning rate0.0013333333333333333, loss:2.851982831954956
batch i:1066
learning rate0.0013333333333333333, loss:2.8039801120758057
batch i:1067
learning rate0.0013333333333333333, loss:2.8973424434661865
batch i:1068
learning rate0.0013333333333333333, loss:2.8311240673065186
batch i:1069
learning rate0.0013333333333333333, loss:2.8742241859436035
batch i:1070
learning rate0.0013333333333333333, loss:2.854203224182129
batch i:1071
learning rate0.0013333333333333333, loss:2.8961076736450195
batch i:1072
learning rate0.0013333333333333333, loss:2.8698782920837402
batch i:1073
learning rate0.0013333333333333333, loss:2.8169569969177246
batch i:1074
learning rate0.0013333333333333333, loss:2.7875118255615234
batch i:1075
learning rate0.0013333333333333333, loss:2.8364834785461426
batch i:1076
learning rate0.0013333333333333333, loss:2.8922040462493896
batch i:1077
learning rate0.0013333333333333333, loss:2.8454370498657227
batch i:1078
learning rate0.0013333333333333333, loss:2.801079273223877
batch i:1079
learning rate0.0013333333333333333, loss:2.864593982696533
batch i:1080
learning rate0.0013333333333333333, loss:2.8182268142700195
batch i:1081
learning rate0.0013333333333333333, loss:2.8167920112609863
batch i:1082
learning rate0.0013333333333333333, loss:2.8518261909484863
batch i:1083
learning rate0.0013333333333333333, loss:2.8786699771881104
batch i:1084
learning rate0.0013333333333333333, loss:2.9457075595855713
batch i:1085
learning rate0.0013333333333333333, loss:2.865633964538574
batch i:1086
learning rate0.0013333333333333333, loss:2.8474979400634766
batch i:1087
learning rate0.0013333333333333333, loss:2.887014627456665
batch i:1088
learning rate0.0013333333333333333, loss:2.8569440841674805
batch i:1089
learning rate0.0013333333333333333, loss:2.824397325515747
batch i:1090
learning rate0.0013333333333333333, loss:2.823514938354492
batch i:1091
learning rate0.0013333333333333333, loss:2.853896141052246
batch i:1092
learning rate0.0013333333333333333, loss:2.8426506519317627
batch i:1093
learning rate0.0013333333333333333, loss:2.955730676651001
batch i:1094
learning rate0.0013333333333333333, loss:2.8015716075897217
batch i:1095
learning rate0.0013333333333333333, loss:2.8569436073303223
batch i:1096
learning rate0.0013333333333333333, loss:2.8726186752319336
batch i:1097
learning rate0.0013333333333333333, loss:2.842313289642334
batch i:1098
learning rate0.0013333333333333333, loss:2.7965006828308105
batch i:1099
learning rate0.0013333333333333333, loss:2.8266191482543945
batch i:1100
learning rate0.0013333333333333333, loss:2.8954405784606934
current self-play batch: 1100
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 593.1718594074249
batch i:1101
learning rate0.0013333333333333333, loss:2.902463912963867
batch i:1102
learning rate0.0013333333333333333, loss:2.8061652183532715
batch i:1103
learning rate0.0013333333333333333, loss:2.8869478702545166
batch i:1104
learning rate0.0013333333333333333, loss:2.8690714836120605
batch i:1105
learning rate0.0013333333333333333, loss:2.911259889602661
batch i:1106
learning rate0.0013333333333333333, loss:2.843404769897461
batch i:1107
learning rate0.0013333333333333333, loss:2.8097453117370605
batch i:1108
learning rate0.0013333333333333333, loss:2.83658504486084
batch i:1109
learning rate0.0013333333333333333, loss:2.8686728477478027
batch i:1110
learning rate0.0013333333333333333, loss:2.8632566928863525
batch i:1111
learning rate0.0013333333333333333, loss:2.98427414894104
batch i:1112
learning rate0.0013333333333333333, loss:2.7332022190093994
batch i:1113
learning rate0.0013333333333333333, loss:2.8649587631225586
batch i:1114
learning rate0.0013333333333333333, loss:2.8213980197906494
batch i:1115
learning rate0.0013333333333333333, loss:2.955580234527588
batch i:1116
learning rate0.0013333333333333333, loss:2.8753914833068848
batch i:1117
learning rate0.0013333333333333333, loss:2.8909008502960205
batch i:1118
learning rate0.0013333333333333333, loss:2.853165626525879
batch i:1119
learning rate0.0013333333333333333, loss:2.9329943656921387
batch i:1120
learning rate0.0013333333333333333, loss:2.820732831954956
batch i:1121
learning rate0.0013333333333333333, loss:2.8461861610412598
batch i:1122
learning rate0.0013333333333333333, loss:2.920041561126709
batch i:1123
learning rate0.0013333333333333333, loss:2.822948932647705
batch i:1124
learning rate0.0013333333333333333, loss:2.9003841876983643
batch i:1125
learning rate0.0013333333333333333, loss:2.8631114959716797
batch i:1126
learning rate0.0013333333333333333, loss:2.819397449493408
batch i:1127
learning rate0.0013333333333333333, loss:2.854618549346924
batch i:1128
learning rate0.0013333333333333333, loss:2.8944692611694336
batch i:1129
learning rate0.0013333333333333333, loss:2.900113582611084
batch i:1130
learning rate0.0013333333333333333, loss:2.879232406616211
batch i:1131
learning rate0.0013333333333333333, loss:2.8155503273010254
batch i:1132
learning rate0.0013333333333333333, loss:2.9404067993164062
batch i:1133
learning rate0.0013333333333333333, loss:2.7969861030578613
batch i:1134
learning rate0.0013333333333333333, loss:2.7818078994750977
batch i:1135
learning rate0.0013333333333333333, loss:2.7793545722961426
batch i:1136
learning rate0.0013333333333333333, loss:2.881254196166992
batch i:1137
learning rate0.0013333333333333333, loss:2.7986719608306885
batch i:1138
learning rate0.0013333333333333333, loss:2.9007365703582764
batch i:1139
learning rate0.0013333333333333333, loss:2.8793394565582275
batch i:1140
learning rate0.0013333333333333333, loss:2.860954999923706
batch i:1141
learning rate0.0013333333333333333, loss:2.847642421722412
batch i:1142
learning rate0.0013333333333333333, loss:2.9266433715820312
batch i:1143
learning rate0.0013333333333333333, loss:2.8441085815429688
batch i:1144
learning rate0.0013333333333333333, loss:2.864978790283203
batch i:1145
learning rate0.0013333333333333333, loss:2.839405059814453
batch i:1146
learning rate0.0013333333333333333, loss:2.849447250366211
batch i:1147
learning rate0.0013333333333333333, loss:2.8650479316711426
batch i:1148
learning rate0.0013333333333333333, loss:2.8909809589385986
batch i:1149
learning rate0.0013333333333333333, loss:2.8751163482666016
batch i:1150
learning rate0.0013333333333333333, loss:2.90779972076416
current self-play batch: 1150
num_playouts:3000, win: 10, lose: 0, tie:0
average time: 593.9116849660874
New best policy from pure MCTS
batch i:1151
learning rate0.0013333333333333333, loss:2.8439722061157227
batch i:1152
learning rate0.0013333333333333333, loss:2.871711254119873
batch i:1153
learning rate0.0013333333333333333, loss:2.821812152862549
batch i:1154
learning rate0.0013333333333333333, loss:2.8789663314819336
batch i:1155
learning rate0.0013333333333333333, loss:2.8671226501464844
batch i:1156
learning rate0.0013333333333333333, loss:2.8414433002471924
batch i:1157
learning rate0.0013333333333333333, loss:2.7994091510772705
batch i:1158
learning rate0.0013333333333333333, loss:2.9754834175109863
batch i:1159
learning rate0.0013333333333333333, loss:2.820068836212158
batch i:1160
learning rate0.0013333333333333333, loss:2.86161470413208
batch i:1161
learning rate0.0013333333333333333, loss:2.8871166706085205
batch i:1162
learning rate0.0013333333333333333, loss:2.793053388595581
batch i:1163
learning rate0.0013333333333333333, loss:2.821995496749878
batch i:1164
learning rate0.0013333333333333333, loss:2.804047107696533
batch i:1165
learning rate0.0013333333333333333, loss:2.9144392013549805
batch i:1166
learning rate0.0013333333333333333, loss:2.7697958946228027
batch i:1167
learning rate0.0013333333333333333, loss:2.8444151878356934
batch i:1168
learning rate0.0013333333333333333, loss:2.8532450199127197
batch i:1169
learning rate0.0013333333333333333, loss:2.864866256713867
batch i:1170
learning rate0.0013333333333333333, loss:2.853919506072998
batch i:1171
learning rate0.0013333333333333333, loss:2.803377628326416
batch i:1172
learning rate0.0013333333333333333, loss:2.947704315185547
batch i:1173
learning rate0.0013333333333333333, loss:2.83219575881958
batch i:1174
learning rate0.0013333333333333333, loss:2.9098973274230957
batch i:1175
learning rate0.0013333333333333333, loss:2.856346845626831
batch i:1176
learning rate0.0013333333333333333, loss:2.8389182090759277
batch i:1177
learning rate0.0013333333333333333, loss:2.830636501312256
batch i:1178
learning rate0.0013333333333333333, loss:2.907245397567749
batch i:1179
learning rate0.0013333333333333333, loss:2.814518928527832
batch i:1180
learning rate0.0013333333333333333, loss:2.906233787536621
batch i:1181
learning rate0.0013333333333333333, loss:2.836789131164551
batch i:1182
learning rate0.0013333333333333333, loss:2.8039586544036865
batch i:1183
learning rate0.0013333333333333333, loss:2.818107843399048
batch i:1184
learning rate0.0013333333333333333, loss:2.8401002883911133
batch i:1185
learning rate0.0013333333333333333, loss:2.8763890266418457
batch i:1186
learning rate0.0013333333333333333, loss:2.8311190605163574
batch i:1187
learning rate0.0013333333333333333, loss:2.9261679649353027
batch i:1188
learning rate0.0013333333333333333, loss:2.8451263904571533
batch i:1189
learning rate0.0013333333333333333, loss:2.8078956604003906
batch i:1190
learning rate0.0013333333333333333, loss:2.8976857662200928
batch i:1191
learning rate0.0013333333333333333, loss:2.862626791000366
batch i:1192
learning rate0.0013333333333333333, loss:2.829831600189209
batch i:1193
learning rate0.0013333333333333333, loss:2.8791327476501465
batch i:1194
learning rate0.0013333333333333333, loss:2.8489179611206055
batch i:1195
learning rate0.0013333333333333333, loss:2.850762128829956
batch i:1196
learning rate0.0013333333333333333, loss:2.8339614868164062
batch i:1197
learning rate0.0013333333333333333, loss:2.886712074279785
batch i:1198
learning rate0.0013333333333333333, loss:2.8808305263519287
batch i:1199
learning rate0.0013333333333333333, loss:2.838737726211548
batch i:1200
learning rate0.0013333333333333333, loss:3.0110011100769043
current self-play batch: 1200
Traceback (most recent call last):
  File "/mnt/nas/home/huangyixin/AI/train.py", line 378, in <module>
    training_pipeline.train(game_batch_num)
  File "/mnt/nas/home/huangyixin/AI/train.py", line 303, in train
    win_ratio = self.game.policy_compete(filename, filename_best,
  File "/mnt/nas/home/huangyixin/AI/game.py", line 448, in policy_compete
    is_shown=0)
  File "/mnt/nas/home/huangyixin/AI/game.py", line 343, in start_play
    self.graphic(self.board, player1.player, player2.player)
  File "/mnt/nas/home/huangyixin/AI/game.py", line 73, in move_to_location
    h = move // self.width
TypeError: unsupported operand type(s) for //: 'tuple' and 'int'
