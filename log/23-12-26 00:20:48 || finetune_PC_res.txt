Start time: 2023-12-26 00:20:48.509849
batch i:1
batch i:2
batch i:3
batch i:4
batch i:5
learning rate0.0013333333333333333, loss:3.4807047843933105
batch i:6
learning rate0.0008888888888888888, loss:3.5705528259277344
batch i:7
learning rate0.0005925925925925926, loss:3.5085690021514893
batch i:8
learning rate0.0003950617283950617, loss:2.8608603477478027
batch i:9
learning rate0.0002633744855967078, loss:2.734971046447754
batch i:10
learning rate0.0002633744855967078, loss:2.7702155113220215
batch i:11
learning rate0.0002633744855967078, loss:2.7938475608825684
batch i:12
learning rate0.0002633744855967078, loss:2.785022735595703
batch i:13
learning rate0.0002633744855967078, loss:2.841383934020996
batch i:14
learning rate0.0002633744855967078, loss:2.908613443374634
batch i:15
learning rate0.0002633744855967078, loss:2.8764171600341797
batch i:16
learning rate0.0002633744855967078, loss:2.8771657943725586
batch i:17
learning rate0.0002633744855967078, loss:2.8470988273620605
batch i:18
learning rate0.0002633744855967078, loss:2.85835599899292
batch i:19
learning rate0.0002633744855967078, loss:2.8593876361846924
batch i:20
learning rate0.0002633744855967078, loss:2.9165420532226562
batch i:21
learning rate0.0002633744855967078, loss:2.92280650138855
batch i:22
learning rate0.0002633744855967078, loss:2.975310802459717
batch i:23
learning rate0.0002633744855967078, loss:2.9674837589263916
batch i:24
learning rate0.0002633744855967078, loss:2.9152140617370605
batch i:25
learning rate0.0002633744855967078, loss:2.9269142150878906
batch i:26
learning rate0.0002633744855967078, loss:2.9373977184295654
batch i:27
learning rate0.0002633744855967078, loss:2.963991641998291
batch i:28
learning rate0.0002633744855967078, loss:2.9551472663879395
batch i:29
learning rate0.0002633744855967078, loss:2.933128595352173
batch i:30
learning rate0.0002633744855967078, loss:2.974001169204712
batch i:31
learning rate0.0002633744855967078, loss:2.973118543624878
batch i:32
learning rate0.0002633744855967078, loss:2.91757869720459
batch i:33
learning rate0.0002633744855967078, loss:2.997798204421997
batch i:34
learning rate0.0002633744855967078, loss:2.952744722366333
batch i:35
learning rate0.0002633744855967078, loss:2.890857458114624
batch i:36
learning rate0.0002633744855967078, loss:2.97537899017334
batch i:37
learning rate0.0002633744855967078, loss:2.989708423614502
batch i:38
learning rate0.0002633744855967078, loss:2.9778671264648438
batch i:39
learning rate0.0002633744855967078, loss:2.9830639362335205
batch i:40
learning rate0.0002633744855967078, loss:2.9290218353271484
batch i:41
learning rate0.0002633744855967078, loss:3.0020761489868164
batch i:42
learning rate0.0002633744855967078, loss:2.937443733215332
batch i:43
learning rate0.0002633744855967078, loss:2.988821506500244
batch i:44
learning rate0.0002633744855967078, loss:2.9919652938842773
batch i:45
learning rate0.0002633744855967078, loss:3.0016062259674072
batch i:46
learning rate0.0002633744855967078, loss:2.9345579147338867
batch i:47
learning rate0.0002633744855967078, loss:2.9980947971343994
batch i:48
learning rate0.0002633744855967078, loss:2.960541248321533
batch i:49
learning rate0.0002633744855967078, loss:2.9729576110839844
batch i:50
learning rate0.0002633744855967078, loss:2.9749464988708496
current self-play batch: 50
num_playouts:1000, win: 10, lose: 0, tie:0
average time: 122.31749303340912
New best policy from pure MCTS
batch i:51
learning rate0.0002633744855967078, loss:3.018906593322754
batch i:52
learning rate0.0002633744855967078, loss:2.943070888519287
batch i:53
learning rate0.0002633744855967078, loss:2.997462749481201
batch i:54
learning rate0.0002633744855967078, loss:2.975492477416992
batch i:55
learning rate0.0002633744855967078, loss:2.973033905029297
batch i:56
learning rate0.0002633744855967078, loss:2.9813880920410156
batch i:57
learning rate0.0002633744855967078, loss:3.0647544860839844
batch i:58
learning rate0.0002633744855967078, loss:2.99623441696167
batch i:59
learning rate0.0002633744855967078, loss:2.960646152496338
batch i:60
learning rate0.0002633744855967078, loss:3.016709327697754
batch i:61
learning rate0.0002633744855967078, loss:2.956387758255005
batch i:62
learning rate0.0002633744855967078, loss:2.9393625259399414
batch i:63
learning rate0.0002633744855967078, loss:2.9924607276916504
batch i:64
learning rate0.0002633744855967078, loss:2.905630111694336
batch i:65
learning rate0.0002633744855967078, loss:2.9540724754333496
batch i:66
learning rate0.0002633744855967078, loss:2.9810242652893066
batch i:67
learning rate0.0002633744855967078, loss:2.984510660171509
batch i:68
learning rate0.0002633744855967078, loss:2.9100399017333984
batch i:69
learning rate0.0002633744855967078, loss:2.922071933746338
batch i:70
learning rate0.0002633744855967078, loss:3.0001327991485596
batch i:71
learning rate0.0002633744855967078, loss:2.9271621704101562
batch i:72
learning rate0.0002633744855967078, loss:2.9390106201171875
batch i:73
learning rate0.0002633744855967078, loss:3.045252561569214
batch i:74
learning rate0.0002633744855967078, loss:2.991802453994751
batch i:75
learning rate0.0002633744855967078, loss:2.962071657180786
batch i:76
learning rate0.0002633744855967078, loss:3.0434467792510986
batch i:77
learning rate0.0002633744855967078, loss:3.0578055381774902
batch i:78
learning rate0.0002633744855967078, loss:3.017791271209717
batch i:79
learning rate0.0002633744855967078, loss:3.0122861862182617
batch i:80
learning rate0.0002633744855967078, loss:3.011441707611084
batch i:81
learning rate0.0002633744855967078, loss:2.947309970855713
batch i:82
learning rate0.0002633744855967078, loss:3.0780513286590576
batch i:83
learning rate0.0002633744855967078, loss:3.0136303901672363
batch i:84
learning rate0.0002633744855967078, loss:2.8870625495910645
batch i:85
learning rate0.0002633744855967078, loss:2.9231643676757812
batch i:86
learning rate0.0002633744855967078, loss:2.9831655025482178
batch i:87
learning rate0.0002633744855967078, loss:2.9921770095825195
batch i:88
learning rate0.0002633744855967078, loss:3.041564702987671
batch i:89
learning rate0.0002633744855967078, loss:3.088789939880371
batch i:90
learning rate0.0002633744855967078, loss:3.0568900108337402
batch i:91
learning rate0.0002633744855967078, loss:2.971357822418213
batch i:92
learning rate0.0002633744855967078, loss:2.938248634338379
batch i:93
learning rate0.0002633744855967078, loss:3.050532341003418
batch i:94
learning rate0.0002633744855967078, loss:3.053668260574341
batch i:95
learning rate0.0002633744855967078, loss:3.0381760597229004
batch i:96
learning rate0.0002633744855967078, loss:3.040775775909424
batch i:97
learning rate0.0002633744855967078, loss:2.9059975147247314
batch i:98
learning rate0.0002633744855967078, loss:3.005549907684326
batch i:99
learning rate0.0002633744855967078, loss:2.9775137901306152
batch i:100
learning rate0.0002633744855967078, loss:2.9689502716064453
current self-play batch: 100
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 300.4985789775848
New best policy from pure MCTS
batch i:101
learning rate0.0002633744855967078, loss:3.0171611309051514
batch i:102
learning rate0.0002633744855967078, loss:2.961965322494507
batch i:103
learning rate0.0002633744855967078, loss:2.8869361877441406
batch i:104
learning rate0.0002633744855967078, loss:3.053809881210327
batch i:105
learning rate0.0002633744855967078, loss:2.9837143421173096
batch i:106
learning rate0.0002633744855967078, loss:2.964444875717163
batch i:107
learning rate0.0002633744855967078, loss:2.998335599899292
batch i:108
learning rate0.0002633744855967078, loss:2.925384759902954
batch i:109
learning rate0.0002633744855967078, loss:3.0115013122558594
batch i:110
learning rate0.0002633744855967078, loss:3.032200813293457
batch i:111
learning rate0.0002633744855967078, loss:2.9267711639404297
batch i:112
learning rate0.0002633744855967078, loss:3.039278268814087
batch i:113
learning rate0.0002633744855967078, loss:3.022989273071289
batch i:114
learning rate0.0002633744855967078, loss:3.03440260887146
batch i:115
learning rate0.0002633744855967078, loss:3.0028228759765625
batch i:116
learning rate0.0002633744855967078, loss:2.9838085174560547
batch i:117
learning rate0.0002633744855967078, loss:2.970705032348633
batch i:118
learning rate0.0002633744855967078, loss:2.923781394958496
batch i:119
learning rate0.0002633744855967078, loss:2.9174938201904297
batch i:120
learning rate0.0002633744855967078, loss:2.9698593616485596
batch i:121
learning rate0.0002633744855967078, loss:2.895620584487915
batch i:122
learning rate0.0002633744855967078, loss:2.9946508407592773
batch i:123
learning rate0.0002633744855967078, loss:2.9609453678131104
batch i:124
learning rate0.0002633744855967078, loss:2.912868022918701
batch i:125
learning rate0.0002633744855967078, loss:2.970569372177124
batch i:126
learning rate0.0002633744855967078, loss:2.937199592590332
batch i:127
learning rate0.0002633744855967078, loss:3.010526657104492
batch i:128
learning rate0.0002633744855967078, loss:2.9105184078216553
batch i:129
learning rate0.0002633744855967078, loss:2.9934277534484863
batch i:130
learning rate0.0002633744855967078, loss:2.948214054107666
batch i:131
learning rate0.0002633744855967078, loss:2.919884204864502
batch i:132
learning rate0.0002633744855967078, loss:3.0189459323883057
batch i:133
learning rate0.0002633744855967078, loss:2.944064140319824
batch i:134
learning rate0.0002633744855967078, loss:2.963176965713501
batch i:135
learning rate0.0002633744855967078, loss:2.937075138092041
batch i:136
learning rate0.0002633744855967078, loss:2.9506492614746094
batch i:137
learning rate0.0002633744855967078, loss:2.9350852966308594
batch i:138
learning rate0.0002633744855967078, loss:2.9791460037231445
batch i:139
learning rate0.0002633744855967078, loss:2.972623348236084
batch i:140
learning rate0.0002633744855967078, loss:2.83005952835083
batch i:141
learning rate0.0002633744855967078, loss:2.9894163608551025
batch i:142
learning rate0.0002633744855967078, loss:2.9623074531555176
batch i:143
learning rate0.0002633744855967078, loss:2.94338321685791
batch i:144
learning rate0.0002633744855967078, loss:2.9221854209899902
batch i:145
learning rate0.0002633744855967078, loss:2.936532974243164
batch i:146
learning rate0.0002633744855967078, loss:2.9629898071289062
batch i:147
learning rate0.0002633744855967078, loss:2.9494729042053223
batch i:148
learning rate0.0002633744855967078, loss:2.922790050506592
batch i:149
learning rate0.0002633744855967078, loss:2.977278709411621
batch i:150
learning rate0.0002633744855967078, loss:2.944721221923828
current self-play batch: 150
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 304.4611616373062
batch i:151
learning rate0.0002633744855967078, loss:2.987326145172119
batch i:152
learning rate0.0002633744855967078, loss:2.9397568702697754
batch i:153
learning rate0.0002633744855967078, loss:2.9399096965789795
batch i:154
learning rate0.0002633744855967078, loss:2.9917025566101074
batch i:155
learning rate0.0002633744855967078, loss:2.8920609951019287
batch i:156
learning rate0.0002633744855967078, loss:2.8894176483154297
batch i:157
learning rate0.0002633744855967078, loss:2.8916215896606445
batch i:158
learning rate0.0002633744855967078, loss:2.923898935317993
batch i:159
learning rate0.0002633744855967078, loss:2.902459144592285
batch i:160
learning rate0.0002633744855967078, loss:2.8753442764282227
batch i:161
learning rate0.0002633744855967078, loss:2.8991427421569824
batch i:162
learning rate0.0002633744855967078, loss:2.8526508808135986
batch i:163
learning rate0.0002633744855967078, loss:2.899947166442871
batch i:164
learning rate0.0002633744855967078, loss:2.8597984313964844
batch i:165
learning rate0.0002633744855967078, loss:2.9562532901763916
batch i:166
learning rate0.0002633744855967078, loss:2.8628151416778564
batch i:167
learning rate0.0002633744855967078, loss:2.9040942192077637
batch i:168
learning rate0.0002633744855967078, loss:2.853534460067749
batch i:169
learning rate0.0002633744855967078, loss:2.8735313415527344
batch i:170
learning rate0.0002633744855967078, loss:2.9173219203948975
batch i:171
learning rate0.0002633744855967078, loss:2.906240463256836
batch i:172
learning rate0.0002633744855967078, loss:2.9017128944396973
batch i:173
learning rate0.0002633744855967078, loss:2.856523275375366
batch i:174
learning rate0.0002633744855967078, loss:2.9431958198547363
batch i:175
learning rate0.0002633744855967078, loss:2.8061845302581787
batch i:176
learning rate0.0002633744855967078, loss:2.8973770141601562
batch i:177
learning rate0.0002633744855967078, loss:2.8753163814544678
batch i:178
learning rate0.0002633744855967078, loss:2.799254894256592
batch i:179
learning rate0.0002633744855967078, loss:2.757291316986084
batch i:180
learning rate0.0002633744855967078, loss:2.7972559928894043
batch i:181
learning rate0.0002633744855967078, loss:2.849102020263672
batch i:182
learning rate0.0002633744855967078, loss:2.761852741241455
batch i:183
learning rate0.0002633744855967078, loss:2.825143337249756
batch i:184
learning rate0.0002633744855967078, loss:2.7480225563049316
batch i:185
learning rate0.0002633744855967078, loss:2.8490915298461914
batch i:186
learning rate0.0002633744855967078, loss:2.8288769721984863
batch i:187
learning rate0.0002633744855967078, loss:2.84971284866333
batch i:188
learning rate0.0002633744855967078, loss:2.8844237327575684
batch i:189
learning rate0.0002633744855967078, loss:2.795001983642578
batch i:190
learning rate0.0002633744855967078, loss:2.8532657623291016
batch i:191
learning rate0.0002633744855967078, loss:2.804008960723877
batch i:192
learning rate0.0002633744855967078, loss:2.7354679107666016
batch i:193
learning rate0.0002633744855967078, loss:2.7816858291625977
batch i:194
learning rate0.0002633744855967078, loss:2.8266520500183105
batch i:195
learning rate0.0002633744855967078, loss:2.768425226211548
batch i:196
learning rate0.0002633744855967078, loss:2.7907562255859375
batch i:197
learning rate0.0002633744855967078, loss:2.8738839626312256
batch i:198
learning rate0.0002633744855967078, loss:2.7448887825012207
batch i:199
learning rate0.0002633744855967078, loss:2.8410229682922363
batch i:200
learning rate0.0002633744855967078, loss:2.846865177154541
current self-play batch: 200
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 520.3633488178253
batch i:201
learning rate0.0002633744855967078, loss:2.812948703765869
batch i:202
learning rate0.0002633744855967078, loss:2.8165369033813477
batch i:203
learning rate0.0002633744855967078, loss:2.8061447143554688
batch i:204
learning rate0.0002633744855967078, loss:2.7916007041931152
batch i:205
learning rate0.0002633744855967078, loss:2.7743778228759766
batch i:206
learning rate0.0002633744855967078, loss:2.809330940246582
batch i:207
learning rate0.0002633744855967078, loss:2.787619113922119
batch i:208
learning rate0.0002633744855967078, loss:2.7798147201538086
batch i:209
learning rate0.0002633744855967078, loss:2.808899402618408
batch i:210
learning rate0.0002633744855967078, loss:2.7660534381866455
batch i:211
learning rate0.0002633744855967078, loss:2.8373780250549316
batch i:212
learning rate0.0002633744855967078, loss:2.8745970726013184
batch i:213
learning rate0.0002633744855967078, loss:2.752516269683838
batch i:214
learning rate0.0002633744855967078, loss:2.755340337753296
batch i:215
learning rate0.0002633744855967078, loss:2.8549318313598633
batch i:216
learning rate0.0002633744855967078, loss:2.7698912620544434
batch i:217
learning rate0.0002633744855967078, loss:2.822007894515991
batch i:218
learning rate0.0002633744855967078, loss:2.864849090576172
batch i:219
learning rate0.0002633744855967078, loss:2.8374781608581543
batch i:220
learning rate0.0002633744855967078, loss:2.7706732749938965
batch i:221
learning rate0.0002633744855967078, loss:2.7499916553497314
batch i:222
learning rate0.0002633744855967078, loss:2.8325915336608887
batch i:223
learning rate0.0002633744855967078, loss:2.676107406616211
batch i:224
learning rate0.0001755829903978052, loss:2.801100730895996
batch i:225
learning rate0.0002633744855967078, loss:2.7807726860046387
batch i:226
learning rate0.0002633744855967078, loss:2.7647786140441895
batch i:227
learning rate0.0002633744855967078, loss:2.7215523719787598
batch i:228
learning rate0.0002633744855967078, loss:2.823206901550293
batch i:229
learning rate0.0002633744855967078, loss:2.802875280380249
batch i:230
learning rate0.0002633744855967078, loss:2.847733497619629
batch i:231
learning rate0.0002633744855967078, loss:2.763385772705078
batch i:232
learning rate0.0002633744855967078, loss:2.765428066253662
batch i:233
learning rate0.0002633744855967078, loss:2.726848840713501
batch i:234
learning rate0.0002633744855967078, loss:2.746837854385376
batch i:235
learning rate0.0002633744855967078, loss:2.734218120574951
batch i:236
learning rate0.0002633744855967078, loss:2.7191109657287598
batch i:237
learning rate0.0002633744855967078, loss:2.6757521629333496
batch i:238
learning rate0.0002633744855967078, loss:2.731228828430176
batch i:239
learning rate0.0002633744855967078, loss:2.756570816040039
batch i:240
learning rate0.0002633744855967078, loss:2.7340593338012695
batch i:241
learning rate0.0002633744855967078, loss:2.834749221801758
batch i:242
learning rate0.0002633744855967078, loss:2.7554755210876465
batch i:243
learning rate0.0002633744855967078, loss:2.7724111080169678
batch i:244
learning rate0.0002633744855967078, loss:2.8035895824432373
batch i:245
learning rate0.0002633744855967078, loss:2.778251886367798
batch i:246
learning rate0.0001755829903978052, loss:2.771031379699707
batch i:247
learning rate0.0002633744855967078, loss:2.8137078285217285
batch i:248
learning rate0.0001755829903978052, loss:2.7699551582336426
batch i:249
learning rate0.0001755829903978052, loss:2.79868745803833
batch i:250
learning rate0.0001755829903978052, loss:2.7033143043518066
current self-play batch: 250
Traceback (most recent call last):
  File "/mnt/nas/home/huangyixin/AI/train.py", line 378, in <module>
    training_pipeline.train(game_batch_num)
  File "/mnt/nas/home/huangyixin/AI/train.py", line 288, in train
    win_ratio, _, _ = self.game.policy_evaluate(filename,
  File "/mnt/nas/home/huangyixin/AI/game.py", line 402, in policy_evaluate
    winner, pos = self.start_play(current_mcts_player,
  File "/mnt/nas/home/huangyixin/AI/game.py", line 339, in start_play
    move, _ = player_in_turn.get_action(self.board)
  File "/mnt/nas/home/huangyixin/AI/mcts_alphaZero.py", line 203, in get_action
    moves, move_probs = self.mcts.get_move_and_probs(board, temp)
  File "/mnt/nas/home/huangyixin/AI/mcts_alphaZero.py", line 158, in get_move_and_probs
    self._playout(state_copy)
  File "/mnt/nas/home/huangyixin/AI/mcts_alphaZero.py", line 126, in _playout
    action_probs, leaf_value = self._policy(state)
  File "/mnt/nas/home/huangyixin/AI/model.py", line 306, in policy_value_fn
    act_probs = zip(legal_positions, act_probs[legal_positions])
IndexError: arrays used as indices must be of integer (or boolean) type
