Start time: 2023-12-29 09:25:25.168227
batch i:1
batch i:2
batch i:3
batch i:4
batch i:5
batch i:6
batch i:7
batch i:8
batch i:9
batch i:10
learning rate0.0013333333333333333, loss:3.6141953468322754
batch i:11
learning rate0.0013333333333333333, loss:3.326240062713623
batch i:12
learning rate0.0013333333333333333, loss:3.338531970977783
batch i:13
learning rate0.0013333333333333333, loss:3.3109753131866455
batch i:14
learning rate0.0013333333333333333, loss:3.3049817085266113
batch i:15
learning rate0.0013333333333333333, loss:3.2529938220977783
batch i:16
learning rate0.0013333333333333333, loss:3.247201919555664
batch i:17
learning rate0.0013333333333333333, loss:3.2189340591430664
batch i:18
learning rate0.0013333333333333333, loss:3.2215232849121094
batch i:19
learning rate0.0013333333333333333, loss:3.274553060531616
batch i:20
learning rate0.0013333333333333333, loss:3.2953691482543945
batch i:21
learning rate0.0013333333333333333, loss:3.1633782386779785
batch i:22
learning rate0.0013333333333333333, loss:3.225994348526001
batch i:23
learning rate0.0013333333333333333, loss:3.222456693649292
batch i:24
learning rate0.0013333333333333333, loss:3.1771750450134277
batch i:25
learning rate0.0013333333333333333, loss:3.1886179447174072
batch i:26
learning rate0.0013333333333333333, loss:3.22762131690979
batch i:27
learning rate0.0013333333333333333, loss:3.2711801528930664
batch i:28
learning rate0.0013333333333333333, loss:3.213209867477417
batch i:29
learning rate0.0013333333333333333, loss:3.1755142211914062
batch i:30
learning rate0.0013333333333333333, loss:3.233534812927246
batch i:31
learning rate0.0013333333333333333, loss:3.2111470699310303
batch i:32
learning rate0.0013333333333333333, loss:3.238238573074341
batch i:33
learning rate0.0013333333333333333, loss:3.165170907974243
batch i:34
learning rate0.0013333333333333333, loss:3.165530204772949
batch i:35
learning rate0.0013333333333333333, loss:3.2242989540100098
batch i:36
learning rate0.0013333333333333333, loss:3.2529120445251465
batch i:37
learning rate0.0013333333333333333, loss:3.166482925415039
batch i:38
learning rate0.0013333333333333333, loss:3.1595277786254883
batch i:39
learning rate0.0013333333333333333, loss:3.125554084777832
batch i:40
learning rate0.0013333333333333333, loss:3.1844029426574707
batch i:41
learning rate0.0013333333333333333, loss:3.1358389854431152
batch i:42
learning rate0.0013333333333333333, loss:3.200544834136963
batch i:43
learning rate0.0013333333333333333, loss:3.1662960052490234
batch i:44
learning rate0.0013333333333333333, loss:3.1818740367889404
batch i:45
learning rate0.0013333333333333333, loss:3.1183409690856934
batch i:46
learning rate0.0013333333333333333, loss:3.1580584049224854
batch i:47
learning rate0.0013333333333333333, loss:3.2542333602905273
batch i:48
learning rate0.0013333333333333333, loss:3.1328725814819336
batch i:49
learning rate0.0013333333333333333, loss:3.19400691986084
batch i:50
learning rate0.0013333333333333333, loss:3.1421964168548584
current self-play batch: 50
num_playouts:1000, win: 10, lose: 0, tie:0
average time: 134.245201587677
New best policy from pure MCTS
batch i:51
learning rate0.0013333333333333333, loss:3.100645065307617
batch i:52
learning rate0.0013333333333333333, loss:3.1495895385742188
batch i:53
learning rate0.0013333333333333333, loss:3.1371145248413086
batch i:54
learning rate0.0013333333333333333, loss:3.0774424076080322
batch i:55
learning rate0.0013333333333333333, loss:3.1092488765716553
batch i:56
learning rate0.0013333333333333333, loss:3.1668338775634766
batch i:57
learning rate0.0013333333333333333, loss:3.0946645736694336
batch i:58
learning rate0.0013333333333333333, loss:3.1639251708984375
batch i:59
learning rate0.0013333333333333333, loss:3.0987491607666016
batch i:60
learning rate0.0013333333333333333, loss:3.1214685440063477
batch i:61
learning rate0.0013333333333333333, loss:3.0979442596435547
batch i:62
learning rate0.0013333333333333333, loss:3.147369146347046
batch i:63
learning rate0.0013333333333333333, loss:3.0578155517578125
batch i:64
learning rate0.0013333333333333333, loss:3.1187515258789062
batch i:65
learning rate0.0013333333333333333, loss:3.05698299407959
batch i:66
learning rate0.0013333333333333333, loss:3.1080331802368164
batch i:67
learning rate0.0013333333333333333, loss:2.959066867828369
batch i:68
learning rate0.0013333333333333333, loss:2.9981889724731445
batch i:69
learning rate0.0013333333333333333, loss:3.0037927627563477
batch i:70
learning rate0.0013333333333333333, loss:2.994058132171631
batch i:71
learning rate0.0013333333333333333, loss:2.966871738433838
batch i:72
learning rate0.0013333333333333333, loss:2.826355218887329
batch i:73
learning rate0.0013333333333333333, loss:2.821533679962158
batch i:74
learning rate0.0013333333333333333, loss:2.9209671020507812
batch i:75
learning rate0.0013333333333333333, loss:2.85953426361084
batch i:76
learning rate0.0013333333333333333, loss:2.770303249359131
batch i:77
learning rate0.0013333333333333333, loss:2.807324171066284
batch i:78
learning rate0.0013333333333333333, loss:2.857107639312744
batch i:79
learning rate0.0013333333333333333, loss:2.8568899631500244
batch i:80
learning rate0.0013333333333333333, loss:2.7862203121185303
batch i:81
learning rate0.0013333333333333333, loss:2.810493230819702
batch i:82
learning rate0.0013333333333333333, loss:2.7568588256835938
batch i:83
learning rate0.0013333333333333333, loss:2.760035991668701
batch i:84
learning rate0.0013333333333333333, loss:2.6952602863311768
batch i:85
learning rate0.0013333333333333333, loss:2.678891658782959
batch i:86
learning rate0.0013333333333333333, loss:2.7201614379882812
batch i:87
learning rate0.0013333333333333333, loss:2.7091946601867676
batch i:88
learning rate0.0013333333333333333, loss:2.6899890899658203
batch i:89
learning rate0.0013333333333333333, loss:2.6378133296966553
batch i:90
learning rate0.0013333333333333333, loss:2.689209222793579
batch i:91
learning rate0.0013333333333333333, loss:2.6358940601348877
batch i:92
learning rate0.0013333333333333333, loss:2.7333199977874756
batch i:93
learning rate0.0013333333333333333, loss:2.7256693840026855
batch i:94
learning rate0.0013333333333333333, loss:2.7224907875061035
batch i:95
learning rate0.0013333333333333333, loss:2.607370376586914
batch i:96
learning rate0.0013333333333333333, loss:2.7607076168060303
batch i:97
learning rate0.0013333333333333333, loss:2.7138514518737793
batch i:98
learning rate0.0013333333333333333, loss:2.7436039447784424
batch i:99
learning rate0.0013333333333333333, loss:2.6781463623046875
batch i:100
learning rate0.0013333333333333333, loss:2.650221347808838
current self-play batch: 100
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 353.39787476062776
New best policy from pure MCTS
batch i:101
learning rate0.0013333333333333333, loss:2.7289552688598633
batch i:102
learning rate0.0013333333333333333, loss:2.6267642974853516
batch i:103
learning rate0.0013333333333333333, loss:2.661726951599121
batch i:104
learning rate0.0013333333333333333, loss:2.676359176635742
batch i:105
learning rate0.0013333333333333333, loss:2.726997137069702
batch i:106
learning rate0.0013333333333333333, loss:2.645510196685791
batch i:107
learning rate0.0013333333333333333, loss:2.5388827323913574
batch i:108
learning rate0.0013333333333333333, loss:2.641291856765747
batch i:109
learning rate0.0013333333333333333, loss:2.5701305866241455
batch i:110
learning rate0.0013333333333333333, loss:2.674558401107788
batch i:111
learning rate0.0013333333333333333, loss:2.5677247047424316
batch i:112
learning rate0.0013333333333333333, loss:2.6445653438568115
batch i:113
learning rate0.0013333333333333333, loss:2.676743984222412
batch i:114
learning rate0.0013333333333333333, loss:2.564937114715576
batch i:115
learning rate0.0013333333333333333, loss:2.6396679878234863
batch i:116
learning rate0.0013333333333333333, loss:2.5907328128814697
batch i:117
learning rate0.0013333333333333333, loss:2.642828941345215
batch i:118
learning rate0.0013333333333333333, loss:2.676814079284668
batch i:119
learning rate0.0013333333333333333, loss:2.6539435386657715
batch i:120
learning rate0.0013333333333333333, loss:2.6499977111816406
batch i:121
learning rate0.0013333333333333333, loss:2.600188732147217
batch i:122
learning rate0.0013333333333333333, loss:2.58842134475708
batch i:123
learning rate0.0013333333333333333, loss:2.5709850788116455
batch i:124
learning rate0.0013333333333333333, loss:2.5969176292419434
batch i:125
learning rate0.0013333333333333333, loss:2.5999085903167725
batch i:126
learning rate0.0013333333333333333, loss:2.6909842491149902
batch i:127
learning rate0.0013333333333333333, loss:2.528153896331787
batch i:128
learning rate0.0013333333333333333, loss:2.668653726577759
batch i:129
learning rate0.0013333333333333333, loss:2.6192686557769775
batch i:130
learning rate0.0013333333333333333, loss:2.5430216789245605
batch i:131
learning rate0.0013333333333333333, loss:2.596482992172241
batch i:132
learning rate0.0013333333333333333, loss:2.5127129554748535
batch i:133
learning rate0.0013333333333333333, loss:2.5571041107177734
batch i:134
learning rate0.0013333333333333333, loss:2.638381242752075
batch i:135
learning rate0.0013333333333333333, loss:2.6833431720733643
batch i:136
learning rate0.0013333333333333333, loss:2.6765496730804443
batch i:137
learning rate0.0013333333333333333, loss:2.6253790855407715
batch i:138
learning rate0.0013333333333333333, loss:2.692765474319458
batch i:139
learning rate0.0013333333333333333, loss:2.6463499069213867
batch i:140
learning rate0.0013333333333333333, loss:2.6730294227600098
batch i:141
learning rate0.0013333333333333333, loss:2.663311243057251
batch i:142
learning rate0.0013333333333333333, loss:2.5847585201263428
batch i:143
learning rate0.0013333333333333333, loss:2.603027820587158
batch i:144
learning rate0.0013333333333333333, loss:2.650028705596924
batch i:145
learning rate0.0013333333333333333, loss:2.5809640884399414
batch i:146
learning rate0.0013333333333333333, loss:2.5823798179626465
batch i:147
learning rate0.0013333333333333333, loss:2.7345051765441895
batch i:148
learning rate0.0013333333333333333, loss:2.6880154609680176
batch i:149
learning rate0.0013333333333333333, loss:2.574946165084839
batch i:150
learning rate0.0013333333333333333, loss:2.6723928451538086
current self-play batch: 150
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 413.0886577606201
batch i:151
learning rate0.0013333333333333333, loss:2.528590679168701
batch i:152
learning rate0.0013333333333333333, loss:2.4856984615325928
batch i:153
learning rate0.0013333333333333333, loss:2.6218910217285156
batch i:154
learning rate0.0013333333333333333, loss:2.502887725830078
batch i:155
learning rate0.0013333333333333333, loss:2.5984835624694824
batch i:156
learning rate0.0013333333333333333, loss:2.5477261543273926
batch i:157
learning rate0.0013333333333333333, loss:2.576596736907959
batch i:158
learning rate0.0013333333333333333, loss:2.6504878997802734
batch i:159
learning rate0.0013333333333333333, loss:2.5826480388641357
batch i:160
learning rate0.0013333333333333333, loss:2.500662326812744
batch i:161
learning rate0.0013333333333333333, loss:2.610250949859619
batch i:162
learning rate0.0013333333333333333, loss:2.4869656562805176
batch i:163
learning rate0.0013333333333333333, loss:2.5943031311035156
batch i:164
learning rate0.0013333333333333333, loss:2.534290075302124
batch i:165
learning rate0.0013333333333333333, loss:2.6045589447021484
batch i:166
learning rate0.0013333333333333333, loss:2.6338322162628174
batch i:167
learning rate0.0013333333333333333, loss:2.5496606826782227
batch i:168
learning rate0.0013333333333333333, loss:2.5299315452575684
batch i:169
learning rate0.0013333333333333333, loss:2.5527544021606445
batch i:170
learning rate0.0013333333333333333, loss:2.536477565765381
batch i:171
learning rate0.0013333333333333333, loss:2.504246711730957
batch i:172
learning rate0.0013333333333333333, loss:2.501345157623291
batch i:173
learning rate0.0013333333333333333, loss:2.642866373062134
batch i:174
learning rate0.0013333333333333333, loss:2.5520973205566406
batch i:175
learning rate0.0013333333333333333, loss:2.4683446884155273
batch i:176
learning rate0.0013333333333333333, loss:2.519465446472168
batch i:177
learning rate0.0013333333333333333, loss:2.5113070011138916
batch i:178
learning rate0.0013333333333333333, loss:2.52189040184021
batch i:179
learning rate0.0013333333333333333, loss:2.5241997241973877
batch i:180
learning rate0.0013333333333333333, loss:2.520211935043335
batch i:181
learning rate0.0013333333333333333, loss:2.6102423667907715
batch i:182
learning rate0.0013333333333333333, loss:2.5408060550689697
batch i:183
learning rate0.0013333333333333333, loss:2.545489549636841
batch i:184
learning rate0.0013333333333333333, loss:2.5855488777160645
batch i:185
learning rate0.0013333333333333333, loss:2.709338426589966
batch i:186
learning rate0.0013333333333333333, loss:2.6440043449401855
batch i:187
learning rate0.0013333333333333333, loss:2.6227927207946777
batch i:188
learning rate0.0013333333333333333, loss:2.594831943511963
batch i:189
learning rate0.0013333333333333333, loss:2.6875033378601074
batch i:190
learning rate0.0013333333333333333, loss:2.5685484409332275
batch i:191
learning rate0.0013333333333333333, loss:2.569502353668213
batch i:192
learning rate0.0013333333333333333, loss:2.6593689918518066
batch i:193
learning rate0.0013333333333333333, loss:2.6470651626586914
batch i:194
learning rate0.0013333333333333333, loss:2.614630699157715
batch i:195
learning rate0.0013333333333333333, loss:2.5749998092651367
batch i:196
learning rate0.0013333333333333333, loss:2.6331751346588135
batch i:197
learning rate0.0013333333333333333, loss:2.57674503326416
batch i:198
learning rate0.0013333333333333333, loss:2.6789450645446777
batch i:199
learning rate0.0013333333333333333, loss:2.5601553916931152
batch i:200
learning rate0.0013333333333333333, loss:2.595207691192627
current self-play batch: 200
num_playouts:2000, win: 5, lose: 0, tie:5
average time: 1019.0856241703034
batch i:201
learning rate0.0013333333333333333, loss:2.6010940074920654
batch i:202
learning rate0.0013333333333333333, loss:2.4870076179504395
batch i:203
learning rate0.0013333333333333333, loss:2.4752774238586426
batch i:204
learning rate0.0013333333333333333, loss:2.6721978187561035
batch i:205
learning rate0.0013333333333333333, loss:2.631319046020508
batch i:206
learning rate0.0013333333333333333, loss:2.6356544494628906
batch i:207
learning rate0.0013333333333333333, loss:2.5754055976867676
batch i:208
learning rate0.0013333333333333333, loss:2.632913589477539
batch i:209
learning rate0.0013333333333333333, loss:2.6696369647979736
batch i:210
learning rate0.0013333333333333333, loss:2.5686795711517334
batch i:211
learning rate0.0013333333333333333, loss:2.537541389465332
batch i:212
learning rate0.0013333333333333333, loss:2.555917739868164
batch i:213
learning rate0.0013333333333333333, loss:2.5920934677124023
batch i:214
learning rate0.0013333333333333333, loss:2.567422866821289
batch i:215
learning rate0.0013333333333333333, loss:2.556863784790039
batch i:216
learning rate0.0013333333333333333, loss:2.546773910522461
batch i:217
learning rate0.0013333333333333333, loss:2.571537733078003
batch i:218
learning rate0.0013333333333333333, loss:2.518015146255493
batch i:219
learning rate0.0013333333333333333, loss:2.5160770416259766
batch i:220
learning rate0.0013333333333333333, loss:2.6826226711273193
batch i:221
learning rate0.0013333333333333333, loss:2.617396354675293
batch i:222
learning rate0.0013333333333333333, loss:2.579854965209961
batch i:223
learning rate0.0013333333333333333, loss:2.639671802520752
batch i:224
learning rate0.0013333333333333333, loss:2.68605899810791
batch i:225
learning rate0.0013333333333333333, loss:2.678349494934082
batch i:226
learning rate0.0013333333333333333, loss:2.6595747470855713
batch i:227
learning rate0.0013333333333333333, loss:2.5996203422546387
batch i:228
learning rate0.0013333333333333333, loss:2.5993762016296387
batch i:229
learning rate0.0013333333333333333, loss:2.5740087032318115
batch i:230
learning rate0.0013333333333333333, loss:2.658924102783203
batch i:231
learning rate0.0013333333333333333, loss:2.6314151287078857
batch i:232
learning rate0.0013333333333333333, loss:2.7035584449768066
batch i:233
learning rate0.0013333333333333333, loss:2.5718886852264404
batch i:234
learning rate0.0013333333333333333, loss:2.6706862449645996
batch i:235
learning rate0.0013333333333333333, loss:2.5651090145111084
batch i:236
learning rate0.0013333333333333333, loss:2.6571249961853027
batch i:237
learning rate0.0013333333333333333, loss:2.667116165161133
batch i:238
learning rate0.0013333333333333333, loss:2.6673848628997803
batch i:239
learning rate0.0013333333333333333, loss:2.6970396041870117
batch i:240
learning rate0.0013333333333333333, loss:2.7031641006469727
batch i:241
learning rate0.0013333333333333333, loss:2.702052116394043
batch i:242
learning rate0.0013333333333333333, loss:2.6928696632385254
batch i:243
learning rate0.0013333333333333333, loss:2.6670727729797363
batch i:244
learning rate0.0013333333333333333, loss:2.6776180267333984
batch i:245
learning rate0.0013333333333333333, loss:2.644181251525879
batch i:246
learning rate0.0013333333333333333, loss:2.6443023681640625
batch i:247
learning rate0.0013333333333333333, loss:2.6528124809265137
batch i:248
learning rate0.0013333333333333333, loss:2.7099556922912598
batch i:249
learning rate0.0013333333333333333, loss:2.7001147270202637
batch i:250
learning rate0.0013333333333333333, loss:2.612827777862549
current self-play batch: 250
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 240.81776289939882
New best policy from pure MCTS
batch i:251
learning rate0.0013333333333333333, loss:2.6753604412078857
batch i:252
learning rate0.0013333333333333333, loss:2.683643341064453
batch i:253
learning rate0.0013333333333333333, loss:2.6775095462799072
batch i:254
learning rate0.0013333333333333333, loss:2.684049129486084
batch i:255
learning rate0.0013333333333333333, loss:2.660675048828125
batch i:256
learning rate0.0013333333333333333, loss:2.7844841480255127
batch i:257
learning rate0.0013333333333333333, loss:2.644761562347412
batch i:258
learning rate0.0013333333333333333, loss:2.61252760887146
batch i:259
learning rate0.0013333333333333333, loss:2.666062355041504
batch i:260
learning rate0.0013333333333333333, loss:2.748147487640381
batch i:261
learning rate0.0013333333333333333, loss:2.7154808044433594
batch i:262
learning rate0.0013333333333333333, loss:2.638556480407715
batch i:263
learning rate0.0013333333333333333, loss:2.656217336654663
batch i:264
learning rate0.0013333333333333333, loss:2.5994873046875
batch i:265
learning rate0.0013333333333333333, loss:2.6850247383117676
batch i:266
learning rate0.0013333333333333333, loss:2.717289447784424
batch i:267
learning rate0.0013333333333333333, loss:2.7137856483459473
batch i:268
learning rate0.0013333333333333333, loss:2.7230567932128906
batch i:269
learning rate0.0013333333333333333, loss:2.6232433319091797
batch i:270
learning rate0.0013333333333333333, loss:2.7296268939971924
batch i:271
learning rate0.0013333333333333333, loss:2.640629529953003
batch i:272
learning rate0.0013333333333333333, loss:2.724074363708496
batch i:273
learning rate0.0013333333333333333, loss:2.685671329498291
batch i:274
learning rate0.0013333333333333333, loss:2.7855896949768066
batch i:275
learning rate0.0013333333333333333, loss:2.6829233169555664
batch i:276
learning rate0.0013333333333333333, loss:2.643125534057617
batch i:277
learning rate0.0013333333333333333, loss:2.6297264099121094
batch i:278
learning rate0.0013333333333333333, loss:2.5836877822875977
batch i:279
learning rate0.0013333333333333333, loss:2.6687674522399902
batch i:280
learning rate0.0013333333333333333, loss:2.6604838371276855
batch i:281
learning rate0.0013333333333333333, loss:2.64017653465271
batch i:282
learning rate0.0013333333333333333, loss:2.739091396331787
batch i:283
learning rate0.0013333333333333333, loss:2.6157641410827637
batch i:284
learning rate0.0013333333333333333, loss:2.6388301849365234
batch i:285
learning rate0.0013333333333333333, loss:2.5977141857147217
batch i:286
learning rate0.0013333333333333333, loss:2.6375982761383057
batch i:287
learning rate0.0013333333333333333, loss:2.7635579109191895
batch i:288
learning rate0.0013333333333333333, loss:2.6715993881225586
batch i:289
learning rate0.0013333333333333333, loss:2.728132724761963
batch i:290
learning rate0.0013333333333333333, loss:2.694613456726074
batch i:291
learning rate0.0013333333333333333, loss:2.771829605102539
batch i:292
learning rate0.0013333333333333333, loss:2.789931297302246
batch i:293
learning rate0.0013333333333333333, loss:2.7252886295318604
batch i:294
learning rate0.0013333333333333333, loss:2.6793782711029053
batch i:295
learning rate0.0013333333333333333, loss:2.671039342880249
batch i:296
learning rate0.0013333333333333333, loss:2.681917190551758
batch i:297
learning rate0.0013333333333333333, loss:2.6257145404815674
batch i:298
learning rate0.0013333333333333333, loss:2.657804012298584
batch i:299
learning rate0.0013333333333333333, loss:2.713193416595459
batch i:300
learning rate0.0013333333333333333, loss:2.68131685256958
current self-play batch: 300
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 210.02351422309874
batch i:301
learning rate0.0013333333333333333, loss:2.6650583744049072
batch i:302
learning rate0.0013333333333333333, loss:2.723651885986328
batch i:303
learning rate0.0013333333333333333, loss:2.725043773651123
batch i:304
learning rate0.0013333333333333333, loss:2.630296230316162
batch i:305
learning rate0.0013333333333333333, loss:2.6179561614990234
batch i:306
learning rate0.0013333333333333333, loss:2.7230491638183594
batch i:307
learning rate0.0013333333333333333, loss:2.6586766242980957
batch i:308
learning rate0.0013333333333333333, loss:2.7119460105895996
batch i:309
learning rate0.0013333333333333333, loss:2.669415235519409
batch i:310
learning rate0.0013333333333333333, loss:2.7986931800842285
batch i:311
learning rate0.0013333333333333333, loss:2.546671152114868
batch i:312
learning rate0.0013333333333333333, loss:2.681257724761963
batch i:313
learning rate0.0013333333333333333, loss:2.701732635498047
batch i:314
learning rate0.0013333333333333333, loss:2.6788792610168457
batch i:315
learning rate0.0013333333333333333, loss:2.7514750957489014
batch i:316
learning rate0.0013333333333333333, loss:2.7679333686828613
batch i:317
learning rate0.0013333333333333333, loss:2.6436221599578857
batch i:318
learning rate0.0013333333333333333, loss:2.6184096336364746
batch i:319
learning rate0.0013333333333333333, loss:2.6508545875549316
batch i:320
learning rate0.0013333333333333333, loss:2.629713535308838
batch i:321
learning rate0.0013333333333333333, loss:2.79435133934021
batch i:322
learning rate0.0013333333333333333, loss:2.7117743492126465
batch i:323
learning rate0.0013333333333333333, loss:2.692194938659668
batch i:324
learning rate0.0013333333333333333, loss:2.664781332015991
batch i:325
learning rate0.0013333333333333333, loss:2.6559321880340576
batch i:326
learning rate0.0013333333333333333, loss:2.6302967071533203
batch i:327
learning rate0.0013333333333333333, loss:2.6567816734313965
batch i:328
learning rate0.0013333333333333333, loss:2.648001194000244
batch i:329
learning rate0.0013333333333333333, loss:2.737513303756714
batch i:330
learning rate0.0013333333333333333, loss:2.733670711517334
batch i:331
learning rate0.0013333333333333333, loss:2.6997127532958984
batch i:332
learning rate0.0013333333333333333, loss:2.7525835037231445
batch i:333
learning rate0.0013333333333333333, loss:2.6959571838378906
batch i:334
learning rate0.0013333333333333333, loss:2.615992784500122
batch i:335
learning rate0.0013333333333333333, loss:2.7683160305023193
batch i:336
learning rate0.0013333333333333333, loss:2.7498281002044678
batch i:337
learning rate0.0013333333333333333, loss:2.773505210876465
batch i:338
learning rate0.0013333333333333333, loss:2.7047746181488037
batch i:339
learning rate0.0013333333333333333, loss:2.7141776084899902
batch i:340
learning rate0.0013333333333333333, loss:2.5861868858337402
batch i:341
learning rate0.0013333333333333333, loss:2.6675071716308594
batch i:342
learning rate0.0013333333333333333, loss:2.6953887939453125
batch i:343
learning rate0.0013333333333333333, loss:2.6184029579162598
batch i:344
learning rate0.0013333333333333333, loss:2.69648814201355
batch i:345
learning rate0.0013333333333333333, loss:2.6339609622955322
batch i:346
learning rate0.0013333333333333333, loss:2.6470465660095215
batch i:347
learning rate0.0013333333333333333, loss:2.74031400680542
batch i:348
learning rate0.0013333333333333333, loss:2.7488107681274414
batch i:349
learning rate0.0013333333333333333, loss:2.7066197395324707
batch i:350
learning rate0.0013333333333333333, loss:2.720139503479004
current self-play batch: 350
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 214.94690203666687
New best policy from pure MCTS
batch i:351
learning rate0.0013333333333333333, loss:2.6655654907226562
batch i:352
learning rate0.0013333333333333333, loss:2.6941561698913574
batch i:353
learning rate0.0013333333333333333, loss:2.763929605484009
batch i:354
learning rate0.0013333333333333333, loss:2.7877817153930664
batch i:355
learning rate0.0013333333333333333, loss:2.715080499649048
batch i:356
learning rate0.0013333333333333333, loss:2.796563148498535
batch i:357
learning rate0.0013333333333333333, loss:2.7981820106506348
batch i:358
learning rate0.0013333333333333333, loss:2.775587558746338
batch i:359
learning rate0.0013333333333333333, loss:2.7065353393554688
batch i:360
learning rate0.0013333333333333333, loss:2.696340799331665
batch i:361
learning rate0.0013333333333333333, loss:2.7949464321136475
batch i:362
learning rate0.0013333333333333333, loss:2.748819351196289
batch i:363
learning rate0.0013333333333333333, loss:2.6821861267089844
batch i:364
learning rate0.0013333333333333333, loss:2.742288589477539
batch i:365
learning rate0.0013333333333333333, loss:2.775721549987793
batch i:366
learning rate0.0013333333333333333, loss:2.8133926391601562
batch i:367
learning rate0.0013333333333333333, loss:2.748159408569336
batch i:368
learning rate0.0013333333333333333, loss:2.81850004196167
batch i:369
learning rate0.0013333333333333333, loss:2.750062942504883
batch i:370
learning rate0.0013333333333333333, loss:2.7546119689941406
batch i:371
learning rate0.0013333333333333333, loss:2.7292866706848145
batch i:372
learning rate0.0013333333333333333, loss:2.8160338401794434
batch i:373
learning rate0.0013333333333333333, loss:2.6227452754974365
batch i:374
learning rate0.0013333333333333333, loss:2.750589370727539
batch i:375
learning rate0.0013333333333333333, loss:2.7464218139648438
batch i:376
learning rate0.0013333333333333333, loss:2.745565414428711
batch i:377
learning rate0.0013333333333333333, loss:2.718364715576172
batch i:378
learning rate0.0013333333333333333, loss:2.6839194297790527
batch i:379
learning rate0.0013333333333333333, loss:2.7027103900909424
batch i:380
learning rate0.0013333333333333333, loss:2.6889843940734863
batch i:381
learning rate0.0013333333333333333, loss:2.627384662628174
batch i:382
learning rate0.0013333333333333333, loss:2.639256477355957
batch i:383
learning rate0.0013333333333333333, loss:2.6893391609191895
batch i:384
learning rate0.0013333333333333333, loss:2.694460391998291
batch i:385
learning rate0.0013333333333333333, loss:2.67018985748291
batch i:386
learning rate0.0013333333333333333, loss:2.6877360343933105
batch i:387
learning rate0.0013333333333333333, loss:2.6747803688049316
batch i:388
learning rate0.0013333333333333333, loss:2.7356953620910645
batch i:389
learning rate0.0013333333333333333, loss:2.7909092903137207
batch i:390
learning rate0.0013333333333333333, loss:2.6873459815979004
batch i:391
learning rate0.0013333333333333333, loss:2.692746162414551
batch i:392
learning rate0.0013333333333333333, loss:2.7277655601501465
batch i:393
learning rate0.0013333333333333333, loss:2.7085351943969727
batch i:394
learning rate0.0013333333333333333, loss:2.6592283248901367
batch i:395
learning rate0.0013333333333333333, loss:2.8076014518737793
batch i:396
learning rate0.0013333333333333333, loss:2.697458267211914
batch i:397
learning rate0.0013333333333333333, loss:2.823823928833008
batch i:398
learning rate0.0013333333333333333, loss:2.768247127532959
batch i:399
learning rate0.0013333333333333333, loss:2.8757169246673584
batch i:400
learning rate0.0013333333333333333, loss:2.7431628704071045
current self-play batch: 400
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 236.26412723064422
batch i:401
learning rate0.0013333333333333333, loss:2.822789192199707
batch i:402
learning rate0.0013333333333333333, loss:2.7514119148254395
batch i:403
learning rate0.0013333333333333333, loss:2.7459874153137207
batch i:404
learning rate0.0013333333333333333, loss:2.721402168273926
batch i:405
learning rate0.0013333333333333333, loss:2.6583099365234375
batch i:406
learning rate0.0013333333333333333, loss:2.7326297760009766
batch i:407
learning rate0.0013333333333333333, loss:2.7625465393066406
batch i:408
learning rate0.0013333333333333333, loss:2.6885576248168945
batch i:409
learning rate0.0013333333333333333, loss:2.8515124320983887
batch i:410
learning rate0.0013333333333333333, loss:2.826199531555176
batch i:411
learning rate0.0013333333333333333, loss:2.709277629852295
batch i:412
learning rate0.0013333333333333333, loss:2.842219829559326
batch i:413
learning rate0.0013333333333333333, loss:2.8163070678710938
batch i:414
learning rate0.0013333333333333333, loss:2.905674695968628
batch i:415
learning rate0.0013333333333333333, loss:2.728116750717163
batch i:416
learning rate0.0013333333333333333, loss:2.7788820266723633
batch i:417
learning rate0.0013333333333333333, loss:2.8249692916870117
batch i:418
learning rate0.0013333333333333333, loss:2.7760868072509766
batch i:419
learning rate0.0013333333333333333, loss:2.763653516769409
batch i:420
learning rate0.0013333333333333333, loss:2.7190184593200684
batch i:421
learning rate0.0013333333333333333, loss:2.765162944793701
batch i:422
learning rate0.0013333333333333333, loss:2.8485360145568848
batch i:423
learning rate0.0013333333333333333, loss:2.788966655731201
batch i:424
learning rate0.0013333333333333333, loss:2.8469762802124023
batch i:425
learning rate0.0013333333333333333, loss:2.8279738426208496
batch i:426
learning rate0.0013333333333333333, loss:2.8095054626464844
batch i:427
learning rate0.0013333333333333333, loss:2.828963279724121
batch i:428
learning rate0.0013333333333333333, loss:2.8925843238830566
batch i:429
learning rate0.0013333333333333333, loss:2.807675838470459
batch i:430
learning rate0.0013333333333333333, loss:2.823796272277832
batch i:431
learning rate0.0013333333333333333, loss:2.8387703895568848
batch i:432
learning rate0.0013333333333333333, loss:2.808475971221924
batch i:433
learning rate0.0013333333333333333, loss:2.815591335296631
batch i:434
learning rate0.0013333333333333333, loss:2.804182529449463
batch i:435
learning rate0.0013333333333333333, loss:2.8353700637817383
batch i:436
learning rate0.0013333333333333333, loss:2.8070144653320312
batch i:437
learning rate0.0013333333333333333, loss:2.8308982849121094
batch i:438
learning rate0.0013333333333333333, loss:2.7507853507995605
batch i:439
learning rate0.0013333333333333333, loss:2.7925615310668945
batch i:440
learning rate0.0013333333333333333, loss:2.8457717895507812
batch i:441
learning rate0.0013333333333333333, loss:2.7912139892578125
batch i:442
learning rate0.0013333333333333333, loss:2.819944381713867
batch i:443
learning rate0.0013333333333333333, loss:2.856138229370117
batch i:444
learning rate0.0013333333333333333, loss:2.8953845500946045
batch i:445
learning rate0.0013333333333333333, loss:2.8813509941101074
batch i:446
learning rate0.0013333333333333333, loss:2.8111729621887207
batch i:447
learning rate0.0013333333333333333, loss:2.8357808589935303
batch i:448
learning rate0.0013333333333333333, loss:2.8640220165252686
batch i:449
learning rate0.0013333333333333333, loss:2.839630126953125
batch i:450
learning rate0.0013333333333333333, loss:2.735213041305542
current self-play batch: 450
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 221.72340395450593
batch i:451
learning rate0.0013333333333333333, loss:2.7896323204040527
batch i:452
learning rate0.0013333333333333333, loss:2.8720197677612305
batch i:453
learning rate0.0013333333333333333, loss:2.8450214862823486
batch i:454
learning rate0.0013333333333333333, loss:2.9070231914520264
batch i:455
learning rate0.0013333333333333333, loss:2.823375701904297
batch i:456
learning rate0.0013333333333333333, loss:2.77382493019104
batch i:457
learning rate0.0013333333333333333, loss:2.819227933883667
batch i:458
learning rate0.0013333333333333333, loss:2.8278894424438477
batch i:459
learning rate0.0013333333333333333, loss:2.810706615447998
batch i:460
learning rate0.0013333333333333333, loss:2.803407669067383
batch i:461
learning rate0.0013333333333333333, loss:2.7808361053466797
batch i:462
learning rate0.0013333333333333333, loss:2.8200273513793945
batch i:463
learning rate0.0013333333333333333, loss:2.839926242828369
batch i:464
learning rate0.0013333333333333333, loss:2.7372803688049316
batch i:465
learning rate0.0013333333333333333, loss:2.836254596710205
batch i:466
learning rate0.0013333333333333333, loss:2.7290549278259277
batch i:467
learning rate0.0013333333333333333, loss:2.7189626693725586
batch i:468
learning rate0.0013333333333333333, loss:2.8151111602783203
batch i:469
learning rate0.0013333333333333333, loss:2.864426374435425
batch i:470
learning rate0.0013333333333333333, loss:2.8585591316223145
batch i:471
learning rate0.0013333333333333333, loss:2.8667163848876953
batch i:472
learning rate0.0013333333333333333, loss:2.8493614196777344
batch i:473
learning rate0.0013333333333333333, loss:2.844484806060791
batch i:474
learning rate0.0013333333333333333, loss:2.839374542236328
batch i:475
learning rate0.0013333333333333333, loss:2.815758466720581
batch i:476
learning rate0.0013333333333333333, loss:2.731806755065918
batch i:477
learning rate0.0013333333333333333, loss:2.7498435974121094
batch i:478
learning rate0.0013333333333333333, loss:2.8424344062805176
batch i:479
learning rate0.0013333333333333333, loss:2.812344551086426
batch i:480
learning rate0.0013333333333333333, loss:2.885032892227173
batch i:481
learning rate0.0013333333333333333, loss:2.820659875869751
batch i:482
learning rate0.0013333333333333333, loss:2.817084789276123
batch i:483
learning rate0.0013333333333333333, loss:2.853017568588257
batch i:484
learning rate0.0013333333333333333, loss:2.8056325912475586
batch i:485
learning rate0.0013333333333333333, loss:2.8851237297058105
batch i:486
learning rate0.0013333333333333333, loss:2.910323143005371
batch i:487
learning rate0.0013333333333333333, loss:2.8286454677581787
batch i:488
learning rate0.0013333333333333333, loss:2.829028606414795
batch i:489
learning rate0.0013333333333333333, loss:2.828202962875366
batch i:490
learning rate0.0013333333333333333, loss:2.8225326538085938
batch i:491
learning rate0.0013333333333333333, loss:2.7743659019470215
batch i:492
learning rate0.0013333333333333333, loss:2.82517671585083
batch i:493
learning rate0.0013333333333333333, loss:2.7885663509368896
batch i:494
learning rate0.0013333333333333333, loss:2.8402953147888184
batch i:495
learning rate0.0013333333333333333, loss:2.900928020477295
batch i:496
learning rate0.0013333333333333333, loss:2.7126553058624268
batch i:497
learning rate0.0013333333333333333, loss:2.786442279815674
batch i:498
learning rate0.0013333333333333333, loss:2.8642797470092773
batch i:499
learning rate0.0013333333333333333, loss:2.8359317779541016
batch i:500
learning rate0.0013333333333333333, loss:2.8331682682037354
current self-play batch: 500
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 213.2253569126129
batch i:501
learning rate0.0013333333333333333, loss:2.785555362701416
batch i:502
learning rate0.0013333333333333333, loss:2.804291248321533
batch i:503
learning rate0.0013333333333333333, loss:2.7459421157836914
batch i:504
learning rate0.0013333333333333333, loss:2.7846286296844482
batch i:505
learning rate0.0013333333333333333, loss:2.733700752258301
batch i:506
learning rate0.0013333333333333333, loss:2.7765750885009766
batch i:507
learning rate0.0013333333333333333, loss:2.822160005569458
batch i:508
learning rate0.0013333333333333333, loss:2.7498672008514404
batch i:509
learning rate0.0013333333333333333, loss:2.7570128440856934
batch i:510
learning rate0.0013333333333333333, loss:2.7171382904052734
batch i:511
learning rate0.0013333333333333333, loss:2.833651065826416
batch i:512
learning rate0.0013333333333333333, loss:2.7639026641845703
batch i:513
learning rate0.0013333333333333333, loss:2.7567715644836426
batch i:514
learning rate0.0013333333333333333, loss:2.834596633911133
batch i:515
learning rate0.0013333333333333333, loss:2.890608310699463
batch i:516
learning rate0.0013333333333333333, loss:2.7926530838012695
batch i:517
learning rate0.0013333333333333333, loss:2.8157408237457275
batch i:518
learning rate0.0013333333333333333, loss:2.8499534130096436
batch i:519
learning rate0.0013333333333333333, loss:2.8506946563720703
batch i:520
learning rate0.0013333333333333333, loss:2.7722370624542236
batch i:521
learning rate0.0013333333333333333, loss:2.8468921184539795
batch i:522
learning rate0.0013333333333333333, loss:2.774010419845581
batch i:523
learning rate0.0013333333333333333, loss:2.8251023292541504
batch i:524
learning rate0.0013333333333333333, loss:2.8325772285461426
batch i:525
learning rate0.0013333333333333333, loss:2.8361997604370117
batch i:526
learning rate0.0013333333333333333, loss:2.838606357574463
batch i:527
learning rate0.0013333333333333333, loss:2.9096949100494385
batch i:528
learning rate0.0013333333333333333, loss:2.810415029525757
batch i:529
learning rate0.0013333333333333333, loss:2.6870357990264893
batch i:530
learning rate0.0013333333333333333, loss:2.8179545402526855
batch i:531
learning rate0.0013333333333333333, loss:2.830112934112549
batch i:532
learning rate0.0013333333333333333, loss:2.717283010482788
batch i:533
learning rate0.0013333333333333333, loss:2.7190921306610107
batch i:534
learning rate0.0013333333333333333, loss:2.757976531982422
batch i:535
learning rate0.0013333333333333333, loss:2.8023667335510254
batch i:536
learning rate0.0013333333333333333, loss:2.8294267654418945
batch i:537
learning rate0.0013333333333333333, loss:2.8632140159606934
batch i:538
learning rate0.0013333333333333333, loss:2.8069233894348145
batch i:539
learning rate0.0013333333333333333, loss:2.866466999053955
batch i:540
learning rate0.0013333333333333333, loss:2.776822805404663
batch i:541
learning rate0.0013333333333333333, loss:2.845231771469116
batch i:542
learning rate0.0013333333333333333, loss:2.8793797492980957
batch i:543
learning rate0.0013333333333333333, loss:2.824350595474243
batch i:544
learning rate0.0013333333333333333, loss:2.7796571254730225
batch i:545
learning rate0.0013333333333333333, loss:2.772432327270508
batch i:546
learning rate0.0013333333333333333, loss:2.75161075592041
batch i:547
learning rate0.0013333333333333333, loss:2.7424163818359375
batch i:548
learning rate0.0013333333333333333, loss:2.7598748207092285
batch i:549
learning rate0.0013333333333333333, loss:2.8040449619293213
batch i:550
learning rate0.0013333333333333333, loss:2.790200710296631
current self-play batch: 550
num_playouts:2000, win: 4, lose: 6, tie:0
average time: 286.7686236143112
batch i:551
learning rate0.0013333333333333333, loss:2.7915871143341064
batch i:552
learning rate0.0013333333333333333, loss:2.7504780292510986
batch i:553
learning rate0.0013333333333333333, loss:2.7440690994262695
batch i:554
learning rate0.0013333333333333333, loss:2.7619855403900146
batch i:555
learning rate0.0013333333333333333, loss:2.7973387241363525
batch i:556
learning rate0.0013333333333333333, loss:2.7461090087890625
batch i:557
learning rate0.0013333333333333333, loss:2.815741777420044
batch i:558
learning rate0.0013333333333333333, loss:2.7457828521728516
batch i:559
learning rate0.0013333333333333333, loss:2.7502458095550537
batch i:560
learning rate0.0013333333333333333, loss:2.8259806632995605
batch i:561
learning rate0.0013333333333333333, loss:2.7849924564361572
batch i:562
learning rate0.0013333333333333333, loss:2.7491278648376465
batch i:563
learning rate0.0013333333333333333, loss:2.786527395248413
batch i:564
learning rate0.0013333333333333333, loss:2.7904553413391113
batch i:565
learning rate0.0013333333333333333, loss:2.8067679405212402
batch i:566
learning rate0.0013333333333333333, loss:2.8712267875671387
batch i:567
learning rate0.0013333333333333333, loss:2.793120861053467
batch i:568
learning rate0.0013333333333333333, loss:2.8491873741149902
batch i:569
learning rate0.0013333333333333333, loss:2.8023388385772705
batch i:570
learning rate0.0013333333333333333, loss:2.876110076904297
batch i:571
learning rate0.0013333333333333333, loss:2.812232494354248
batch i:572
learning rate0.0013333333333333333, loss:2.867771625518799
batch i:573
learning rate0.0013333333333333333, loss:2.9043996334075928
batch i:574
learning rate0.0013333333333333333, loss:2.8579277992248535
batch i:575
learning rate0.0013333333333333333, loss:2.8693714141845703
batch i:576
learning rate0.0013333333333333333, loss:2.890413761138916
batch i:577
learning rate0.0013333333333333333, loss:2.8512353897094727
batch i:578
learning rate0.0013333333333333333, loss:2.8728506565093994
batch i:579
learning rate0.0013333333333333333, loss:2.8940377235412598
batch i:580
learning rate0.0013333333333333333, loss:2.958099603652954
batch i:581
learning rate0.0013333333333333333, loss:2.9854748249053955
batch i:582
learning rate0.0013333333333333333, loss:2.941211700439453
batch i:583
learning rate0.0013333333333333333, loss:2.872661828994751
batch i:584
learning rate0.0013333333333333333, loss:2.949667453765869
batch i:585
learning rate0.0013333333333333333, loss:2.959914207458496
batch i:586
learning rate0.0013333333333333333, loss:2.892841339111328
batch i:587
learning rate0.0013333333333333333, loss:2.881540298461914
batch i:588
learning rate0.0013333333333333333, loss:2.934154987335205
batch i:589
learning rate0.0013333333333333333, loss:2.829483985900879
batch i:590
learning rate0.0013333333333333333, loss:2.812403440475464
batch i:591
learning rate0.0013333333333333333, loss:2.8670220375061035
batch i:592
learning rate0.0013333333333333333, loss:2.8277082443237305
batch i:593
learning rate0.0013333333333333333, loss:2.906480312347412
batch i:594
learning rate0.0013333333333333333, loss:2.8608546257019043
batch i:595
learning rate0.0013333333333333333, loss:2.8263015747070312
batch i:596
learning rate0.0013333333333333333, loss:2.942164897918701
batch i:597
learning rate0.0013333333333333333, loss:2.957882881164551
batch i:598
learning rate0.0013333333333333333, loss:2.79646635055542
batch i:599
learning rate0.0013333333333333333, loss:2.8398661613464355
batch i:600
learning rate0.0013333333333333333, loss:2.933173179626465
current self-play batch: 600
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 259.8691817998886
batch i:601
learning rate0.0013333333333333333, loss:2.944080352783203
batch i:602
learning rate0.0013333333333333333, loss:2.89739990234375
batch i:603
learning rate0.0013333333333333333, loss:2.7913289070129395
batch i:604
learning rate0.0013333333333333333, loss:2.8487586975097656
batch i:605
learning rate0.0013333333333333333, loss:2.9167943000793457
batch i:606
learning rate0.0013333333333333333, loss:2.832517147064209
batch i:607
learning rate0.0013333333333333333, loss:2.822636842727661
batch i:608
learning rate0.0013333333333333333, loss:2.8373517990112305
batch i:609
learning rate0.0013333333333333333, loss:2.8426365852355957
batch i:610
learning rate0.0013333333333333333, loss:2.9550909996032715
batch i:611
learning rate0.0013333333333333333, loss:2.8747169971466064
batch i:612
learning rate0.0013333333333333333, loss:2.877540349960327
batch i:613
learning rate0.0013333333333333333, loss:2.8703386783599854
batch i:614
learning rate0.0013333333333333333, loss:2.9512526988983154
batch i:615
learning rate0.0013333333333333333, loss:2.927694320678711
batch i:616
learning rate0.0013333333333333333, loss:2.9011569023132324
batch i:617
learning rate0.0013333333333333333, loss:2.844496726989746
batch i:618
learning rate0.0013333333333333333, loss:2.921670913696289
batch i:619
learning rate0.0013333333333333333, loss:2.862166404724121
batch i:620
learning rate0.0013333333333333333, loss:2.9120142459869385
batch i:621
learning rate0.0013333333333333333, loss:2.901089668273926
batch i:622
learning rate0.0013333333333333333, loss:2.9309821128845215
batch i:623
learning rate0.0013333333333333333, loss:2.9707794189453125
batch i:624
learning rate0.0013333333333333333, loss:2.979546546936035
batch i:625
learning rate0.0013333333333333333, loss:2.954010248184204
batch i:626
learning rate0.0013333333333333333, loss:2.9357845783233643
batch i:627
learning rate0.0013333333333333333, loss:2.915910482406616
batch i:628
learning rate0.0013333333333333333, loss:2.8962595462799072
batch i:629
learning rate0.0013333333333333333, loss:2.928255081176758
batch i:630
learning rate0.0013333333333333333, loss:2.863520622253418
batch i:631
learning rate0.0013333333333333333, loss:3.0014870166778564
batch i:632
learning rate0.0013333333333333333, loss:2.869765520095825
batch i:633
learning rate0.0013333333333333333, loss:2.866701364517212
batch i:634
learning rate0.0013333333333333333, loss:2.8641366958618164
batch i:635
learning rate0.0013333333333333333, loss:2.91571044921875
batch i:636
learning rate0.0013333333333333333, loss:2.8263988494873047
batch i:637
learning rate0.0013333333333333333, loss:2.889267683029175
batch i:638
learning rate0.0013333333333333333, loss:2.980905055999756
batch i:639
learning rate0.0013333333333333333, loss:2.9127423763275146
batch i:640
learning rate0.0013333333333333333, loss:2.9722084999084473
batch i:641
learning rate0.0013333333333333333, loss:2.845777750015259
batch i:642
learning rate0.0013333333333333333, loss:2.898226022720337
batch i:643
learning rate0.0013333333333333333, loss:2.8483424186706543
batch i:644
learning rate0.0013333333333333333, loss:2.8270134925842285
batch i:645
learning rate0.0013333333333333333, loss:2.810765266418457
batch i:646
learning rate0.0013333333333333333, loss:2.912259578704834
batch i:647
learning rate0.0013333333333333333, loss:2.8995702266693115
batch i:648
learning rate0.0013333333333333333, loss:2.8679919242858887
batch i:649
learning rate0.0013333333333333333, loss:2.775330066680908
batch i:650
learning rate0.0013333333333333333, loss:2.879221200942993
current self-play batch: 650
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 264.04087285995485
batch i:651
learning rate0.0013333333333333333, loss:2.85347843170166
batch i:652
learning rate0.0013333333333333333, loss:2.8137691020965576
batch i:653
learning rate0.0013333333333333333, loss:2.929641008377075
batch i:654
learning rate0.0013333333333333333, loss:2.844271421432495
batch i:655
learning rate0.0013333333333333333, loss:2.8762125968933105
batch i:656
learning rate0.0013333333333333333, loss:2.8359463214874268
batch i:657
learning rate0.0013333333333333333, loss:2.8260645866394043
batch i:658
learning rate0.0013333333333333333, loss:2.802802085876465
batch i:659
learning rate0.0013333333333333333, loss:2.9211480617523193
batch i:660
learning rate0.0013333333333333333, loss:2.868917465209961
batch i:661
learning rate0.0013333333333333333, loss:2.8637337684631348
batch i:662
learning rate0.0013333333333333333, loss:2.8613476753234863
batch i:663
learning rate0.0013333333333333333, loss:2.841860771179199
batch i:664
learning rate0.0013333333333333333, loss:2.7982125282287598
batch i:665
learning rate0.0013333333333333333, loss:2.896367073059082
batch i:666
learning rate0.0013333333333333333, loss:2.729545831680298
batch i:667
learning rate0.0013333333333333333, loss:2.8146095275878906
batch i:668
learning rate0.0013333333333333333, loss:2.9120826721191406
batch i:669
learning rate0.0013333333333333333, loss:2.8526721000671387
batch i:670
learning rate0.0013333333333333333, loss:2.77596378326416
batch i:671
learning rate0.0013333333333333333, loss:2.8035314083099365
batch i:672
learning rate0.0013333333333333333, loss:2.90583872795105
batch i:673
learning rate0.0013333333333333333, loss:2.8117659091949463
batch i:674
learning rate0.0013333333333333333, loss:2.8611321449279785
batch i:675
learning rate0.0013333333333333333, loss:2.8079209327697754
batch i:676
learning rate0.0013333333333333333, loss:2.8506383895874023
batch i:677
learning rate0.0013333333333333333, loss:2.846388816833496
batch i:678
learning rate0.0013333333333333333, loss:2.791775703430176
batch i:679
learning rate0.0013333333333333333, loss:2.8719208240509033
batch i:680
learning rate0.0013333333333333333, loss:2.8416178226470947
batch i:681
learning rate0.0013333333333333333, loss:2.8233513832092285
batch i:682
learning rate0.0013333333333333333, loss:2.884826898574829
batch i:683
learning rate0.0013333333333333333, loss:2.9395077228546143
batch i:684
learning rate0.0013333333333333333, loss:2.89121150970459
batch i:685
learning rate0.0013333333333333333, loss:2.8641371726989746
batch i:686
learning rate0.0013333333333333333, loss:2.8679730892181396
batch i:687
learning rate0.0013333333333333333, loss:2.7913949489593506
batch i:688
learning rate0.0013333333333333333, loss:2.84275221824646
batch i:689
learning rate0.0013333333333333333, loss:2.786736011505127
batch i:690
learning rate0.0013333333333333333, loss:2.9212124347686768
batch i:691
learning rate0.0013333333333333333, loss:2.9267287254333496
batch i:692
learning rate0.0013333333333333333, loss:2.84546160697937
batch i:693
learning rate0.0013333333333333333, loss:2.7913520336151123
batch i:694
learning rate0.0013333333333333333, loss:2.873593330383301
batch i:695
learning rate0.0013333333333333333, loss:2.8509838581085205
batch i:696
learning rate0.0013333333333333333, loss:2.74477481842041
batch i:697
learning rate0.0013333333333333333, loss:2.8577187061309814
batch i:698
learning rate0.0013333333333333333, loss:2.7972512245178223
batch i:699
learning rate0.0013333333333333333, loss:2.8732619285583496
batch i:700
learning rate0.0013333333333333333, loss:2.8546535968780518
current self-play batch: 700
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 214.9114548444748
batch i:701
learning rate0.0013333333333333333, loss:2.9604291915893555
batch i:702
learning rate0.0013333333333333333, loss:2.7714271545410156
batch i:703
learning rate0.0013333333333333333, loss:2.889143943786621
batch i:704
learning rate0.0013333333333333333, loss:2.840620994567871
batch i:705
learning rate0.0013333333333333333, loss:2.911583185195923
batch i:706
learning rate0.0013333333333333333, loss:2.970036745071411
batch i:707
learning rate0.0013333333333333333, loss:2.8666441440582275
batch i:708
learning rate0.0013333333333333333, loss:2.94566011428833
batch i:709
learning rate0.0013333333333333333, loss:2.8664445877075195
batch i:710
learning rate0.0013333333333333333, loss:2.848820447921753
batch i:711
learning rate0.0013333333333333333, loss:2.9048562049865723
batch i:712
learning rate0.0013333333333333333, loss:2.8067684173583984
batch i:713
learning rate0.0013333333333333333, loss:2.847895622253418
batch i:714
learning rate0.0013333333333333333, loss:2.810303211212158
batch i:715
learning rate0.0013333333333333333, loss:2.8938674926757812
batch i:716
learning rate0.0013333333333333333, loss:2.781881809234619
batch i:717
learning rate0.0013333333333333333, loss:2.8904924392700195
batch i:718
learning rate0.0013333333333333333, loss:2.897368907928467
batch i:719
learning rate0.0013333333333333333, loss:2.9086008071899414
batch i:720
learning rate0.0013333333333333333, loss:2.8984055519104004
batch i:721
learning rate0.0013333333333333333, loss:2.8347091674804688
batch i:722
learning rate0.0013333333333333333, loss:2.8527324199676514
batch i:723
learning rate0.0013333333333333333, loss:2.928220748901367
batch i:724
learning rate0.0013333333333333333, loss:2.875117540359497
batch i:725
learning rate0.0013333333333333333, loss:2.837307929992676
batch i:726
learning rate0.0013333333333333333, loss:2.9667625427246094
batch i:727
learning rate0.0013333333333333333, loss:2.934635639190674
batch i:728
learning rate0.0013333333333333333, loss:2.8896002769470215
batch i:729
learning rate0.0013333333333333333, loss:2.8419737815856934
batch i:730
learning rate0.0013333333333333333, loss:2.8866989612579346
batch i:731
learning rate0.0013333333333333333, loss:2.8625690937042236
batch i:732
learning rate0.0013333333333333333, loss:2.9573235511779785
batch i:733
learning rate0.0013333333333333333, loss:2.9424495697021484
batch i:734
learning rate0.0013333333333333333, loss:2.9926249980926514
batch i:735
learning rate0.0013333333333333333, loss:2.9811015129089355
batch i:736
learning rate0.0013333333333333333, loss:2.969709634780884
batch i:737
learning rate0.0013333333333333333, loss:2.970975875854492
batch i:738
learning rate0.0013333333333333333, loss:2.998093843460083
batch i:739
learning rate0.0013333333333333333, loss:3.016491413116455
batch i:740
learning rate0.0013333333333333333, loss:2.9806530475616455
batch i:741
learning rate0.0013333333333333333, loss:2.899658679962158
batch i:742
learning rate0.0013333333333333333, loss:2.971823215484619
batch i:743
learning rate0.0013333333333333333, loss:3.0501885414123535
batch i:744
learning rate0.0013333333333333333, loss:2.9364306926727295
batch i:745
learning rate0.0013333333333333333, loss:2.853706121444702
batch i:746
learning rate0.0013333333333333333, loss:3.0726542472839355
batch i:747
learning rate0.0013333333333333333, loss:2.8734054565429688
batch i:748
learning rate0.0013333333333333333, loss:2.958838701248169
batch i:749
learning rate0.0013333333333333333, loss:3.0173895359039307
batch i:750
learning rate0.0013333333333333333, loss:2.9677157402038574
current self-play batch: 750
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 221.43272726535798
batch i:751
learning rate0.0013333333333333333, loss:2.900866985321045
batch i:752
learning rate0.0013333333333333333, loss:2.979735851287842
batch i:753
learning rate0.0013333333333333333, loss:3.0183093547821045
batch i:754
learning rate0.0013333333333333333, loss:3.015632152557373
batch i:755
learning rate0.0013333333333333333, loss:2.8909215927124023
batch i:756
learning rate0.0013333333333333333, loss:2.9569993019104004
batch i:757
learning rate0.0013333333333333333, loss:3.008575439453125
batch i:758
learning rate0.0013333333333333333, loss:3.0263547897338867
batch i:759
learning rate0.0013333333333333333, loss:2.9119150638580322
batch i:760
learning rate0.0013333333333333333, loss:3.1033997535705566
batch i:761
learning rate0.0013333333333333333, loss:2.9277584552764893
batch i:762
learning rate0.0013333333333333333, loss:2.9875457286834717
batch i:763
learning rate0.0013333333333333333, loss:3.066985845565796
batch i:764
learning rate0.0013333333333333333, loss:3.086486577987671
batch i:765
learning rate0.0013333333333333333, loss:3.0504026412963867
batch i:766
learning rate0.0013333333333333333, loss:3.0961790084838867
batch i:767
learning rate0.0013333333333333333, loss:3.080073833465576
batch i:768
learning rate0.0013333333333333333, loss:3.011103868484497
batch i:769
learning rate0.0013333333333333333, loss:2.963184356689453
batch i:770
learning rate0.0013333333333333333, loss:3.0773050785064697
batch i:771
learning rate0.0013333333333333333, loss:3.0111565589904785
batch i:772
learning rate0.0013333333333333333, loss:3.0476603507995605
batch i:773
learning rate0.0013333333333333333, loss:2.9362335205078125
batch i:774
learning rate0.0013333333333333333, loss:3.119631767272949
batch i:775
learning rate0.0013333333333333333, loss:3.035346031188965
batch i:776
learning rate0.0013333333333333333, loss:2.983682155609131
batch i:777
learning rate0.0013333333333333333, loss:3.045773983001709
batch i:778
learning rate0.0013333333333333333, loss:3.0944619178771973
batch i:779
learning rate0.0013333333333333333, loss:3.1009230613708496
batch i:780
learning rate0.0013333333333333333, loss:3.0249829292297363
batch i:781
learning rate0.0013333333333333333, loss:3.1377205848693848
batch i:782
learning rate0.0013333333333333333, loss:3.05373477935791
batch i:783
learning rate0.0013333333333333333, loss:3.086700201034546
batch i:784
learning rate0.0013333333333333333, loss:3.067011833190918
batch i:785
learning rate0.0013333333333333333, loss:3.097485065460205
batch i:786
learning rate0.0013333333333333333, loss:3.092541217803955
batch i:787
learning rate0.0013333333333333333, loss:2.986442804336548
batch i:788
learning rate0.0013333333333333333, loss:3.0022599697113037
batch i:789
learning rate0.0013333333333333333, loss:3.0236308574676514
batch i:790
learning rate0.0013333333333333333, loss:3.03672194480896
batch i:791
learning rate0.0013333333333333333, loss:3.071160316467285
batch i:792
learning rate0.0013333333333333333, loss:3.1571130752563477
batch i:793
learning rate0.0013333333333333333, loss:3.1428775787353516
batch i:794
learning rate0.0013333333333333333, loss:3.090505361557007
batch i:795
learning rate0.0013333333333333333, loss:3.071321725845337
batch i:796
learning rate0.0013333333333333333, loss:3.0917439460754395
batch i:797
learning rate0.0013333333333333333, loss:3.0164992809295654
batch i:798
learning rate0.0013333333333333333, loss:3.0552430152893066
batch i:799
learning rate0.0013333333333333333, loss:3.0164947509765625
batch i:800
learning rate0.0013333333333333333, loss:3.066547393798828
current self-play batch: 800
num_playouts:2000, win: 6, lose: 4, tie:0
average time: 248.36244916915894
batch i:801
learning rate0.0013333333333333333, loss:3.0631089210510254
batch i:802
learning rate0.0013333333333333333, loss:3.011870861053467
batch i:803
learning rate0.0013333333333333333, loss:3.0691964626312256
batch i:804
learning rate0.0013333333333333333, loss:3.0999062061309814
batch i:805
learning rate0.0013333333333333333, loss:3.139915704727173
batch i:806
learning rate0.0013333333333333333, loss:3.0929312705993652
batch i:807
learning rate0.0013333333333333333, loss:3.203491687774658
batch i:808
learning rate0.0013333333333333333, loss:3.1517932415008545
batch i:809
learning rate0.0013333333333333333, loss:3.1560776233673096
batch i:810
learning rate0.0013333333333333333, loss:3.13775897026062
batch i:811
learning rate0.0013333333333333333, loss:3.136561870574951
batch i:812
learning rate0.0013333333333333333, loss:3.1599884033203125
batch i:813
learning rate0.0013333333333333333, loss:3.2808165550231934
batch i:814
learning rate0.0013333333333333333, loss:3.095897912979126
batch i:815
learning rate0.0013333333333333333, loss:3.108941078186035
batch i:816
learning rate0.0013333333333333333, loss:3.166889190673828
batch i:817
learning rate0.0013333333333333333, loss:3.0651769638061523
batch i:818
learning rate0.0013333333333333333, loss:3.1437487602233887
batch i:819
learning rate0.0013333333333333333, loss:3.132995128631592
batch i:820
learning rate0.0013333333333333333, loss:3.0628561973571777
batch i:821
learning rate0.0013333333333333333, loss:3.170914649963379
batch i:822
learning rate0.0013333333333333333, loss:3.138538360595703
batch i:823
learning rate0.0013333333333333333, loss:3.0929903984069824
batch i:824
learning rate0.0013333333333333333, loss:3.1880428791046143
batch i:825
learning rate0.0013333333333333333, loss:3.1713850498199463
batch i:826
learning rate0.0013333333333333333, loss:3.086703300476074
batch i:827
learning rate0.0013333333333333333, loss:3.115532875061035
batch i:828
learning rate0.0013333333333333333, loss:3.18808650970459
batch i:829
learning rate0.0013333333333333333, loss:3.119547128677368
batch i:830
learning rate0.0013333333333333333, loss:3.0581233501434326
batch i:831
learning rate0.0013333333333333333, loss:3.1232781410217285
batch i:832
learning rate0.0013333333333333333, loss:2.979343891143799
batch i:833
learning rate0.0013333333333333333, loss:3.1953349113464355
batch i:834
learning rate0.0013333333333333333, loss:3.1065661907196045
batch i:835
learning rate0.0013333333333333333, loss:3.110417366027832
batch i:836
learning rate0.0013333333333333333, loss:3.119147300720215
batch i:837
learning rate0.0013333333333333333, loss:3.1300101280212402
batch i:838
learning rate0.0013333333333333333, loss:3.102707624435425
batch i:839
learning rate0.0013333333333333333, loss:3.038304328918457
batch i:840
learning rate0.0013333333333333333, loss:3.060009479522705
batch i:841
learning rate0.0013333333333333333, loss:3.1152610778808594
batch i:842
learning rate0.0013333333333333333, loss:3.0509955883026123
batch i:843
learning rate0.0013333333333333333, loss:3.0798861980438232
batch i:844
learning rate0.0013333333333333333, loss:3.0203819274902344
batch i:845
learning rate0.0013333333333333333, loss:3.036597490310669
batch i:846
learning rate0.0013333333333333333, loss:3.0402815341949463
batch i:847
learning rate0.0013333333333333333, loss:2.980809211730957
batch i:848
learning rate0.0013333333333333333, loss:3.0736169815063477
batch i:849
learning rate0.0013333333333333333, loss:3.136336326599121
batch i:850
learning rate0.0013333333333333333, loss:3.0779263973236084
current self-play batch: 850
num_playouts:2000, win: 6, lose: 4, tie:0
average time: 219.58089225292207
batch i:851
learning rate0.0013333333333333333, loss:3.1329076290130615
batch i:852
learning rate0.0013333333333333333, loss:3.1332006454467773
batch i:853
learning rate0.0013333333333333333, loss:3.0599069595336914
batch i:854
learning rate0.0013333333333333333, loss:3.1307077407836914
batch i:855
learning rate0.0013333333333333333, loss:3.1417174339294434
batch i:856
learning rate0.0013333333333333333, loss:3.060621500015259
batch i:857
learning rate0.0013333333333333333, loss:3.109797954559326
batch i:858
learning rate0.0013333333333333333, loss:3.1259407997131348
batch i:859
learning rate0.0013333333333333333, loss:3.157933235168457
batch i:860
learning rate0.0013333333333333333, loss:3.148437976837158
batch i:861
learning rate0.0013333333333333333, loss:3.1089820861816406
batch i:862
learning rate0.0013333333333333333, loss:3.124744415283203
batch i:863
learning rate0.0013333333333333333, loss:3.1120524406433105
batch i:864
learning rate0.0013333333333333333, loss:3.0992608070373535
batch i:865
learning rate0.0013333333333333333, loss:3.1576666831970215
batch i:866
learning rate0.0013333333333333333, loss:3.1966030597686768
batch i:867
learning rate0.0013333333333333333, loss:3.108067274093628
batch i:868
learning rate0.0013333333333333333, loss:3.0213420391082764
batch i:869
learning rate0.0013333333333333333, loss:3.054182291030884
batch i:870
learning rate0.0013333333333333333, loss:3.0830416679382324
batch i:871
learning rate0.0013333333333333333, loss:3.2419443130493164
batch i:872
learning rate0.0013333333333333333, loss:3.146981716156006
batch i:873
learning rate0.0013333333333333333, loss:3.1897592544555664
batch i:874
learning rate0.0013333333333333333, loss:3.1236424446105957
batch i:875
learning rate0.0013333333333333333, loss:3.1068973541259766
batch i:876
learning rate0.0013333333333333333, loss:3.1977005004882812
batch i:877
learning rate0.0013333333333333333, loss:3.10070538520813
batch i:878
learning rate0.0013333333333333333, loss:3.083383083343506
batch i:879
learning rate0.0013333333333333333, loss:3.1201319694519043
batch i:880
learning rate0.0013333333333333333, loss:3.1642258167266846
batch i:881
learning rate0.0013333333333333333, loss:3.0894455909729004
batch i:882
learning rate0.0013333333333333333, loss:3.081035614013672
batch i:883
learning rate0.0013333333333333333, loss:3.168123722076416
batch i:884
learning rate0.0013333333333333333, loss:3.150984764099121
batch i:885
learning rate0.0013333333333333333, loss:3.143294334411621
batch i:886
learning rate0.0013333333333333333, loss:3.1060895919799805
batch i:887
learning rate0.0013333333333333333, loss:3.192256212234497
batch i:888
learning rate0.0013333333333333333, loss:3.0979580879211426
batch i:889
learning rate0.0013333333333333333, loss:3.198383331298828
batch i:890
learning rate0.0013333333333333333, loss:3.097437858581543
batch i:891
learning rate0.0013333333333333333, loss:3.1166820526123047
batch i:892
learning rate0.0013333333333333333, loss:3.1323280334472656
batch i:893
learning rate0.0013333333333333333, loss:3.156033515930176
batch i:894
learning rate0.0013333333333333333, loss:3.101982593536377
batch i:895
learning rate0.0013333333333333333, loss:3.0456032752990723
batch i:896
learning rate0.0013333333333333333, loss:3.0425312519073486
batch i:897
learning rate0.0013333333333333333, loss:3.05529522895813
batch i:898
learning rate0.0013333333333333333, loss:3.1677865982055664
batch i:899
learning rate0.0013333333333333333, loss:3.1895956993103027
batch i:900
learning rate0.0013333333333333333, loss:3.117851734161377
current self-play batch: 900
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 730.7511852025985
New best policy by beating the previous best
batch i:901
learning rate0.0013333333333333333, loss:3.210594892501831
batch i:902
learning rate0.0013333333333333333, loss:3.2617223262786865
batch i:903
learning rate0.0013333333333333333, loss:3.1142587661743164
batch i:904
learning rate0.0013333333333333333, loss:3.182900905609131
batch i:905
learning rate0.0013333333333333333, loss:3.2380542755126953
batch i:906
learning rate0.0013333333333333333, loss:3.109450340270996
batch i:907
learning rate0.0013333333333333333, loss:3.276606559753418
batch i:908
learning rate0.0013333333333333333, loss:3.143655300140381
batch i:909
learning rate0.0013333333333333333, loss:3.233734130859375
batch i:910
learning rate0.0013333333333333333, loss:3.128753662109375
batch i:911
learning rate0.0013333333333333333, loss:3.190417766571045
batch i:912
learning rate0.0013333333333333333, loss:3.196129083633423
batch i:913
learning rate0.0013333333333333333, loss:3.0683398246765137
batch i:914
learning rate0.0013333333333333333, loss:3.0523455142974854
batch i:915
learning rate0.0013333333333333333, loss:3.118575096130371
batch i:916
learning rate0.0013333333333333333, loss:3.082258701324463
batch i:917
learning rate0.0013333333333333333, loss:3.1461119651794434
batch i:918
learning rate0.0013333333333333333, loss:3.125685214996338
batch i:919
learning rate0.0013333333333333333, loss:3.0793325901031494
batch i:920
learning rate0.0013333333333333333, loss:3.1474218368530273
batch i:921
learning rate0.0013333333333333333, loss:3.1270198822021484
batch i:922
learning rate0.0013333333333333333, loss:3.140044689178467
batch i:923
learning rate0.0013333333333333333, loss:3.1732187271118164
batch i:924
learning rate0.0013333333333333333, loss:3.1697797775268555
batch i:925
learning rate0.0013333333333333333, loss:3.1234474182128906
batch i:926
learning rate0.0013333333333333333, loss:3.1332623958587646
batch i:927
learning rate0.0013333333333333333, loss:3.087615489959717
batch i:928
learning rate0.0013333333333333333, loss:3.09474515914917
batch i:929
learning rate0.0013333333333333333, loss:3.041318893432617
batch i:930
learning rate0.0013333333333333333, loss:3.151423931121826
batch i:931
learning rate0.0013333333333333333, loss:3.0400843620300293
batch i:932
learning rate0.0013333333333333333, loss:3.0996150970458984
batch i:933
learning rate0.0013333333333333333, loss:3.0768158435821533
batch i:934
learning rate0.0013333333333333333, loss:3.040630578994751
batch i:935
learning rate0.0013333333333333333, loss:2.9927492141723633
batch i:936
learning rate0.0013333333333333333, loss:3.149716854095459
batch i:937
learning rate0.0013333333333333333, loss:3.129422187805176
batch i:938
learning rate0.0013333333333333333, loss:3.1290462017059326
batch i:939
learning rate0.0013333333333333333, loss:3.071014404296875
batch i:940
learning rate0.0013333333333333333, loss:3.017237663269043
batch i:941
learning rate0.0013333333333333333, loss:3.0335869789123535
batch i:942
learning rate0.0013333333333333333, loss:3.132918119430542
batch i:943
learning rate0.0013333333333333333, loss:3.081845760345459
batch i:944
learning rate0.0013333333333333333, loss:3.187364101409912
batch i:945
learning rate0.0013333333333333333, loss:3.0332818031311035
batch i:946
learning rate0.0013333333333333333, loss:3.238834857940674
batch i:947
learning rate0.0013333333333333333, loss:3.1071205139160156
batch i:948
learning rate0.0013333333333333333, loss:3.063765287399292
batch i:949
learning rate0.0013333333333333333, loss:3.1127753257751465
batch i:950
learning rate0.0013333333333333333, loss:3.1595687866210938
current self-play batch: 950
num_playouts:2000, win: 4, lose: 6, tie:0
average time: 276.7624141454697
batch i:951
learning rate0.0013333333333333333, loss:3.0609941482543945
batch i:952
learning rate0.0013333333333333333, loss:3.059579372406006
batch i:953
learning rate0.0013333333333333333, loss:3.066871166229248
batch i:954
learning rate0.0013333333333333333, loss:3.098160743713379
batch i:955
learning rate0.0013333333333333333, loss:3.1271989345550537
batch i:956
learning rate0.0013333333333333333, loss:3.083207130432129
batch i:957
learning rate0.0013333333333333333, loss:3.154106855392456
batch i:958
learning rate0.0013333333333333333, loss:3.171194076538086
batch i:959
learning rate0.0013333333333333333, loss:3.1194114685058594
batch i:960
learning rate0.0013333333333333333, loss:3.097649097442627
batch i:961
learning rate0.0013333333333333333, loss:3.0601425170898438
batch i:962
learning rate0.0013333333333333333, loss:3.0949368476867676
batch i:963
learning rate0.0013333333333333333, loss:3.199918746948242
batch i:964
learning rate0.0013333333333333333, loss:3.0865697860717773
batch i:965
learning rate0.0013333333333333333, loss:3.063964366912842
batch i:966
learning rate0.0013333333333333333, loss:3.124675750732422
batch i:967
learning rate0.0013333333333333333, loss:3.054202079772949
batch i:968
learning rate0.0013333333333333333, loss:3.127819061279297
batch i:969
learning rate0.0013333333333333333, loss:3.1289939880371094
batch i:970
learning rate0.0013333333333333333, loss:3.142963171005249
batch i:971
learning rate0.0013333333333333333, loss:3.0540781021118164
batch i:972
learning rate0.0013333333333333333, loss:3.12833833694458
batch i:973
learning rate0.0013333333333333333, loss:3.1113669872283936
batch i:974
learning rate0.0013333333333333333, loss:3.142545223236084
batch i:975
learning rate0.0013333333333333333, loss:3.1114110946655273
batch i:976
learning rate0.0013333333333333333, loss:3.0978786945343018
batch i:977
learning rate0.0013333333333333333, loss:3.0536954402923584
batch i:978
learning rate0.0013333333333333333, loss:3.1528120040893555
batch i:979
learning rate0.0013333333333333333, loss:3.106210708618164
batch i:980
learning rate0.0013333333333333333, loss:3.033830165863037
batch i:981
learning rate0.0013333333333333333, loss:3.140286922454834
batch i:982
learning rate0.0013333333333333333, loss:3.098278522491455
batch i:983
learning rate0.0013333333333333333, loss:3.078618049621582
batch i:984
learning rate0.0013333333333333333, loss:3.148670196533203
batch i:985
learning rate0.0013333333333333333, loss:3.0511608123779297
batch i:986
learning rate0.0013333333333333333, loss:3.01967716217041
batch i:987
learning rate0.0013333333333333333, loss:3.08412504196167
batch i:988
learning rate0.0013333333333333333, loss:3.0152029991149902
batch i:989
learning rate0.0013333333333333333, loss:3.0163283348083496
batch i:990
learning rate0.0013333333333333333, loss:3.0902140140533447
batch i:991
learning rate0.0013333333333333333, loss:3.0518627166748047
batch i:992
learning rate0.0013333333333333333, loss:3.116074323654175
batch i:993
learning rate0.0013333333333333333, loss:3.179759979248047
batch i:994
learning rate0.0013333333333333333, loss:3.0879549980163574
batch i:995
learning rate0.0013333333333333333, loss:3.033015727996826
batch i:996
learning rate0.0013333333333333333, loss:3.092196226119995
batch i:997
learning rate0.0013333333333333333, loss:3.110600471496582
batch i:998
learning rate0.0013333333333333333, loss:3.151864528656006
batch i:999
learning rate0.0013333333333333333, loss:3.006978750228882
batch i:1000
learning rate0.0013333333333333333, loss:2.997060537338257
current self-play batch: 1000
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 252.964759016037
batch i:1001
learning rate0.0013333333333333333, loss:3.0364115238189697
batch i:1002
learning rate0.0013333333333333333, loss:3.0445632934570312
batch i:1003
learning rate0.0013333333333333333, loss:3.049610137939453
batch i:1004
learning rate0.0013333333333333333, loss:3.102966785430908
batch i:1005
learning rate0.0013333333333333333, loss:3.109898090362549
batch i:1006
learning rate0.0013333333333333333, loss:3.1971518993377686
batch i:1007
learning rate0.0013333333333333333, loss:3.1345629692077637
batch i:1008
learning rate0.0013333333333333333, loss:3.0558950901031494
batch i:1009
learning rate0.0013333333333333333, loss:3.0315113067626953
batch i:1010
learning rate0.0013333333333333333, loss:3.0302467346191406
batch i:1011
learning rate0.0013333333333333333, loss:3.0794477462768555
batch i:1012
learning rate0.0013333333333333333, loss:3.0651564598083496
batch i:1013
learning rate0.0013333333333333333, loss:3.1712169647216797
batch i:1014
learning rate0.0013333333333333333, loss:3.1003193855285645
batch i:1015
learning rate0.0013333333333333333, loss:3.0093038082122803
batch i:1016
learning rate0.0013333333333333333, loss:3.0527901649475098
batch i:1017
learning rate0.0013333333333333333, loss:3.1454386711120605
batch i:1018
learning rate0.0013333333333333333, loss:3.0241355895996094
batch i:1019
learning rate0.0013333333333333333, loss:3.0519964694976807
batch i:1020
learning rate0.0013333333333333333, loss:3.00700044631958
batch i:1021
learning rate0.0013333333333333333, loss:3.063502311706543
batch i:1022
learning rate0.0013333333333333333, loss:3.085164785385132
batch i:1023
learning rate0.0013333333333333333, loss:3.1498687267303467
batch i:1024
learning rate0.0013333333333333333, loss:3.09738826751709
batch i:1025
learning rate0.0013333333333333333, loss:3.0729591846466064
batch i:1026
learning rate0.0013333333333333333, loss:3.0405426025390625
batch i:1027
learning rate0.0013333333333333333, loss:3.089837074279785
batch i:1028
learning rate0.0013333333333333333, loss:3.0075974464416504
batch i:1029
learning rate0.0013333333333333333, loss:3.114259719848633
batch i:1030
learning rate0.0013333333333333333, loss:3.0855917930603027
batch i:1031
learning rate0.0013333333333333333, loss:3.1147022247314453
batch i:1032
learning rate0.0013333333333333333, loss:3.0846312046051025
batch i:1033
learning rate0.0013333333333333333, loss:3.0239968299865723
batch i:1034
learning rate0.0013333333333333333, loss:3.1126885414123535
batch i:1035
learning rate0.0013333333333333333, loss:3.069566249847412
batch i:1036
learning rate0.0013333333333333333, loss:3.005586862564087
batch i:1037
learning rate0.0013333333333333333, loss:3.0202269554138184
batch i:1038
learning rate0.0013333333333333333, loss:3.0094194412231445
batch i:1039
learning rate0.0013333333333333333, loss:3.07865571975708
batch i:1040
learning rate0.0013333333333333333, loss:3.095351219177246
batch i:1041
learning rate0.0013333333333333333, loss:3.064697742462158
batch i:1042
learning rate0.0013333333333333333, loss:3.1339151859283447
batch i:1043
learning rate0.0013333333333333333, loss:3.122558355331421
batch i:1044
learning rate0.0013333333333333333, loss:3.1037302017211914
batch i:1045
learning rate0.0013333333333333333, loss:3.2172703742980957
batch i:1046
learning rate0.0013333333333333333, loss:3.0832109451293945
batch i:1047
learning rate0.0013333333333333333, loss:3.1247398853302
batch i:1048
learning rate0.0013333333333333333, loss:3.137281894683838
batch i:1049
learning rate0.0013333333333333333, loss:3.132969856262207
batch i:1050
learning rate0.0013333333333333333, loss:3.1575303077697754
current self-play batch: 1050
num_playouts:2000, win: 6, lose: 4, tie:0
average time: 250.74780781269072
batch i:1051
learning rate0.0013333333333333333, loss:3.155892848968506
batch i:1052
learning rate0.0013333333333333333, loss:3.1487107276916504
batch i:1053
learning rate0.0013333333333333333, loss:3.239184617996216
batch i:1054
learning rate0.0013333333333333333, loss:3.2220311164855957
batch i:1055
learning rate0.0013333333333333333, loss:3.160787582397461
batch i:1056
learning rate0.0013333333333333333, loss:3.0660483837127686
batch i:1057
learning rate0.0013333333333333333, loss:3.188504219055176
batch i:1058
learning rate0.0013333333333333333, loss:3.163996696472168
batch i:1059
learning rate0.0013333333333333333, loss:3.2226057052612305
batch i:1060
learning rate0.0013333333333333333, loss:3.13883638381958
batch i:1061
learning rate0.0013333333333333333, loss:3.294119358062744
batch i:1062
learning rate0.0013333333333333333, loss:3.1418848037719727
batch i:1063
learning rate0.0013333333333333333, loss:3.1210927963256836
batch i:1064
learning rate0.0013333333333333333, loss:3.2402358055114746
batch i:1065
learning rate0.0013333333333333333, loss:3.1494343280792236
batch i:1066
learning rate0.0013333333333333333, loss:3.2010788917541504
batch i:1067
learning rate0.0013333333333333333, loss:3.190877914428711
batch i:1068
learning rate0.0013333333333333333, loss:3.100399971008301
batch i:1069
learning rate0.0013333333333333333, loss:3.1130428314208984
batch i:1070
learning rate0.0013333333333333333, loss:3.0892200469970703
batch i:1071
learning rate0.0013333333333333333, loss:3.161325454711914
batch i:1072
learning rate0.0013333333333333333, loss:3.0994067192077637
batch i:1073
learning rate0.0013333333333333333, loss:3.129148006439209
batch i:1074
learning rate0.0013333333333333333, loss:3.100616931915283
batch i:1075
learning rate0.0013333333333333333, loss:2.9941208362579346
batch i:1076
learning rate0.0013333333333333333, loss:3.1704177856445312
batch i:1077
learning rate0.0013333333333333333, loss:3.1105430126190186
batch i:1078
learning rate0.0013333333333333333, loss:3.101351737976074
batch i:1079
learning rate0.0013333333333333333, loss:3.0937790870666504
batch i:1080
learning rate0.0013333333333333333, loss:3.116645336151123
batch i:1081
learning rate0.0013333333333333333, loss:3.0759403705596924
batch i:1082
learning rate0.0013333333333333333, loss:3.0403599739074707
batch i:1083
learning rate0.0013333333333333333, loss:3.1206440925598145
batch i:1084
learning rate0.0013333333333333333, loss:3.103853702545166
batch i:1085
learning rate0.0013333333333333333, loss:3.1954712867736816
batch i:1086
learning rate0.0013333333333333333, loss:3.0322370529174805
batch i:1087
learning rate0.0013333333333333333, loss:3.1652398109436035
batch i:1088
learning rate0.0013333333333333333, loss:3.0879390239715576
batch i:1089
learning rate0.0013333333333333333, loss:3.1377596855163574
batch i:1090
learning rate0.0013333333333333333, loss:3.1276326179504395
batch i:1091
learning rate0.0013333333333333333, loss:3.117025136947632
batch i:1092
learning rate0.0013333333333333333, loss:3.1406028270721436
batch i:1093
learning rate0.0013333333333333333, loss:3.1170287132263184
batch i:1094
learning rate0.0013333333333333333, loss:3.062098264694214
batch i:1095
learning rate0.0013333333333333333, loss:3.106797218322754
batch i:1096
learning rate0.0013333333333333333, loss:3.1710455417633057
batch i:1097
learning rate0.0013333333333333333, loss:3.1879324913024902
batch i:1098
learning rate0.0013333333333333333, loss:3.252675771713257
batch i:1099
learning rate0.0013333333333333333, loss:3.286374807357788
batch i:1100
learning rate0.0013333333333333333, loss:3.164703845977783
current self-play batch: 1100
num_playouts:2000, win: 5, lose: 5, tie:0
average time: 265.04200360774996
batch i:1101
learning rate0.0013333333333333333, loss:3.0811710357666016
batch i:1102
learning rate0.0013333333333333333, loss:3.321903705596924
batch i:1103
learning rate0.0013333333333333333, loss:3.1879615783691406
batch i:1104
learning rate0.0013333333333333333, loss:3.2407379150390625
batch i:1105
learning rate0.0013333333333333333, loss:3.1207387447357178
batch i:1106
learning rate0.0013333333333333333, loss:3.0314149856567383
batch i:1107
learning rate0.0013333333333333333, loss:3.1824769973754883
batch i:1108
learning rate0.0013333333333333333, loss:3.181760311126709
batch i:1109
learning rate0.0013333333333333333, loss:3.198347330093384
batch i:1110
learning rate0.0013333333333333333, loss:3.2624356746673584
batch i:1111
learning rate0.0013333333333333333, loss:3.27066707611084
batch i:1112
learning rate0.0013333333333333333, loss:3.311847448348999
batch i:1113
learning rate0.0013333333333333333, loss:3.2264533042907715
batch i:1114
learning rate0.0013333333333333333, loss:3.1836092472076416
batch i:1115
learning rate0.0013333333333333333, loss:3.2371931076049805
batch i:1116
learning rate0.0013333333333333333, loss:3.1691598892211914
batch i:1117
learning rate0.0013333333333333333, loss:3.200986385345459
batch i:1118
learning rate0.0013333333333333333, loss:3.208270788192749
batch i:1119
learning rate0.0013333333333333333, loss:3.2394983768463135
batch i:1120
learning rate0.0013333333333333333, loss:3.207427978515625
batch i:1121
learning rate0.0013333333333333333, loss:3.108809471130371
batch i:1122
learning rate0.0013333333333333333, loss:3.103059768676758
batch i:1123
learning rate0.0013333333333333333, loss:3.098268747329712
batch i:1124
learning rate0.0013333333333333333, loss:3.158142566680908
batch i:1125
learning rate0.0013333333333333333, loss:3.252366304397583
batch i:1126
learning rate0.0013333333333333333, loss:3.1469321250915527
batch i:1127
learning rate0.0013333333333333333, loss:3.140669345855713
batch i:1128
learning rate0.0013333333333333333, loss:3.199733257293701
batch i:1129
learning rate0.0013333333333333333, loss:3.1648716926574707
batch i:1130
learning rate0.0013333333333333333, loss:3.142378568649292
batch i:1131
learning rate0.0013333333333333333, loss:3.0885238647460938
batch i:1132
learning rate0.0013333333333333333, loss:3.0791890621185303
batch i:1133
learning rate0.0013333333333333333, loss:3.1411936283111572
batch i:1134
learning rate0.0013333333333333333, loss:3.142272472381592
batch i:1135
learning rate0.0013333333333333333, loss:3.130096912384033
batch i:1136
learning rate0.0013333333333333333, loss:3.1668953895568848
batch i:1137
learning rate0.0013333333333333333, loss:3.162665843963623
batch i:1138
learning rate0.0013333333333333333, loss:3.0689897537231445
batch i:1139
learning rate0.0013333333333333333, loss:3.1251437664031982
batch i:1140
learning rate0.0013333333333333333, loss:3.1135013103485107
batch i:1141
learning rate0.0013333333333333333, loss:3.129697561264038
batch i:1142
learning rate0.0013333333333333333, loss:3.111022472381592
batch i:1143
learning rate0.0013333333333333333, loss:3.1191768646240234
batch i:1144
learning rate0.0013333333333333333, loss:3.0739188194274902
batch i:1145
learning rate0.0013333333333333333, loss:3.1107311248779297
batch i:1146
learning rate0.0013333333333333333, loss:3.041891574859619
batch i:1147
learning rate0.0013333333333333333, loss:3.1888232231140137
batch i:1148
learning rate0.0013333333333333333, loss:3.118044376373291
batch i:1149
learning rate0.0013333333333333333, loss:3.187779426574707
batch i:1150
learning rate0.0013333333333333333, loss:2.995849132537842
current self-play batch: 1150
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 265.71536169052126
batch i:1151
learning rate0.0013333333333333333, loss:3.136949062347412
batch i:1152
learning rate0.0013333333333333333, loss:3.1704347133636475
batch i:1153
learning rate0.0013333333333333333, loss:3.131844997406006
batch i:1154
learning rate0.0013333333333333333, loss:3.1373205184936523
batch i:1155
learning rate0.0013333333333333333, loss:3.0977187156677246
batch i:1156
learning rate0.0013333333333333333, loss:3.060655355453491
batch i:1157
learning rate0.0013333333333333333, loss:3.172779083251953
batch i:1158
learning rate0.0013333333333333333, loss:3.1091370582580566
batch i:1159
learning rate0.0013333333333333333, loss:3.239664077758789
batch i:1160
learning rate0.0013333333333333333, loss:3.128908157348633
batch i:1161
learning rate0.0013333333333333333, loss:3.140761375427246
batch i:1162
learning rate0.0013333333333333333, loss:3.1760857105255127
batch i:1163
learning rate0.0013333333333333333, loss:3.159385919570923
batch i:1164
learning rate0.0013333333333333333, loss:3.084486246109009
batch i:1165
learning rate0.0013333333333333333, loss:3.109865188598633
batch i:1166
learning rate0.0013333333333333333, loss:3.105020523071289
batch i:1167
learning rate0.0013333333333333333, loss:3.1888651847839355
batch i:1168
learning rate0.0013333333333333333, loss:3.1017684936523438
batch i:1169
learning rate0.0013333333333333333, loss:3.1187922954559326
batch i:1170
learning rate0.0013333333333333333, loss:3.1561450958251953
batch i:1171
learning rate0.0013333333333333333, loss:3.200000286102295
batch i:1172
learning rate0.0013333333333333333, loss:3.174466609954834
batch i:1173
learning rate0.0013333333333333333, loss:3.1391990184783936
batch i:1174
learning rate0.0013333333333333333, loss:3.0193045139312744
batch i:1175
learning rate0.0013333333333333333, loss:3.1084084510803223
batch i:1176
learning rate0.0013333333333333333, loss:3.067253589630127
batch i:1177
learning rate0.0013333333333333333, loss:3.077641248703003
batch i:1178
learning rate0.0013333333333333333, loss:3.149427890777588
batch i:1179
learning rate0.0013333333333333333, loss:3.105288505554199
batch i:1180
learning rate0.0013333333333333333, loss:3.0907537937164307
batch i:1181
learning rate0.0013333333333333333, loss:3.1486458778381348
batch i:1182
learning rate0.0013333333333333333, loss:3.151433229446411
batch i:1183
learning rate0.0013333333333333333, loss:3.0926685333251953
batch i:1184
learning rate0.0013333333333333333, loss:3.1697957515716553
batch i:1185
learning rate0.0013333333333333333, loss:3.0992612838745117
batch i:1186
learning rate0.0013333333333333333, loss:3.164486885070801
batch i:1187
learning rate0.0013333333333333333, loss:3.0744965076446533
batch i:1188
learning rate0.0013333333333333333, loss:3.050355911254883
batch i:1189
learning rate0.0013333333333333333, loss:3.131847381591797
batch i:1190
learning rate0.0013333333333333333, loss:3.133347272872925
batch i:1191
learning rate0.0013333333333333333, loss:3.0741310119628906
batch i:1192
learning rate0.0013333333333333333, loss:3.0988080501556396
batch i:1193
learning rate0.0013333333333333333, loss:3.1572632789611816
batch i:1194
learning rate0.0013333333333333333, loss:3.0493268966674805
batch i:1195
learning rate0.0013333333333333333, loss:3.1553921699523926
batch i:1196
learning rate0.0013333333333333333, loss:3.0805463790893555
batch i:1197
learning rate0.0013333333333333333, loss:3.1693687438964844
batch i:1198
learning rate0.0013333333333333333, loss:3.018986225128174
batch i:1199
learning rate0.0013333333333333333, loss:3.136228084564209
batch i:1200
learning rate0.0013333333333333333, loss:3.1482343673706055
current self-play batch: 1200
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 205.70439772605897
batch i:1201
learning rate0.0013333333333333333, loss:3.120807647705078
batch i:1202
learning rate0.0013333333333333333, loss:3.146603584289551
batch i:1203
learning rate0.0013333333333333333, loss:3.141946792602539
batch i:1204
learning rate0.0013333333333333333, loss:3.180776596069336
batch i:1205
learning rate0.0013333333333333333, loss:3.1907958984375
batch i:1206
learning rate0.0013333333333333333, loss:3.161560535430908
batch i:1207
learning rate0.0013333333333333333, loss:3.157444953918457
batch i:1208
learning rate0.0013333333333333333, loss:3.1665213108062744
batch i:1209
learning rate0.0013333333333333333, loss:3.1892833709716797
batch i:1210
learning rate0.0013333333333333333, loss:3.227919101715088
batch i:1211
learning rate0.0013333333333333333, loss:3.2174201011657715
batch i:1212
learning rate0.0013333333333333333, loss:3.185481071472168
batch i:1213
learning rate0.0013333333333333333, loss:3.265169620513916
batch i:1214
learning rate0.0013333333333333333, loss:3.1272521018981934
batch i:1215
learning rate0.0013333333333333333, loss:3.0954582691192627
batch i:1216
learning rate0.0013333333333333333, loss:3.0946009159088135
batch i:1217
learning rate0.0013333333333333333, loss:3.148026466369629
batch i:1218
learning rate0.0013333333333333333, loss:3.1122989654541016
batch i:1219
learning rate0.0013333333333333333, loss:3.179096221923828
batch i:1220
learning rate0.0013333333333333333, loss:3.171719789505005
batch i:1221
learning rate0.0013333333333333333, loss:3.1546874046325684
batch i:1222
learning rate0.0013333333333333333, loss:3.034695625305176
batch i:1223
learning rate0.0013333333333333333, loss:3.0965895652770996
batch i:1224
learning rate0.0013333333333333333, loss:3.0943796634674072
batch i:1225
learning rate0.0013333333333333333, loss:3.165215492248535
batch i:1226
learning rate0.0013333333333333333, loss:3.1330175399780273
batch i:1227
learning rate0.0013333333333333333, loss:3.130584239959717
batch i:1228
learning rate0.0013333333333333333, loss:3.038297176361084
batch i:1229
learning rate0.0013333333333333333, loss:3.1845626831054688
batch i:1230
learning rate0.0013333333333333333, loss:3.078972339630127
batch i:1231
learning rate0.0013333333333333333, loss:3.0072884559631348
batch i:1232
learning rate0.0013333333333333333, loss:3.056907892227173
batch i:1233
learning rate0.0013333333333333333, loss:3.0211353302001953
batch i:1234
learning rate0.0013333333333333333, loss:3.109060525894165
batch i:1235
learning rate0.0013333333333333333, loss:3.091709613800049
batch i:1236
learning rate0.0013333333333333333, loss:3.027461528778076
batch i:1237
learning rate0.0013333333333333333, loss:3.2241482734680176
batch i:1238
learning rate0.0013333333333333333, loss:3.134087085723877
batch i:1239
learning rate0.0013333333333333333, loss:3.0638887882232666
batch i:1240
learning rate0.0013333333333333333, loss:3.1175549030303955
batch i:1241
learning rate0.0013333333333333333, loss:3.111135244369507
batch i:1242
learning rate0.0013333333333333333, loss:3.1291122436523438
batch i:1243
learning rate0.0013333333333333333, loss:3.1758766174316406
batch i:1244
learning rate0.0013333333333333333, loss:3.086834669113159
batch i:1245
learning rate0.0013333333333333333, loss:3.20054030418396
batch i:1246
learning rate0.0013333333333333333, loss:3.112186908721924
batch i:1247
learning rate0.0013333333333333333, loss:3.2076377868652344
batch i:1248
learning rate0.0013333333333333333, loss:3.025071144104004
batch i:1249
learning rate0.0013333333333333333, loss:3.1342804431915283
batch i:1250
learning rate0.0013333333333333333, loss:3.0241661071777344
current self-play batch: 1250
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 192.1780823469162
batch i:1251
learning rate0.0013333333333333333, loss:3.133317470550537
batch i:1252
learning rate0.0013333333333333333, loss:2.98538875579834
batch i:1253
learning rate0.0013333333333333333, loss:3.047077178955078
batch i:1254
learning rate0.0013333333333333333, loss:3.14670467376709
batch i:1255
learning rate0.0013333333333333333, loss:3.100935935974121
batch i:1256
learning rate0.0013333333333333333, loss:3.0309629440307617
batch i:1257
learning rate0.0013333333333333333, loss:2.9889159202575684
batch i:1258
learning rate0.0013333333333333333, loss:3.119607448577881
batch i:1259
learning rate0.0013333333333333333, loss:3.052772045135498
batch i:1260
learning rate0.0013333333333333333, loss:3.084641456604004
batch i:1261
learning rate0.0013333333333333333, loss:3.075524091720581
batch i:1262
learning rate0.0013333333333333333, loss:3.073612689971924
batch i:1263
learning rate0.0013333333333333333, loss:3.141045331954956
batch i:1264
learning rate0.0013333333333333333, loss:3.095106840133667
batch i:1265
learning rate0.0013333333333333333, loss:3.122708797454834
batch i:1266
learning rate0.0013333333333333333, loss:3.1358652114868164
batch i:1267
learning rate0.0013333333333333333, loss:3.1710801124572754
batch i:1268
learning rate0.0013333333333333333, loss:3.122664451599121
batch i:1269
learning rate0.0013333333333333333, loss:3.0931105613708496
batch i:1270
learning rate0.0013333333333333333, loss:3.1948330402374268
batch i:1271
learning rate0.0013333333333333333, loss:3.1391749382019043
batch i:1272
learning rate0.0013333333333333333, loss:3.1572649478912354
batch i:1273
learning rate0.0013333333333333333, loss:3.1906609535217285
batch i:1274
learning rate0.0013333333333333333, loss:3.268404960632324
batch i:1275
learning rate0.0013333333333333333, loss:3.1756858825683594
batch i:1276
learning rate0.0013333333333333333, loss:3.21348237991333
batch i:1277
learning rate0.0013333333333333333, loss:3.2454447746276855
batch i:1278
learning rate0.0013333333333333333, loss:3.1354329586029053
batch i:1279
learning rate0.0013333333333333333, loss:3.204439640045166
batch i:1280
learning rate0.0013333333333333333, loss:3.1692070960998535
batch i:1281
learning rate0.0013333333333333333, loss:3.062192916870117
batch i:1282
learning rate0.0013333333333333333, loss:3.1010730266571045
batch i:1283
learning rate0.0013333333333333333, loss:3.184143543243408
batch i:1284
learning rate0.0013333333333333333, loss:3.146879196166992
batch i:1285
learning rate0.0013333333333333333, loss:2.972555160522461
batch i:1286
learning rate0.0013333333333333333, loss:3.0278451442718506
batch i:1287
learning rate0.0013333333333333333, loss:3.0718321800231934
batch i:1288
learning rate0.0013333333333333333, loss:3.2139511108398438
batch i:1289
learning rate0.0013333333333333333, loss:3.1761221885681152
batch i:1290
learning rate0.0013333333333333333, loss:3.1607911586761475
batch i:1291
learning rate0.0013333333333333333, loss:3.0520923137664795
batch i:1292
learning rate0.0013333333333333333, loss:3.0692780017852783
batch i:1293
learning rate0.0013333333333333333, loss:3.1472830772399902
batch i:1294
learning rate0.0013333333333333333, loss:3.0779080390930176
batch i:1295
learning rate0.0013333333333333333, loss:3.143895387649536
batch i:1296
learning rate0.0013333333333333333, loss:3.2026734352111816
batch i:1297
learning rate0.0013333333333333333, loss:3.08327317237854
batch i:1298
learning rate0.0013333333333333333, loss:3.184356212615967
batch i:1299
learning rate0.0013333333333333333, loss:3.1164329051971436
batch i:1300
learning rate0.0013333333333333333, loss:3.2235867977142334
current self-play batch: 1300
num_playouts:2000, win: 6, lose: 4, tie:0
average time: 286.2626673460007
batch i:1301
learning rate0.0013333333333333333, loss:3.1855297088623047
batch i:1302
learning rate0.0013333333333333333, loss:3.0975735187530518
batch i:1303
learning rate0.0013333333333333333, loss:3.101177215576172
batch i:1304
learning rate0.0013333333333333333, loss:3.097745656967163
batch i:1305
learning rate0.0013333333333333333, loss:3.0603444576263428
batch i:1306
learning rate0.0013333333333333333, loss:3.063847541809082
batch i:1307
learning rate0.0013333333333333333, loss:3.0984256267547607
batch i:1308
learning rate0.0013333333333333333, loss:3.021358013153076
batch i:1309
learning rate0.0013333333333333333, loss:3.06093168258667
batch i:1310
learning rate0.0013333333333333333, loss:3.0247273445129395
batch i:1311
learning rate0.0013333333333333333, loss:3.151515483856201
batch i:1312
learning rate0.0013333333333333333, loss:3.0236854553222656
batch i:1313
learning rate0.0013333333333333333, loss:3.0747101306915283
batch i:1314
learning rate0.0013333333333333333, loss:3.0732407569885254
batch i:1315
learning rate0.0013333333333333333, loss:3.0780463218688965
batch i:1316
learning rate0.0013333333333333333, loss:3.0912413597106934
batch i:1317
learning rate0.0013333333333333333, loss:3.0848066806793213
batch i:1318
learning rate0.0013333333333333333, loss:3.1849732398986816
batch i:1319
learning rate0.0013333333333333333, loss:3.125330924987793
batch i:1320
learning rate0.0013333333333333333, loss:3.0297892093658447
batch i:1321
learning rate0.0013333333333333333, loss:3.122734308242798
batch i:1322
learning rate0.0013333333333333333, loss:3.1167025566101074
batch i:1323
learning rate0.0013333333333333333, loss:3.186164617538452
batch i:1324
learning rate0.0013333333333333333, loss:3.111966609954834
batch i:1325
learning rate0.0013333333333333333, loss:3.250051975250244
batch i:1326
learning rate0.0013333333333333333, loss:3.1995346546173096
batch i:1327
learning rate0.0013333333333333333, loss:3.0763864517211914
batch i:1328
learning rate0.0013333333333333333, loss:3.1031179428100586
batch i:1329
learning rate0.0013333333333333333, loss:3.0951156616210938
batch i:1330
learning rate0.0013333333333333333, loss:3.1256158351898193
batch i:1331
learning rate0.0013333333333333333, loss:3.121969223022461
batch i:1332
learning rate0.0013333333333333333, loss:3.0898871421813965
batch i:1333
learning rate0.0013333333333333333, loss:3.129964828491211
batch i:1334
learning rate0.0013333333333333333, loss:3.0626678466796875
batch i:1335
learning rate0.0013333333333333333, loss:3.111506223678589
batch i:1336
learning rate0.0013333333333333333, loss:3.048999309539795
batch i:1337
learning rate0.0013333333333333333, loss:3.163355588912964
batch i:1338
learning rate0.0013333333333333333, loss:3.1061601638793945
batch i:1339
learning rate0.0013333333333333333, loss:3.10659122467041
batch i:1340
learning rate0.0013333333333333333, loss:3.050915241241455
batch i:1341
learning rate0.0013333333333333333, loss:3.0743985176086426
batch i:1342
learning rate0.0013333333333333333, loss:3.1385960578918457
batch i:1343
learning rate0.0013333333333333333, loss:3.0988993644714355
batch i:1344
learning rate0.0013333333333333333, loss:3.0696892738342285
batch i:1345
learning rate0.0013333333333333333, loss:3.061476230621338
batch i:1346
learning rate0.0013333333333333333, loss:3.120629072189331
batch i:1347
learning rate0.0013333333333333333, loss:3.0724072456359863
batch i:1348
learning rate0.0013333333333333333, loss:3.025455951690674
batch i:1349
learning rate0.0013333333333333333, loss:3.1213836669921875
batch i:1350
learning rate0.0013333333333333333, loss:3.149275302886963
current self-play batch: 1350
num_playouts:2000, win: 3, lose: 7, tie:0
average time: 378.14499406814576
batch i:1351
learning rate0.0013333333333333333, loss:3.2019758224487305
batch i:1352
learning rate0.0013333333333333333, loss:3.174633502960205
batch i:1353
learning rate0.0013333333333333333, loss:3.2264819145202637
batch i:1354
learning rate0.0013333333333333333, loss:3.1248674392700195
batch i:1355
learning rate0.0013333333333333333, loss:3.250612258911133
batch i:1356
learning rate0.0013333333333333333, loss:3.1476709842681885
batch i:1357
learning rate0.0013333333333333333, loss:3.1799142360687256
batch i:1358
learning rate0.0013333333333333333, loss:3.1138691902160645
batch i:1359
learning rate0.0013333333333333333, loss:3.0160868167877197
batch i:1360
learning rate0.0013333333333333333, loss:3.020383358001709
batch i:1361
learning rate0.0013333333333333333, loss:3.1249780654907227
batch i:1362
learning rate0.0013333333333333333, loss:3.066117525100708
batch i:1363
learning rate0.0013333333333333333, loss:3.2109179496765137
batch i:1364
learning rate0.0013333333333333333, loss:3.1768550872802734
batch i:1365
learning rate0.0013333333333333333, loss:3.1506311893463135
batch i:1366
learning rate0.0013333333333333333, loss:3.1845288276672363
batch i:1367
learning rate0.0013333333333333333, loss:3.1851491928100586
batch i:1368
learning rate0.0013333333333333333, loss:3.194307804107666
batch i:1369
learning rate0.0013333333333333333, loss:3.099418878555298
batch i:1370
learning rate0.0013333333333333333, loss:3.0638716220855713
batch i:1371
learning rate0.0013333333333333333, loss:3.060558319091797
batch i:1372
learning rate0.0013333333333333333, loss:3.0811381340026855
batch i:1373
learning rate0.0013333333333333333, loss:3.0917153358459473
batch i:1374
learning rate0.0013333333333333333, loss:3.074763298034668
batch i:1375
learning rate0.0013333333333333333, loss:3.048175811767578
batch i:1376
learning rate0.0013333333333333333, loss:2.9695022106170654
batch i:1377
learning rate0.0013333333333333333, loss:3.0355758666992188
batch i:1378
learning rate0.0013333333333333333, loss:3.0636587142944336
batch i:1379
learning rate0.0013333333333333333, loss:3.0111637115478516
batch i:1380
learning rate0.0013333333333333333, loss:2.958449363708496
batch i:1381
learning rate0.0013333333333333333, loss:3.0204458236694336
batch i:1382
learning rate0.0013333333333333333, loss:3.058382749557495
batch i:1383
learning rate0.0013333333333333333, loss:2.9876961708068848
batch i:1384
learning rate0.0013333333333333333, loss:3.0094361305236816
batch i:1385
learning rate0.0013333333333333333, loss:3.045680046081543
batch i:1386
learning rate0.0013333333333333333, loss:3.017364501953125
batch i:1387
learning rate0.0013333333333333333, loss:2.9890379905700684
batch i:1388
learning rate0.0013333333333333333, loss:2.9577598571777344
batch i:1389
learning rate0.0013333333333333333, loss:2.980106830596924
batch i:1390
learning rate0.0013333333333333333, loss:2.9482460021972656
batch i:1391
learning rate0.0013333333333333333, loss:3.0364770889282227
batch i:1392
learning rate0.0013333333333333333, loss:3.0371789932250977
batch i:1393
learning rate0.0013333333333333333, loss:3.036384105682373
batch i:1394
learning rate0.0013333333333333333, loss:3.0206236839294434
batch i:1395
learning rate0.0013333333333333333, loss:2.9541783332824707
batch i:1396
learning rate0.0013333333333333333, loss:3.043457508087158
batch i:1397
learning rate0.0013333333333333333, loss:2.8640317916870117
batch i:1398
learning rate0.0013333333333333333, loss:3.0210673809051514
batch i:1399
learning rate0.0013333333333333333, loss:3.057433605194092
batch i:1400
learning rate0.0013333333333333333, loss:2.9788718223571777
current self-play batch: 1400
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 251.2147047996521
batch i:1401
learning rate0.0013333333333333333, loss:2.9651732444763184
batch i:1402
learning rate0.0013333333333333333, loss:2.978778839111328
batch i:1403
learning rate0.0013333333333333333, loss:2.846438407897949
batch i:1404
learning rate0.0013333333333333333, loss:3.016779899597168
batch i:1405
learning rate0.0013333333333333333, loss:3.0526862144470215
batch i:1406
learning rate0.0013333333333333333, loss:3.0412001609802246
batch i:1407
learning rate0.0013333333333333333, loss:2.909885883331299
batch i:1408
learning rate0.0013333333333333333, loss:3.0453755855560303
batch i:1409
learning rate0.0013333333333333333, loss:2.90440034866333
batch i:1410
learning rate0.0013333333333333333, loss:3.0572116374969482
batch i:1411
learning rate0.0013333333333333333, loss:2.833828926086426
batch i:1412
learning rate0.0013333333333333333, loss:2.9004828929901123
batch i:1413
learning rate0.0013333333333333333, loss:2.999495506286621
batch i:1414
learning rate0.0013333333333333333, loss:2.948761224746704
batch i:1415
learning rate0.0013333333333333333, loss:2.975965976715088
batch i:1416
learning rate0.0013333333333333333, loss:3.078132152557373
batch i:1417
learning rate0.0013333333333333333, loss:3.007664918899536
batch i:1418
learning rate0.0013333333333333333, loss:2.9606504440307617
batch i:1419
learning rate0.0013333333333333333, loss:2.944526433944702
batch i:1420
learning rate0.0013333333333333333, loss:2.9654500484466553
batch i:1421
learning rate0.0013333333333333333, loss:3.0314197540283203
batch i:1422
learning rate0.0013333333333333333, loss:2.9833383560180664
batch i:1423
learning rate0.0013333333333333333, loss:2.982067108154297
batch i:1424
learning rate0.0013333333333333333, loss:3.1197986602783203
batch i:1425
learning rate0.0013333333333333333, loss:2.999690055847168
batch i:1426
learning rate0.0013333333333333333, loss:3.0989558696746826
batch i:1427
learning rate0.0013333333333333333, loss:2.9859681129455566
batch i:1428
learning rate0.0013333333333333333, loss:3.0021281242370605
batch i:1429
learning rate0.0013333333333333333, loss:3.0128674507141113
batch i:1430
learning rate0.0013333333333333333, loss:2.9593935012817383
batch i:1431
learning rate0.0013333333333333333, loss:3.0078063011169434
batch i:1432
learning rate0.0013333333333333333, loss:3.019672393798828
batch i:1433
learning rate0.0013333333333333333, loss:3.1063156127929688
batch i:1434
learning rate0.0013333333333333333, loss:3.0873000621795654
batch i:1435
learning rate0.0013333333333333333, loss:2.9905195236206055
batch i:1436
learning rate0.0013333333333333333, loss:3.0037827491760254
batch i:1437
learning rate0.0013333333333333333, loss:2.986877679824829
batch i:1438
learning rate0.0013333333333333333, loss:3.0825018882751465
batch i:1439
learning rate0.0013333333333333333, loss:2.990854263305664
batch i:1440
learning rate0.0013333333333333333, loss:2.9954590797424316
batch i:1441
learning rate0.0013333333333333333, loss:3.0384440422058105
batch i:1442
learning rate0.0013333333333333333, loss:3.008239269256592
batch i:1443
learning rate0.0013333333333333333, loss:2.9746665954589844
batch i:1444
learning rate0.0013333333333333333, loss:3.076603889465332
batch i:1445
learning rate0.0013333333333333333, loss:2.9933481216430664
batch i:1446
learning rate0.0013333333333333333, loss:3.0589632987976074
batch i:1447
learning rate0.0013333333333333333, loss:3.0027031898498535
batch i:1448
learning rate0.0013333333333333333, loss:3.0177299976348877
batch i:1449
learning rate0.0013333333333333333, loss:3.046564817428589
batch i:1450
learning rate0.0013333333333333333, loss:3.098721981048584
current self-play batch: 1450
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 207.7190637588501
batch i:1451
learning rate0.0013333333333333333, loss:3.073809862136841
batch i:1452
learning rate0.0013333333333333333, loss:3.0326662063598633
batch i:1453
learning rate0.0013333333333333333, loss:2.98281192779541
batch i:1454
learning rate0.0013333333333333333, loss:3.111318349838257
batch i:1455
learning rate0.0013333333333333333, loss:2.9764556884765625
batch i:1456
learning rate0.0013333333333333333, loss:3.0580642223358154
batch i:1457
learning rate0.0013333333333333333, loss:3.003246784210205
batch i:1458
learning rate0.0013333333333333333, loss:3.03713321685791
batch i:1459
learning rate0.0013333333333333333, loss:2.992973566055298
batch i:1460
learning rate0.0013333333333333333, loss:3.0884833335876465
batch i:1461
learning rate0.0013333333333333333, loss:3.0808730125427246
batch i:1462
learning rate0.0013333333333333333, loss:3.082637071609497
batch i:1463
learning rate0.0013333333333333333, loss:2.998948097229004
batch i:1464
learning rate0.0013333333333333333, loss:3.0714833736419678
batch i:1465
learning rate0.0013333333333333333, loss:3.0137088298797607
batch i:1466
learning rate0.0013333333333333333, loss:3.03344988822937
batch i:1467
learning rate0.0013333333333333333, loss:2.9794678688049316
batch i:1468
learning rate0.0013333333333333333, loss:2.984436511993408
batch i:1469
learning rate0.0013333333333333333, loss:3.0788755416870117
batch i:1470
learning rate0.0013333333333333333, loss:2.940143585205078
batch i:1471
learning rate0.0013333333333333333, loss:3.053311824798584
batch i:1472
learning rate0.0013333333333333333, loss:3.0052623748779297
batch i:1473
learning rate0.0013333333333333333, loss:2.9195046424865723
batch i:1474
learning rate0.0013333333333333333, loss:2.8973746299743652
batch i:1475
learning rate0.0013333333333333333, loss:3.017483711242676
batch i:1476
learning rate0.0013333333333333333, loss:2.944547653198242
batch i:1477
learning rate0.0013333333333333333, loss:3.069401264190674
batch i:1478
learning rate0.0013333333333333333, loss:2.9579272270202637
batch i:1479
learning rate0.0013333333333333333, loss:2.9994091987609863
batch i:1480
learning rate0.0013333333333333333, loss:3.0756235122680664
batch i:1481
learning rate0.0013333333333333333, loss:2.9398598670959473
batch i:1482
learning rate0.0013333333333333333, loss:2.966726779937744
batch i:1483
learning rate0.0013333333333333333, loss:3.0073370933532715
batch i:1484
learning rate0.0013333333333333333, loss:3.0457756519317627
batch i:1485
learning rate0.0013333333333333333, loss:3.009033679962158
batch i:1486
learning rate0.0013333333333333333, loss:3.053561210632324
batch i:1487
learning rate0.0013333333333333333, loss:3.076970100402832
batch i:1488
learning rate0.0013333333333333333, loss:3.191574811935425
batch i:1489
learning rate0.0013333333333333333, loss:2.984330177307129
batch i:1490
learning rate0.0013333333333333333, loss:3.073672294616699
batch i:1491
learning rate0.0013333333333333333, loss:2.9372265338897705
batch i:1492
learning rate0.0013333333333333333, loss:2.9381375312805176
batch i:1493
learning rate0.0013333333333333333, loss:3.060343027114868
batch i:1494
learning rate0.0013333333333333333, loss:2.9779233932495117
batch i:1495
learning rate0.0013333333333333333, loss:2.9931252002716064
batch i:1496
learning rate0.0013333333333333333, loss:2.9556894302368164
batch i:1497
learning rate0.0013333333333333333, loss:3.0697569847106934
batch i:1498
learning rate0.0013333333333333333, loss:3.0328431129455566
batch i:1499
learning rate0.0013333333333333333, loss:2.9821958541870117
batch i:1500
learning rate0.0013333333333333333, loss:2.9288127422332764
current self-play batch: 1500
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 209.35095782279967
