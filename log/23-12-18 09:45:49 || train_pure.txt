Start time: 2023-12-18 09:45:49.181626
batch i:1
batch i:2
batch i:3
batch i:4
learning rate: 0.0013333333333333333, loss: 3.904360055923462
batch i:5
learning rate: 0.0013333333333333333, loss: 3.679576873779297
batch i:6
learning rate: 0.0008888888888888888, loss: 3.7365264892578125
batch i:7
learning rate: 0.0008888888888888888, loss: 3.643355369567871
batch i:8
learning rate: 0.0008888888888888888, loss: 3.2592551708221436
batch i:9
learning rate: 0.0008888888888888888, loss: 3.2130322456359863
batch i:10
learning rate: 0.0008888888888888888, loss: 3.431087017059326
batch i:11
learning rate: 0.0008888888888888888, loss: 3.2158002853393555
batch i:12
learning rate: 0.0013333333333333333, loss: 3.123084783554077
batch i:13
learning rate: 0.0013333333333333333, loss: 3.463500499725342
batch i:14
learning rate: 0.0013333333333333333, loss: 3.3891971111297607
batch i:15
learning rate: 0.0013333333333333333, loss: 3.50996994972229
batch i:16
learning rate: 0.0013333333333333333, loss: 3.2590622901916504
batch i:17
learning rate: 0.0013333333333333333, loss: 3.26487398147583
batch i:18
learning rate: 0.0013333333333333333, loss: 3.199070453643799
batch i:19
learning rate: 0.0013333333333333333, loss: 3.1976027488708496
batch i:20
learning rate: 0.0013333333333333333, loss: 3.0871710777282715
batch i:21
learning rate: 0.0013333333333333333, loss: 3.075161933898926
batch i:22
learning rate: 0.0013333333333333333, loss: 3.0835001468658447
batch i:23
learning rate: 0.0013333333333333333, loss: 3.1577627658843994
batch i:24
learning rate: 0.0013333333333333333, loss: 3.0374643802642822
batch i:25
learning rate: 0.0013333333333333333, loss: 3.16928768157959
batch i:26
learning rate: 0.0013333333333333333, loss: 3.0733327865600586
batch i:27
learning rate: 0.0013333333333333333, loss: 3.13387131690979
batch i:28
learning rate: 0.0013333333333333333, loss: 3.212705135345459
batch i:29
learning rate: 0.0013333333333333333, loss: 3.208486795425415
batch i:30
learning rate: 0.0013333333333333333, loss: 3.1423754692077637
batch i:31
learning rate: 0.0013333333333333333, loss: 3.0885603427886963
batch i:32
learning rate: 0.0013333333333333333, loss: 3.164729356765747
batch i:33
learning rate: 0.0013333333333333333, loss: 3.095513343811035
batch i:34
learning rate: 0.0013333333333333333, loss: 3.187171459197998
batch i:35
learning rate: 0.0013333333333333333, loss: 3.1807806491851807
batch i:36
learning rate: 0.0013333333333333333, loss: 3.164024829864502
batch i:37
learning rate: 0.0013333333333333333, loss: 3.082252025604248
batch i:38
learning rate: 0.0013333333333333333, loss: 3.1637277603149414
batch i:39
learning rate: 0.0013333333333333333, loss: 3.142042875289917
batch i:40
learning rate: 0.0013333333333333333, loss: 3.1261191368103027
batch i:41
learning rate: 0.0013333333333333333, loss: 3.1182823181152344
batch i:42
learning rate: 0.0013333333333333333, loss: 3.15641450881958
batch i:43
learning rate: 0.0013333333333333333, loss: 3.0591018199920654
batch i:44
learning rate: 0.0013333333333333333, loss: 3.031794309616089
batch i:45
learning rate: 0.0013333333333333333, loss: 3.0241246223449707
batch i:46
learning rate: 0.0013333333333333333, loss: 3.0816547870635986
batch i:47
learning rate: 0.0013333333333333333, loss: 3.0745058059692383
batch i:48
learning rate: 0.0013333333333333333, loss: 2.9586710929870605
batch i:49
learning rate: 0.0013333333333333333, loss: 2.9984395503997803
batch i:50
learning rate: 0.0013333333333333333, loss: 2.904287815093994
current self-play batch: 50
num_playouts:1000, win: 6, lose: 4, tie:0
average time: 177.0517664194107
New best policy from pure MCTS
batch i:51
learning rate: 0.0013333333333333333, loss: 3.010590076446533
batch i:52
learning rate: 0.0013333333333333333, loss: 3.075944185256958
batch i:53
learning rate: 0.0013333333333333333, loss: 3.0756356716156006
batch i:54
learning rate: 0.0013333333333333333, loss: 3.1201725006103516
batch i:55
learning rate: 0.0013333333333333333, loss: 3.013167381286621
batch i:56
learning rate: 0.0013333333333333333, loss: 2.98771595954895
batch i:57
learning rate: 0.0013333333333333333, loss: 3.0199246406555176
batch i:58
learning rate: 0.0013333333333333333, loss: 2.9774091243743896
batch i:59
learning rate: 0.0013333333333333333, loss: 2.920301914215088
batch i:60
learning rate: 0.0013333333333333333, loss: 2.951935052871704
batch i:61
learning rate: 0.0013333333333333333, loss: 2.9555859565734863
batch i:62
learning rate: 0.0013333333333333333, loss: 2.855950355529785
batch i:63
learning rate: 0.0013333333333333333, loss: 2.9867823123931885
batch i:64
learning rate: 0.0013333333333333333, loss: 2.861078977584839
batch i:65
learning rate: 0.0013333333333333333, loss: 2.8594110012054443
batch i:66
learning rate: 0.0013333333333333333, loss: 2.8889362812042236
batch i:67
learning rate: 0.0013333333333333333, loss: 2.8918375968933105
batch i:68
learning rate: 0.0013333333333333333, loss: 2.773947238922119
batch i:69
learning rate: 0.0013333333333333333, loss: 2.819507122039795
batch i:70
learning rate: 0.0013333333333333333, loss: 2.9603230953216553
batch i:71
learning rate: 0.0013333333333333333, loss: 2.9706218242645264
batch i:72
learning rate: 0.0013333333333333333, loss: 2.8047518730163574
batch i:73
learning rate: 0.0013333333333333333, loss: 2.829677104949951
batch i:74
learning rate: 0.0013333333333333333, loss: 2.9210853576660156
batch i:75
learning rate: 0.0013333333333333333, loss: 2.912763833999634
batch i:76
learning rate: 0.0013333333333333333, loss: 2.895836353302002
batch i:77
learning rate: 0.0013333333333333333, loss: 2.8716931343078613
batch i:78
learning rate: 0.0013333333333333333, loss: 2.8789539337158203
batch i:79
learning rate: 0.0013333333333333333, loss: 2.8625636100769043
batch i:80
learning rate: 0.0013333333333333333, loss: 2.813589096069336
batch i:81
learning rate: 0.0013333333333333333, loss: 2.8995227813720703
batch i:82
learning rate: 0.0013333333333333333, loss: 2.8828229904174805
batch i:83
learning rate: 0.0013333333333333333, loss: 2.8848776817321777
batch i:84
learning rate: 0.0013333333333333333, loss: 2.809162139892578
batch i:85
learning rate: 0.0013333333333333333, loss: 2.9575905799865723
batch i:86
learning rate: 0.0013333333333333333, loss: 2.943115472793579
batch i:87
learning rate: 0.0013333333333333333, loss: 2.814391613006592
batch i:88
learning rate: 0.0013333333333333333, loss: 2.913451671600342
batch i:89
learning rate: 0.0013333333333333333, loss: 2.8697328567504883
batch i:90
learning rate: 0.0013333333333333333, loss: 2.961501121520996
batch i:91
learning rate: 0.0013333333333333333, loss: 2.8911890983581543
batch i:92
learning rate: 0.0013333333333333333, loss: 2.835232734680176
batch i:93
learning rate: 0.0013333333333333333, loss: 2.84718918800354
batch i:94
learning rate: 0.0013333333333333333, loss: 2.777308225631714
batch i:95
learning rate: 0.0013333333333333333, loss: 2.8949966430664062
batch i:96
learning rate: 0.0013333333333333333, loss: 2.8581442832946777
batch i:97
learning rate: 0.0013333333333333333, loss: 2.8302159309387207
batch i:98
learning rate: 0.0013333333333333333, loss: 2.796139717102051
batch i:99
learning rate: 0.0013333333333333333, loss: 2.7626614570617676
batch i:100
learning rate: 0.0013333333333333333, loss: 2.804924488067627
current self-play batch: 100
num_playouts:1000, win: 6, lose: 4, tie:0
average time: 168.3387796640396
batch i:101
learning rate: 0.0013333333333333333, loss: 2.784792423248291
batch i:102
learning rate: 0.0013333333333333333, loss: 2.7983903884887695
batch i:103
learning rate: 0.0013333333333333333, loss: 2.741706371307373
batch i:104
learning rate: 0.0013333333333333333, loss: 2.770071506500244
batch i:105
learning rate: 0.0013333333333333333, loss: 2.8387107849121094
batch i:106
learning rate: 0.0013333333333333333, loss: 2.8274073600769043
batch i:107
learning rate: 0.0013333333333333333, loss: 2.8385701179504395
batch i:108
learning rate: 0.0013333333333333333, loss: 2.8341312408447266
batch i:109
learning rate: 0.0013333333333333333, loss: 2.876924514770508
batch i:110
learning rate: 0.0013333333333333333, loss: 2.8308520317077637
batch i:111
learning rate: 0.0013333333333333333, loss: 2.852041244506836
batch i:112
learning rate: 0.0013333333333333333, loss: 2.8536951541900635
batch i:113
learning rate: 0.0013333333333333333, loss: 2.8847949504852295
batch i:114
learning rate: 0.0013333333333333333, loss: 2.8805718421936035
batch i:115
learning rate: 0.0013333333333333333, loss: 2.8271584510803223
batch i:116
learning rate: 0.0013333333333333333, loss: 2.8535027503967285
batch i:117
learning rate: 0.0013333333333333333, loss: 2.834087371826172
batch i:118
learning rate: 0.0013333333333333333, loss: 2.903266429901123
batch i:119
learning rate: 0.0013333333333333333, loss: 2.858213186264038
batch i:120
learning rate: 0.0013333333333333333, loss: 2.8654487133026123
batch i:121
learning rate: 0.0013333333333333333, loss: 2.8973772525787354
batch i:122
learning rate: 0.0013333333333333333, loss: 2.9729037284851074
batch i:123
learning rate: 0.0013333333333333333, loss: 2.96697735786438
batch i:124
learning rate: 0.0013333333333333333, loss: 2.888791561126709
batch i:125
learning rate: 0.0013333333333333333, loss: 2.8797800540924072
batch i:126
learning rate: 0.0013333333333333333, loss: 2.9342541694641113
batch i:127
learning rate: 0.0013333333333333333, loss: 2.910309314727783
batch i:128
learning rate: 0.0013333333333333333, loss: 3.017702102661133
batch i:129
learning rate: 0.0013333333333333333, loss: 2.900791645050049
batch i:130
learning rate: 0.0013333333333333333, loss: 2.9244062900543213
batch i:131
learning rate: 0.0013333333333333333, loss: 2.9229249954223633
batch i:132
learning rate: 0.0013333333333333333, loss: 2.9672796726226807
batch i:133
learning rate: 0.0013333333333333333, loss: 3.066403865814209
batch i:134
learning rate: 0.0013333333333333333, loss: 2.9693217277526855
batch i:135
learning rate: 0.0013333333333333333, loss: 2.925776958465576
batch i:136
learning rate: 0.0013333333333333333, loss: 2.96307373046875
batch i:137
learning rate: 0.0013333333333333333, loss: 3.0232229232788086
batch i:138
learning rate: 0.0013333333333333333, loss: 2.8843021392822266
batch i:139
learning rate: 0.0013333333333333333, loss: 2.865144968032837
batch i:140
learning rate: 0.0013333333333333333, loss: 2.860887050628662
batch i:141
learning rate: 0.0013333333333333333, loss: 2.951550245285034
batch i:142
learning rate: 0.0013333333333333333, loss: 2.8412680625915527
batch i:143
learning rate: 0.0013333333333333333, loss: 2.9145803451538086
batch i:144
learning rate: 0.0013333333333333333, loss: 2.9571049213409424
batch i:145
learning rate: 0.0013333333333333333, loss: 2.807509422302246
batch i:146
learning rate: 0.0013333333333333333, loss: 2.920198917388916
batch i:147
learning rate: 0.0013333333333333333, loss: 2.864503860473633
batch i:148
learning rate: 0.0013333333333333333, loss: 2.7680933475494385
batch i:149
learning rate: 0.0013333333333333333, loss: 2.8116087913513184
batch i:150
learning rate: 0.0013333333333333333, loss: 2.8206615447998047
current self-play batch: 150
num_playouts:1000, win: 10, lose: 0, tie:0
average time: 127.08499896526337
New best policy from pure MCTS
batch i:151
learning rate: 0.0013333333333333333, loss: 2.8972136974334717
batch i:152
learning rate: 0.0013333333333333333, loss: 2.871342420578003
batch i:153
learning rate: 0.0013333333333333333, loss: 2.84889817237854
batch i:154
learning rate: 0.0013333333333333333, loss: 2.928046226501465
batch i:155
learning rate: 0.0013333333333333333, loss: 2.810805320739746
batch i:156
learning rate: 0.0013333333333333333, loss: 2.9313526153564453
batch i:157
learning rate: 0.0013333333333333333, loss: 2.768127202987671
batch i:158
learning rate: 0.0013333333333333333, loss: 2.948991060256958
batch i:159
learning rate: 0.0013333333333333333, loss: 2.8710074424743652
batch i:160
learning rate: 0.0013333333333333333, loss: 2.956193208694458
batch i:161
learning rate: 0.0013333333333333333, loss: 2.8569698333740234
batch i:162
learning rate: 0.0013333333333333333, loss: 2.8671634197235107
batch i:163
learning rate: 0.0013333333333333333, loss: 2.81089448928833
batch i:164
learning rate: 0.0013333333333333333, loss: 2.894070625305176
batch i:165
learning rate: 0.0013333333333333333, loss: 2.880077362060547
batch i:166
learning rate: 0.0013333333333333333, loss: 2.909893035888672
batch i:167
learning rate: 0.0013333333333333333, loss: 2.9022655487060547
batch i:168
learning rate: 0.0013333333333333333, loss: 2.9822375774383545
batch i:169
learning rate: 0.0013333333333333333, loss: 2.9195010662078857
batch i:170
learning rate: 0.0013333333333333333, loss: 2.849001169204712
batch i:171
learning rate: 0.0013333333333333333, loss: 2.9730381965637207
batch i:172
learning rate: 0.0013333333333333333, loss: 2.7841005325317383
batch i:173
learning rate: 0.0013333333333333333, loss: 2.880284309387207
batch i:174
learning rate: 0.0013333333333333333, loss: 2.8884880542755127
batch i:175
learning rate: 0.0013333333333333333, loss: 2.926981210708618
batch i:176
learning rate: 0.0013333333333333333, loss: 2.8760337829589844
batch i:177
learning rate: 0.0013333333333333333, loss: 2.8671045303344727
batch i:178
learning rate: 0.0013333333333333333, loss: 2.806117057800293
batch i:179
learning rate: 0.0013333333333333333, loss: 2.853309154510498
batch i:180
learning rate: 0.0013333333333333333, loss: 2.8146212100982666
batch i:181
learning rate: 0.0013333333333333333, loss: 2.7911839485168457
batch i:182
learning rate: 0.0013333333333333333, loss: 2.758265495300293
batch i:183
learning rate: 0.0013333333333333333, loss: 2.8451924324035645
batch i:184
learning rate: 0.0013333333333333333, loss: 2.8141136169433594
batch i:185
learning rate: 0.0013333333333333333, loss: 2.831805944442749
batch i:186
learning rate: 0.0013333333333333333, loss: 2.824502944946289
batch i:187
learning rate: 0.0013333333333333333, loss: 2.895529270172119
batch i:188
learning rate: 0.0013333333333333333, loss: 2.7449870109558105
batch i:189
learning rate: 0.0013333333333333333, loss: 2.8493356704711914
batch i:190
learning rate: 0.0013333333333333333, loss: 2.809359073638916
batch i:191
learning rate: 0.0013333333333333333, loss: 2.772172451019287
batch i:192
learning rate: 0.0013333333333333333, loss: 2.904324531555176
batch i:193
learning rate: 0.0013333333333333333, loss: 2.7929773330688477
batch i:194
learning rate: 0.0013333333333333333, loss: 2.7855091094970703
batch i:195
learning rate: 0.0013333333333333333, loss: 2.8289828300476074
batch i:196
learning rate: 0.0013333333333333333, loss: 2.8751635551452637
batch i:197
learning rate: 0.0013333333333333333, loss: 2.8466572761535645
batch i:198
learning rate: 0.0013333333333333333, loss: 2.8363571166992188
batch i:199
learning rate: 0.0013333333333333333, loss: 2.82204008102417
batch i:200
learning rate: 0.0013333333333333333, loss: 2.922720432281494
current self-play batch: 200
num_playouts:2000, win: 4, lose: 6, tie:0
average time: 424.3798079252243
New best policy from pure MCTS
batch i:201
learning rate: 0.0013333333333333333, loss: 2.81740140914917
batch i:202
learning rate: 0.0013333333333333333, loss: 2.856092929840088
batch i:203
learning rate: 0.0013333333333333333, loss: 2.845747947692871
batch i:204
learning rate: 0.0013333333333333333, loss: 2.840786933898926
batch i:205
learning rate: 0.0013333333333333333, loss: 2.89808988571167
batch i:206
learning rate: 0.0013333333333333333, loss: 2.77500057220459
batch i:207
learning rate: 0.0013333333333333333, loss: 2.7676610946655273
batch i:208
learning rate: 0.0013333333333333333, loss: 2.812102794647217
batch i:209
learning rate: 0.0013333333333333333, loss: 2.8940529823303223
batch i:210
learning rate: 0.0013333333333333333, loss: 2.871467113494873
batch i:211
learning rate: 0.0013333333333333333, loss: 2.8334388732910156
batch i:212
learning rate: 0.0013333333333333333, loss: 2.8221871852874756
batch i:213
learning rate: 0.0013333333333333333, loss: 2.946505069732666
batch i:214
learning rate: 0.0013333333333333333, loss: 2.8126304149627686
batch i:215
learning rate: 0.0013333333333333333, loss: 2.8733344078063965
batch i:216
learning rate: 0.0013333333333333333, loss: 2.8041062355041504
batch i:217
learning rate: 0.0013333333333333333, loss: 2.8470778465270996
batch i:218
learning rate: 0.0013333333333333333, loss: 2.8172013759613037
batch i:219
learning rate: 0.0013333333333333333, loss: 2.737999200820923
batch i:220
learning rate: 0.0013333333333333333, loss: 2.9200522899627686
batch i:221
learning rate: 0.0013333333333333333, loss: 2.703491687774658
batch i:222
learning rate: 0.0013333333333333333, loss: 2.842217206954956
batch i:223
learning rate: 0.0013333333333333333, loss: 2.8181095123291016
batch i:224
learning rate: 0.0013333333333333333, loss: 2.9516680240631104
batch i:225
learning rate: 0.0013333333333333333, loss: 2.835465431213379
batch i:226
learning rate: 0.0013333333333333333, loss: 2.865744113922119
batch i:227
learning rate: 0.0013333333333333333, loss: 2.8214125633239746
batch i:228
learning rate: 0.0013333333333333333, loss: 2.8792011737823486
batch i:229
learning rate: 0.0013333333333333333, loss: 2.9140963554382324
batch i:230
learning rate: 0.0013333333333333333, loss: 2.904198169708252
batch i:231
learning rate: 0.0013333333333333333, loss: 2.91243577003479
batch i:232
learning rate: 0.0013333333333333333, loss: 2.861848831176758
batch i:233
learning rate: 0.0013333333333333333, loss: 2.905488967895508
batch i:234
learning rate: 0.0013333333333333333, loss: 2.988387107849121
batch i:235
learning rate: 0.0013333333333333333, loss: 2.929108142852783
batch i:236
learning rate: 0.0013333333333333333, loss: 2.861386775970459
batch i:237
learning rate: 0.0013333333333333333, loss: 2.9404382705688477
batch i:238
learning rate: 0.0013333333333333333, loss: 2.838245153427124
batch i:239
learning rate: 0.0013333333333333333, loss: 2.9539003372192383
batch i:240
learning rate: 0.0013333333333333333, loss: 2.9700279235839844
batch i:241
learning rate: 0.0013333333333333333, loss: 2.8789658546447754
batch i:242
learning rate: 0.0013333333333333333, loss: 2.8355371952056885
batch i:243
learning rate: 0.0013333333333333333, loss: 2.7941737174987793
batch i:244
learning rate: 0.0013333333333333333, loss: 2.8962767124176025
batch i:245
learning rate: 0.0013333333333333333, loss: 2.854566812515259
batch i:246
learning rate: 0.0013333333333333333, loss: 2.985515594482422
batch i:247
learning rate: 0.0013333333333333333, loss: 2.873892307281494
batch i:248
learning rate: 0.0013333333333333333, loss: 2.8382468223571777
batch i:249
learning rate: 0.0013333333333333333, loss: 2.766205310821533
batch i:250
learning rate: 0.0013333333333333333, loss: 2.899341344833374
current self-play batch: 250
num_playouts:2000, win: 5, lose: 5, tie:0
average time: 455.0507016420364
New best policy from pure MCTS
batch i:251
learning rate: 0.0013333333333333333, loss: 2.909273147583008
batch i:252
learning rate: 0.0013333333333333333, loss: 2.9916720390319824
batch i:253
learning rate: 0.0013333333333333333, loss: 2.9392895698547363
batch i:254
learning rate: 0.0013333333333333333, loss: 2.980506658554077
batch i:255
learning rate: 0.0013333333333333333, loss: 2.9108896255493164
batch i:256
learning rate: 0.0013333333333333333, loss: 2.906885862350464
batch i:257
learning rate: 0.0013333333333333333, loss: 2.9388930797576904
batch i:258
learning rate: 0.0013333333333333333, loss: 2.8633217811584473
batch i:259
learning rate: 0.0013333333333333333, loss: 2.9511804580688477
batch i:260
learning rate: 0.0013333333333333333, loss: 2.7722113132476807
batch i:261
learning rate: 0.0013333333333333333, loss: 2.7799177169799805
batch i:262
learning rate: 0.0013333333333333333, loss: 2.768281936645508
batch i:263
learning rate: 0.0013333333333333333, loss: 2.7721118927001953
batch i:264
learning rate: 0.0013333333333333333, loss: 2.7761521339416504
batch i:265
learning rate: 0.0013333333333333333, loss: 2.841829538345337
batch i:266
learning rate: 0.0013333333333333333, loss: 2.7544264793395996
batch i:267
learning rate: 0.0013333333333333333, loss: 2.762979030609131
batch i:268
learning rate: 0.0013333333333333333, loss: 2.771817684173584
batch i:269
learning rate: 0.0013333333333333333, loss: 2.6563730239868164
batch i:270
learning rate: 0.0013333333333333333, loss: 2.7473840713500977
batch i:271
learning rate: 0.0013333333333333333, loss: 2.749398708343506
batch i:272
learning rate: 0.0013333333333333333, loss: 2.632542848587036
batch i:273
learning rate: 0.0013333333333333333, loss: 2.736382484436035
batch i:274
learning rate: 0.0013333333333333333, loss: 2.6579599380493164
batch i:275
learning rate: 0.0013333333333333333, loss: 2.7272472381591797
batch i:276
learning rate: 0.0013333333333333333, loss: 2.728560447692871
batch i:277
learning rate: 0.0013333333333333333, loss: 2.769920587539673
batch i:278
learning rate: 0.0013333333333333333, loss: 2.775205612182617
batch i:279
learning rate: 0.0013333333333333333, loss: 2.756481170654297
batch i:280
learning rate: 0.0013333333333333333, loss: 2.8210129737854004
batch i:281
learning rate: 0.0013333333333333333, loss: 2.8181304931640625
batch i:282
learning rate: 0.0013333333333333333, loss: 2.7019693851470947
batch i:283
learning rate: 0.0013333333333333333, loss: 2.7615914344787598
batch i:284
learning rate: 0.0013333333333333333, loss: 2.75229811668396
batch i:285
learning rate: 0.0013333333333333333, loss: 2.709730863571167
batch i:286
learning rate: 0.0013333333333333333, loss: 2.583174705505371
batch i:287
learning rate: 0.0013333333333333333, loss: 2.6875157356262207
batch i:288
learning rate: 0.0013333333333333333, loss: 2.6642136573791504
batch i:289
learning rate: 0.0013333333333333333, loss: 2.669257640838623
batch i:290
learning rate: 0.0013333333333333333, loss: 2.6280317306518555
batch i:291
learning rate: 0.0013333333333333333, loss: 2.617856979370117
batch i:292
learning rate: 0.0013333333333333333, loss: 2.6015961170196533
batch i:293
learning rate: 0.0013333333333333333, loss: 2.6935832500457764
batch i:294
learning rate: 0.0013333333333333333, loss: 2.818896770477295
batch i:295
learning rate: 0.0013333333333333333, loss: 2.690904140472412
batch i:296
learning rate: 0.0013333333333333333, loss: 2.6230273246765137
batch i:297
learning rate: 0.0013333333333333333, loss: 2.632136344909668
batch i:298
learning rate: 0.0013333333333333333, loss: 2.630237340927124
batch i:299
learning rate: 0.0013333333333333333, loss: 2.617220878601074
batch i:300
learning rate: 0.0013333333333333333, loss: 2.6663119792938232
current self-play batch: 300
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 167.1405042886734
New best policy from pure MCTS
batch i:301
learning rate: 0.0013333333333333333, loss: 2.6610584259033203
batch i:302
learning rate: 0.0013333333333333333, loss: 2.6298294067382812
batch i:303
learning rate: 0.0013333333333333333, loss: 2.7554051876068115
batch i:304
learning rate: 0.0013333333333333333, loss: 2.6855173110961914
batch i:305
learning rate: 0.0013333333333333333, loss: 2.574002981185913
batch i:306
learning rate: 0.0013333333333333333, loss: 2.628960371017456
batch i:307
learning rate: 0.0013333333333333333, loss: 2.639754056930542
batch i:308
learning rate: 0.0013333333333333333, loss: 2.633876323699951
batch i:309
learning rate: 0.0013333333333333333, loss: 2.5843214988708496
batch i:310
learning rate: 0.0013333333333333333, loss: 2.5136446952819824
batch i:311
learning rate: 0.0013333333333333333, loss: 2.592606782913208
batch i:312
learning rate: 0.0013333333333333333, loss: 2.4357409477233887
batch i:313
learning rate: 0.0013333333333333333, loss: 2.650876522064209
batch i:314
learning rate: 0.0013333333333333333, loss: 2.5937886238098145
batch i:315
learning rate: 0.0013333333333333333, loss: 2.6570186614990234
batch i:316
learning rate: 0.0013333333333333333, loss: 2.6190993785858154
batch i:317
learning rate: 0.0013333333333333333, loss: 2.649629592895508
batch i:318
learning rate: 0.0013333333333333333, loss: 2.5624661445617676
batch i:319
learning rate: 0.0013333333333333333, loss: 2.670659065246582
batch i:320
learning rate: 0.0013333333333333333, loss: 2.5889391899108887
batch i:321
learning rate: 0.0013333333333333333, loss: 2.5530600547790527
batch i:322
learning rate: 0.0013333333333333333, loss: 2.6120243072509766
batch i:323
learning rate: 0.0013333333333333333, loss: 2.606476068496704
batch i:324
learning rate: 0.0013333333333333333, loss: 2.505767345428467
batch i:325
learning rate: 0.0013333333333333333, loss: 2.755279541015625
batch i:326
learning rate: 0.0013333333333333333, loss: 2.59436297416687
batch i:327
learning rate: 0.0013333333333333333, loss: 2.6530280113220215
batch i:328
learning rate: 0.0013333333333333333, loss: 2.6550047397613525
batch i:329
learning rate: 0.0013333333333333333, loss: 2.6855244636535645
batch i:330
learning rate: 0.0013333333333333333, loss: 2.664374828338623
batch i:331
learning rate: 0.0013333333333333333, loss: 2.631256580352783
batch i:332
learning rate: 0.0013333333333333333, loss: 2.6288795471191406
batch i:333
learning rate: 0.0013333333333333333, loss: 2.704423189163208
batch i:334
learning rate: 0.0013333333333333333, loss: 2.6760177612304688
batch i:335
learning rate: 0.0013333333333333333, loss: 2.711853504180908
batch i:336
learning rate: 0.0013333333333333333, loss: 2.6435046195983887
batch i:337
learning rate: 0.0013333333333333333, loss: 2.6505227088928223
batch i:338
learning rate: 0.0013333333333333333, loss: 2.657386302947998
batch i:339
learning rate: 0.0013333333333333333, loss: 2.652604579925537
batch i:340
learning rate: 0.0013333333333333333, loss: 2.6884517669677734
batch i:341
learning rate: 0.0013333333333333333, loss: 2.6875295639038086
batch i:342
learning rate: 0.0013333333333333333, loss: 2.584561586380005
batch i:343
learning rate: 0.0013333333333333333, loss: 2.6690423488616943
batch i:344
learning rate: 0.0013333333333333333, loss: 2.7479851245880127
batch i:345
learning rate: 0.0013333333333333333, loss: 2.7175443172454834
batch i:346
learning rate: 0.0013333333333333333, loss: 2.690642833709717
batch i:347
learning rate: 0.0013333333333333333, loss: 2.5776686668395996
batch i:348
learning rate: 0.0013333333333333333, loss: 2.746952533721924
batch i:349
learning rate: 0.0013333333333333333, loss: 2.6843817234039307
batch i:350
learning rate: 0.0013333333333333333, loss: 2.7305803298950195
current self-play batch: 350
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 141.28491983413696
batch i:351
learning rate: 0.0013333333333333333, loss: 2.6193506717681885
batch i:352
learning rate: 0.0013333333333333333, loss: 2.7233147621154785
batch i:353
learning rate: 0.0013333333333333333, loss: 2.7019026279449463
batch i:354
learning rate: 0.0013333333333333333, loss: 2.5253312587738037
batch i:355
learning rate: 0.0013333333333333333, loss: 2.647862434387207
batch i:356
learning rate: 0.0013333333333333333, loss: 2.632124900817871
batch i:357
learning rate: 0.0013333333333333333, loss: 2.679321527481079
batch i:358
learning rate: 0.0013333333333333333, loss: 2.604367733001709
batch i:359
learning rate: 0.0013333333333333333, loss: 2.6997852325439453
batch i:360
learning rate: 0.0013333333333333333, loss: 2.6092605590820312
batch i:361
learning rate: 0.0013333333333333333, loss: 2.5882883071899414
batch i:362
learning rate: 0.0013333333333333333, loss: 2.5676112174987793
batch i:363
learning rate: 0.0013333333333333333, loss: 2.6256299018859863
batch i:364
learning rate: 0.0013333333333333333, loss: 2.5819554328918457
batch i:365
learning rate: 0.0013333333333333333, loss: 2.57796311378479
batch i:366
learning rate: 0.0013333333333333333, loss: 2.654409885406494
batch i:367
learning rate: 0.0013333333333333333, loss: 2.6217806339263916
batch i:368
learning rate: 0.0013333333333333333, loss: 2.5528860092163086
batch i:369
learning rate: 0.0013333333333333333, loss: 2.5597338676452637
batch i:370
learning rate: 0.0013333333333333333, loss: 2.5290000438690186
batch i:371
learning rate: 0.0013333333333333333, loss: 2.581364631652832
batch i:372
learning rate: 0.0013333333333333333, loss: 2.6175379753112793
batch i:373
learning rate: 0.0013333333333333333, loss: 2.56795072555542
batch i:374
learning rate: 0.0013333333333333333, loss: 2.6173672676086426
batch i:375
learning rate: 0.0013333333333333333, loss: 2.5727038383483887
batch i:376
learning rate: 0.0013333333333333333, loss: 2.5406086444854736
batch i:377
learning rate: 0.0013333333333333333, loss: 2.6403329372406006
batch i:378
learning rate: 0.0013333333333333333, loss: 2.5387349128723145
batch i:379
learning rate: 0.0013333333333333333, loss: 2.591865301132202
batch i:380
learning rate: 0.0013333333333333333, loss: 2.4933559894561768
batch i:381
learning rate: 0.0013333333333333333, loss: 2.637209177017212
batch i:382
learning rate: 0.0013333333333333333, loss: 2.6736764907836914
batch i:383
learning rate: 0.0013333333333333333, loss: 2.569410800933838
batch i:384
learning rate: 0.0013333333333333333, loss: 2.6502718925476074
batch i:385
learning rate: 0.0013333333333333333, loss: 2.6140761375427246
batch i:386
learning rate: 0.0013333333333333333, loss: 2.649746894836426
batch i:387
learning rate: 0.0013333333333333333, loss: 2.5907962322235107
batch i:388
learning rate: 0.0013333333333333333, loss: 2.6924915313720703
batch i:389
learning rate: 0.0013333333333333333, loss: 2.6302101612091064
batch i:390
learning rate: 0.0013333333333333333, loss: 2.6206817626953125
batch i:391
learning rate: 0.0013333333333333333, loss: 2.723966360092163
batch i:392
learning rate: 0.0013333333333333333, loss: 2.616331100463867
batch i:393
learning rate: 0.0013333333333333333, loss: 2.5940723419189453
batch i:394
learning rate: 0.0013333333333333333, loss: 2.6853885650634766
batch i:395
learning rate: 0.0013333333333333333, loss: 2.588942289352417
batch i:396
learning rate: 0.0013333333333333333, loss: 2.6035802364349365
batch i:397
learning rate: 0.0013333333333333333, loss: 2.5585107803344727
batch i:398
learning rate: 0.0013333333333333333, loss: 2.553098201751709
batch i:399
learning rate: 0.0013333333333333333, loss: 2.5964770317077637
batch i:400
learning rate: 0.0013333333333333333, loss: 2.5326969623565674
current self-play batch: 400
num_playouts:2000, win: 6, lose: 0, tie:4
average time: 504.9923764228821
New best policy by beating the previous best
batch i:401
learning rate: 0.0013333333333333333, loss: 2.579928159713745
batch i:402
learning rate: 0.0013333333333333333, loss: 2.585787296295166
batch i:403
learning rate: 0.0013333333333333333, loss: 2.5816969871520996
batch i:404
learning rate: 0.0013333333333333333, loss: 2.501492738723755
batch i:405
learning rate: 0.0013333333333333333, loss: 2.6634373664855957
batch i:406
learning rate: 0.0013333333333333333, loss: 2.5062780380249023
batch i:407
learning rate: 0.0013333333333333333, loss: 2.620990037918091
batch i:408
learning rate: 0.0013333333333333333, loss: 2.522937774658203
batch i:409
learning rate: 0.0013333333333333333, loss: 2.627622127532959
batch i:410
learning rate: 0.0013333333333333333, loss: 2.596557140350342
batch i:411
learning rate: 0.0013333333333333333, loss: 2.526850938796997
batch i:412
learning rate: 0.0013333333333333333, loss: 2.5567290782928467
batch i:413
learning rate: 0.0013333333333333333, loss: 2.620121479034424
batch i:414
learning rate: 0.0013333333333333333, loss: 2.7026782035827637
batch i:415
learning rate: 0.0013333333333333333, loss: 2.57560396194458
batch i:416
learning rate: 0.0013333333333333333, loss: 2.530726909637451
batch i:417
learning rate: 0.0013333333333333333, loss: 2.533292770385742
batch i:418
learning rate: 0.0013333333333333333, loss: 2.555819034576416
batch i:419
learning rate: 0.0013333333333333333, loss: 2.6160366535186768
batch i:420
learning rate: 0.0013333333333333333, loss: 2.6203341484069824
batch i:421
learning rate: 0.0013333333333333333, loss: 2.5769381523132324
batch i:422
learning rate: 0.0013333333333333333, loss: 2.7583019733428955
batch i:423
learning rate: 0.0013333333333333333, loss: 2.5808072090148926
batch i:424
learning rate: 0.0013333333333333333, loss: 2.4080357551574707
batch i:425
learning rate: 0.0013333333333333333, loss: 2.6197690963745117
batch i:426
learning rate: 0.0013333333333333333, loss: 2.5302631855010986
batch i:427
learning rate: 0.0013333333333333333, loss: 2.5885391235351562
batch i:428
learning rate: 0.0013333333333333333, loss: 2.5871973037719727
batch i:429
learning rate: 0.0013333333333333333, loss: 2.609898805618286
batch i:430
learning rate: 0.0013333333333333333, loss: 2.690774917602539
batch i:431
learning rate: 0.0013333333333333333, loss: 2.6690845489501953
batch i:432
learning rate: 0.0013333333333333333, loss: 2.5705223083496094
batch i:433
learning rate: 0.0013333333333333333, loss: 2.4715003967285156
batch i:434
learning rate: 0.0013333333333333333, loss: 2.56917142868042
batch i:435
learning rate: 0.0013333333333333333, loss: 2.5593466758728027
batch i:436
learning rate: 0.0013333333333333333, loss: 2.4471163749694824
batch i:437
learning rate: 0.0013333333333333333, loss: 2.544853687286377
batch i:438
learning rate: 0.0013333333333333333, loss: 2.481200695037842
batch i:439
learning rate: 0.0013333333333333333, loss: 2.5566961765289307
batch i:440
learning rate: 0.0013333333333333333, loss: 2.5604453086853027
batch i:441
learning rate: 0.0013333333333333333, loss: 2.6037368774414062
batch i:442
learning rate: 0.0013333333333333333, loss: 2.6086769104003906
batch i:443
learning rate: 0.0013333333333333333, loss: 2.5688068866729736
batch i:444
learning rate: 0.0013333333333333333, loss: 2.4841556549072266
batch i:445
learning rate: 0.0013333333333333333, loss: 2.6519947052001953
batch i:446
learning rate: 0.0013333333333333333, loss: 2.6776134967803955
batch i:447
learning rate: 0.0013333333333333333, loss: 2.657241106033325
batch i:448
learning rate: 0.0013333333333333333, loss: 2.626512050628662
batch i:449
learning rate: 0.0013333333333333333, loss: 2.58282732963562
batch i:450
learning rate: 0.0013333333333333333, loss: 2.675818920135498
current self-play batch: 450
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 165.7556445837021
New best policy from pure MCTS
batch i:451
learning rate: 0.0013333333333333333, loss: 2.640826463699341
batch i:452
learning rate: 0.0013333333333333333, loss: 2.709632635116577
batch i:453
learning rate: 0.0013333333333333333, loss: 2.704489231109619
batch i:454
learning rate: 0.0013333333333333333, loss: 2.7084708213806152
batch i:455
learning rate: 0.0013333333333333333, loss: 2.7413933277130127
batch i:456
learning rate: 0.0013333333333333333, loss: 2.762960433959961
batch i:457
learning rate: 0.0013333333333333333, loss: 2.772134304046631
batch i:458
learning rate: 0.0013333333333333333, loss: 2.7622904777526855
batch i:459
learning rate: 0.0013333333333333333, loss: 2.8736157417297363
batch i:460
learning rate: 0.0013333333333333333, loss: 2.6177783012390137
batch i:461
learning rate: 0.0013333333333333333, loss: 2.8118321895599365
batch i:462
learning rate: 0.0013333333333333333, loss: 2.7194371223449707
batch i:463
learning rate: 0.0013333333333333333, loss: 2.868614912033081
batch i:464
learning rate: 0.0013333333333333333, loss: 2.802544116973877
batch i:465
learning rate: 0.0013333333333333333, loss: 2.847193956375122
batch i:466
learning rate: 0.0013333333333333333, loss: 2.6932520866394043
batch i:467
learning rate: 0.0013333333333333333, loss: 2.7579081058502197
batch i:468
learning rate: 0.0013333333333333333, loss: 2.778557300567627
batch i:469
learning rate: 0.0013333333333333333, loss: 2.718818426132202
batch i:470
learning rate: 0.0013333333333333333, loss: 2.6501998901367188
batch i:471
learning rate: 0.0013333333333333333, loss: 2.8476476669311523
batch i:472
learning rate: 0.0013333333333333333, loss: 2.6677539348602295
batch i:473
learning rate: 0.0013333333333333333, loss: 2.7821245193481445
batch i:474
learning rate: 0.0013333333333333333, loss: 2.8566362857818604
batch i:475
learning rate: 0.0013333333333333333, loss: 2.784146308898926
batch i:476
learning rate: 0.0013333333333333333, loss: 2.8055784702301025
batch i:477
learning rate: 0.0013333333333333333, loss: 2.813481330871582
batch i:478
learning rate: 0.0013333333333333333, loss: 2.7692508697509766
batch i:479
learning rate: 0.0013333333333333333, loss: 2.8490054607391357
batch i:480
learning rate: 0.0013333333333333333, loss: 2.7622363567352295
batch i:481
learning rate: 0.0013333333333333333, loss: 2.709097385406494
batch i:482
learning rate: 0.0013333333333333333, loss: 2.61354398727417
batch i:483
learning rate: 0.0013333333333333333, loss: 2.6668620109558105
batch i:484
learning rate: 0.0013333333333333333, loss: 2.7692365646362305
batch i:485
learning rate: 0.0013333333333333333, loss: 2.6840996742248535
batch i:486
learning rate: 0.0013333333333333333, loss: 2.6816115379333496
batch i:487
learning rate: 0.0013333333333333333, loss: 2.6242899894714355
batch i:488
learning rate: 0.0013333333333333333, loss: 2.7524948120117188
batch i:489
learning rate: 0.0013333333333333333, loss: 2.579318046569824
batch i:490
learning rate: 0.0013333333333333333, loss: 2.5653271675109863
batch i:491
learning rate: 0.0013333333333333333, loss: 2.716709613800049
batch i:492
learning rate: 0.0013333333333333333, loss: 2.6940488815307617
batch i:493
learning rate: 0.0013333333333333333, loss: 2.762704372406006
batch i:494
learning rate: 0.0013333333333333333, loss: 2.6420509815216064
batch i:495
learning rate: 0.0013333333333333333, loss: 2.6505541801452637
batch i:496
learning rate: 0.0013333333333333333, loss: 2.6432008743286133
batch i:497
learning rate: 0.0013333333333333333, loss: 2.6552963256835938
batch i:498
learning rate: 0.0013333333333333333, loss: 2.7249014377593994
batch i:499
learning rate: 0.0013333333333333333, loss: 2.70530104637146
batch i:500
learning rate: 0.0013333333333333333, loss: 2.7770185470581055
current self-play batch: 500
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 136.02548265457153
New best policy from pure MCTS
batch i:501
learning rate: 0.0013333333333333333, loss: 2.854294538497925
batch i:502
learning rate: 0.0013333333333333333, loss: 2.745908737182617
batch i:503
learning rate: 0.0013333333333333333, loss: 2.8624181747436523
batch i:504
learning rate: 0.0013333333333333333, loss: 2.802739143371582
batch i:505
learning rate: 0.0013333333333333333, loss: 2.7870750427246094
batch i:506
learning rate: 0.0013333333333333333, loss: 2.7221460342407227
batch i:507
learning rate: 0.0013333333333333333, loss: 2.8076748847961426
batch i:508
learning rate: 0.0013333333333333333, loss: 2.76340651512146
batch i:509
learning rate: 0.0013333333333333333, loss: 2.7460927963256836
batch i:510
learning rate: 0.0013333333333333333, loss: 2.6544041633605957
batch i:511
learning rate: 0.0013333333333333333, loss: 2.695646286010742
batch i:512
learning rate: 0.0013333333333333333, loss: 2.6694467067718506
batch i:513
learning rate: 0.0013333333333333333, loss: 2.615518093109131
batch i:514
learning rate: 0.0013333333333333333, loss: 2.8148698806762695
batch i:515
learning rate: 0.0013333333333333333, loss: 2.787090301513672
batch i:516
learning rate: 0.0013333333333333333, loss: 2.7155721187591553
batch i:517
learning rate: 0.0013333333333333333, loss: 2.7672431468963623
batch i:518
learning rate: 0.0013333333333333333, loss: 2.798025131225586
batch i:519
learning rate: 0.0013333333333333333, loss: 2.772397518157959
batch i:520
learning rate: 0.0013333333333333333, loss: 2.747370719909668
batch i:521
learning rate: 0.0013333333333333333, loss: 2.680039405822754
batch i:522
learning rate: 0.0013333333333333333, loss: 2.683372974395752
batch i:523
learning rate: 0.0013333333333333333, loss: 2.7937002182006836
batch i:524
learning rate: 0.0013333333333333333, loss: 2.7544374465942383
batch i:525
learning rate: 0.0013333333333333333, loss: 2.780916929244995
batch i:526
learning rate: 0.0013333333333333333, loss: 2.815688133239746
batch i:527
learning rate: 0.0013333333333333333, loss: 2.8015642166137695
batch i:528
learning rate: 0.0013333333333333333, loss: 2.7278099060058594
batch i:529
learning rate: 0.0013333333333333333, loss: 2.7567272186279297
batch i:530
learning rate: 0.0013333333333333333, loss: 2.7631726264953613
batch i:531
learning rate: 0.0013333333333333333, loss: 2.813753604888916
batch i:532
learning rate: 0.0013333333333333333, loss: 2.80529522895813
batch i:533
learning rate: 0.0013333333333333333, loss: 2.801610231399536
batch i:534
learning rate: 0.0013333333333333333, loss: 2.7423815727233887
batch i:535
learning rate: 0.0013333333333333333, loss: 2.719144344329834
batch i:536
learning rate: 0.0013333333333333333, loss: 2.764261245727539
batch i:537
learning rate: 0.0013333333333333333, loss: 2.7044456005096436
batch i:538
learning rate: 0.0013333333333333333, loss: 2.7049813270568848
batch i:539
learning rate: 0.0013333333333333333, loss: 2.7755379676818848
batch i:540
learning rate: 0.0013333333333333333, loss: 2.648329973220825
batch i:541
learning rate: 0.0013333333333333333, loss: 2.6592535972595215
batch i:542
learning rate: 0.0013333333333333333, loss: 2.727787971496582
batch i:543
learning rate: 0.0013333333333333333, loss: 2.6382927894592285
batch i:544
learning rate: 0.0013333333333333333, loss: 2.6302871704101562
batch i:545
learning rate: 0.0013333333333333333, loss: 2.659836530685425
batch i:546
learning rate: 0.0013333333333333333, loss: 2.6697182655334473
batch i:547
learning rate: 0.0013333333333333333, loss: 2.6155786514282227
batch i:548
learning rate: 0.0013333333333333333, loss: 2.682380437850952
batch i:549
learning rate: 0.0013333333333333333, loss: 2.698871374130249
batch i:550
learning rate: 0.0013333333333333333, loss: 2.6610682010650635
current self-play batch: 550
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 144.0523129940033
batch i:551
learning rate: 0.0013333333333333333, loss: 2.6372978687286377
batch i:552
learning rate: 0.0013333333333333333, loss: 2.7844009399414062
batch i:553
learning rate: 0.0013333333333333333, loss: 2.609570026397705
batch i:554
learning rate: 0.0013333333333333333, loss: 2.7157721519470215
batch i:555
learning rate: 0.0013333333333333333, loss: 2.711507797241211
batch i:556
learning rate: 0.0013333333333333333, loss: 2.7062065601348877
batch i:557
learning rate: 0.0013333333333333333, loss: 2.747030258178711
batch i:558
learning rate: 0.0013333333333333333, loss: 2.732588291168213
batch i:559
learning rate: 0.0013333333333333333, loss: 2.649440050125122
batch i:560
learning rate: 0.0013333333333333333, loss: 2.688981056213379
batch i:561
learning rate: 0.0013333333333333333, loss: 2.6900835037231445
batch i:562
learning rate: 0.0013333333333333333, loss: 2.7006382942199707
batch i:563
learning rate: 0.0013333333333333333, loss: 2.6655569076538086
batch i:564
learning rate: 0.0013333333333333333, loss: 2.661961555480957
batch i:565
learning rate: 0.0013333333333333333, loss: 2.6391022205352783
batch i:566
learning rate: 0.0013333333333333333, loss: 2.606016159057617
batch i:567
learning rate: 0.0013333333333333333, loss: 2.701554298400879
batch i:568
learning rate: 0.0013333333333333333, loss: 2.676760196685791
batch i:569
learning rate: 0.0013333333333333333, loss: 2.5909414291381836
batch i:570
learning rate: 0.0013333333333333333, loss: 2.596343994140625
batch i:571
learning rate: 0.0013333333333333333, loss: 2.7543511390686035
batch i:572
learning rate: 0.0013333333333333333, loss: 2.6796634197235107
batch i:573
learning rate: 0.0013333333333333333, loss: 2.714702844619751
batch i:574
learning rate: 0.0013333333333333333, loss: 2.7125792503356934
batch i:575
learning rate: 0.0013333333333333333, loss: 2.7727341651916504
batch i:576
learning rate: 0.0013333333333333333, loss: 2.5985019207000732
batch i:577
learning rate: 0.0013333333333333333, loss: 2.7226600646972656
batch i:578
learning rate: 0.0013333333333333333, loss: 2.747727394104004
batch i:579
learning rate: 0.0013333333333333333, loss: 2.6847076416015625
batch i:580
learning rate: 0.0013333333333333333, loss: 2.727661371231079
batch i:581
learning rate: 0.0013333333333333333, loss: 2.738297462463379
batch i:582
learning rate: 0.0013333333333333333, loss: 2.6857094764709473
batch i:583
learning rate: 0.0013333333333333333, loss: 2.7396364212036133
batch i:584
learning rate: 0.0013333333333333333, loss: 2.674830436706543
batch i:585
learning rate: 0.0013333333333333333, loss: 2.7934367656707764
batch i:586
learning rate: 0.0013333333333333333, loss: 2.6341023445129395
batch i:587
learning rate: 0.0013333333333333333, loss: 2.5810773372650146
batch i:588
learning rate: 0.0013333333333333333, loss: 2.6603331565856934
batch i:589
learning rate: 0.0013333333333333333, loss: 2.7381908893585205
batch i:590
learning rate: 0.0013333333333333333, loss: 2.738739013671875
batch i:591
learning rate: 0.0013333333333333333, loss: 2.771486759185791
batch i:592
learning rate: 0.0013333333333333333, loss: 2.7383830547332764
batch i:593
learning rate: 0.0013333333333333333, loss: 2.69881534576416
batch i:594
learning rate: 0.0013333333333333333, loss: 2.799452543258667
batch i:595
learning rate: 0.0013333333333333333, loss: 2.706590414047241
batch i:596
learning rate: 0.0013333333333333333, loss: 2.7398080825805664
batch i:597
learning rate: 0.0013333333333333333, loss: 2.681612491607666
batch i:598
learning rate: 0.0013333333333333333, loss: 2.7764205932617188
batch i:599
learning rate: 0.0013333333333333333, loss: 2.6768856048583984
batch i:600
learning rate: 0.0013333333333333333, loss: 2.599665641784668
current self-play batch: 600
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 153.950439786911
batch i:601
learning rate: 0.0013333333333333333, loss: 2.6985177993774414
batch i:602
learning rate: 0.0013333333333333333, loss: 2.6194965839385986
batch i:603
learning rate: 0.0013333333333333333, loss: 2.6627228260040283
batch i:604
learning rate: 0.0013333333333333333, loss: 2.686974287033081
batch i:605
learning rate: 0.0013333333333333333, loss: 2.6155028343200684
batch i:606
learning rate: 0.0013333333333333333, loss: 2.7490272521972656
batch i:607
learning rate: 0.0013333333333333333, loss: 2.678142547607422
batch i:608
learning rate: 0.0013333333333333333, loss: 2.5601563453674316
batch i:609
learning rate: 0.0013333333333333333, loss: 2.6606390476226807
batch i:610
learning rate: 0.0013333333333333333, loss: 2.7271640300750732
batch i:611
learning rate: 0.0013333333333333333, loss: 2.633589267730713
batch i:612
learning rate: 0.0013333333333333333, loss: 2.631556987762451
batch i:613
learning rate: 0.0013333333333333333, loss: 2.7126612663269043
batch i:614
learning rate: 0.0013333333333333333, loss: 2.626708507537842
batch i:615
learning rate: 0.0013333333333333333, loss: 2.5538330078125
batch i:616
learning rate: 0.0013333333333333333, loss: 2.560556650161743
batch i:617
learning rate: 0.0013333333333333333, loss: 2.580510139465332
batch i:618
learning rate: 0.0013333333333333333, loss: 2.5343313217163086
batch i:619
learning rate: 0.0013333333333333333, loss: 2.662109375
batch i:620
learning rate: 0.0013333333333333333, loss: 2.6545510292053223
batch i:621
learning rate: 0.0013333333333333333, loss: 2.657329559326172
batch i:622
learning rate: 0.0013333333333333333, loss: 2.7317469120025635
batch i:623
learning rate: 0.0013333333333333333, loss: 2.689535140991211
batch i:624
learning rate: 0.0013333333333333333, loss: 2.661471128463745
batch i:625
learning rate: 0.0013333333333333333, loss: 2.6467366218566895
batch i:626
learning rate: 0.0013333333333333333, loss: 2.736943483352661
batch i:627
learning rate: 0.0013333333333333333, loss: 2.6772022247314453
batch i:628
learning rate: 0.0013333333333333333, loss: 2.5496644973754883
batch i:629
learning rate: 0.0013333333333333333, loss: 2.642486572265625
batch i:630
learning rate: 0.0013333333333333333, loss: 2.613126039505005
batch i:631
learning rate: 0.0013333333333333333, loss: 2.7011680603027344
batch i:632
learning rate: 0.0013333333333333333, loss: 2.6513724327087402
batch i:633
learning rate: 0.0013333333333333333, loss: 2.7377474308013916
batch i:634
learning rate: 0.0013333333333333333, loss: 2.5764739513397217
batch i:635
learning rate: 0.0013333333333333333, loss: 2.6897168159484863
batch i:636
learning rate: 0.0013333333333333333, loss: 2.6877849102020264
batch i:637
learning rate: 0.0013333333333333333, loss: 2.655320644378662
batch i:638
learning rate: 0.0013333333333333333, loss: 2.60256290435791
batch i:639
learning rate: 0.0013333333333333333, loss: 2.6383213996887207
batch i:640
learning rate: 0.0013333333333333333, loss: 2.538583755493164
batch i:641
learning rate: 0.0013333333333333333, loss: 2.600602626800537
batch i:642
learning rate: 0.0013333333333333333, loss: 2.6149630546569824
batch i:643
learning rate: 0.0013333333333333333, loss: 2.7384374141693115
batch i:644
learning rate: 0.0013333333333333333, loss: 2.6443848609924316
batch i:645
learning rate: 0.0013333333333333333, loss: 2.5757274627685547
batch i:646
learning rate: 0.0013333333333333333, loss: 2.595043897628784
batch i:647
learning rate: 0.0013333333333333333, loss: 2.5849387645721436
batch i:648
learning rate: 0.0013333333333333333, loss: 2.5449676513671875
batch i:649
learning rate: 0.0013333333333333333, loss: 2.537963390350342
batch i:650
learning rate: 0.0013333333333333333, loss: 2.5633320808410645
current self-play batch: 650
num_playouts:2000, win: 5, lose: 5, tie:0
average time: 198.97103035449982
batch i:651
learning rate: 0.0013333333333333333, loss: 2.629319190979004
batch i:652
learning rate: 0.0013333333333333333, loss: 2.5733022689819336
batch i:653
learning rate: 0.0013333333333333333, loss: 2.6392245292663574
batch i:654
learning rate: 0.0013333333333333333, loss: 2.585148334503174
batch i:655
learning rate: 0.0013333333333333333, loss: 2.6335437297821045
batch i:656
learning rate: 0.0013333333333333333, loss: 2.6980090141296387
batch i:657
learning rate: 0.0013333333333333333, loss: 2.636878252029419
batch i:658
learning rate: 0.0013333333333333333, loss: 2.546898365020752
batch i:659
learning rate: 0.0013333333333333333, loss: 2.6441168785095215
batch i:660
learning rate: 0.0013333333333333333, loss: 2.615994453430176
batch i:661
learning rate: 0.0013333333333333333, loss: 2.686126232147217
batch i:662
learning rate: 0.0013333333333333333, loss: 2.6378307342529297
batch i:663
learning rate: 0.0013333333333333333, loss: 2.636969804763794
batch i:664
learning rate: 0.0013333333333333333, loss: 2.6479620933532715
batch i:665
learning rate: 0.0013333333333333333, loss: 2.6084821224212646
batch i:666
learning rate: 0.0013333333333333333, loss: 2.541234254837036
batch i:667
learning rate: 0.0013333333333333333, loss: 2.502213478088379
batch i:668
learning rate: 0.0013333333333333333, loss: 2.626610279083252
batch i:669
learning rate: 0.0013333333333333333, loss: 2.6316471099853516
batch i:670
learning rate: 0.0013333333333333333, loss: 2.518048048019409
batch i:671
learning rate: 0.0013333333333333333, loss: 2.5442051887512207
batch i:672
learning rate: 0.0013333333333333333, loss: 2.5648367404937744
batch i:673
learning rate: 0.0013333333333333333, loss: 2.588489532470703
batch i:674
learning rate: 0.0013333333333333333, loss: 2.650067090988159
batch i:675
learning rate: 0.0013333333333333333, loss: 2.570089817047119
batch i:676
learning rate: 0.0013333333333333333, loss: 2.580984115600586
batch i:677
learning rate: 0.0013333333333333333, loss: 2.517650604248047
batch i:678
learning rate: 0.0013333333333333333, loss: 2.4632749557495117
batch i:679
learning rate: 0.0013333333333333333, loss: 2.5255942344665527
batch i:680
learning rate: 0.0013333333333333333, loss: 2.6753032207489014
batch i:681
learning rate: 0.0013333333333333333, loss: 2.46150541305542
batch i:682
learning rate: 0.0013333333333333333, loss: 2.655648708343506
batch i:683
learning rate: 0.0013333333333333333, loss: 2.472182273864746
batch i:684
learning rate: 0.0013333333333333333, loss: 2.6449780464172363
batch i:685
learning rate: 0.0013333333333333333, loss: 2.521406412124634
batch i:686
learning rate: 0.0013333333333333333, loss: 2.5466127395629883
batch i:687
learning rate: 0.0013333333333333333, loss: 2.5810372829437256
batch i:688
learning rate: 0.0013333333333333333, loss: 2.5132880210876465
batch i:689
learning rate: 0.0013333333333333333, loss: 2.521172523498535
batch i:690
learning rate: 0.0013333333333333333, loss: 2.3876147270202637
batch i:691
learning rate: 0.0013333333333333333, loss: 2.5604000091552734
batch i:692
learning rate: 0.0013333333333333333, loss: 2.4781265258789062
batch i:693
learning rate: 0.0013333333333333333, loss: 2.3715882301330566
batch i:694
learning rate: 0.0013333333333333333, loss: 2.4905455112457275
batch i:695
learning rate: 0.0013333333333333333, loss: 2.4519968032836914
batch i:696
learning rate: 0.0013333333333333333, loss: 2.407886505126953
batch i:697
learning rate: 0.0013333333333333333, loss: 2.5375185012817383
batch i:698
learning rate: 0.0013333333333333333, loss: 2.4131417274475098
batch i:699
learning rate: 0.0013333333333333333, loss: 2.5447168350219727
batch i:700
learning rate: 0.0013333333333333333, loss: 2.490830421447754
current self-play batch: 700
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 154.70555267333984
batch i:701
learning rate: 0.0013333333333333333, loss: 2.5598950386047363
batch i:702
learning rate: 0.0013333333333333333, loss: 2.518261432647705
batch i:703
learning rate: 0.0013333333333333333, loss: 2.4999842643737793
batch i:704
learning rate: 0.0013333333333333333, loss: 2.69120454788208
batch i:705
learning rate: 0.0013333333333333333, loss: 2.6175413131713867
batch i:706
learning rate: 0.0013333333333333333, loss: 2.5129308700561523
batch i:707
learning rate: 0.0013333333333333333, loss: 2.5435149669647217
batch i:708
learning rate: 0.0013333333333333333, loss: 2.539674997329712
batch i:709
learning rate: 0.0013333333333333333, loss: 2.5073702335357666
batch i:710
learning rate: 0.0013333333333333333, loss: 2.5336036682128906
batch i:711
learning rate: 0.0013333333333333333, loss: 2.6106317043304443
batch i:712
learning rate: 0.0013333333333333333, loss: 2.579098701477051
batch i:713
learning rate: 0.0013333333333333333, loss: 2.4987294673919678
batch i:714
learning rate: 0.0013333333333333333, loss: 2.5197906494140625
batch i:715
learning rate: 0.0013333333333333333, loss: 2.5693092346191406
batch i:716
learning rate: 0.0013333333333333333, loss: 2.5444750785827637
batch i:717
learning rate: 0.0013333333333333333, loss: 2.522806406021118
batch i:718
learning rate: 0.0013333333333333333, loss: 2.502495765686035
batch i:719
learning rate: 0.0013333333333333333, loss: 2.4010651111602783
batch i:720
learning rate: 0.0013333333333333333, loss: 2.5775606632232666
batch i:721
learning rate: 0.0013333333333333333, loss: 2.517601251602173
batch i:722
learning rate: 0.0013333333333333333, loss: 2.513202428817749
batch i:723
learning rate: 0.0013333333333333333, loss: 2.5190649032592773
batch i:724
learning rate: 0.0013333333333333333, loss: 2.561586380004883
batch i:725
learning rate: 0.0013333333333333333, loss: 2.5599584579467773
batch i:726
learning rate: 0.0013333333333333333, loss: 2.482545852661133
batch i:727
learning rate: 0.0013333333333333333, loss: 2.4680891036987305
batch i:728
learning rate: 0.0013333333333333333, loss: 2.546050786972046
batch i:729
learning rate: 0.0013333333333333333, loss: 2.448629379272461
batch i:730
learning rate: 0.0013333333333333333, loss: 2.523409843444824
batch i:731
learning rate: 0.0013333333333333333, loss: 2.4266810417175293
batch i:732
learning rate: 0.0013333333333333333, loss: 2.590301513671875
batch i:733
learning rate: 0.0013333333333333333, loss: 2.5401759147644043
batch i:734
learning rate: 0.0013333333333333333, loss: 2.5961122512817383
batch i:735
learning rate: 0.0013333333333333333, loss: 2.561384916305542
batch i:736
learning rate: 0.0013333333333333333, loss: 2.535958766937256
batch i:737
learning rate: 0.0013333333333333333, loss: 2.4864630699157715
batch i:738
learning rate: 0.0013333333333333333, loss: 2.479936122894287
batch i:739
learning rate: 0.0013333333333333333, loss: 2.559081792831421
batch i:740
learning rate: 0.0013333333333333333, loss: 2.6419084072113037
batch i:741
learning rate: 0.0013333333333333333, loss: 2.4598183631896973
batch i:742
learning rate: 0.0013333333333333333, loss: 2.487921714782715
batch i:743
learning rate: 0.0013333333333333333, loss: 2.4186606407165527
batch i:744
learning rate: 0.0013333333333333333, loss: 2.3953773975372314
batch i:745
learning rate: 0.0013333333333333333, loss: 2.4615135192871094
batch i:746
learning rate: 0.0013333333333333333, loss: 2.529090404510498
batch i:747
learning rate: 0.0013333333333333333, loss: 2.4378485679626465
batch i:748
learning rate: 0.0013333333333333333, loss: 2.4740474224090576
batch i:749
learning rate: 0.0013333333333333333, loss: 2.4833364486694336
batch i:750
learning rate: 0.0013333333333333333, loss: 2.625215530395508
current self-play batch: 750
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 179.3843594789505
batch i:751
learning rate: 0.0013333333333333333, loss: 2.602919101715088
batch i:752
learning rate: 0.0013333333333333333, loss: 2.4768624305725098
batch i:753
learning rate: 0.0013333333333333333, loss: 2.5122997760772705
batch i:754
learning rate: 0.0013333333333333333, loss: 2.5382795333862305
batch i:755
learning rate: 0.0013333333333333333, loss: 2.5568413734436035
batch i:756
learning rate: 0.0013333333333333333, loss: 2.4726972579956055
batch i:757
learning rate: 0.0013333333333333333, loss: 2.469184637069702
batch i:758
learning rate: 0.0013333333333333333, loss: 2.4083456993103027
batch i:759
learning rate: 0.0013333333333333333, loss: 2.47161865234375
batch i:760
learning rate: 0.0013333333333333333, loss: 2.511390209197998
batch i:761
learning rate: 0.0013333333333333333, loss: 2.4369845390319824
batch i:762
learning rate: 0.0013333333333333333, loss: 2.402655601501465
batch i:763
learning rate: 0.0013333333333333333, loss: 2.5839591026306152
batch i:764
learning rate: 0.0013333333333333333, loss: 2.5463778972625732
batch i:765
learning rate: 0.0013333333333333333, loss: 2.4319090843200684
batch i:766
learning rate: 0.0013333333333333333, loss: 2.473437547683716
batch i:767
learning rate: 0.0013333333333333333, loss: 2.4233341217041016
batch i:768
learning rate: 0.0013333333333333333, loss: 2.4429750442504883
batch i:769
learning rate: 0.0013333333333333333, loss: 2.4008989334106445
batch i:770
learning rate: 0.0013333333333333333, loss: 2.470235824584961
batch i:771
learning rate: 0.0013333333333333333, loss: 2.5322539806365967
batch i:772
learning rate: 0.0013333333333333333, loss: 2.4602136611938477
batch i:773
learning rate: 0.0013333333333333333, loss: 2.4352197647094727
batch i:774
learning rate: 0.0013333333333333333, loss: 2.4720630645751953
batch i:775
learning rate: 0.0013333333333333333, loss: 2.422492027282715
batch i:776
learning rate: 0.0013333333333333333, loss: 2.4721193313598633
batch i:777
learning rate: 0.0013333333333333333, loss: 2.434121608734131
batch i:778
learning rate: 0.0013333333333333333, loss: 2.427333354949951
batch i:779
learning rate: 0.0013333333333333333, loss: 2.4238195419311523
batch i:780
learning rate: 0.0013333333333333333, loss: 2.4210116863250732
batch i:781
learning rate: 0.0013333333333333333, loss: 2.3439106941223145
batch i:782
learning rate: 0.0013333333333333333, loss: 2.452791929244995
batch i:783
learning rate: 0.0013333333333333333, loss: 2.3360705375671387
batch i:784
learning rate: 0.0013333333333333333, loss: 2.399082660675049
batch i:785
learning rate: 0.0013333333333333333, loss: 2.365140438079834
batch i:786
learning rate: 0.0013333333333333333, loss: 2.3649179935455322
batch i:787
learning rate: 0.0013333333333333333, loss: 2.3502182960510254
batch i:788
learning rate: 0.0013333333333333333, loss: 2.3440287113189697
batch i:789
learning rate: 0.0013333333333333333, loss: 2.284348726272583
batch i:790
learning rate: 0.0013333333333333333, loss: 2.365196704864502
batch i:791
learning rate: 0.0013333333333333333, loss: 2.35028076171875
batch i:792
learning rate: 0.0013333333333333333, loss: 2.3753151893615723
batch i:793
learning rate: 0.0013333333333333333, loss: 2.3613946437835693
batch i:794
learning rate: 0.0013333333333333333, loss: 2.3842878341674805
batch i:795
learning rate: 0.0013333333333333333, loss: 2.308623790740967
batch i:796
learning rate: 0.0013333333333333333, loss: 2.353120803833008
batch i:797
learning rate: 0.0013333333333333333, loss: 2.455531120300293
batch i:798
learning rate: 0.0013333333333333333, loss: 2.3079419136047363
batch i:799
learning rate: 0.0013333333333333333, loss: 2.413823127746582
batch i:800
learning rate: 0.0013333333333333333, loss: 2.3829991817474365
current self-play batch: 800
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 197.94254627227784
batch i:801
learning rate: 0.0013333333333333333, loss: 2.4502933025360107
batch i:802
learning rate: 0.0013333333333333333, loss: 2.4280552864074707
batch i:803
learning rate: 0.0013333333333333333, loss: 2.4078867435455322
batch i:804
learning rate: 0.0013333333333333333, loss: 2.4070065021514893
batch i:805
learning rate: 0.0013333333333333333, loss: 2.3288073539733887
batch i:806
learning rate: 0.0013333333333333333, loss: 2.489758014678955
batch i:807
learning rate: 0.0013333333333333333, loss: 2.4925637245178223
batch i:808
learning rate: 0.0013333333333333333, loss: 2.4390668869018555
batch i:809
learning rate: 0.0013333333333333333, loss: 2.4682724475860596
batch i:810
learning rate: 0.0013333333333333333, loss: 2.433267116546631
batch i:811
learning rate: 0.0013333333333333333, loss: 2.5714612007141113
batch i:812
learning rate: 0.0013333333333333333, loss: 2.5426740646362305
batch i:813
learning rate: 0.0013333333333333333, loss: 2.5373165607452393
batch i:814
learning rate: 0.0013333333333333333, loss: 2.5645973682403564
batch i:815
learning rate: 0.0013333333333333333, loss: 2.4972639083862305
batch i:816
learning rate: 0.0013333333333333333, loss: 2.422506809234619
batch i:817
learning rate: 0.0013333333333333333, loss: 2.5222856998443604
batch i:818
learning rate: 0.0013333333333333333, loss: 2.4787545204162598
batch i:819
learning rate: 0.0013333333333333333, loss: 2.571781635284424
batch i:820
learning rate: 0.0013333333333333333, loss: 2.5080981254577637
batch i:821
learning rate: 0.0013333333333333333, loss: 2.569551467895508
batch i:822
learning rate: 0.0013333333333333333, loss: 2.5324604511260986
batch i:823
learning rate: 0.0013333333333333333, loss: 2.482069969177246
batch i:824
learning rate: 0.0013333333333333333, loss: 2.577078342437744
batch i:825
learning rate: 0.0013333333333333333, loss: 2.530041217803955
batch i:826
learning rate: 0.0013333333333333333, loss: 2.4654364585876465
batch i:827
learning rate: 0.0013333333333333333, loss: 2.5686545372009277
batch i:828
learning rate: 0.0013333333333333333, loss: 2.6088013648986816
batch i:829
learning rate: 0.0013333333333333333, loss: 2.450861692428589
batch i:830
learning rate: 0.0013333333333333333, loss: 2.5768136978149414
batch i:831
learning rate: 0.0013333333333333333, loss: 2.4509596824645996
batch i:832
learning rate: 0.0013333333333333333, loss: 2.521916627883911
batch i:833
learning rate: 0.0013333333333333333, loss: 2.557860851287842
batch i:834
learning rate: 0.0013333333333333333, loss: 2.4950225353240967
batch i:835
learning rate: 0.0013333333333333333, loss: 2.47128963470459
batch i:836
learning rate: 0.0013333333333333333, loss: 2.4632089138031006
batch i:837
learning rate: 0.0013333333333333333, loss: 2.463237762451172
batch i:838
learning rate: 0.0013333333333333333, loss: 2.477517604827881
batch i:839
learning rate: 0.0013333333333333333, loss: 2.433103084564209
batch i:840
learning rate: 0.0013333333333333333, loss: 2.5251970291137695
batch i:841
learning rate: 0.0013333333333333333, loss: 2.57658314704895
batch i:842
learning rate: 0.0013333333333333333, loss: 2.5434508323669434
batch i:843
learning rate: 0.0013333333333333333, loss: 2.50439190864563
batch i:844
learning rate: 0.0013333333333333333, loss: 2.493964672088623
batch i:845
learning rate: 0.0013333333333333333, loss: 2.522291898727417
batch i:846
learning rate: 0.0013333333333333333, loss: 2.6179590225219727
batch i:847
learning rate: 0.0013333333333333333, loss: 2.621368646621704
batch i:848
learning rate: 0.0013333333333333333, loss: 2.599740982055664
batch i:849
learning rate: 0.0013333333333333333, loss: 2.629629135131836
batch i:850
learning rate: 0.0013333333333333333, loss: 2.575409412384033
current self-play batch: 850
num_playouts:2000, win: 7, lose: 3, tie:0
average time: 353.53735036849974
batch i:851
learning rate: 0.0013333333333333333, loss: 2.594327926635742
batch i:852
learning rate: 0.0013333333333333333, loss: 2.6327195167541504
batch i:853
learning rate: 0.0013333333333333333, loss: 2.627800464630127
batch i:854
learning rate: 0.0013333333333333333, loss: 2.629492998123169
batch i:855
learning rate: 0.0013333333333333333, loss: 2.6617233753204346
batch i:856
learning rate: 0.0013333333333333333, loss: 2.618623733520508
batch i:857
learning rate: 0.0013333333333333333, loss: 2.674757957458496
batch i:858
learning rate: 0.0013333333333333333, loss: 2.6223559379577637
batch i:859
learning rate: 0.0013333333333333333, loss: 2.6307806968688965
batch i:860
learning rate: 0.0013333333333333333, loss: 2.614206314086914
batch i:861
learning rate: 0.0013333333333333333, loss: 2.6325857639312744
batch i:862
learning rate: 0.0013333333333333333, loss: 2.719913959503174
batch i:863
learning rate: 0.0013333333333333333, loss: 2.7341182231903076
batch i:864
learning rate: 0.0013333333333333333, loss: 2.622589349746704
batch i:865
learning rate: 0.0013333333333333333, loss: 2.612567186355591
batch i:866
learning rate: 0.0013333333333333333, loss: 2.5428900718688965
batch i:867
learning rate: 0.0013333333333333333, loss: 2.6573119163513184
batch i:868
learning rate: 0.0013333333333333333, loss: 2.7250289916992188
batch i:869
learning rate: 0.0013333333333333333, loss: 2.6843128204345703
batch i:870
learning rate: 0.0013333333333333333, loss: 2.7542779445648193
batch i:871
learning rate: 0.0013333333333333333, loss: 2.6340889930725098
batch i:872
learning rate: 0.0013333333333333333, loss: 2.7661120891571045
batch i:873
learning rate: 0.0013333333333333333, loss: 2.5899643898010254
batch i:874
learning rate: 0.0013333333333333333, loss: 2.775343656539917
batch i:875
learning rate: 0.0013333333333333333, loss: 2.794842481613159
batch i:876
learning rate: 0.0013333333333333333, loss: 2.695838689804077
batch i:877
learning rate: 0.0013333333333333333, loss: 2.607351541519165
batch i:878
learning rate: 0.0013333333333333333, loss: 2.7650718688964844
batch i:879
learning rate: 0.0013333333333333333, loss: 2.6790175437927246
batch i:880
learning rate: 0.0013333333333333333, loss: 2.6491429805755615
batch i:881
learning rate: 0.0013333333333333333, loss: 2.70908260345459
batch i:882
learning rate: 0.0013333333333333333, loss: 2.7181241512298584
batch i:883
learning rate: 0.0013333333333333333, loss: 2.731868267059326
batch i:884
learning rate: 0.0013333333333333333, loss: 2.591186761856079
batch i:885
learning rate: 0.0013333333333333333, loss: 2.682610034942627
batch i:886
learning rate: 0.0013333333333333333, loss: 2.7224767208099365
batch i:887
learning rate: 0.0013333333333333333, loss: 2.7095465660095215
batch i:888
learning rate: 0.0013333333333333333, loss: 2.774660110473633
batch i:889
learning rate: 0.0013333333333333333, loss: 2.6981418132781982
batch i:890
learning rate: 0.0013333333333333333, loss: 2.8101725578308105
batch i:891
learning rate: 0.0013333333333333333, loss: 2.719031810760498
batch i:892
learning rate: 0.0013333333333333333, loss: 2.6186914443969727
batch i:893
learning rate: 0.0013333333333333333, loss: 2.7440130710601807
batch i:894
learning rate: 0.0013333333333333333, loss: 2.7143869400024414
batch i:895
learning rate: 0.0013333333333333333, loss: 2.7045540809631348
batch i:896
learning rate: 0.0013333333333333333, loss: 2.7051608562469482
batch i:897
learning rate: 0.0013333333333333333, loss: 2.7180562019348145
batch i:898
learning rate: 0.0013333333333333333, loss: 2.7248144149780273
batch i:899
learning rate: 0.0013333333333333333, loss: 2.7362546920776367
batch i:900
learning rate: 0.0013333333333333333, loss: 2.815830707550049
current self-play batch: 900
num_playouts:2000, win: 10, lose: 0, tie:0
average time: 310.6749569892883
New best policy from pure MCTS
batch i:901
learning rate: 0.0013333333333333333, loss: 2.778665781021118
batch i:902
learning rate: 0.0013333333333333333, loss: 2.6849169731140137
batch i:903
learning rate: 0.0013333333333333333, loss: 2.8687736988067627
batch i:904
learning rate: 0.0013333333333333333, loss: 2.715864658355713
batch i:905
learning rate: 0.0013333333333333333, loss: 2.6966681480407715
batch i:906
learning rate: 0.0013333333333333333, loss: 2.7322211265563965
batch i:907
learning rate: 0.0013333333333333333, loss: 2.691500186920166
batch i:908
learning rate: 0.0013333333333333333, loss: 2.708641529083252
batch i:909
learning rate: 0.0013333333333333333, loss: 2.6623148918151855
batch i:910
learning rate: 0.0013333333333333333, loss: 2.677093029022217
batch i:911
learning rate: 0.0013333333333333333, loss: 2.7703752517700195
batch i:912
learning rate: 0.0013333333333333333, loss: 2.6136181354522705
batch i:913
learning rate: 0.0013333333333333333, loss: 2.7399327754974365
batch i:914
learning rate: 0.0013333333333333333, loss: 2.7198257446289062
batch i:915
learning rate: 0.0013333333333333333, loss: 2.777944564819336
batch i:916
learning rate: 0.0013333333333333333, loss: 2.726745128631592
batch i:917
learning rate: 0.0013333333333333333, loss: 2.8228635787963867
batch i:918
learning rate: 0.0013333333333333333, loss: 2.7977728843688965
batch i:919
learning rate: 0.0013333333333333333, loss: 2.82429838180542
batch i:920
learning rate: 0.0013333333333333333, loss: 2.7319750785827637
batch i:921
learning rate: 0.0013333333333333333, loss: 2.7218222618103027
batch i:922
learning rate: 0.0013333333333333333, loss: 2.7358055114746094
batch i:923
learning rate: 0.0013333333333333333, loss: 2.7259371280670166
batch i:924
learning rate: 0.0013333333333333333, loss: 2.7309694290161133
batch i:925
learning rate: 0.0013333333333333333, loss: 2.6984941959381104
batch i:926
learning rate: 0.0013333333333333333, loss: 2.7436118125915527
batch i:927
learning rate: 0.0013333333333333333, loss: 2.6963934898376465
batch i:928
learning rate: 0.0013333333333333333, loss: 2.689901828765869
batch i:929
learning rate: 0.0013333333333333333, loss: 2.678340435028076
batch i:930
learning rate: 0.0013333333333333333, loss: 2.7699215412139893
batch i:931
learning rate: 0.0013333333333333333, loss: 2.629836320877075
batch i:932
learning rate: 0.0013333333333333333, loss: 2.651301383972168
batch i:933
learning rate: 0.0013333333333333333, loss: 2.6649155616760254
batch i:934
learning rate: 0.0013333333333333333, loss: 2.6855695247650146
batch i:935
learning rate: 0.0013333333333333333, loss: 2.6574501991271973
batch i:936
learning rate: 0.0013333333333333333, loss: 2.588197708129883
batch i:937
learning rate: 0.0013333333333333333, loss: 2.60006046295166
batch i:938
learning rate: 0.0013333333333333333, loss: 2.624812126159668
batch i:939
learning rate: 0.0013333333333333333, loss: 2.6429362297058105
batch i:940
learning rate: 0.0013333333333333333, loss: 2.557455539703369
batch i:941
learning rate: 0.0013333333333333333, loss: 2.6992650032043457
batch i:942
learning rate: 0.0013333333333333333, loss: 2.6605968475341797
batch i:943
learning rate: 0.0013333333333333333, loss: 2.569093704223633
batch i:944
learning rate: 0.0013333333333333333, loss: 2.5544323921203613
batch i:945
learning rate: 0.0013333333333333333, loss: 2.632570266723633
batch i:946
learning rate: 0.0013333333333333333, loss: 2.6861188411712646
batch i:947
learning rate: 0.0013333333333333333, loss: 2.505479335784912
batch i:948
learning rate: 0.0013333333333333333, loss: 2.5916247367858887
batch i:949
learning rate: 0.0013333333333333333, loss: 2.6855628490448
batch i:950
learning rate: 0.0013333333333333333, loss: 2.629786491394043
current self-play batch: 950
num_playouts:3000, win: 5, lose: 5, tie:0
average time: 1239.3068988323212
batch i:951
learning rate: 0.0013333333333333333, loss: 2.666898727416992
batch i:952
learning rate: 0.0013333333333333333, loss: 2.628957986831665
batch i:953
learning rate: 0.0013333333333333333, loss: 2.613593339920044
batch i:954
learning rate: 0.0013333333333333333, loss: 2.5644724369049072
batch i:955
learning rate: 0.0013333333333333333, loss: 2.5366506576538086
batch i:956
learning rate: 0.0013333333333333333, loss: 2.615874767303467
batch i:957
learning rate: 0.0013333333333333333, loss: 2.6347553730010986
batch i:958
learning rate: 0.0013333333333333333, loss: 2.652831554412842
batch i:959
learning rate: 0.0013333333333333333, loss: 2.6139702796936035
batch i:960
learning rate: 0.0013333333333333333, loss: 2.5954880714416504
batch i:961
learning rate: 0.0013333333333333333, loss: 2.611316442489624
batch i:962
learning rate: 0.0013333333333333333, loss: 2.740640640258789
batch i:963
learning rate: 0.0013333333333333333, loss: 2.7265000343322754
batch i:964
learning rate: 0.0013333333333333333, loss: 2.6306748390197754
batch i:965
learning rate: 0.0013333333333333333, loss: 2.7925362586975098
batch i:966
learning rate: 0.0013333333333333333, loss: 2.8289074897766113
batch i:967
learning rate: 0.0013333333333333333, loss: 2.825326442718506
batch i:968
learning rate: 0.0013333333333333333, loss: 2.696213960647583
batch i:969
learning rate: 0.0013333333333333333, loss: 2.693788528442383
batch i:970
learning rate: 0.0013333333333333333, loss: 2.639800548553467
batch i:971
learning rate: 0.0013333333333333333, loss: 2.765376329421997
batch i:972
learning rate: 0.0013333333333333333, loss: 2.7244017124176025
batch i:973
learning rate: 0.0013333333333333333, loss: 2.647129535675049
batch i:974
learning rate: 0.0013333333333333333, loss: 2.739564895629883
batch i:975
learning rate: 0.0013333333333333333, loss: 2.68078875541687
batch i:976
learning rate: 0.0013333333333333333, loss: 2.661210536956787
batch i:977
learning rate: 0.0013333333333333333, loss: 2.63651180267334
batch i:978
learning rate: 0.0013333333333333333, loss: 2.6630172729492188
batch i:979
learning rate: 0.0013333333333333333, loss: 2.681856632232666
batch i:980
learning rate: 0.0013333333333333333, loss: 2.617928981781006
batch i:981
learning rate: 0.0013333333333333333, loss: 2.7688872814178467
batch i:982
learning rate: 0.0013333333333333333, loss: 2.6838507652282715
batch i:983
learning rate: 0.0013333333333333333, loss: 2.6395320892333984
batch i:984
learning rate: 0.0013333333333333333, loss: 2.5879721641540527
batch i:985
learning rate: 0.0013333333333333333, loss: 2.52187180519104
batch i:986
learning rate: 0.0013333333333333333, loss: 2.5931849479675293
batch i:987
learning rate: 0.0013333333333333333, loss: 2.6209330558776855
batch i:988
learning rate: 0.0013333333333333333, loss: 2.646082639694214
batch i:989
learning rate: 0.0013333333333333333, loss: 2.599914789199829
batch i:990
learning rate: 0.0013333333333333333, loss: 2.557222604751587
batch i:991
learning rate: 0.0013333333333333333, loss: 2.500192880630493
batch i:992
learning rate: 0.0013333333333333333, loss: 2.563011646270752
batch i:993
learning rate: 0.0013333333333333333, loss: 2.5325608253479004
batch i:994
learning rate: 0.0013333333333333333, loss: 2.6172561645507812
batch i:995
learning rate: 0.0013333333333333333, loss: 2.532874345779419
batch i:996
learning rate: 0.0013333333333333333, loss: 2.6294331550598145
batch i:997
learning rate: 0.0013333333333333333, loss: 2.6229491233825684
batch i:998
learning rate: 0.0013333333333333333, loss: 2.580778121948242
batch i:999
learning rate: 0.0013333333333333333, loss: 2.638472557067871
batch i:1000
learning rate: 0.0013333333333333333, loss: 2.5422756671905518
current self-play batch: 1000
num_playouts:3000, win: 4, lose: 6, tie:0
average time: 1022.5806653499603
New best policy from pure MCTS
batch i:1001
learning rate: 0.0013333333333333333, loss: 2.5881266593933105
batch i:1002
learning rate: 0.0013333333333333333, loss: 2.6292061805725098
batch i:1003
learning rate: 0.0013333333333333333, loss: 2.6110920906066895
batch i:1004
learning rate: 0.0013333333333333333, loss: 2.6721887588500977
batch i:1005
learning rate: 0.0013333333333333333, loss: 2.610736846923828
batch i:1006
learning rate: 0.0013333333333333333, loss: 2.727303981781006
batch i:1007
learning rate: 0.0013333333333333333, loss: 2.6694765090942383
batch i:1008
learning rate: 0.0013333333333333333, loss: 2.6025497913360596
batch i:1009
learning rate: 0.0013333333333333333, loss: 2.5812087059020996
batch i:1010
learning rate: 0.0013333333333333333, loss: 2.6058051586151123
batch i:1011
learning rate: 0.0013333333333333333, loss: 2.7338695526123047
batch i:1012
learning rate: 0.0013333333333333333, loss: 2.617295503616333
batch i:1013
learning rate: 0.0013333333333333333, loss: 2.66054630279541
batch i:1014
learning rate: 0.0013333333333333333, loss: 2.5972166061401367
batch i:1015
learning rate: 0.0013333333333333333, loss: 2.6295175552368164
batch i:1016
learning rate: 0.0013333333333333333, loss: 2.5086536407470703
batch i:1017
learning rate: 0.0013333333333333333, loss: 2.612565040588379
batch i:1018
learning rate: 0.0013333333333333333, loss: 2.582469940185547
batch i:1019
learning rate: 0.0013333333333333333, loss: 2.5282368659973145
batch i:1020
learning rate: 0.0013333333333333333, loss: 2.5255954265594482
batch i:1021
learning rate: 0.0013333333333333333, loss: 2.518481969833374
batch i:1022
learning rate: 0.0013333333333333333, loss: 2.567866563796997
batch i:1023
learning rate: 0.0013333333333333333, loss: 2.4648165702819824
batch i:1024
learning rate: 0.0013333333333333333, loss: 2.497716188430786
batch i:1025
learning rate: 0.0013333333333333333, loss: 2.5922093391418457
batch i:1026
learning rate: 0.0013333333333333333, loss: 2.5326759815216064
batch i:1027
learning rate: 0.0013333333333333333, loss: 2.491783618927002
batch i:1028
learning rate: 0.0013333333333333333, loss: 2.5533957481384277
batch i:1029
learning rate: 0.0013333333333333333, loss: 2.473903179168701
batch i:1030
learning rate: 0.0013333333333333333, loss: 2.592775821685791
batch i:1031
learning rate: 0.0013333333333333333, loss: 2.466592788696289
batch i:1032
learning rate: 0.0013333333333333333, loss: 2.447516441345215
batch i:1033
learning rate: 0.0013333333333333333, loss: 2.481825590133667
batch i:1034
learning rate: 0.0013333333333333333, loss: 2.442365884780884
batch i:1035
learning rate: 0.0013333333333333333, loss: 2.5598740577697754
batch i:1036
learning rate: 0.0013333333333333333, loss: 2.504990339279175
batch i:1037
learning rate: 0.0013333333333333333, loss: 2.412630558013916
batch i:1038
learning rate: 0.0013333333333333333, loss: 2.379317283630371
batch i:1039
learning rate: 0.0013333333333333333, loss: 2.504533529281616
batch i:1040
learning rate: 0.0013333333333333333, loss: 2.4298043251037598
batch i:1041
learning rate: 0.0013333333333333333, loss: 2.4413113594055176
batch i:1042
learning rate: 0.0013333333333333333, loss: 2.445821762084961
batch i:1043
learning rate: 0.0013333333333333333, loss: 2.471628189086914
batch i:1044
learning rate: 0.0013333333333333333, loss: 2.412369966506958
batch i:1045
learning rate: 0.0013333333333333333, loss: 2.475496292114258
batch i:1046
learning rate: 0.0013333333333333333, loss: 2.5524826049804688
batch i:1047
learning rate: 0.0013333333333333333, loss: 2.436981678009033
batch i:1048
learning rate: 0.0013333333333333333, loss: 2.398744583129883
batch i:1049
learning rate: 0.0013333333333333333, loss: 2.5036063194274902
batch i:1050
learning rate: 0.0013333333333333333, loss: 2.466965675354004
current self-play batch: 1050
num_playouts:3000, win: 6, lose: 4, tie:0
average time: 572.3436191320419
New best policy from pure MCTS
batch i:1051
learning rate: 0.0013333333333333333, loss: 2.5181989669799805
batch i:1052
learning rate: 0.0013333333333333333, loss: 2.4208974838256836
batch i:1053
learning rate: 0.0013333333333333333, loss: 2.570762872695923
batch i:1054
learning rate: 0.0013333333333333333, loss: 2.581991195678711
batch i:1055
learning rate: 0.0013333333333333333, loss: 2.5408997535705566
batch i:1056
learning rate: 0.0013333333333333333, loss: 2.507659673690796
batch i:1057
learning rate: 0.0013333333333333333, loss: 2.4947118759155273
batch i:1058
learning rate: 0.0013333333333333333, loss: 2.4243383407592773
batch i:1059
learning rate: 0.0013333333333333333, loss: 2.5579707622528076
batch i:1060
learning rate: 0.0013333333333333333, loss: 2.4624037742614746
batch i:1061
learning rate: 0.0013333333333333333, loss: 2.5626115798950195
batch i:1062
learning rate: 0.0013333333333333333, loss: 2.6925692558288574
batch i:1063
learning rate: 0.0013333333333333333, loss: 2.6202187538146973
batch i:1064
learning rate: 0.0013333333333333333, loss: 2.620316982269287
batch i:1065
learning rate: 0.0013333333333333333, loss: 2.510535717010498
batch i:1066
learning rate: 0.0013333333333333333, loss: 2.548462390899658
batch i:1067
learning rate: 0.0013333333333333333, loss: 2.5907974243164062
batch i:1068
learning rate: 0.0013333333333333333, loss: 2.6446025371551514
batch i:1069
learning rate: 0.0013333333333333333, loss: 2.6164236068725586
batch i:1070
learning rate: 0.0013333333333333333, loss: 2.629854202270508
batch i:1071
learning rate: 0.0013333333333333333, loss: 2.6157495975494385
batch i:1072
learning rate: 0.0013333333333333333, loss: 2.609102964401245
batch i:1073
learning rate: 0.0013333333333333333, loss: 2.589418888092041
batch i:1074
learning rate: 0.0013333333333333333, loss: 2.5908913612365723
batch i:1075
learning rate: 0.0013333333333333333, loss: 2.563282012939453
batch i:1076
learning rate: 0.0013333333333333333, loss: 2.5096988677978516
batch i:1077
learning rate: 0.0013333333333333333, loss: 2.5889370441436768
batch i:1078
learning rate: 0.0013333333333333333, loss: 2.632949113845825
batch i:1079
learning rate: 0.0013333333333333333, loss: 2.6852855682373047
batch i:1080
learning rate: 0.0013333333333333333, loss: 2.569148302078247
batch i:1081
learning rate: 0.0013333333333333333, loss: 2.5749106407165527
batch i:1082
learning rate: 0.0013333333333333333, loss: 2.58945369720459
batch i:1083
learning rate: 0.0013333333333333333, loss: 2.6377079486846924
batch i:1084
learning rate: 0.0013333333333333333, loss: 2.6096630096435547
batch i:1085
learning rate: 0.0013333333333333333, loss: 2.7039356231689453
batch i:1086
learning rate: 0.0013333333333333333, loss: 2.594616413116455
batch i:1087
learning rate: 0.0013333333333333333, loss: 2.6562962532043457
batch i:1088
learning rate: 0.0013333333333333333, loss: 2.689230442047119
batch i:1089
learning rate: 0.0013333333333333333, loss: 2.597878932952881
batch i:1090
learning rate: 0.0013333333333333333, loss: 2.597989320755005
batch i:1091
learning rate: 0.0013333333333333333, loss: 2.5997121334075928
batch i:1092
learning rate: 0.0013333333333333333, loss: 2.5403835773468018
batch i:1093
learning rate: 0.0013333333333333333, loss: 2.5736374855041504
batch i:1094
learning rate: 0.0013333333333333333, loss: 2.6217403411865234
batch i:1095
learning rate: 0.0013333333333333333, loss: 2.5956921577453613
batch i:1096
learning rate: 0.0013333333333333333, loss: 2.608574867248535
batch i:1097
learning rate: 0.0013333333333333333, loss: 2.7656681537628174
batch i:1098
learning rate: 0.0013333333333333333, loss: 2.6907341480255127
batch i:1099
learning rate: 0.0013333333333333333, loss: 2.690436840057373
batch i:1100
learning rate: 0.0013333333333333333, loss: 2.711036205291748
current self-play batch: 1100
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 694.4288024663925
New best policy from pure MCTS
batch i:1101
learning rate: 0.0013333333333333333, loss: 2.6043195724487305
batch i:1102
learning rate: 0.0013333333333333333, loss: 2.700690746307373
batch i:1103
learning rate: 0.0013333333333333333, loss: 2.714479923248291
batch i:1104
learning rate: 0.0013333333333333333, loss: 2.636622667312622
batch i:1105
learning rate: 0.0013333333333333333, loss: 2.758042335510254
batch i:1106
learning rate: 0.0013333333333333333, loss: 2.675328493118286
batch i:1107
learning rate: 0.0013333333333333333, loss: 2.659756660461426
batch i:1108
learning rate: 0.0013333333333333333, loss: 2.7505929470062256
batch i:1109
learning rate: 0.0013333333333333333, loss: 2.7166926860809326
batch i:1110
learning rate: 0.0013333333333333333, loss: 2.749356746673584
batch i:1111
learning rate: 0.0013333333333333333, loss: 2.7746312618255615
batch i:1112
learning rate: 0.0013333333333333333, loss: 2.7142038345336914
batch i:1113
learning rate: 0.0013333333333333333, loss: 2.766274929046631
batch i:1114
learning rate: 0.0013333333333333333, loss: 2.636932611465454
batch i:1115
learning rate: 0.0013333333333333333, loss: 2.729891777038574
batch i:1116
learning rate: 0.0013333333333333333, loss: 2.729351758956909
batch i:1117
learning rate: 0.0013333333333333333, loss: 2.6759612560272217
batch i:1118
learning rate: 0.0013333333333333333, loss: 2.6923956871032715
batch i:1119
learning rate: 0.0013333333333333333, loss: 2.6758387088775635
batch i:1120
learning rate: 0.0013333333333333333, loss: 2.7553024291992188
batch i:1121
learning rate: 0.0013333333333333333, loss: 2.8087596893310547
batch i:1122
learning rate: 0.0013333333333333333, loss: 2.735379457473755
batch i:1123
learning rate: 0.0013333333333333333, loss: 2.7534685134887695
batch i:1124
learning rate: 0.0013333333333333333, loss: 2.712306022644043
batch i:1125
learning rate: 0.0013333333333333333, loss: 2.642062187194824
batch i:1126
learning rate: 0.0013333333333333333, loss: 2.6943535804748535
batch i:1127
learning rate: 0.0013333333333333333, loss: 2.7104880809783936
batch i:1128
learning rate: 0.0013333333333333333, loss: 2.6901206970214844
batch i:1129
learning rate: 0.0013333333333333333, loss: 2.744321823120117
batch i:1130
learning rate: 0.0013333333333333333, loss: 2.749065399169922
batch i:1131
learning rate: 0.0013333333333333333, loss: 2.7193994522094727
batch i:1132
learning rate: 0.0013333333333333333, loss: 2.782045364379883
batch i:1133
learning rate: 0.0013333333333333333, loss: 2.764248847961426
batch i:1134
learning rate: 0.0013333333333333333, loss: 2.839735984802246
batch i:1135
learning rate: 0.0013333333333333333, loss: 2.8361246585845947
batch i:1136
learning rate: 0.0013333333333333333, loss: 2.642381191253662
batch i:1137
learning rate: 0.0013333333333333333, loss: 2.8367741107940674
batch i:1138
learning rate: 0.0013333333333333333, loss: 2.699489116668701
batch i:1139
learning rate: 0.0013333333333333333, loss: 2.7957839965820312
batch i:1140
learning rate: 0.0013333333333333333, loss: 2.8790063858032227
batch i:1141
learning rate: 0.0013333333333333333, loss: 2.731335163116455
batch i:1142
learning rate: 0.0013333333333333333, loss: 2.7246665954589844
batch i:1143
learning rate: 0.0013333333333333333, loss: 2.643735408782959
batch i:1144
learning rate: 0.0013333333333333333, loss: 2.7113828659057617
batch i:1145
learning rate: 0.0013333333333333333, loss: 2.7412338256835938
batch i:1146
learning rate: 0.0013333333333333333, loss: 2.675056219100952
batch i:1147
learning rate: 0.0013333333333333333, loss: 2.7736880779266357
batch i:1148
learning rate: 0.0013333333333333333, loss: 2.624809741973877
batch i:1149
learning rate: 0.0013333333333333333, loss: 2.6531975269317627
batch i:1150
learning rate: 0.0013333333333333333, loss: 2.7623229026794434
current self-play batch: 1150
num_playouts:3000, win: 4, lose: 6, tie:0
average time: 762.3533845424652
batch i:1151
learning rate: 0.0013333333333333333, loss: 2.620494842529297
batch i:1152
learning rate: 0.0013333333333333333, loss: 2.6746129989624023
batch i:1153
learning rate: 0.0013333333333333333, loss: 2.6289846897125244
batch i:1154
learning rate: 0.0013333333333333333, loss: 2.612581729888916
batch i:1155
learning rate: 0.0013333333333333333, loss: 2.668325424194336
batch i:1156
learning rate: 0.0013333333333333333, loss: 2.6217947006225586
batch i:1157
learning rate: 0.0013333333333333333, loss: 2.694169044494629
batch i:1158
learning rate: 0.0013333333333333333, loss: 2.630352735519409
batch i:1159
learning rate: 0.0013333333333333333, loss: 2.578434944152832
batch i:1160
learning rate: 0.0013333333333333333, loss: 2.563079357147217
batch i:1161
learning rate: 0.0013333333333333333, loss: 2.6029739379882812
batch i:1162
learning rate: 0.0013333333333333333, loss: 2.566429615020752
batch i:1163
learning rate: 0.0013333333333333333, loss: 2.5605692863464355
batch i:1164
learning rate: 0.0013333333333333333, loss: 2.637232780456543
batch i:1165
learning rate: 0.0013333333333333333, loss: 2.620151996612549
batch i:1166
learning rate: 0.0013333333333333333, loss: 2.606555461883545
batch i:1167
learning rate: 0.0013333333333333333, loss: 2.5806689262390137
batch i:1168
learning rate: 0.0013333333333333333, loss: 2.5478835105895996
batch i:1169
learning rate: 0.0013333333333333333, loss: 2.5995049476623535
batch i:1170
learning rate: 0.0013333333333333333, loss: 2.6834287643432617
batch i:1171
learning rate: 0.0013333333333333333, loss: 2.723005771636963
batch i:1172
learning rate: 0.0013333333333333333, loss: 2.5894668102264404
batch i:1173
learning rate: 0.0013333333333333333, loss: 2.6326913833618164
batch i:1174
learning rate: 0.0013333333333333333, loss: 2.734494209289551
batch i:1175
learning rate: 0.0013333333333333333, loss: 2.585813522338867
batch i:1176
learning rate: 0.0013333333333333333, loss: 2.682960033416748
batch i:1177
learning rate: 0.0013333333333333333, loss: 2.6055126190185547
batch i:1178
learning rate: 0.0013333333333333333, loss: 2.7310562133789062
batch i:1179
learning rate: 0.0013333333333333333, loss: 2.7066726684570312
batch i:1180
learning rate: 0.0013333333333333333, loss: 2.5308542251586914
batch i:1181
learning rate: 0.0013333333333333333, loss: 2.574082374572754
batch i:1182
learning rate: 0.0013333333333333333, loss: 2.5372018814086914
batch i:1183
learning rate: 0.0013333333333333333, loss: 2.635983467102051
batch i:1184
learning rate: 0.0013333333333333333, loss: 2.621436595916748
batch i:1185
learning rate: 0.0013333333333333333, loss: 2.56955623626709
batch i:1186
learning rate: 0.0013333333333333333, loss: 2.6092848777770996
batch i:1187
learning rate: 0.0013333333333333333, loss: 2.630054235458374
batch i:1188
learning rate: 0.0013333333333333333, loss: 2.6664791107177734
batch i:1189
learning rate: 0.0013333333333333333, loss: 2.6044814586639404
batch i:1190
learning rate: 0.0013333333333333333, loss: 2.5739173889160156
batch i:1191
learning rate: 0.0013333333333333333, loss: 2.622554302215576
batch i:1192
learning rate: 0.0013333333333333333, loss: 2.7166709899902344
batch i:1193
learning rate: 0.0013333333333333333, loss: 2.6264491081237793
batch i:1194
learning rate: 0.0013333333333333333, loss: 2.602079391479492
batch i:1195
learning rate: 0.0013333333333333333, loss: 2.6494131088256836
batch i:1196
learning rate: 0.0013333333333333333, loss: 2.7618818283081055
batch i:1197
learning rate: 0.0013333333333333333, loss: 2.7184743881225586
batch i:1198
learning rate: 0.0013333333333333333, loss: 2.643942356109619
batch i:1199
learning rate: 0.0013333333333333333, loss: 2.7616968154907227
batch i:1200
learning rate: 0.0013333333333333333, loss: 2.8166909217834473
current self-play batch: 1200
num_playouts:3000, win: 5, lose: 5, tie:0
average time: 578.0046494960785
batch i:1201
learning rate: 0.0013333333333333333, loss: 2.753262519836426
batch i:1202
learning rate: 0.0013333333333333333, loss: 2.848513126373291
batch i:1203
learning rate: 0.0013333333333333333, loss: 2.7762911319732666
batch i:1204
learning rate: 0.0013333333333333333, loss: 2.746004581451416
batch i:1205
learning rate: 0.0013333333333333333, loss: 2.7246289253234863
batch i:1206
learning rate: 0.0013333333333333333, loss: 2.789644479751587
batch i:1207
learning rate: 0.0013333333333333333, loss: 2.8135266304016113
batch i:1208
learning rate: 0.0013333333333333333, loss: 2.7873663902282715
batch i:1209
learning rate: 0.0013333333333333333, loss: 2.7053303718566895
batch i:1210
learning rate: 0.0013333333333333333, loss: 2.7711238861083984
batch i:1211
learning rate: 0.0013333333333333333, loss: 2.7049617767333984
batch i:1212
learning rate: 0.0013333333333333333, loss: 2.676377534866333
batch i:1213
learning rate: 0.0013333333333333333, loss: 2.6364901065826416
batch i:1214
learning rate: 0.0013333333333333333, loss: 2.6580958366394043
batch i:1215
learning rate: 0.0013333333333333333, loss: 2.6575770378112793
batch i:1216
learning rate: 0.0013333333333333333, loss: 2.688706159591675
batch i:1217
learning rate: 0.0013333333333333333, loss: 2.5923407077789307
batch i:1218
learning rate: 0.0013333333333333333, loss: 2.679677724838257
batch i:1219
learning rate: 0.0013333333333333333, loss: 2.7983856201171875
batch i:1220
learning rate: 0.0013333333333333333, loss: 2.7426705360412598
batch i:1221
learning rate: 0.0013333333333333333, loss: 2.657752513885498
batch i:1222
learning rate: 0.0013333333333333333, loss: 2.6629703044891357
batch i:1223
learning rate: 0.0013333333333333333, loss: 2.801264762878418
batch i:1224
learning rate: 0.0013333333333333333, loss: 2.8275249004364014
batch i:1225
learning rate: 0.0013333333333333333, loss: 2.5987889766693115
batch i:1226
learning rate: 0.0013333333333333333, loss: 2.7699830532073975
batch i:1227
learning rate: 0.0013333333333333333, loss: 2.7418651580810547
batch i:1228
learning rate: 0.0013333333333333333, loss: 2.712571620941162
batch i:1229
learning rate: 0.0013333333333333333, loss: 2.7926244735717773
batch i:1230
learning rate: 0.0013333333333333333, loss: 2.78977108001709
batch i:1231
learning rate: 0.0013333333333333333, loss: 2.775529384613037
batch i:1232
learning rate: 0.0013333333333333333, loss: 2.7535488605499268
batch i:1233
learning rate: 0.0013333333333333333, loss: 2.743288040161133
batch i:1234
learning rate: 0.0013333333333333333, loss: 2.8273446559906006
batch i:1235
learning rate: 0.0013333333333333333, loss: 2.783494234085083
batch i:1236
learning rate: 0.0013333333333333333, loss: 2.834437847137451
batch i:1237
learning rate: 0.0013333333333333333, loss: 2.9832992553710938
batch i:1238
learning rate: 0.0013333333333333333, loss: 2.868136167526245
batch i:1239
learning rate: 0.0013333333333333333, loss: 2.783329725265503
batch i:1240
learning rate: 0.0013333333333333333, loss: 2.8369412422180176
batch i:1241
learning rate: 0.0013333333333333333, loss: 2.809290885925293
batch i:1242
learning rate: 0.0013333333333333333, loss: 2.772684335708618
batch i:1243
learning rate: 0.0013333333333333333, loss: 2.797132968902588
batch i:1244
learning rate: 0.0013333333333333333, loss: 2.862865924835205
batch i:1245
learning rate: 0.0013333333333333333, loss: 2.768805503845215
batch i:1246
learning rate: 0.0013333333333333333, loss: 2.800659656524658
batch i:1247
learning rate: 0.0013333333333333333, loss: 2.815002202987671
batch i:1248
learning rate: 0.0013333333333333333, loss: 2.6632423400878906
batch i:1249
learning rate: 0.0013333333333333333, loss: 2.6341865062713623
batch i:1250
learning rate: 0.0013333333333333333, loss: 2.794057846069336
current self-play batch: 1250
num_playouts:3000, win: 3, lose: 7, tie:0
average time: 803.1166058301926
batch i:1251
learning rate: 0.0013333333333333333, loss: 2.7638416290283203
batch i:1252
learning rate: 0.0013333333333333333, loss: 2.695596694946289
batch i:1253
learning rate: 0.0013333333333333333, loss: 2.7981419563293457
batch i:1254
learning rate: 0.0013333333333333333, loss: 2.75889253616333
batch i:1255
learning rate: 0.0013333333333333333, loss: 2.7711596488952637
batch i:1256
learning rate: 0.0013333333333333333, loss: 2.69140625
batch i:1257
learning rate: 0.0013333333333333333, loss: 2.781108856201172
batch i:1258
learning rate: 0.0013333333333333333, loss: 2.732921600341797
batch i:1259
learning rate: 0.0013333333333333333, loss: 2.6729605197906494
batch i:1260
learning rate: 0.0013333333333333333, loss: 2.8978185653686523
batch i:1261
learning rate: 0.0013333333333333333, loss: 2.7629470825195312
batch i:1262
learning rate: 0.0013333333333333333, loss: 2.8026280403137207
batch i:1263
learning rate: 0.0013333333333333333, loss: 2.883387804031372
batch i:1264
learning rate: 0.0013333333333333333, loss: 2.8103854656219482
batch i:1265
learning rate: 0.0013333333333333333, loss: 2.872803211212158
batch i:1266
learning rate: 0.0013333333333333333, loss: 2.7385950088500977
batch i:1267
learning rate: 0.0013333333333333333, loss: 2.7281250953674316
batch i:1268
learning rate: 0.0013333333333333333, loss: 2.70944881439209
batch i:1269
learning rate: 0.0013333333333333333, loss: 2.811372995376587
batch i:1270
learning rate: 0.0013333333333333333, loss: 2.7896180152893066
batch i:1271
learning rate: 0.0013333333333333333, loss: 2.8299856185913086
batch i:1272
learning rate: 0.0013333333333333333, loss: 2.845228672027588
batch i:1273
learning rate: 0.0013333333333333333, loss: 2.8581275939941406
batch i:1274
learning rate: 0.0013333333333333333, loss: 2.867246150970459
batch i:1275
learning rate: 0.0013333333333333333, loss: 2.8125672340393066
batch i:1276
learning rate: 0.0013333333333333333, loss: 2.7889509201049805
batch i:1277
learning rate: 0.0013333333333333333, loss: 2.8804311752319336
batch i:1278
learning rate: 0.0013333333333333333, loss: 2.950817346572876
batch i:1279
learning rate: 0.0013333333333333333, loss: 2.9738101959228516
batch i:1280
learning rate: 0.0013333333333333333, loss: 2.889033317565918
batch i:1281
learning rate: 0.0013333333333333333, loss: 2.914872169494629
batch i:1282
learning rate: 0.0013333333333333333, loss: 2.810925006866455
batch i:1283
learning rate: 0.0013333333333333333, loss: 2.900132894515991
batch i:1284
learning rate: 0.0013333333333333333, loss: 2.897237777709961
batch i:1285
learning rate: 0.0013333333333333333, loss: 2.8776655197143555
batch i:1286
learning rate: 0.0013333333333333333, loss: 2.8185315132141113
batch i:1287
learning rate: 0.0013333333333333333, loss: 2.8623666763305664
batch i:1288
learning rate: 0.0013333333333333333, loss: 2.8362059593200684
batch i:1289
learning rate: 0.0013333333333333333, loss: 2.8043289184570312
batch i:1290
learning rate: 0.0013333333333333333, loss: 2.796943187713623
batch i:1291
learning rate: 0.0013333333333333333, loss: 2.846666097640991
batch i:1292
learning rate: 0.0013333333333333333, loss: 2.8571486473083496
batch i:1293
learning rate: 0.0013333333333333333, loss: 2.8646676540374756
batch i:1294
learning rate: 0.0013333333333333333, loss: 2.8219289779663086
batch i:1295
learning rate: 0.0013333333333333333, loss: 2.8237464427948
batch i:1296
learning rate: 0.0013333333333333333, loss: 2.7492637634277344
batch i:1297
learning rate: 0.0013333333333333333, loss: 2.765636444091797
batch i:1298
learning rate: 0.0013333333333333333, loss: 2.753462314605713
batch i:1299
learning rate: 0.0013333333333333333, loss: 2.7704856395721436
batch i:1300
learning rate: 0.0013333333333333333, loss: 2.8038954734802246
current self-play batch: 1300
num_playouts:3000, win: 7, lose: 3, tie:0
average time: 521.3573773384094
batch i:1301
learning rate: 0.0013333333333333333, loss: 2.739224910736084
batch i:1302
learning rate: 0.0013333333333333333, loss: 2.7978909015655518
batch i:1303
learning rate: 0.0013333333333333333, loss: 2.7666687965393066
batch i:1304
learning rate: 0.0013333333333333333, loss: 2.817225456237793
batch i:1305
learning rate: 0.0013333333333333333, loss: 2.785125255584717
batch i:1306
learning rate: 0.0013333333333333333, loss: 2.7722320556640625
batch i:1307
learning rate: 0.0013333333333333333, loss: 2.921128988265991
batch i:1308
learning rate: 0.0013333333333333333, loss: 2.718395471572876
batch i:1309
learning rate: 0.0013333333333333333, loss: 2.746507167816162
batch i:1310
learning rate: 0.0013333333333333333, loss: 2.792877674102783
batch i:1311
learning rate: 0.0013333333333333333, loss: 2.8879432678222656
batch i:1312
learning rate: 0.0013333333333333333, loss: 2.8460030555725098
batch i:1313
learning rate: 0.0013333333333333333, loss: 2.8370349407196045
batch i:1314
learning rate: 0.0013333333333333333, loss: 2.837599992752075
batch i:1315
learning rate: 0.0013333333333333333, loss: 2.844315767288208
batch i:1316
learning rate: 0.0013333333333333333, loss: 2.8402457237243652
batch i:1317
learning rate: 0.0013333333333333333, loss: 2.7516226768493652
batch i:1318
learning rate: 0.0013333333333333333, loss: 2.7508392333984375
batch i:1319
learning rate: 0.0013333333333333333, loss: 2.912731647491455
batch i:1320
learning rate: 0.0013333333333333333, loss: 2.841700315475464
batch i:1321
learning rate: 0.0013333333333333333, loss: 2.7418079376220703
batch i:1322
learning rate: 0.0013333333333333333, loss: 2.7170305252075195
batch i:1323
learning rate: 0.0013333333333333333, loss: 2.7653517723083496
batch i:1324
learning rate: 0.0013333333333333333, loss: 2.7517685890197754
batch i:1325
learning rate: 0.0013333333333333333, loss: 2.7105789184570312
batch i:1326
learning rate: 0.0013333333333333333, loss: 2.9063587188720703
batch i:1327
learning rate: 0.0013333333333333333, loss: 2.9000706672668457
batch i:1328
learning rate: 0.0013333333333333333, loss: 2.779695749282837
batch i:1329
learning rate: 0.0013333333333333333, loss: 2.8426241874694824
batch i:1330
learning rate: 0.0013333333333333333, loss: 2.824143171310425
batch i:1331
learning rate: 0.0013333333333333333, loss: 2.7680599689483643
batch i:1332
learning rate: 0.0013333333333333333, loss: 2.7825169563293457
batch i:1333
learning rate: 0.0013333333333333333, loss: 2.7894392013549805
batch i:1334
learning rate: 0.0013333333333333333, loss: 2.791773796081543
batch i:1335
learning rate: 0.0013333333333333333, loss: 2.764739990234375
batch i:1336
learning rate: 0.0013333333333333333, loss: 2.8152847290039062
batch i:1337
learning rate: 0.0013333333333333333, loss: 2.8750743865966797
batch i:1338
learning rate: 0.0013333333333333333, loss: 2.8483428955078125
batch i:1339
learning rate: 0.0013333333333333333, loss: 2.9415695667266846
batch i:1340
learning rate: 0.0013333333333333333, loss: 2.7275426387786865
batch i:1341
learning rate: 0.0013333333333333333, loss: 2.8503808975219727
batch i:1342
learning rate: 0.0013333333333333333, loss: 2.783764123916626
batch i:1343
learning rate: 0.0013333333333333333, loss: 2.796888828277588
batch i:1344
learning rate: 0.0013333333333333333, loss: 2.717161178588867
batch i:1345
learning rate: 0.0013333333333333333, loss: 2.7566707134246826
batch i:1346
learning rate: 0.0013333333333333333, loss: 2.6486599445343018
batch i:1347
learning rate: 0.0013333333333333333, loss: 2.7534148693084717
batch i:1348
learning rate: 0.0013333333333333333, loss: 2.733306407928467
batch i:1349
learning rate: 0.0013333333333333333, loss: 2.7592179775238037
batch i:1350
learning rate: 0.0013333333333333333, loss: 2.7941341400146484
current self-play batch: 1350
num_playouts:3000, win: 4, lose: 6, tie:0
average time: 621.1892130613327
batch i:1351
learning rate: 0.0013333333333333333, loss: 2.7702412605285645
batch i:1352
learning rate: 0.0013333333333333333, loss: 2.8414483070373535
batch i:1353
learning rate: 0.0013333333333333333, loss: 2.830625295639038
batch i:1354
learning rate: 0.0013333333333333333, loss: 2.708592414855957
batch i:1355
learning rate: 0.0013333333333333333, loss: 2.787029981613159
batch i:1356
learning rate: 0.0013333333333333333, loss: 2.725013017654419
batch i:1357
learning rate: 0.0013333333333333333, loss: 2.7437338829040527
batch i:1358
learning rate: 0.0013333333333333333, loss: 2.9052672386169434
batch i:1359
learning rate: 0.0013333333333333333, loss: 2.7494800090789795
batch i:1360
learning rate: 0.0013333333333333333, loss: 2.7304177284240723
batch i:1361
learning rate: 0.0013333333333333333, loss: 2.801748752593994
batch i:1362
learning rate: 0.0013333333333333333, loss: 2.7513296604156494
batch i:1363
learning rate: 0.0013333333333333333, loss: 2.7556686401367188
batch i:1364
learning rate: 0.0013333333333333333, loss: 2.8863847255706787
batch i:1365
learning rate: 0.0013333333333333333, loss: 2.8466908931732178
batch i:1366
learning rate: 0.0013333333333333333, loss: 2.8491039276123047
batch i:1367
learning rate: 0.0013333333333333333, loss: 2.8377833366394043
batch i:1368
learning rate: 0.0013333333333333333, loss: 2.829073429107666
batch i:1369
learning rate: 0.0013333333333333333, loss: 2.945230007171631
batch i:1370
learning rate: 0.0013333333333333333, loss: 2.853898525238037
batch i:1371
learning rate: 0.0013333333333333333, loss: 2.7848005294799805
batch i:1372
learning rate: 0.0013333333333333333, loss: 2.8675026893615723
batch i:1373
learning rate: 0.0013333333333333333, loss: 2.8934712409973145
batch i:1374
learning rate: 0.0013333333333333333, loss: 2.8555500507354736
batch i:1375
learning rate: 0.0013333333333333333, loss: 2.913621187210083
batch i:1376
learning rate: 0.0013333333333333333, loss: 2.8994250297546387
batch i:1377
learning rate: 0.0013333333333333333, loss: 2.899381637573242
batch i:1378
learning rate: 0.0013333333333333333, loss: 3.010288715362549
batch i:1379
learning rate: 0.0013333333333333333, loss: 2.8920016288757324
batch i:1380
learning rate: 0.0013333333333333333, loss: 2.8749728202819824
batch i:1381
learning rate: 0.0013333333333333333, loss: 2.931579828262329
batch i:1382
learning rate: 0.0013333333333333333, loss: 2.9223756790161133
batch i:1383
learning rate: 0.0013333333333333333, loss: 2.9824745655059814
batch i:1384
learning rate: 0.0013333333333333333, loss: 2.8442256450653076
batch i:1385
learning rate: 0.0013333333333333333, loss: 2.8374757766723633
batch i:1386
learning rate: 0.0013333333333333333, loss: 2.9979171752929688
batch i:1387
learning rate: 0.0013333333333333333, loss: 2.8908579349517822
batch i:1388
learning rate: 0.0013333333333333333, loss: 3.0471839904785156
batch i:1389
learning rate: 0.0013333333333333333, loss: 2.9703760147094727
batch i:1390
learning rate: 0.0013333333333333333, loss: 2.9236528873443604
batch i:1391
learning rate: 0.0013333333333333333, loss: 2.9480578899383545
batch i:1392
learning rate: 0.0013333333333333333, loss: 2.9001431465148926
batch i:1393
learning rate: 0.0013333333333333333, loss: 2.8932156562805176
batch i:1394
learning rate: 0.0013333333333333333, loss: 2.913989782333374
batch i:1395
learning rate: 0.0013333333333333333, loss: 2.843306064605713
batch i:1396
learning rate: 0.0013333333333333333, loss: 2.8873236179351807
batch i:1397
learning rate: 0.0013333333333333333, loss: 2.8716135025024414
batch i:1398
learning rate: 0.0013333333333333333, loss: 2.946031332015991
batch i:1399
learning rate: 0.0013333333333333333, loss: 2.9888253211975098
batch i:1400
learning rate: 0.0013333333333333333, loss: 2.9600956439971924
current self-play batch: 1400
num_playouts:3000, win: 4, lose: 6, tie:0
average time: 821.7018893480301
batch i:1401
learning rate: 0.0013333333333333333, loss: 2.8571693897247314
batch i:1402
learning rate: 0.0013333333333333333, loss: 3.0701160430908203
batch i:1403
learning rate: 0.0013333333333333333, loss: 2.8687050342559814
batch i:1404
learning rate: 0.0013333333333333333, loss: 2.9244399070739746
batch i:1405
learning rate: 0.0013333333333333333, loss: 2.8668699264526367
batch i:1406
learning rate: 0.0013333333333333333, loss: 2.821816921234131
batch i:1407
learning rate: 0.0013333333333333333, loss: 2.9032883644104004
batch i:1408
learning rate: 0.0013333333333333333, loss: 2.9819960594177246
batch i:1409
learning rate: 0.0013333333333333333, loss: 2.8747591972351074
batch i:1410
learning rate: 0.0013333333333333333, loss: 2.9211816787719727
batch i:1411
learning rate: 0.0013333333333333333, loss: 2.9524636268615723
batch i:1412
learning rate: 0.0013333333333333333, loss: 3.0079827308654785
batch i:1413
learning rate: 0.0013333333333333333, loss: 3.104282855987549
batch i:1414
learning rate: 0.0013333333333333333, loss: 3.0654306411743164
batch i:1415
learning rate: 0.0013333333333333333, loss: 2.975006580352783
batch i:1416
learning rate: 0.0013333333333333333, loss: 2.9715752601623535
batch i:1417
learning rate: 0.0013333333333333333, loss: 3.010223150253296
batch i:1418
learning rate: 0.0013333333333333333, loss: 2.9480018615722656
batch i:1419
learning rate: 0.0013333333333333333, loss: 2.9131014347076416
batch i:1420
learning rate: 0.0013333333333333333, loss: 2.9111859798431396
batch i:1421
learning rate: 0.0013333333333333333, loss: 3.0150346755981445
batch i:1422
learning rate: 0.0013333333333333333, loss: 3.0898633003234863
batch i:1423
learning rate: 0.0013333333333333333, loss: 2.920103073120117
batch i:1424
learning rate: 0.0013333333333333333, loss: 2.9858222007751465
batch i:1425
learning rate: 0.0013333333333333333, loss: 2.9196228981018066
batch i:1426
learning rate: 0.0013333333333333333, loss: 2.956427574157715
batch i:1427
learning rate: 0.0013333333333333333, loss: 3.029949426651001
batch i:1428
learning rate: 0.0013333333333333333, loss: 2.9073052406311035
batch i:1429
learning rate: 0.0013333333333333333, loss: 3.0168051719665527
batch i:1430
learning rate: 0.0013333333333333333, loss: 2.8561654090881348
batch i:1431
learning rate: 0.0013333333333333333, loss: 2.85585355758667
batch i:1432
learning rate: 0.0013333333333333333, loss: 2.9663100242614746
batch i:1433
learning rate: 0.0013333333333333333, loss: 2.941382884979248
batch i:1434
learning rate: 0.0013333333333333333, loss: 2.908965826034546
batch i:1435
learning rate: 0.0013333333333333333, loss: 3.0064449310302734
batch i:1436
learning rate: 0.0013333333333333333, loss: 2.881063938140869
batch i:1437
learning rate: 0.0013333333333333333, loss: 2.961029529571533
batch i:1438
learning rate: 0.0013333333333333333, loss: 2.857409954071045
batch i:1439
learning rate: 0.0013333333333333333, loss: 2.9062654972076416
batch i:1440
learning rate: 0.0013333333333333333, loss: 2.8490748405456543
batch i:1441
learning rate: 0.0013333333333333333, loss: 2.916029214859009
batch i:1442
learning rate: 0.0013333333333333333, loss: 2.9496994018554688
batch i:1443
learning rate: 0.0013333333333333333, loss: 2.9670515060424805
batch i:1444
learning rate: 0.0013333333333333333, loss: 2.875007152557373
batch i:1445
learning rate: 0.0013333333333333333, loss: 2.869144916534424
batch i:1446
learning rate: 0.0013333333333333333, loss: 2.8888254165649414
batch i:1447
learning rate: 0.0013333333333333333, loss: 2.8219947814941406
batch i:1448
learning rate: 0.0013333333333333333, loss: 2.8787992000579834
batch i:1449
learning rate: 0.0013333333333333333, loss: 2.999258518218994
batch i:1450
learning rate: 0.0013333333333333333, loss: 2.9015302658081055
current self-play batch: 1450
num_playouts:3000, win: 7, lose: 3, tie:0
average time: 489.9814002037048
batch i:1451
learning rate: 0.0013333333333333333, loss: 2.8731024265289307
batch i:1452
learning rate: 0.0013333333333333333, loss: 2.917159080505371
batch i:1453
learning rate: 0.0013333333333333333, loss: 2.9131920337677
batch i:1454
learning rate: 0.0013333333333333333, loss: 2.9608476161956787
batch i:1455
learning rate: 0.0013333333333333333, loss: 2.8553695678710938
batch i:1456
learning rate: 0.0013333333333333333, loss: 2.868030071258545
batch i:1457
learning rate: 0.0013333333333333333, loss: 2.954857587814331
batch i:1458
learning rate: 0.0013333333333333333, loss: 2.8861279487609863
batch i:1459
learning rate: 0.0013333333333333333, loss: 2.833085060119629
batch i:1460
learning rate: 0.0013333333333333333, loss: 2.64530611038208
batch i:1461
learning rate: 0.0013333333333333333, loss: 2.7468292713165283
batch i:1462
learning rate: 0.0013333333333333333, loss: 2.825871467590332
batch i:1463
learning rate: 0.0013333333333333333, loss: 2.7921035289764404
batch i:1464
learning rate: 0.0013333333333333333, loss: 2.7945311069488525
batch i:1465
learning rate: 0.0013333333333333333, loss: 2.861936569213867
batch i:1466
learning rate: 0.0013333333333333333, loss: 2.843838930130005
batch i:1467
learning rate: 0.0013333333333333333, loss: 2.8818845748901367
batch i:1468
learning rate: 0.0013333333333333333, loss: 2.7871198654174805
batch i:1469
learning rate: 0.0013333333333333333, loss: 2.8158326148986816
batch i:1470
learning rate: 0.0013333333333333333, loss: 2.8130922317504883
batch i:1471
learning rate: 0.0013333333333333333, loss: 2.6980133056640625
batch i:1472
learning rate: 0.0013333333333333333, loss: 2.743163585662842
batch i:1473
learning rate: 0.0013333333333333333, loss: 2.835772752761841
batch i:1474
learning rate: 0.0013333333333333333, loss: 2.7529079914093018
batch i:1475
learning rate: 0.0013333333333333333, loss: 2.69856858253479
batch i:1476
learning rate: 0.0013333333333333333, loss: 2.762098789215088
batch i:1477
learning rate: 0.0013333333333333333, loss: 2.7277913093566895
batch i:1478
learning rate: 0.0013333333333333333, loss: 2.693333148956299
batch i:1479
learning rate: 0.0013333333333333333, loss: 2.729174852371216
batch i:1480
learning rate: 0.0013333333333333333, loss: 2.719428539276123
batch i:1481
learning rate: 0.0013333333333333333, loss: 2.6412901878356934
batch i:1482
learning rate: 0.0013333333333333333, loss: 2.647942304611206
batch i:1483
learning rate: 0.0013333333333333333, loss: 2.702303886413574
batch i:1484
learning rate: 0.0013333333333333333, loss: 2.710322856903076
batch i:1485
learning rate: 0.0013333333333333333, loss: 2.7012977600097656
batch i:1486
learning rate: 0.0013333333333333333, loss: 2.67409086227417
batch i:1487
learning rate: 0.0013333333333333333, loss: 2.6445140838623047
batch i:1488
learning rate: 0.0013333333333333333, loss: 2.614372968673706
batch i:1489
learning rate: 0.0013333333333333333, loss: 2.555500030517578
batch i:1490
learning rate: 0.0013333333333333333, loss: 2.5971624851226807
batch i:1491
learning rate: 0.0013333333333333333, loss: 2.6776371002197266
batch i:1492
learning rate: 0.0013333333333333333, loss: 2.5603065490722656
batch i:1493
learning rate: 0.0013333333333333333, loss: 2.642411947250366
batch i:1494
learning rate: 0.0013333333333333333, loss: 2.5939064025878906
batch i:1495
learning rate: 0.0013333333333333333, loss: 2.6431772708892822
batch i:1496
learning rate: 0.0013333333333333333, loss: 2.46866512298584
batch i:1497
learning rate: 0.0013333333333333333, loss: 2.626502513885498
batch i:1498
learning rate: 0.0013333333333333333, loss: 2.7471706867218018
batch i:1499
learning rate: 0.0013333333333333333, loss: 2.752401828765869
batch i:1500
learning rate: 0.0013333333333333333, loss: 2.7012243270874023
current self-play batch: 1500
num_playouts:3000, win: 8, lose: 2, tie:0
average time: 615.5541317939758
