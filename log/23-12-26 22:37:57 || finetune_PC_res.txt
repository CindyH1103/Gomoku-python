Start time: 2023-12-26 22:37:57.341178
batch i:1
batch i:2
batch i:3
batch i:4
learning rate0.0013333333333333333, loss:2.8806285858154297
batch i:5
learning rate0.0008888888888888888, loss:3.074230432510376
batch i:6
learning rate0.0005925925925925926, loss:3.021599054336548
batch i:7
learning rate0.0003950617283950617, loss:3.0009536743164062
batch i:8
learning rate0.0002633744855967078, loss:3.0636839866638184
batch i:9
learning rate0.0002633744855967078, loss:3.1737747192382812
batch i:10
learning rate0.0002633744855967078, loss:3.0177676677703857
batch i:11
learning rate0.0002633744855967078, loss:3.06477689743042
batch i:12
learning rate0.0002633744855967078, loss:2.9845333099365234
batch i:13
learning rate0.0002633744855967078, loss:2.963341236114502
batch i:14
learning rate0.00039506172839506165, loss:2.8865506649017334
batch i:15
learning rate0.00039506172839506165, loss:3.0209126472473145
batch i:16
learning rate0.00039506172839506165, loss:3.225076675415039
batch i:17
learning rate0.00039506172839506165, loss:3.1346216201782227
batch i:18
learning rate0.00039506172839506165, loss:3.107537269592285
batch i:19
learning rate0.00039506172839506165, loss:3.0956482887268066
batch i:20
learning rate0.00039506172839506165, loss:3.058243989944458
batch i:21
learning rate0.00039506172839506165, loss:3.137479782104492
batch i:22
learning rate0.00039506172839506165, loss:3.121016502380371
batch i:23
learning rate0.00039506172839506165, loss:3.133303165435791
batch i:24
learning rate0.00039506172839506165, loss:2.999037742614746
batch i:25
learning rate0.00039506172839506165, loss:3.058366298675537
batch i:26
learning rate0.00039506172839506165, loss:3.0410232543945312
batch i:27
learning rate0.00039506172839506165, loss:3.0364866256713867
batch i:28
learning rate0.00039506172839506165, loss:3.0168981552124023
batch i:29
learning rate0.00039506172839506165, loss:3.0546696186065674
batch i:30
learning rate0.00039506172839506165, loss:3.0537402629852295
batch i:31
learning rate0.00039506172839506165, loss:2.9640417098999023
batch i:32
learning rate0.00039506172839506165, loss:3.040886402130127
batch i:33
learning rate0.00039506172839506165, loss:3.0313215255737305
batch i:34
learning rate0.00039506172839506165, loss:3.0881881713867188
batch i:35
learning rate0.00039506172839506165, loss:2.951793909072876
batch i:36
learning rate0.00039506172839506165, loss:3.031916618347168
batch i:37
learning rate0.00039506172839506165, loss:3.0083861351013184
batch i:38
learning rate0.00039506172839506165, loss:3.0620980262756348
batch i:39
learning rate0.00039506172839506165, loss:3.028313159942627
batch i:40
learning rate0.00039506172839506165, loss:2.986503839492798
batch i:41
learning rate0.00039506172839506165, loss:3.0167200565338135
batch i:42
learning rate0.00039506172839506165, loss:3.0289242267608643
batch i:43
learning rate0.00039506172839506165, loss:3.0869505405426025
batch i:44
learning rate0.00039506172839506165, loss:2.9523062705993652
batch i:45
learning rate0.00039506172839506165, loss:3.0599350929260254
batch i:46
learning rate0.00039506172839506165, loss:3.0157735347747803
batch i:47
learning rate0.00039506172839506165, loss:3.012826919555664
batch i:48
learning rate0.00039506172839506165, loss:3.0166802406311035
batch i:49
learning rate0.00039506172839506165, loss:2.951218605041504
batch i:50
learning rate0.00039506172839506165, loss:2.9646835327148438
current self-play batch: 50
num_playouts:1000, win: 10, lose: 0, tie:0
average time: 188.83315269947053
New best policy from pure MCTS
batch i:51
learning rate0.00039506172839506165, loss:3.0018234252929688
batch i:52
learning rate0.00039506172839506165, loss:3.0165209770202637
batch i:53
learning rate0.00039506172839506165, loss:3.019387722015381
batch i:54
learning rate0.00039506172839506165, loss:3.0619850158691406
batch i:55
learning rate0.00039506172839506165, loss:2.9703450202941895
batch i:56
learning rate0.00039506172839506165, loss:3.0326991081237793
batch i:57
learning rate0.00039506172839506165, loss:3.007622718811035
batch i:58
learning rate0.00039506172839506165, loss:3.012230157852173
batch i:59
learning rate0.00039506172839506165, loss:3.0441575050354004
batch i:60
learning rate0.00039506172839506165, loss:3.052614212036133
batch i:61
learning rate0.00039506172839506165, loss:3.04478120803833
batch i:62
learning rate0.00039506172839506165, loss:2.976454973220825
batch i:63
learning rate0.0002633744855967078, loss:3.093639850616455
batch i:64
learning rate0.0002633744855967078, loss:3.1177101135253906
batch i:65
learning rate0.0002633744855967078, loss:3.0908641815185547
batch i:66
learning rate0.0002633744855967078, loss:2.9529266357421875
batch i:67
learning rate0.0002633744855967078, loss:2.9881863594055176
batch i:68
learning rate0.0002633744855967078, loss:3.041645050048828
batch i:69
learning rate0.0002633744855967078, loss:3.0003862380981445
batch i:70
learning rate0.0002633744855967078, loss:3.0053329467773438
batch i:71
learning rate0.00039506172839506165, loss:3.0252137184143066
batch i:72
learning rate0.00039506172839506165, loss:3.0293214321136475
batch i:73
learning rate0.00039506172839506165, loss:2.996102809906006
batch i:74
learning rate0.00039506172839506165, loss:3.0562591552734375
batch i:75
learning rate0.00039506172839506165, loss:2.9591774940490723
batch i:76
learning rate0.00039506172839506165, loss:3.0181169509887695
batch i:77
learning rate0.00039506172839506165, loss:2.9940528869628906
batch i:78
learning rate0.00039506172839506165, loss:3.0739498138427734
batch i:79
learning rate0.00039506172839506165, loss:3.003085136413574
batch i:80
learning rate0.00039506172839506165, loss:2.970977783203125
batch i:81
learning rate0.00039506172839506165, loss:2.9833171367645264
batch i:82
learning rate0.00039506172839506165, loss:3.0147807598114014
batch i:83
learning rate0.00039506172839506165, loss:2.936934471130371
batch i:84
learning rate0.00039506172839506165, loss:2.961575508117676
batch i:85
learning rate0.00039506172839506165, loss:3.023301601409912
batch i:86
learning rate0.00039506172839506165, loss:2.985567569732666
batch i:87
learning rate0.00039506172839506165, loss:3.0066065788269043
batch i:88
learning rate0.00039506172839506165, loss:3.0675692558288574
batch i:89
learning rate0.00039506172839506165, loss:2.9194798469543457
batch i:90
learning rate0.00039506172839506165, loss:2.947831630706787
batch i:91
learning rate0.00039506172839506165, loss:3.0407156944274902
batch i:92
learning rate0.00039506172839506165, loss:2.9772515296936035
batch i:93
learning rate0.00039506172839506165, loss:2.9553041458129883
batch i:94
learning rate0.00039506172839506165, loss:2.9976840019226074
batch i:95
learning rate0.00039506172839506165, loss:2.9898695945739746
batch i:96
learning rate0.00039506172839506165, loss:2.9804391860961914
batch i:97
learning rate0.00039506172839506165, loss:2.988643169403076
batch i:98
learning rate0.00039506172839506165, loss:2.969902992248535
batch i:99
learning rate0.00039506172839506165, loss:2.9815266132354736
batch i:100
learning rate0.00039506172839506165, loss:2.9492850303649902
current self-play batch: 100
num_playouts:2000, win: 8, lose: 2, tie:0
average time: 272.0781328439713
New best policy from pure MCTS
batch i:101
learning rate0.00039506172839506165, loss:3.034491539001465
batch i:102
learning rate0.0002633744855967078, loss:3.0633063316345215
batch i:103
learning rate0.0002633744855967078, loss:3.034487247467041
batch i:104
learning rate0.0002633744855967078, loss:3.032421112060547
batch i:105
learning rate0.0002633744855967078, loss:2.9780282974243164
batch i:106
learning rate0.0002633744855967078, loss:3.0191636085510254
batch i:107
learning rate0.0002633744855967078, loss:3.0142312049865723
batch i:108
learning rate0.0002633744855967078, loss:3.0148563385009766
batch i:109
learning rate0.0002633744855967078, loss:3.068915367126465
batch i:110
learning rate0.0002633744855967078, loss:3.0135018825531006
batch i:111
learning rate0.0002633744855967078, loss:3.0750908851623535
batch i:112
learning rate0.0002633744855967078, loss:2.997581720352173
batch i:113
learning rate0.0002633744855967078, loss:3.0330522060394287
batch i:114
learning rate0.0002633744855967078, loss:2.9511446952819824
batch i:115
learning rate0.0002633744855967078, loss:2.96468448638916
batch i:116
learning rate0.0002633744855967078, loss:3.0018670558929443
batch i:117
learning rate0.0002633744855967078, loss:3.0354490280151367
batch i:118
learning rate0.0002633744855967078, loss:2.9688000679016113
batch i:119
learning rate0.0002633744855967078, loss:2.969986915588379
batch i:120
learning rate0.0002633744855967078, loss:3.059793472290039
batch i:121
learning rate0.0002633744855967078, loss:3.022831678390503
batch i:122
learning rate0.0002633744855967078, loss:3.0624566078186035
batch i:123
learning rate0.0002633744855967078, loss:3.0064592361450195
batch i:124
learning rate0.0002633744855967078, loss:2.990715265274048
batch i:125
learning rate0.0002633744855967078, loss:2.9074020385742188
batch i:126
learning rate0.0002633744855967078, loss:3.09566330909729
batch i:127
learning rate0.0002633744855967078, loss:2.957608699798584
batch i:128
learning rate0.0002633744855967078, loss:2.953266143798828
batch i:129
learning rate0.0002633744855967078, loss:2.96560001373291
batch i:130
learning rate0.0002633744855967078, loss:2.9393506050109863
batch i:131
learning rate0.0002633744855967078, loss:2.9105257987976074
batch i:132
learning rate0.0002633744855967078, loss:2.985306978225708
batch i:133
learning rate0.0002633744855967078, loss:2.976032018661499
batch i:134
learning rate0.0002633744855967078, loss:2.915855884552002
batch i:135
learning rate0.0002633744855967078, loss:2.909564256668091
batch i:136
learning rate0.0002633744855967078, loss:2.962692975997925
batch i:137
learning rate0.0002633744855967078, loss:2.870382308959961
batch i:138
learning rate0.0002633744855967078, loss:2.9272050857543945
batch i:139
learning rate0.0002633744855967078, loss:2.8155696392059326
batch i:140
learning rate0.0002633744855967078, loss:2.888198137283325
batch i:141
learning rate0.0002633744855967078, loss:2.8616104125976562
batch i:142
learning rate0.0002633744855967078, loss:2.880962371826172
batch i:143
learning rate0.0002633744855967078, loss:2.924419403076172
batch i:144
learning rate0.0002633744855967078, loss:2.8875620365142822
batch i:145
learning rate0.0002633744855967078, loss:2.855501174926758
batch i:146
learning rate0.0002633744855967078, loss:2.8354287147521973
batch i:147
learning rate0.0002633744855967078, loss:2.8175835609436035
batch i:148
learning rate0.0002633744855967078, loss:2.866635322570801
batch i:149
learning rate0.0002633744855967078, loss:2.872860908508301
batch i:150
learning rate0.0002633744855967078, loss:2.823129892349243
current self-play batch: 150
num_playouts:2000, win: 6, lose: 3, tie:1
average time: 576.9721428155899
batch i:151
learning rate0.0002633744855967078, loss:2.80816912651062
batch i:152
learning rate0.0002633744855967078, loss:2.8858256340026855
batch i:153
learning rate0.0002633744855967078, loss:2.850351333618164
batch i:154
learning rate0.0002633744855967078, loss:2.799605131149292
batch i:155
learning rate0.0002633744855967078, loss:2.8851020336151123
batch i:156
learning rate0.0002633744855967078, loss:2.831408977508545
batch i:157
learning rate0.0002633744855967078, loss:2.8644986152648926
batch i:158
learning rate0.0002633744855967078, loss:2.836265802383423
batch i:159
learning rate0.0002633744855967078, loss:2.842076301574707
batch i:160
learning rate0.0002633744855967078, loss:2.8481369018554688
batch i:161
learning rate0.0002633744855967078, loss:2.8774490356445312
batch i:162
learning rate0.0002633744855967078, loss:2.8351354598999023
batch i:163
learning rate0.0002633744855967078, loss:2.7588071823120117
batch i:164
learning rate0.0002633744855967078, loss:2.744509220123291
batch i:165
learning rate0.0002633744855967078, loss:2.890554904937744
batch i:166
learning rate0.0002633744855967078, loss:2.801863670349121
batch i:167
learning rate0.0002633744855967078, loss:2.7273924350738525
batch i:168
learning rate0.0002633744855967078, loss:2.867983341217041
batch i:169
learning rate0.0002633744855967078, loss:2.845210075378418
batch i:170
learning rate0.0002633744855967078, loss:2.7849647998809814
batch i:171
learning rate0.0002633744855967078, loss:2.7335128784179688
batch i:172
learning rate0.0002633744855967078, loss:2.778724193572998
batch i:173
learning rate0.0002633744855967078, loss:2.733433246612549
batch i:174
learning rate0.0002633744855967078, loss:2.823073387145996
batch i:175
learning rate0.0002633744855967078, loss:2.7528076171875
batch i:176
learning rate0.0002633744855967078, loss:2.8022983074188232
batch i:177
learning rate0.0002633744855967078, loss:2.7469735145568848
batch i:178
learning rate0.0002633744855967078, loss:2.7600584030151367
batch i:179
learning rate0.0002633744855967078, loss:2.6893677711486816
batch i:180
learning rate0.0002633744855967078, loss:2.706066608428955
batch i:181
learning rate0.0002633744855967078, loss:2.7462453842163086
batch i:182
learning rate0.0002633744855967078, loss:2.777876615524292
batch i:183
learning rate0.0002633744855967078, loss:2.770059108734131
batch i:184
learning rate0.0002633744855967078, loss:2.7806520462036133
batch i:185
learning rate0.0002633744855967078, loss:2.7509965896606445
batch i:186
learning rate0.0002633744855967078, loss:2.7566823959350586
batch i:187
learning rate0.0002633744855967078, loss:2.798988103866577
batch i:188
learning rate0.0002633744855967078, loss:2.803274154663086
batch i:189
learning rate0.0002633744855967078, loss:2.8370039463043213
batch i:190
learning rate0.0002633744855967078, loss:2.867682456970215
batch i:191
learning rate0.0002633744855967078, loss:2.731828212738037
batch i:192
learning rate0.0002633744855967078, loss:2.7836105823516846
batch i:193
learning rate0.0002633744855967078, loss:2.7784736156463623
batch i:194
learning rate0.0002633744855967078, loss:2.8507113456726074
batch i:195
learning rate0.0002633744855967078, loss:2.848705291748047
batch i:196
learning rate0.0002633744855967078, loss:2.7108476161956787
batch i:197
learning rate0.0002633744855967078, loss:2.7599027156829834
batch i:198
learning rate0.0002633744855967078, loss:2.7026543617248535
batch i:199
learning rate0.0002633744855967078, loss:2.7177212238311768
batch i:200
learning rate0.0002633744855967078, loss:2.7548136711120605
current self-play batch: 200
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 416.48292565345764
New best policy from pure MCTS
batch i:201
learning rate0.0002633744855967078, loss:2.7176034450531006
batch i:202
learning rate0.0002633744855967078, loss:2.7990283966064453
batch i:203
learning rate0.0002633744855967078, loss:2.7645065784454346
batch i:204
learning rate0.0002633744855967078, loss:2.706005096435547
batch i:205
learning rate0.0002633744855967078, loss:2.854118824005127
batch i:206
learning rate0.0002633744855967078, loss:2.8456380367279053
batch i:207
learning rate0.0002633744855967078, loss:2.843013286590576
batch i:208
learning rate0.0002633744855967078, loss:2.792606830596924
batch i:209
learning rate0.0002633744855967078, loss:2.7694690227508545
batch i:210
learning rate0.0002633744855967078, loss:2.766228675842285
batch i:211
learning rate0.0002633744855967078, loss:2.7221479415893555
batch i:212
learning rate0.0002633744855967078, loss:2.7738828659057617
batch i:213
learning rate0.0002633744855967078, loss:2.7057600021362305
batch i:214
learning rate0.0002633744855967078, loss:2.7390925884246826
batch i:215
learning rate0.0002633744855967078, loss:2.7576332092285156
batch i:216
learning rate0.0002633744855967078, loss:2.8302292823791504
batch i:217
learning rate0.0002633744855967078, loss:2.814479351043701
batch i:218
learning rate0.0002633744855967078, loss:2.763092041015625
batch i:219
learning rate0.0002633744855967078, loss:2.8096718788146973
batch i:220
learning rate0.0002633744855967078, loss:2.7541520595550537
batch i:221
learning rate0.0002633744855967078, loss:2.7845816612243652
batch i:222
learning rate0.0002633744855967078, loss:2.777317762374878
batch i:223
learning rate0.0002633744855967078, loss:2.6734609603881836
batch i:224
learning rate0.0002633744855967078, loss:2.7914047241210938
batch i:225
learning rate0.0002633744855967078, loss:2.7571825981140137
batch i:226
learning rate0.0002633744855967078, loss:2.7964282035827637
batch i:227
learning rate0.0002633744855967078, loss:2.7700226306915283
batch i:228
learning rate0.0002633744855967078, loss:2.743513584136963
batch i:229
learning rate0.0002633744855967078, loss:2.6702935695648193
batch i:230
learning rate0.0002633744855967078, loss:2.6725268363952637
batch i:231
learning rate0.0002633744855967078, loss:2.7240843772888184
batch i:232
learning rate0.0002633744855967078, loss:2.777215003967285
batch i:233
learning rate0.0002633744855967078, loss:2.6998000144958496
batch i:234
learning rate0.0002633744855967078, loss:2.7338168621063232
batch i:235
learning rate0.0002633744855967078, loss:2.8512256145477295
batch i:236
learning rate0.0002633744855967078, loss:2.749134063720703
batch i:237
learning rate0.0002633744855967078, loss:2.75921368598938
batch i:238
learning rate0.0002633744855967078, loss:2.73543643951416
batch i:239
learning rate0.0002633744855967078, loss:2.7798209190368652
batch i:240
learning rate0.0002633744855967078, loss:2.7673637866973877
batch i:241
learning rate0.0002633744855967078, loss:2.7761709690093994
batch i:242
learning rate0.0002633744855967078, loss:2.7200417518615723
batch i:243
learning rate0.0002633744855967078, loss:2.6739249229431152
batch i:244
learning rate0.0002633744855967078, loss:2.7574641704559326
batch i:245
learning rate0.0002633744855967078, loss:2.703359842300415
batch i:246
learning rate0.0002633744855967078, loss:2.7561235427856445
batch i:247
learning rate0.0002633744855967078, loss:2.771855592727661
batch i:248
learning rate0.0002633744855967078, loss:2.8686559200286865
batch i:249
learning rate0.0002633744855967078, loss:2.701415538787842
batch i:250
learning rate0.0002633744855967078, loss:2.7383761405944824
current self-play batch: 250
num_playouts:2000, win: 9, lose: 1, tie:0
average time: 349.84528822898864
batch i:251
learning rate0.0002633744855967078, loss:2.873359441757202
batch i:252
learning rate0.0002633744855967078, loss:2.7736668586730957
batch i:253
learning rate0.0002633744855967078, loss:2.8600597381591797
batch i:254
learning rate0.0002633744855967078, loss:2.7893800735473633
batch i:255
learning rate0.0002633744855967078, loss:2.7489304542541504
batch i:256
learning rate0.0002633744855967078, loss:2.8302595615386963
batch i:257
learning rate0.0002633744855967078, loss:2.8376235961914062
batch i:258
learning rate0.0002633744855967078, loss:2.725128173828125
batch i:259
learning rate0.0002633744855967078, loss:2.8097057342529297
batch i:260
learning rate0.0002633744855967078, loss:2.8462672233581543
batch i:261
learning rate0.0002633744855967078, loss:2.833247661590576
batch i:262
learning rate0.0001755829903978052, loss:2.870220422744751
batch i:263
learning rate0.0001755829903978052, loss:2.7026238441467285
batch i:264
learning rate0.0001755829903978052, loss:2.8058431148529053
batch i:265
learning rate0.0001755829903978052, loss:2.7968528270721436
batch i:266
learning rate0.0001755829903978052, loss:2.9342193603515625
batch i:267
learning rate0.0001755829903978052, loss:2.728304862976074
batch i:268
learning rate0.0001755829903978052, loss:2.826616048812866
batch i:269
learning rate0.0001755829903978052, loss:2.77139949798584
batch i:270
learning rate0.0001755829903978052, loss:2.815825939178467
batch i:271
learning rate0.0001755829903978052, loss:2.7731881141662598
batch i:272
learning rate0.0002633744855967078, loss:2.7985520362854004
batch i:273
learning rate0.0002633744855967078, loss:2.7366654872894287
batch i:274
learning rate0.0002633744855967078, loss:2.8139848709106445
batch i:275
learning rate0.0002633744855967078, loss:2.821564197540283
batch i:276
learning rate0.0002633744855967078, loss:2.79887318611145
batch i:277
learning rate0.0002633744855967078, loss:2.8771109580993652
batch i:278
learning rate0.0002633744855967078, loss:2.846752882003784
batch i:279
learning rate0.0002633744855967078, loss:2.861743211746216
batch i:280
learning rate0.0002633744855967078, loss:2.8108150959014893
batch i:281
learning rate0.0002633744855967078, loss:2.827732563018799
batch i:282
learning rate0.0002633744855967078, loss:2.8307876586914062
batch i:283
learning rate0.0002633744855967078, loss:2.8654446601867676
batch i:284
learning rate0.0002633744855967078, loss:2.8058862686157227
batch i:285
learning rate0.0002633744855967078, loss:2.8588385581970215
batch i:286
learning rate0.0002633744855967078, loss:2.8601155281066895
batch i:287
learning rate0.0002633744855967078, loss:2.89353084564209
batch i:288
learning rate0.0002633744855967078, loss:2.806565523147583
batch i:289
learning rate0.0002633744855967078, loss:2.857856035232544
batch i:290
learning rate0.0002633744855967078, loss:2.814037322998047
batch i:291
learning rate0.0002633744855967078, loss:2.853417158126831
batch i:292
learning rate0.0001755829903978052, loss:2.866368293762207
batch i:293
learning rate0.0001755829903978052, loss:2.964237928390503
batch i:294
learning rate0.0001755829903978052, loss:2.883859395980835
batch i:295
learning rate0.0001755829903978052, loss:2.8999743461608887
batch i:296
learning rate0.0001755829903978052, loss:2.8916637897491455
batch i:297
learning rate0.0001755829903978052, loss:2.7872378826141357
batch i:298
learning rate0.0002633744855967078, loss:2.834604263305664
batch i:299
learning rate0.0002633744855967078, loss:2.892263889312744
batch i:300
learning rate0.0002633744855967078, loss:2.7791457176208496
current self-play batch: 300
num_playouts:2000, win: 10, lose: 0, tie:0
average time: 378.8334365606308
New best policy from pure MCTS
batch i:301
learning rate0.0002633744855967078, loss:2.8241214752197266
batch i:302
learning rate0.0002633744855967078, loss:2.823385715484619
batch i:303
learning rate0.0002633744855967078, loss:2.95880126953125
batch i:304
learning rate0.0002633744855967078, loss:2.845057487487793
batch i:305
learning rate0.0002633744855967078, loss:2.8871500492095947
batch i:306
learning rate0.0002633744855967078, loss:2.8912482261657715
batch i:307
learning rate0.0002633744855967078, loss:2.8742833137512207
batch i:308
learning rate0.0002633744855967078, loss:2.7900404930114746
batch i:309
learning rate0.0002633744855967078, loss:2.8459677696228027
batch i:310
learning rate0.0002633744855967078, loss:2.816303253173828
batch i:311
learning rate0.0002633744855967078, loss:2.791219711303711
batch i:312
learning rate0.0002633744855967078, loss:2.8376455307006836
batch i:313
learning rate0.0002633744855967078, loss:2.9080286026000977
batch i:314
learning rate0.0002633744855967078, loss:2.7671005725860596
batch i:315
learning rate0.0002633744855967078, loss:2.8708744049072266
batch i:316
learning rate0.0002633744855967078, loss:2.8495826721191406
batch i:317
learning rate0.0002633744855967078, loss:2.8556318283081055
batch i:318
learning rate0.0002633744855967078, loss:2.8437461853027344
batch i:319
learning rate0.0002633744855967078, loss:2.798457145690918
batch i:320
learning rate0.0002633744855967078, loss:2.799384117126465
batch i:321
learning rate0.0002633744855967078, loss:2.745199680328369
batch i:322
learning rate0.0002633744855967078, loss:2.9165000915527344
batch i:323
learning rate0.0002633744855967078, loss:2.8486132621765137
batch i:324
learning rate0.0002633744855967078, loss:2.826089859008789
batch i:325
learning rate0.0002633744855967078, loss:2.866368532180786
batch i:326
learning rate0.0002633744855967078, loss:2.88537859916687
batch i:327
learning rate0.0002633744855967078, loss:2.8058524131774902
batch i:328
learning rate0.0002633744855967078, loss:2.8552658557891846
batch i:329
learning rate0.0002633744855967078, loss:2.80026912689209
batch i:330
learning rate0.0002633744855967078, loss:2.8178892135620117
batch i:331
learning rate0.0002633744855967078, loss:2.8135130405426025
batch i:332
learning rate0.0002633744855967078, loss:2.8513455390930176
batch i:333
learning rate0.0002633744855967078, loss:2.764195680618286
batch i:334
learning rate0.0002633744855967078, loss:2.8404829502105713
batch i:335
learning rate0.0002633744855967078, loss:2.846961498260498
batch i:336
learning rate0.0002633744855967078, loss:2.7999653816223145
batch i:337
learning rate0.0002633744855967078, loss:2.7751410007476807
batch i:338
learning rate0.0002633744855967078, loss:2.867445230484009
batch i:339
learning rate0.0002633744855967078, loss:2.7668099403381348
batch i:340
learning rate0.0002633744855967078, loss:2.8294126987457275
batch i:341
learning rate0.0002633744855967078, loss:2.8401660919189453
batch i:342
learning rate0.0002633744855967078, loss:2.7650179862976074
batch i:343
learning rate0.0002633744855967078, loss:2.6960813999176025
batch i:344
learning rate0.0002633744855967078, loss:2.763637065887451
batch i:345
learning rate0.0002633744855967078, loss:2.770840883255005
batch i:346
learning rate0.0002633744855967078, loss:2.8542540073394775
batch i:347
learning rate0.0002633744855967078, loss:2.89412260055542
batch i:348
learning rate0.0002633744855967078, loss:2.7540674209594727
batch i:349
learning rate0.0002633744855967078, loss:2.748596668243408
batch i:350
learning rate0.0002633744855967078, loss:2.6859824657440186
current self-play batch: 350
num_playouts:3000, win: 10, lose: 0, tie:0
average time: 774.6441027879715
New best policy from pure MCTS
batch i:351
learning rate0.0002633744855967078, loss:2.7705047130584717
batch i:352
learning rate0.0002633744855967078, loss:2.8162355422973633
batch i:353
learning rate0.0002633744855967078, loss:2.708040714263916
batch i:354
learning rate0.0002633744855967078, loss:2.795241594314575
batch i:355
learning rate0.0002633744855967078, loss:2.8463215827941895
batch i:356
learning rate0.0002633744855967078, loss:2.7750062942504883
batch i:357
learning rate0.0002633744855967078, loss:2.6720707416534424
batch i:358
learning rate0.0002633744855967078, loss:2.682309627532959
batch i:359
learning rate0.0002633744855967078, loss:2.8432469367980957
batch i:360
learning rate0.0002633744855967078, loss:2.7958078384399414
batch i:361
learning rate0.0002633744855967078, loss:2.668900489807129
batch i:362
learning rate0.0002633744855967078, loss:2.663855791091919
batch i:363
learning rate0.0002633744855967078, loss:2.7721259593963623
batch i:364
learning rate0.0002633744855967078, loss:2.686680793762207
batch i:365
learning rate0.0002633744855967078, loss:2.8093085289001465
batch i:366
learning rate0.0002633744855967078, loss:2.7624926567077637
batch i:367
learning rate0.0002633744855967078, loss:2.816577434539795
batch i:368
learning rate0.0002633744855967078, loss:2.7202229499816895
batch i:369
learning rate0.0002633744855967078, loss:2.6617252826690674
batch i:370
learning rate0.0002633744855967078, loss:2.7555365562438965
batch i:371
learning rate0.0002633744855967078, loss:2.7417728900909424
batch i:372
learning rate0.0002633744855967078, loss:2.7712838649749756
batch i:373
learning rate0.0002633744855967078, loss:2.781970500946045
batch i:374
learning rate0.0002633744855967078, loss:2.6793813705444336
batch i:375
learning rate0.0002633744855967078, loss:2.6893324851989746
batch i:376
learning rate0.0002633744855967078, loss:2.7772176265716553
batch i:377
learning rate0.0002633744855967078, loss:2.708259105682373
batch i:378
learning rate0.0002633744855967078, loss:2.715444803237915
batch i:379
learning rate0.0002633744855967078, loss:2.7324821949005127
batch i:380
learning rate0.0002633744855967078, loss:2.691051721572876
batch i:381
learning rate0.0002633744855967078, loss:2.6152658462524414
batch i:382
learning rate0.0002633744855967078, loss:2.6878530979156494
batch i:383
learning rate0.0002633744855967078, loss:2.7131659984588623
batch i:384
learning rate0.0002633744855967078, loss:2.6699912548065186
batch i:385
learning rate0.0002633744855967078, loss:2.7459969520568848
batch i:386
learning rate0.0002633744855967078, loss:2.7118685245513916
batch i:387
learning rate0.0002633744855967078, loss:2.7227087020874023
batch i:388
learning rate0.0002633744855967078, loss:2.696831226348877
batch i:389
learning rate0.0002633744855967078, loss:2.747713088989258
batch i:390
learning rate0.0002633744855967078, loss:2.6799588203430176
batch i:391
learning rate0.0002633744855967078, loss:2.6887264251708984
batch i:392
learning rate0.0002633744855967078, loss:2.702932834625244
batch i:393
learning rate0.0002633744855967078, loss:2.733199119567871
batch i:394
learning rate0.0002633744855967078, loss:2.767519474029541
batch i:395
learning rate0.0002633744855967078, loss:2.7146825790405273
batch i:396
learning rate0.0002633744855967078, loss:2.780423879623413
batch i:397
learning rate0.0002633744855967078, loss:2.721053123474121
batch i:398
learning rate0.0002633744855967078, loss:2.774184465408325
batch i:399
learning rate0.0002633744855967078, loss:2.737210988998413
batch i:400
learning rate0.0002633744855967078, loss:2.690197467803955
current self-play batch: 400
num_playouts:4000, win: 9, lose: 1, tie:0
average time: 774.9715065956116
New best policy from pure MCTS
batch i:401
learning rate0.0002633744855967078, loss:2.6670138835906982
batch i:402
learning rate0.0002633744855967078, loss:2.735417127609253
batch i:403
learning rate0.0002633744855967078, loss:2.7031497955322266
batch i:404
learning rate0.0002633744855967078, loss:2.746697187423706
batch i:405
learning rate0.0002633744855967078, loss:2.758185386657715
batch i:406
learning rate0.0002633744855967078, loss:2.7190630435943604
batch i:407
learning rate0.0002633744855967078, loss:2.646831750869751
batch i:408
learning rate0.0002633744855967078, loss:2.6261677742004395
batch i:409
learning rate0.0002633744855967078, loss:2.7042653560638428
batch i:410
learning rate0.0002633744855967078, loss:2.6687777042388916
batch i:411
learning rate0.0002633744855967078, loss:2.720423936843872
batch i:412
learning rate0.0002633744855967078, loss:2.7345566749572754
batch i:413
learning rate0.0002633744855967078, loss:2.671419620513916
batch i:414
learning rate0.0002633744855967078, loss:2.704385757446289
batch i:415
learning rate0.0002633744855967078, loss:2.6216650009155273
batch i:416
learning rate0.0002633744855967078, loss:2.693049430847168
batch i:417
learning rate0.0002633744855967078, loss:2.6707675457000732
batch i:418
learning rate0.0002633744855967078, loss:2.706760883331299
batch i:419
learning rate0.0002633744855967078, loss:2.614537239074707
batch i:420
learning rate0.0002633744855967078, loss:2.6818580627441406
batch i:421
learning rate0.0002633744855967078, loss:2.684067726135254
batch i:422
learning rate0.0002633744855967078, loss:2.7279398441314697
batch i:423
learning rate0.0002633744855967078, loss:2.632560968399048
batch i:424
learning rate0.0002633744855967078, loss:2.7301697731018066
batch i:425
learning rate0.0002633744855967078, loss:2.655668258666992
batch i:426
learning rate0.0002633744855967078, loss:2.6528258323669434
batch i:427
learning rate0.0002633744855967078, loss:2.739529609680176
batch i:428
learning rate0.0002633744855967078, loss:2.6644949913024902
batch i:429
learning rate0.0002633744855967078, loss:2.6461477279663086
batch i:430
learning rate0.0002633744855967078, loss:2.757913112640381
batch i:431
learning rate0.0002633744855967078, loss:2.772061824798584
batch i:432
learning rate0.0002633744855967078, loss:2.651061534881592
batch i:433
learning rate0.0002633744855967078, loss:2.7164602279663086
batch i:434
learning rate0.0002633744855967078, loss:2.740626096725464
batch i:435
learning rate0.0002633744855967078, loss:2.6995654106140137
batch i:436
learning rate0.0002633744855967078, loss:2.7628049850463867
batch i:437
learning rate0.0002633744855967078, loss:2.745868682861328
batch i:438
learning rate0.0002633744855967078, loss:2.68007493019104
batch i:439
learning rate0.0002633744855967078, loss:2.7006869316101074
batch i:440
learning rate0.0002633744855967078, loss:2.7780332565307617
batch i:441
learning rate0.0002633744855967078, loss:2.713324546813965
batch i:442
learning rate0.0001755829903978052, loss:2.768869400024414
batch i:443
learning rate0.0001755829903978052, loss:2.6910016536712646
batch i:444
learning rate0.0001755829903978052, loss:2.7056422233581543
batch i:445
learning rate0.0001755829903978052, loss:2.716608762741089
batch i:446
learning rate0.0001755829903978052, loss:2.7482874393463135
batch i:447
learning rate0.00011705532693187012, loss:2.7768328189849854
batch i:448
learning rate0.00011705532693187012, loss:2.7349939346313477
batch i:449
learning rate0.00011705532693187012, loss:2.771658420562744
batch i:450
learning rate0.00011705532693187012, loss:2.76147198677063
current self-play batch: 450
num_playouts:4000, win: 4, lose: 5, tie:1
average time: 2268.7856990337373
batch i:451
learning rate0.0001755829903978052, loss:2.7358946800231934
batch i:452
learning rate0.0001755829903978052, loss:2.7561299800872803
batch i:453
learning rate0.0001755829903978052, loss:2.7745327949523926
batch i:454
learning rate0.0001755829903978052, loss:2.7578506469726562
batch i:455
learning rate0.0001755829903978052, loss:2.774622678756714
batch i:456
learning rate0.0001755829903978052, loss:2.790808916091919
batch i:457
learning rate0.0001755829903978052, loss:2.7422876358032227
batch i:458
learning rate0.0001755829903978052, loss:2.789710521697998
batch i:459
learning rate0.0001755829903978052, loss:2.802159070968628
batch i:460
learning rate0.0001755829903978052, loss:2.766409397125244
batch i:461
learning rate0.0001755829903978052, loss:2.690993070602417
batch i:462
learning rate0.0001755829903978052, loss:2.729980945587158
batch i:463
learning rate0.0001755829903978052, loss:2.70479416847229
batch i:464
learning rate0.0001755829903978052, loss:2.691251516342163
batch i:465
learning rate0.0001755829903978052, loss:2.757296323776245
batch i:466
learning rate0.0001755829903978052, loss:2.7858333587646484
batch i:467
learning rate0.0001755829903978052, loss:2.6507492065429688
batch i:468
learning rate0.0001755829903978052, loss:2.7066850662231445
batch i:469
learning rate0.0001755829903978052, loss:2.7211670875549316
batch i:470
learning rate0.0001755829903978052, loss:2.7788596153259277
batch i:471
learning rate0.0001755829903978052, loss:2.722085475921631
batch i:472
learning rate0.0001755829903978052, loss:2.6847782135009766
batch i:473
learning rate0.0001755829903978052, loss:2.8122453689575195
batch i:474
learning rate0.0001755829903978052, loss:2.6959893703460693
batch i:475
learning rate0.0001755829903978052, loss:2.70237398147583
batch i:476
learning rate0.0001755829903978052, loss:2.7473840713500977
batch i:477
learning rate0.0001755829903978052, loss:2.778395652770996
batch i:478
learning rate0.0001755829903978052, loss:2.7779641151428223
batch i:479
learning rate0.0001755829903978052, loss:2.608818531036377
batch i:480
learning rate0.0001755829903978052, loss:2.676320791244507
batch i:481
learning rate0.0001755829903978052, loss:2.7185983657836914
batch i:482
learning rate0.0001755829903978052, loss:2.71345853805542
batch i:483
learning rate0.0001755829903978052, loss:2.7579073905944824
batch i:484
learning rate0.0001755829903978052, loss:2.724163055419922
batch i:485
learning rate0.0001755829903978052, loss:2.7173333168029785
batch i:486
learning rate0.0001755829903978052, loss:2.7035560607910156
batch i:487
learning rate0.0001755829903978052, loss:2.6781277656555176
batch i:488
learning rate0.0001755829903978052, loss:2.7386107444763184
batch i:489
learning rate0.0001755829903978052, loss:2.7151360511779785
batch i:490
learning rate0.0001755829903978052, loss:2.7063164710998535
batch i:491
learning rate0.0001755829903978052, loss:2.7134690284729004
batch i:492
learning rate0.0001755829903978052, loss:2.6793112754821777
batch i:493
learning rate0.0001755829903978052, loss:2.846907138824463
batch i:494
learning rate0.0001755829903978052, loss:2.7255160808563232
batch i:495
learning rate0.0001755829903978052, loss:2.6969361305236816
batch i:496
learning rate0.0001755829903978052, loss:2.7022151947021484
batch i:497
learning rate0.0001755829903978052, loss:2.752939224243164
batch i:498
learning rate0.0001755829903978052, loss:2.8021678924560547
batch i:499
learning rate0.0001755829903978052, loss:2.6880040168762207
batch i:500
learning rate0.0001755829903978052, loss:2.7123687267303467
current self-play batch: 500
num_playouts:4000, win: 7, lose: 1, tie:2
average time: 1387.8037549734115
batch i:501
learning rate0.0001755829903978052, loss:2.7022452354431152
batch i:502
learning rate0.0001755829903978052, loss:2.7374963760375977
batch i:503
learning rate0.0001755829903978052, loss:2.8070054054260254
batch i:504
learning rate0.0001755829903978052, loss:2.6533079147338867
batch i:505
learning rate0.0001755829903978052, loss:2.7242445945739746
batch i:506
learning rate0.0001755829903978052, loss:2.751413345336914
batch i:507
learning rate0.0001755829903978052, loss:2.697749137878418
batch i:508
learning rate0.0001755829903978052, loss:2.745231866836548
batch i:509
learning rate0.0001755829903978052, loss:2.6735410690307617
batch i:510
learning rate0.0001755829903978052, loss:2.8155605792999268
batch i:511
learning rate0.0001755829903978052, loss:2.838188409805298
batch i:512
learning rate0.0001755829903978052, loss:2.75661563873291
batch i:513
learning rate0.0001755829903978052, loss:2.7578840255737305
batch i:514
learning rate0.0001755829903978052, loss:2.766345500946045
batch i:515
learning rate0.0001755829903978052, loss:2.8055152893066406
batch i:516
learning rate0.0001755829903978052, loss:2.7885689735412598
batch i:517
learning rate0.0001755829903978052, loss:2.7214415073394775
batch i:518
learning rate0.0001755829903978052, loss:2.7785398960113525
batch i:519
learning rate0.0001755829903978052, loss:2.773293972015381
batch i:520
learning rate0.0001755829903978052, loss:2.821493148803711
batch i:521
learning rate0.0001755829903978052, loss:2.790043592453003
batch i:522
learning rate0.0001755829903978052, loss:2.7933220863342285
batch i:523
learning rate0.0001755829903978052, loss:2.8460991382598877
batch i:524
learning rate0.0001755829903978052, loss:2.8243517875671387
batch i:525
learning rate0.0001755829903978052, loss:2.939171314239502
batch i:526
learning rate0.0001755829903978052, loss:2.8187901973724365
batch i:527
learning rate0.0001755829903978052, loss:2.7925076484680176
batch i:528
learning rate0.0001755829903978052, loss:2.7634713649749756
batch i:529
learning rate0.0001755829903978052, loss:2.791506767272949
batch i:530
learning rate0.0001755829903978052, loss:2.8333547115325928
batch i:531
learning rate0.0001755829903978052, loss:2.8156604766845703
batch i:532
learning rate0.0001755829903978052, loss:2.7968409061431885
batch i:533
learning rate0.0001755829903978052, loss:2.8756446838378906
batch i:534
learning rate0.0001755829903978052, loss:2.767670154571533
batch i:535
learning rate0.0001755829903978052, loss:2.81186580657959
batch i:536
learning rate0.0001755829903978052, loss:2.7129156589508057
batch i:537
learning rate0.0001755829903978052, loss:2.7580313682556152
batch i:538
learning rate0.0001755829903978052, loss:2.837696075439453
batch i:539
learning rate0.0001755829903978052, loss:2.796912908554077
batch i:540
learning rate0.0001755829903978052, loss:2.8654515743255615
batch i:541
learning rate0.0001755829903978052, loss:2.7918310165405273
batch i:542
learning rate0.0001755829903978052, loss:2.832442045211792
batch i:543
learning rate0.0001755829903978052, loss:2.9096803665161133
batch i:544
learning rate0.0001755829903978052, loss:2.7406728267669678
batch i:545
learning rate0.0001755829903978052, loss:2.8333749771118164
batch i:546
learning rate0.0001755829903978052, loss:2.7600796222686768
batch i:547
learning rate0.0001755829903978052, loss:2.8414595127105713
batch i:548
learning rate0.0001755829903978052, loss:2.829954147338867
batch i:549
learning rate0.0002633744855967078, loss:2.7831850051879883
batch i:550
learning rate0.0002633744855967078, loss:2.82485294342041
current self-play batch: 550
num_playouts:4000, win: 7, lose: 2, tie:1
average time: 1382.159639286995
batch i:551
learning rate0.0002633744855967078, loss:2.796603202819824
batch i:552
learning rate0.0002633744855967078, loss:2.806952953338623
batch i:553
learning rate0.0001755829903978052, loss:2.7998905181884766
batch i:554
learning rate0.0001755829903978052, loss:2.741455554962158
batch i:555
learning rate0.0001755829903978052, loss:2.852489471435547
batch i:556
learning rate0.0001755829903978052, loss:2.762929916381836
batch i:557
learning rate0.0001755829903978052, loss:2.7766780853271484
batch i:558
learning rate0.0001755829903978052, loss:2.700864315032959
batch i:559
learning rate0.0001755829903978052, loss:2.7486324310302734
batch i:560
learning rate0.0001755829903978052, loss:2.729483127593994
batch i:561
learning rate0.0001755829903978052, loss:2.822627305984497
batch i:562
learning rate0.0001755829903978052, loss:2.7540853023529053
batch i:563
learning rate0.0001755829903978052, loss:2.7062978744506836
batch i:564
learning rate0.0001755829903978052, loss:2.799488067626953
batch i:565
learning rate0.0001755829903978052, loss:2.76894211769104
batch i:566
learning rate0.0001755829903978052, loss:2.7543587684631348
batch i:567
learning rate0.0001755829903978052, loss:2.7555935382843018
batch i:568
learning rate0.0001755829903978052, loss:2.756401300430298
batch i:569
learning rate0.0001755829903978052, loss:2.834304094314575
batch i:570
learning rate0.0001755829903978052, loss:2.8191492557525635
batch i:571
learning rate0.0001755829903978052, loss:2.745131492614746
batch i:572
learning rate0.0001755829903978052, loss:2.8058362007141113
batch i:573
learning rate0.0001755829903978052, loss:2.799949884414673
batch i:574
learning rate0.0001755829903978052, loss:2.7663650512695312
batch i:575
learning rate0.0001755829903978052, loss:2.7792587280273438
batch i:576
learning rate0.0001755829903978052, loss:2.7692885398864746
batch i:577
learning rate0.0001755829903978052, loss:2.8434536457061768
batch i:578
learning rate0.0001755829903978052, loss:2.7324180603027344
batch i:579
learning rate0.0001755829903978052, loss:2.7819809913635254
batch i:580
learning rate0.0001755829903978052, loss:2.7848129272460938
batch i:581
learning rate0.0001755829903978052, loss:2.765047550201416
batch i:582
learning rate0.0001755829903978052, loss:2.7683815956115723
batch i:583
learning rate0.0001755829903978052, loss:2.8102803230285645
batch i:584
learning rate0.0001755829903978052, loss:2.838292121887207
batch i:585
learning rate0.0001755829903978052, loss:2.8353137969970703
batch i:586
learning rate0.0001755829903978052, loss:2.7819628715515137
batch i:587
learning rate0.0001755829903978052, loss:2.7332887649536133
batch i:588
learning rate0.0001755829903978052, loss:2.77931547164917
batch i:589
learning rate0.0001755829903978052, loss:2.8795928955078125
batch i:590
learning rate0.0001755829903978052, loss:2.8342862129211426
batch i:591
learning rate0.0001755829903978052, loss:2.8344366550445557
batch i:592
learning rate0.0001755829903978052, loss:2.82307767868042
batch i:593
learning rate0.0001755829903978052, loss:2.892385959625244
batch i:594
learning rate0.0001755829903978052, loss:2.8339385986328125
batch i:595
learning rate0.0001755829903978052, loss:2.86508846282959
batch i:596
learning rate0.0001755829903978052, loss:2.8664731979370117
batch i:597
learning rate0.0001755829903978052, loss:2.841383934020996
batch i:598
learning rate0.0001755829903978052, loss:2.8301851749420166
batch i:599
learning rate0.0001755829903978052, loss:2.7982523441314697
batch i:600
learning rate0.0001755829903978052, loss:2.9202404022216797
current self-play batch: 600
num_playouts:4000, win: 6, lose: 4, tie:0
average time: 1342.2918375253678
batch i:601
learning rate0.0001755829903978052, loss:2.910665512084961
batch i:602
learning rate0.0001755829903978052, loss:2.8141775131225586
batch i:603
learning rate0.0001755829903978052, loss:2.81292724609375
batch i:604
learning rate0.0001755829903978052, loss:2.8523731231689453
batch i:605
learning rate0.0001755829903978052, loss:2.8303775787353516
batch i:606
learning rate0.0002633744855967078, loss:2.8375847339630127
batch i:607
learning rate0.0002633744855967078, loss:2.754601240158081
batch i:608
learning rate0.0001755829903978052, loss:2.7398550510406494
batch i:609
learning rate0.0001755829903978052, loss:2.836735725402832
batch i:610
learning rate0.0001755829903978052, loss:2.767235040664673
batch i:611
learning rate0.0001755829903978052, loss:2.893996000289917
batch i:612
learning rate0.0001755829903978052, loss:2.864650011062622
batch i:613
learning rate0.0001755829903978052, loss:2.8844642639160156
batch i:614
learning rate0.0001755829903978052, loss:2.807352066040039
batch i:615
learning rate0.0001755829903978052, loss:2.8093457221984863
batch i:616
learning rate0.0001755829903978052, loss:2.8466973304748535
batch i:617
learning rate0.0001755829903978052, loss:2.857095718383789
batch i:618
learning rate0.0001755829903978052, loss:2.776430130004883
batch i:619
learning rate0.0001755829903978052, loss:2.900716781616211
batch i:620
learning rate0.0001755829903978052, loss:2.9046411514282227
batch i:621
learning rate0.0001755829903978052, loss:2.9105491638183594
batch i:622
learning rate0.0001755829903978052, loss:2.8432159423828125
batch i:623
learning rate0.0001755829903978052, loss:2.8679604530334473
batch i:624
learning rate0.0001755829903978052, loss:2.9277868270874023
batch i:625
learning rate0.0001755829903978052, loss:2.967180013656616
batch i:626
learning rate0.0001755829903978052, loss:2.915144681930542
batch i:627
learning rate0.0001755829903978052, loss:2.980602979660034
batch i:628
learning rate0.0001755829903978052, loss:2.990267515182495
batch i:629
learning rate0.0001755829903978052, loss:2.9041495323181152
batch i:630
learning rate0.0001755829903978052, loss:2.919273614883423
batch i:631
learning rate0.0001755829903978052, loss:3.035187005996704
batch i:632
learning rate0.0001755829903978052, loss:2.960888385772705
batch i:633
learning rate0.0001755829903978052, loss:3.0463666915893555
batch i:634
learning rate0.0001755829903978052, loss:2.989729881286621
batch i:635
learning rate0.0001755829903978052, loss:3.0292539596557617
batch i:636
learning rate0.0001755829903978052, loss:2.9960641860961914
batch i:637
learning rate0.0001755829903978052, loss:2.992097854614258
batch i:638
learning rate0.0001755829903978052, loss:3.04754638671875
batch i:639
learning rate0.0001755829903978052, loss:2.9273064136505127
batch i:640
learning rate0.0001755829903978052, loss:2.9157862663269043
batch i:641
learning rate0.0001755829903978052, loss:2.833881378173828
batch i:642
learning rate0.0001755829903978052, loss:2.980422019958496
batch i:643
learning rate0.0001755829903978052, loss:2.981987476348877
batch i:644
learning rate0.0001755829903978052, loss:3.0246922969818115
batch i:645
learning rate0.0001755829903978052, loss:2.9978408813476562
batch i:646
learning rate0.0002633744855967078, loss:3.0185647010803223
batch i:647
learning rate0.0002633744855967078, loss:3.0297398567199707
batch i:648
learning rate0.0002633744855967078, loss:2.9518749713897705
batch i:649
learning rate0.0002633744855967078, loss:2.9878640174865723
batch i:650
learning rate0.0002633744855967078, loss:2.947100877761841
current self-play batch: 650
num_playouts:4000, win: 5, lose: 4, tie:1
average time: 1563.7353829622268
batch i:651
learning rate0.0002633744855967078, loss:3.058377504348755
batch i:652
learning rate0.0002633744855967078, loss:3.092128276824951
batch i:653
learning rate0.0002633744855967078, loss:2.993441104888916
batch i:654
learning rate0.0002633744855967078, loss:3.058063268661499
batch i:655
learning rate0.0002633744855967078, loss:3.0261526107788086
batch i:656
learning rate0.0002633744855967078, loss:2.970156192779541
batch i:657
learning rate0.0002633744855967078, loss:2.9562108516693115
batch i:658
learning rate0.0002633744855967078, loss:3.0113306045532227
batch i:659
learning rate0.0002633744855967078, loss:2.9940989017486572
batch i:660
learning rate0.0002633744855967078, loss:2.9611082077026367
batch i:661
learning rate0.0002633744855967078, loss:3.001497268676758
batch i:662
learning rate0.0002633744855967078, loss:2.981144428253174
batch i:663
learning rate0.0001755829903978052, loss:2.8889193534851074
batch i:664
learning rate0.0001755829903978052, loss:3.118129253387451
batch i:665
learning rate0.0001755829903978052, loss:3.0011017322540283
batch i:666
learning rate0.0001755829903978052, loss:2.970266342163086
batch i:667
learning rate0.0001755829903978052, loss:2.970543384552002
batch i:668
learning rate0.0001755829903978052, loss:2.9515485763549805
batch i:669
learning rate0.0001755829903978052, loss:2.958127975463867
batch i:670
learning rate0.0001755829903978052, loss:3.015688419342041
batch i:671
learning rate0.0001755829903978052, loss:3.017509937286377
batch i:672
learning rate0.0001755829903978052, loss:2.9472246170043945
batch i:673
learning rate0.0001755829903978052, loss:2.9647886753082275
batch i:674
learning rate0.0001755829903978052, loss:2.9912989139556885
batch i:675
learning rate0.0001755829903978052, loss:2.997903347015381
batch i:676
learning rate0.0001755829903978052, loss:3.0629799365997314
batch i:677
learning rate0.0001755829903978052, loss:2.945388078689575
batch i:678
learning rate0.0001755829903978052, loss:2.993344783782959
batch i:679
learning rate0.0001755829903978052, loss:3.0324249267578125
batch i:680
learning rate0.0001755829903978052, loss:2.938657760620117
batch i:681
learning rate0.0001755829903978052, loss:2.9917378425598145
batch i:682
learning rate0.0001755829903978052, loss:3.0632686614990234
batch i:683
learning rate0.0001755829903978052, loss:3.0831198692321777
batch i:684
learning rate0.0001755829903978052, loss:3.1314609050750732
batch i:685
learning rate0.0001755829903978052, loss:3.1077075004577637
batch i:686
learning rate0.0001755829903978052, loss:3.0439491271972656
batch i:687
learning rate0.0001755829903978052, loss:3.062586545944214
batch i:688
learning rate0.0001755829903978052, loss:3.012390375137329
batch i:689
learning rate0.0001755829903978052, loss:3.0267491340637207
batch i:690
learning rate0.0001755829903978052, loss:3.045912981033325
batch i:691
learning rate0.0001755829903978052, loss:3.106228828430176
batch i:692
learning rate0.0001755829903978052, loss:2.9588048458099365
batch i:693
learning rate0.0001755829903978052, loss:3.0120151042938232
batch i:694
learning rate0.0001755829903978052, loss:3.0409743785858154
batch i:695
learning rate0.0001755829903978052, loss:2.9654908180236816
batch i:696
learning rate0.0001755829903978052, loss:2.9030189514160156
batch i:697
learning rate0.0001755829903978052, loss:3.007534980773926
batch i:698
learning rate0.0001755829903978052, loss:2.9715957641601562
batch i:699
learning rate0.0001755829903978052, loss:2.92584228515625
batch i:700
learning rate0.0001755829903978052, loss:2.955659866333008
current self-play batch: 700
num_playouts:4000, win: 5, lose: 5, tie:0
average time: 848.6334160089493
batch i:701
learning rate0.0001755829903978052, loss:2.9465436935424805
batch i:702
learning rate0.0001755829903978052, loss:2.9061474800109863
batch i:703
learning rate0.0001755829903978052, loss:2.9920854568481445
batch i:704
learning rate0.0001755829903978052, loss:2.9597136974334717
batch i:705
learning rate0.0001755829903978052, loss:3.0177817344665527
batch i:706
learning rate0.0001755829903978052, loss:2.9909257888793945
batch i:707
learning rate0.0001755829903978052, loss:2.9334254264831543
batch i:708
learning rate0.0001755829903978052, loss:2.9543073177337646
batch i:709
learning rate0.0001755829903978052, loss:2.931126594543457
batch i:710
learning rate0.0001755829903978052, loss:2.9729061126708984
batch i:711
learning rate0.0001755829903978052, loss:2.9637398719787598
batch i:712
learning rate0.0001755829903978052, loss:2.957261562347412
batch i:713
learning rate0.0001755829903978052, loss:2.9660799503326416
batch i:714
learning rate0.0001755829903978052, loss:2.8588175773620605
batch i:715
learning rate0.0001755829903978052, loss:2.955875873565674
batch i:716
learning rate0.0001755829903978052, loss:2.9045848846435547
batch i:717
learning rate0.0001755829903978052, loss:2.8795998096466064
batch i:718
learning rate0.0001755829903978052, loss:2.9149885177612305
batch i:719
learning rate0.0001755829903978052, loss:2.900200843811035
batch i:720
learning rate0.0001755829903978052, loss:2.8373804092407227
batch i:721
learning rate0.0001755829903978052, loss:2.9516308307647705
batch i:722
learning rate0.0001755829903978052, loss:2.9319210052490234
batch i:723
learning rate0.0001755829903978052, loss:2.8477067947387695
batch i:724
learning rate0.0001755829903978052, loss:2.880704879760742
batch i:725
learning rate0.0001755829903978052, loss:2.885481834411621
batch i:726
learning rate0.0001755829903978052, loss:2.961238384246826
batch i:727
learning rate0.0001755829903978052, loss:2.9525644779205322
batch i:728
learning rate0.0001755829903978052, loss:2.8808908462524414
batch i:729
learning rate0.0001755829903978052, loss:2.9276344776153564
batch i:730
learning rate0.0001755829903978052, loss:2.9107589721679688
batch i:731
learning rate0.0001755829903978052, loss:2.8965377807617188
batch i:732
learning rate0.0001755829903978052, loss:2.8988208770751953
batch i:733
learning rate0.0001755829903978052, loss:2.901381731033325
batch i:734
learning rate0.0001755829903978052, loss:2.9122791290283203
batch i:735
learning rate0.0001755829903978052, loss:2.958411693572998
batch i:736
learning rate0.0001755829903978052, loss:2.968398094177246
batch i:737
learning rate0.0001755829903978052, loss:2.956702470779419
batch i:738
learning rate0.0001755829903978052, loss:2.85691499710083
batch i:739
learning rate0.0001755829903978052, loss:2.9850597381591797
batch i:740
learning rate0.0001755829903978052, loss:2.9829230308532715
batch i:741
learning rate0.0001755829903978052, loss:2.990408182144165
batch i:742
learning rate0.0001755829903978052, loss:2.963721752166748
batch i:743
learning rate0.0001755829903978052, loss:2.914193630218506
batch i:744
learning rate0.0001755829903978052, loss:2.962660312652588
batch i:745
learning rate0.0001755829903978052, loss:2.9119091033935547
batch i:746
learning rate0.0001755829903978052, loss:2.8928327560424805
batch i:747
learning rate0.0001755829903978052, loss:2.8937957286834717
batch i:748
learning rate0.0001755829903978052, loss:2.8745651245117188
batch i:749
learning rate0.0001755829903978052, loss:2.9359354972839355
batch i:750
learning rate0.0001755829903978052, loss:2.8989267349243164
current self-play batch: 750
num_playouts:4000, win: 4, lose: 6, tie:0
average time: 1111.2421629428864
batch i:751
learning rate0.0001755829903978052, loss:2.8998255729675293
batch i:752
learning rate0.0001755829903978052, loss:2.9166808128356934
batch i:753
learning rate0.0001755829903978052, loss:2.8327393531799316
batch i:754
learning rate0.0001755829903978052, loss:2.9432880878448486
batch i:755
learning rate0.0001755829903978052, loss:2.810044050216675
batch i:756
learning rate0.0001755829903978052, loss:2.906482458114624
batch i:757
learning rate0.0001755829903978052, loss:2.8904967308044434
batch i:758
learning rate0.0001755829903978052, loss:2.898993492126465
batch i:759
learning rate0.0001755829903978052, loss:2.9116053581237793
batch i:760
learning rate0.0001755829903978052, loss:2.8852410316467285
batch i:761
learning rate0.0001755829903978052, loss:2.9224636554718018
batch i:762
learning rate0.0001755829903978052, loss:2.942075729370117
batch i:763
learning rate0.0001755829903978052, loss:2.8616156578063965
batch i:764
learning rate0.0001755829903978052, loss:2.9437856674194336
batch i:765
learning rate0.0001755829903978052, loss:2.9609591960906982
batch i:766
learning rate0.0001755829903978052, loss:2.8213753700256348
batch i:767
learning rate0.0001755829903978052, loss:2.7875490188598633
batch i:768
learning rate0.0001755829903978052, loss:2.8531532287597656
batch i:769
learning rate0.0001755829903978052, loss:2.887119770050049
batch i:770
learning rate0.0001755829903978052, loss:2.9767675399780273
batch i:771
learning rate0.0001755829903978052, loss:2.8660168647766113
batch i:772
learning rate0.0001755829903978052, loss:2.9418158531188965
batch i:773
learning rate0.0001755829903978052, loss:2.977592706680298
batch i:774
learning rate0.0001755829903978052, loss:2.9992382526397705
batch i:775
learning rate0.0001755829903978052, loss:2.8806886672973633
batch i:776
learning rate0.0001755829903978052, loss:2.9490509033203125
batch i:777
learning rate0.0001755829903978052, loss:2.9510412216186523
batch i:778
learning rate0.0001755829903978052, loss:2.9220333099365234
batch i:779
learning rate0.0001755829903978052, loss:2.9032139778137207
batch i:780
learning rate0.0001755829903978052, loss:2.9609923362731934
batch i:781
learning rate0.0001755829903978052, loss:2.884779930114746
batch i:782
learning rate0.0001755829903978052, loss:2.9037201404571533
batch i:783
learning rate0.0001755829903978052, loss:2.8896288871765137
batch i:784
learning rate0.0001755829903978052, loss:2.804360866546631
batch i:785
learning rate0.0001755829903978052, loss:2.8985259532928467
batch i:786
learning rate0.0001755829903978052, loss:2.966151714324951
batch i:787
learning rate0.0001755829903978052, loss:2.967006206512451
batch i:788
learning rate0.0001755829903978052, loss:2.871110200881958
batch i:789
learning rate0.0001755829903978052, loss:2.819896697998047
batch i:790
learning rate0.0001755829903978052, loss:2.8566465377807617
batch i:791
learning rate0.0001755829903978052, loss:2.885646343231201
batch i:792
learning rate0.0001755829903978052, loss:2.8876123428344727
batch i:793
learning rate0.0001755829903978052, loss:2.924131393432617
batch i:794
learning rate0.0001755829903978052, loss:2.8274593353271484
batch i:795
learning rate0.0001755829903978052, loss:2.8519771099090576
batch i:796
learning rate0.0001755829903978052, loss:2.924919605255127
batch i:797
learning rate0.0001755829903978052, loss:2.8040428161621094
batch i:798
learning rate0.0001755829903978052, loss:2.889852523803711
batch i:799
learning rate0.0001755829903978052, loss:2.846696138381958
batch i:800
learning rate0.0001755829903978052, loss:2.7867038249969482
current self-play batch: 800
num_playouts:4000, win: 8, lose: 0, tie:2
average time: 1354.450737309456
batch i:801
learning rate0.0001755829903978052, loss:2.8678646087646484
batch i:802
learning rate0.0001755829903978052, loss:2.8937106132507324
batch i:803
learning rate0.0001755829903978052, loss:2.88429594039917
batch i:804
learning rate0.0001755829903978052, loss:2.829270124435425
batch i:805
learning rate0.0001755829903978052, loss:2.834261417388916
batch i:806
learning rate0.0001755829903978052, loss:2.919304847717285
batch i:807
learning rate0.0001755829903978052, loss:2.8649404048919678
batch i:808
learning rate0.0001755829903978052, loss:2.752847194671631
batch i:809
learning rate0.0001755829903978052, loss:2.856005907058716
batch i:810
learning rate0.0001755829903978052, loss:2.891845226287842
batch i:811
learning rate0.0001755829903978052, loss:2.8769571781158447
batch i:812
learning rate0.0001755829903978052, loss:2.867189407348633
batch i:813
learning rate0.0001755829903978052, loss:2.866219997406006
batch i:814
learning rate0.0001755829903978052, loss:2.8907957077026367
batch i:815
learning rate0.0001755829903978052, loss:2.850213050842285
batch i:816
learning rate0.0001755829903978052, loss:2.8967580795288086
batch i:817
learning rate0.0001755829903978052, loss:2.883049726486206
batch i:818
learning rate0.0001755829903978052, loss:2.886496067047119
batch i:819
learning rate0.0001755829903978052, loss:2.819260597229004
batch i:820
learning rate0.0001755829903978052, loss:2.933680534362793
batch i:821
learning rate0.0001755829903978052, loss:2.8301327228546143
batch i:822
learning rate0.0001755829903978052, loss:2.8301851749420166
batch i:823
learning rate0.0001755829903978052, loss:2.8925743103027344
batch i:824
learning rate0.0001755829903978052, loss:2.933525562286377
batch i:825
learning rate0.0001755829903978052, loss:2.8593692779541016
batch i:826
learning rate0.0001755829903978052, loss:2.8822131156921387
batch i:827
learning rate0.0001755829903978052, loss:2.892160415649414
batch i:828
learning rate0.0001755829903978052, loss:2.7860682010650635
batch i:829
learning rate0.0001755829903978052, loss:2.8645541667938232
batch i:830
learning rate0.0001755829903978052, loss:2.852116346359253
batch i:831
learning rate0.0001755829903978052, loss:2.888125419616699
batch i:832
learning rate0.0001755829903978052, loss:2.8209924697875977
batch i:833
learning rate0.0001755829903978052, loss:2.74621319770813
batch i:834
learning rate0.0001755829903978052, loss:2.8327972888946533
batch i:835
learning rate0.0001755829903978052, loss:2.7681264877319336
batch i:836
learning rate0.0001755829903978052, loss:2.7930288314819336
batch i:837
learning rate0.0001755829903978052, loss:2.82430100440979
batch i:838
learning rate0.0001755829903978052, loss:2.845690965652466
batch i:839
learning rate0.0001755829903978052, loss:2.8731725215911865
batch i:840
learning rate0.0001755829903978052, loss:2.7777915000915527
batch i:841
learning rate0.0001755829903978052, loss:2.8200273513793945
batch i:842
learning rate0.0001755829903978052, loss:2.7627925872802734
batch i:843
learning rate0.0001755829903978052, loss:2.7395453453063965
batch i:844
learning rate0.0001755829903978052, loss:2.793205499649048
batch i:845
learning rate0.0001755829903978052, loss:2.844949722290039
batch i:846
learning rate0.0001755829903978052, loss:2.823629140853882
batch i:847
learning rate0.0001755829903978052, loss:2.847485065460205
batch i:848
learning rate0.0001755829903978052, loss:2.7504138946533203
batch i:849
learning rate0.0001755829903978052, loss:2.8186604976654053
batch i:850
learning rate0.0001755829903978052, loss:2.8138809204101562
current self-play batch: 850
num_playouts:4000, win: 8, lose: 0, tie:2
average time: 1359.4519399881362
batch i:851
learning rate0.0001755829903978052, loss:2.8585288524627686
batch i:852
learning rate0.0001755829903978052, loss:2.7954795360565186
batch i:853
learning rate0.0001755829903978052, loss:2.861395835876465
batch i:854
learning rate0.0001755829903978052, loss:2.8927230834960938
batch i:855
learning rate0.0001755829903978052, loss:2.911633253097534
batch i:856
learning rate0.0001755829903978052, loss:2.7993268966674805
batch i:857
learning rate0.0001755829903978052, loss:2.8126416206359863
batch i:858
learning rate0.0001755829903978052, loss:2.8114566802978516
batch i:859
learning rate0.0001755829903978052, loss:2.781301259994507
batch i:860
learning rate0.0001755829903978052, loss:2.8312318325042725
batch i:861
learning rate0.0001755829903978052, loss:2.8420910835266113
batch i:862
learning rate0.0001755829903978052, loss:2.8459720611572266
batch i:863
learning rate0.0001755829903978052, loss:2.8222126960754395
batch i:864
learning rate0.0001755829903978052, loss:2.8425793647766113
batch i:865
learning rate0.0001755829903978052, loss:2.7940821647644043
batch i:866
learning rate0.0001755829903978052, loss:2.786038875579834
batch i:867
learning rate0.0001755829903978052, loss:2.7215163707733154
batch i:868
learning rate0.0001755829903978052, loss:2.76481294631958
batch i:869
learning rate0.0001755829903978052, loss:2.845693588256836
batch i:870
learning rate0.0001755829903978052, loss:2.819915294647217
batch i:871
learning rate0.0001755829903978052, loss:2.7475638389587402
batch i:872
learning rate0.0001755829903978052, loss:2.768190860748291
batch i:873
learning rate0.0001755829903978052, loss:2.836296558380127
batch i:874
learning rate0.0001755829903978052, loss:2.7653567790985107
batch i:875
learning rate0.0001755829903978052, loss:2.8243751525878906
batch i:876
learning rate0.0001755829903978052, loss:2.774777889251709
batch i:877
learning rate0.0001755829903978052, loss:2.8579516410827637
batch i:878
learning rate0.0001755829903978052, loss:2.804892063140869
batch i:879
learning rate0.0001755829903978052, loss:2.8071770668029785
batch i:880
learning rate0.0001755829903978052, loss:2.871115207672119
batch i:881
learning rate0.0001755829903978052, loss:2.763092041015625
batch i:882
learning rate0.0001755829903978052, loss:2.819261074066162
batch i:883
learning rate0.0001755829903978052, loss:2.6699328422546387
batch i:884
learning rate0.0001755829903978052, loss:2.7914552688598633
batch i:885
learning rate0.0001755829903978052, loss:2.8090100288391113
batch i:886
learning rate0.0001755829903978052, loss:2.7825002670288086
batch i:887
learning rate0.0001755829903978052, loss:2.7511157989501953
batch i:888
learning rate0.0001755829903978052, loss:2.8191661834716797
batch i:889
learning rate0.0001755829903978052, loss:2.7630128860473633
batch i:890
learning rate0.0001755829903978052, loss:2.804076671600342
batch i:891
learning rate0.0001755829903978052, loss:2.7892351150512695
batch i:892
learning rate0.0001755829903978052, loss:2.7545886039733887
batch i:893
learning rate0.0001755829903978052, loss:2.760211229324341
batch i:894
learning rate0.0001755829903978052, loss:2.7769508361816406
batch i:895
learning rate0.0001755829903978052, loss:2.7903714179992676
batch i:896
learning rate0.0001755829903978052, loss:2.8466689586639404
batch i:897
learning rate0.0001755829903978052, loss:2.7256202697753906
batch i:898
learning rate0.0001755829903978052, loss:2.9090487957000732
batch i:899
learning rate0.0001755829903978052, loss:2.8302576541900635
batch i:900
learning rate0.0001755829903978052, loss:2.822633743286133
current self-play batch: 900
num_playouts:4000, win: 6, lose: 2, tie:2
average time: 1420.4433518648148
batch i:901
learning rate0.0001755829903978052, loss:2.8273708820343018
batch i:902
learning rate0.0001755829903978052, loss:2.777381181716919
batch i:903
learning rate0.0001755829903978052, loss:2.8520913124084473
batch i:904
learning rate0.0001755829903978052, loss:2.8680386543273926
batch i:905
learning rate0.0001755829903978052, loss:2.90872859954834
batch i:906
learning rate0.0001755829903978052, loss:2.8306491374969482
batch i:907
learning rate0.0001755829903978052, loss:2.851698875427246
batch i:908
learning rate0.0001755829903978052, loss:2.8565711975097656
batch i:909
learning rate0.0001755829903978052, loss:2.8037333488464355
batch i:910
learning rate0.0001755829903978052, loss:2.813772678375244
batch i:911
learning rate0.0001755829903978052, loss:2.8570351600646973
batch i:912
learning rate0.0001755829903978052, loss:2.893280029296875
batch i:913
learning rate0.0001755829903978052, loss:2.7644662857055664
batch i:914
learning rate0.0001755829903978052, loss:2.857314109802246
batch i:915
learning rate0.0001755829903978052, loss:2.9254798889160156
batch i:916
learning rate0.0001755829903978052, loss:2.8244874477386475
batch i:917
learning rate0.0001755829903978052, loss:2.806201934814453
batch i:918
learning rate0.0001755829903978052, loss:2.8454389572143555
batch i:919
learning rate0.0001755829903978052, loss:2.899721622467041
batch i:920
learning rate0.0001755829903978052, loss:2.8630447387695312
batch i:921
learning rate0.0001755829903978052, loss:2.860461950302124
batch i:922
learning rate0.0001755829903978052, loss:2.8031630516052246
batch i:923
learning rate0.0001755829903978052, loss:2.8156607151031494
batch i:924
learning rate0.0001755829903978052, loss:2.8059067726135254
batch i:925
learning rate0.0001755829903978052, loss:2.7848048210144043
batch i:926
learning rate0.0001755829903978052, loss:2.837090015411377
batch i:927
learning rate0.0001755829903978052, loss:2.8419923782348633
batch i:928
learning rate0.0001755829903978052, loss:2.9631309509277344
batch i:929
learning rate0.0001755829903978052, loss:2.892824649810791
batch i:930
learning rate0.0001755829903978052, loss:2.8401432037353516
batch i:931
learning rate0.0001755829903978052, loss:2.892280101776123
batch i:932
learning rate0.0001755829903978052, loss:2.9499213695526123
batch i:933
learning rate0.0001755829903978052, loss:2.923438549041748
batch i:934
learning rate0.0001755829903978052, loss:2.842629909515381
batch i:935
learning rate0.0001755829903978052, loss:2.97745680809021
batch i:936
learning rate0.0001755829903978052, loss:2.917555809020996
batch i:937
learning rate0.0001755829903978052, loss:2.808076858520508
batch i:938
learning rate0.0001755829903978052, loss:2.8654282093048096
batch i:939
learning rate0.0001755829903978052, loss:2.9860291481018066
batch i:940
learning rate0.0001755829903978052, loss:3.0707273483276367
batch i:941
learning rate0.0001755829903978052, loss:2.8937230110168457
batch i:942
learning rate0.0001755829903978052, loss:2.954298973083496
batch i:943
learning rate0.0001755829903978052, loss:2.89371657371521
batch i:944
learning rate0.0001755829903978052, loss:2.923105478286743
batch i:945
learning rate0.0001755829903978052, loss:2.840057134628296
batch i:946
learning rate0.0001755829903978052, loss:2.9351134300231934
batch i:947
learning rate0.0001755829903978052, loss:2.941068649291992
batch i:948
learning rate0.0001755829903978052, loss:2.938558578491211
batch i:949
learning rate0.0001755829903978052, loss:2.946755886077881
batch i:950
learning rate0.0001755829903978052, loss:2.903797149658203
current self-play batch: 950
num_playouts:4000, win: 4, lose: 5, tie:1
average time: 1347.217497229576
batch i:951
learning rate0.0001755829903978052, loss:2.892637252807617
batch i:952
learning rate0.0001755829903978052, loss:2.968235969543457
batch i:953
learning rate0.0001755829903978052, loss:2.9392261505126953
batch i:954
learning rate0.0001755829903978052, loss:2.8946943283081055
batch i:955
learning rate0.0001755829903978052, loss:2.8864660263061523
batch i:956
learning rate0.0001755829903978052, loss:2.8611137866973877
batch i:957
learning rate0.0001755829903978052, loss:2.8602185249328613
batch i:958
learning rate0.0001755829903978052, loss:2.998520851135254
batch i:959
learning rate0.0001755829903978052, loss:2.9183621406555176
batch i:960
learning rate0.0001755829903978052, loss:2.9013211727142334
batch i:961
learning rate0.0001755829903978052, loss:2.877629041671753
batch i:962
learning rate0.0001755829903978052, loss:2.9215667247772217
batch i:963
learning rate0.0001755829903978052, loss:2.8982181549072266
batch i:964
learning rate0.0001755829903978052, loss:2.8649661540985107
batch i:965
learning rate0.0001755829903978052, loss:2.9815053939819336
batch i:966
learning rate0.0001755829903978052, loss:2.955266237258911
batch i:967
learning rate0.0001755829903978052, loss:2.9200572967529297
batch i:968
learning rate0.0001755829903978052, loss:2.9558324813842773
batch i:969
learning rate0.0001755829903978052, loss:2.849517345428467
batch i:970
learning rate0.0001755829903978052, loss:2.952754497528076
batch i:971
learning rate0.0001755829903978052, loss:2.9264016151428223
batch i:972
learning rate0.0001755829903978052, loss:2.876344919204712
batch i:973
learning rate0.0001755829903978052, loss:2.9272708892822266
batch i:974
learning rate0.0001755829903978052, loss:2.872929573059082
batch i:975
learning rate0.0001755829903978052, loss:2.885004758834839
batch i:976
learning rate0.0001755829903978052, loss:2.919118881225586
batch i:977
learning rate0.0001755829903978052, loss:2.866240978240967
batch i:978
learning rate0.0001755829903978052, loss:2.881551742553711
batch i:979
learning rate0.0001755829903978052, loss:2.9108848571777344
batch i:980
learning rate0.0001755829903978052, loss:2.9135279655456543
batch i:981
learning rate0.0001755829903978052, loss:2.929751396179199
batch i:982
learning rate0.0001755829903978052, loss:2.9850759506225586
batch i:983
learning rate0.0001755829903978052, loss:2.985168218612671
batch i:984
learning rate0.0001755829903978052, loss:2.9675703048706055
batch i:985
learning rate0.0001755829903978052, loss:3.0014805793762207
batch i:986
learning rate0.0001755829903978052, loss:2.8987655639648438
batch i:987
learning rate0.0001755829903978052, loss:2.9766530990600586
batch i:988
learning rate0.0001755829903978052, loss:2.9698359966278076
batch i:989
learning rate0.0001755829903978052, loss:2.961275100708008
batch i:990
learning rate0.0001755829903978052, loss:2.917381763458252
batch i:991
learning rate0.0001755829903978052, loss:2.877309560775757
batch i:992
learning rate0.0001755829903978052, loss:2.8822364807128906
batch i:993
learning rate0.0001755829903978052, loss:2.857921838760376
batch i:994
learning rate0.0001755829903978052, loss:2.958427906036377
batch i:995
learning rate0.0001755829903978052, loss:2.8610901832580566
batch i:996
learning rate0.0001755829903978052, loss:2.9259839057922363
batch i:997
learning rate0.0001755829903978052, loss:2.945906639099121
batch i:998
learning rate0.0001755829903978052, loss:2.9174537658691406
batch i:999
learning rate0.0001755829903978052, loss:2.959010124206543
batch i:1000
learning rate0.0001755829903978052, loss:2.935940980911255
current self-play batch: 1000
num_playouts:4000, win: 5, lose: 4, tie:1
average time: 1259.6455004930497
batch i:1001
learning rate0.0001755829903978052, loss:2.961779832839966
batch i:1002
learning rate0.0001755829903978052, loss:2.9558329582214355
batch i:1003
learning rate0.0001755829903978052, loss:2.9250881671905518
batch i:1004
learning rate0.0001755829903978052, loss:2.962681770324707
batch i:1005
learning rate0.0001755829903978052, loss:2.9678289890289307
batch i:1006
learning rate0.0001755829903978052, loss:2.9465670585632324
batch i:1007
learning rate0.0001755829903978052, loss:2.953103542327881
batch i:1008
learning rate0.0001755829903978052, loss:2.98358416557312
batch i:1009
learning rate0.0001755829903978052, loss:2.95798397064209
batch i:1010
learning rate0.0001755829903978052, loss:2.9672865867614746
batch i:1011
learning rate0.0001755829903978052, loss:2.840972900390625
batch i:1012
learning rate0.0001755829903978052, loss:2.8875484466552734
batch i:1013
learning rate0.0001755829903978052, loss:2.8969295024871826
batch i:1014
learning rate0.0001755829903978052, loss:2.9333152770996094
batch i:1015
learning rate0.0001755829903978052, loss:2.900773286819458
batch i:1016
learning rate0.0001755829903978052, loss:3.0199599266052246
batch i:1017
learning rate0.0001755829903978052, loss:2.962585926055908
batch i:1018
learning rate0.0001755829903978052, loss:2.9347522258758545
batch i:1019
learning rate0.0001755829903978052, loss:2.91158390045166
batch i:1020
learning rate0.0001755829903978052, loss:2.940272331237793
batch i:1021
learning rate0.0001755829903978052, loss:2.866272449493408
batch i:1022
learning rate0.0001755829903978052, loss:2.9076547622680664
batch i:1023
learning rate0.0001755829903978052, loss:2.871943950653076
batch i:1024
learning rate0.0001755829903978052, loss:2.897465705871582
batch i:1025
learning rate0.0001755829903978052, loss:2.940415620803833
batch i:1026
learning rate0.0001755829903978052, loss:2.967646598815918
batch i:1027
learning rate0.0001755829903978052, loss:2.9201431274414062
batch i:1028
learning rate0.0001755829903978052, loss:2.8948493003845215
batch i:1029
learning rate0.0001755829903978052, loss:2.883512496948242
batch i:1030
learning rate0.0001755829903978052, loss:2.8872790336608887
batch i:1031
learning rate0.0001755829903978052, loss:2.843904733657837
batch i:1032
learning rate0.0001755829903978052, loss:2.880756378173828
batch i:1033
learning rate0.0001755829903978052, loss:2.7885847091674805
batch i:1034
learning rate0.0001755829903978052, loss:2.894592523574829
batch i:1035
learning rate0.0001755829903978052, loss:2.8914570808410645
batch i:1036
learning rate0.0001755829903978052, loss:2.815619945526123
batch i:1037
learning rate0.0001755829903978052, loss:2.9282679557800293
batch i:1038
learning rate0.0001755829903978052, loss:2.9450554847717285
batch i:1039
learning rate0.0001755829903978052, loss:2.931809186935425
batch i:1040
learning rate0.0001755829903978052, loss:2.8576064109802246
batch i:1041
learning rate0.0001755829903978052, loss:2.9299628734588623
batch i:1042
learning rate0.0001755829903978052, loss:2.9588913917541504
batch i:1043
learning rate0.0001755829903978052, loss:2.8719327449798584
batch i:1044
learning rate0.0001755829903978052, loss:2.911799669265747
batch i:1045
learning rate0.0001755829903978052, loss:2.9417362213134766
batch i:1046
learning rate0.0001755829903978052, loss:2.8785789012908936
batch i:1047
learning rate0.0001755829903978052, loss:2.9671335220336914
batch i:1048
learning rate0.0001755829903978052, loss:2.9292285442352295
batch i:1049
learning rate0.0001755829903978052, loss:2.935490846633911
batch i:1050
learning rate0.0001755829903978052, loss:2.9072811603546143
current self-play batch: 1050
num_playouts:4000, win: 7, lose: 1, tie:2
average time: 1408.9210292816163
batch i:1051
learning rate0.0001755829903978052, loss:2.934309244155884
batch i:1052
learning rate0.0001755829903978052, loss:2.9332149028778076
batch i:1053
learning rate0.0001755829903978052, loss:2.8312342166900635
batch i:1054
learning rate0.0001755829903978052, loss:2.940859079360962
batch i:1055
learning rate0.0001755829903978052, loss:2.857436180114746
batch i:1056
learning rate0.0001755829903978052, loss:2.961027145385742
batch i:1057
learning rate0.0001755829903978052, loss:2.9781270027160645
batch i:1058
learning rate0.0001755829903978052, loss:2.9003279209136963
batch i:1059
learning rate0.0001755829903978052, loss:2.9189815521240234
batch i:1060
learning rate0.0001755829903978052, loss:2.8022263050079346
batch i:1061
learning rate0.0001755829903978052, loss:2.8603672981262207
batch i:1062
learning rate0.0001755829903978052, loss:2.8982951641082764
batch i:1063
learning rate0.0001755829903978052, loss:2.9504613876342773
batch i:1064
learning rate0.0001755829903978052, loss:2.899322271347046
batch i:1065
learning rate0.0001755829903978052, loss:2.943155288696289
batch i:1066
learning rate0.0001755829903978052, loss:2.918842077255249
batch i:1067
learning rate0.0001755829903978052, loss:2.8711729049682617
batch i:1068
learning rate0.0001755829903978052, loss:2.862677812576294
batch i:1069
learning rate0.0001755829903978052, loss:2.8241145610809326
batch i:1070
learning rate0.0001755829903978052, loss:2.794917583465576
batch i:1071
learning rate0.0001755829903978052, loss:2.7932419776916504
batch i:1072
learning rate0.0001755829903978052, loss:2.856834888458252
batch i:1073
learning rate0.0001755829903978052, loss:2.88014817237854
batch i:1074
learning rate0.0001755829903978052, loss:2.865163564682007
batch i:1075
learning rate0.0001755829903978052, loss:2.876755714416504
batch i:1076
learning rate0.0001755829903978052, loss:2.8213772773742676
batch i:1077
learning rate0.0001755829903978052, loss:2.793853998184204
batch i:1078
learning rate0.0001755829903978052, loss:2.8879544734954834
batch i:1079
learning rate0.0001755829903978052, loss:2.857267379760742
batch i:1080
learning rate0.0001755829903978052, loss:2.8611485958099365
batch i:1081
learning rate0.0001755829903978052, loss:2.882272481918335
batch i:1082
learning rate0.0001755829903978052, loss:2.8513360023498535
batch i:1083
learning rate0.0001755829903978052, loss:2.8584887981414795
batch i:1084
learning rate0.0001755829903978052, loss:2.9209744930267334
batch i:1085
learning rate0.0001755829903978052, loss:2.8618273735046387
batch i:1086
learning rate0.0001755829903978052, loss:2.8287911415100098
batch i:1087
learning rate0.0001755829903978052, loss:2.8086605072021484
batch i:1088
learning rate0.0001755829903978052, loss:2.7706832885742188
batch i:1089
learning rate0.0001755829903978052, loss:2.895097255706787
batch i:1090
learning rate0.0001755829903978052, loss:2.8311009407043457
batch i:1091
learning rate0.0001755829903978052, loss:2.8307695388793945
batch i:1092
learning rate0.0001755829903978052, loss:2.9657840728759766
batch i:1093
learning rate0.0001755829903978052, loss:2.9073004722595215
batch i:1094
learning rate0.0001755829903978052, loss:2.959879159927368
batch i:1095
learning rate0.0001755829903978052, loss:2.86222505569458
batch i:1096
learning rate0.0001755829903978052, loss:2.859790325164795
batch i:1097
learning rate0.0001755829903978052, loss:2.7637064456939697
batch i:1098
learning rate0.0001755829903978052, loss:2.9101147651672363
batch i:1099
learning rate0.0001755829903978052, loss:2.916090726852417
batch i:1100
learning rate0.0001755829903978052, loss:2.8648934364318848
current self-play batch: 1100
num_playouts:4000, win: 6, lose: 1, tie:3
average time: 1845.3281117916108
batch i:1101
learning rate0.0001755829903978052, loss:2.858856439590454
batch i:1102
learning rate0.0001755829903978052, loss:2.7912466526031494
batch i:1103
learning rate0.0001755829903978052, loss:2.858220100402832
batch i:1104
learning rate0.0001755829903978052, loss:2.8501782417297363
batch i:1105
learning rate0.0001755829903978052, loss:2.824612617492676
batch i:1106
learning rate0.0001755829903978052, loss:2.8380415439605713
batch i:1107
learning rate0.0001755829903978052, loss:2.8268465995788574
batch i:1108
learning rate0.0001755829903978052, loss:2.8963942527770996
batch i:1109
learning rate0.0001755829903978052, loss:2.8085668087005615
batch i:1110
learning rate0.0001755829903978052, loss:2.861915111541748
batch i:1111
learning rate0.0001755829903978052, loss:2.8326849937438965
batch i:1112
learning rate0.0001755829903978052, loss:2.830789804458618
batch i:1113
learning rate0.0001755829903978052, loss:2.863955020904541
batch i:1114
learning rate0.0001755829903978052, loss:2.7873668670654297
batch i:1115
learning rate0.0001755829903978052, loss:2.832408905029297
batch i:1116
learning rate0.0001755829903978052, loss:2.8076205253601074
batch i:1117
learning rate0.0001755829903978052, loss:2.860377311706543
batch i:1118
learning rate0.0001755829903978052, loss:2.838595390319824
batch i:1119
learning rate0.0001755829903978052, loss:2.889070987701416
batch i:1120
learning rate0.0001755829903978052, loss:2.8627052307128906
batch i:1121
learning rate0.0001755829903978052, loss:2.9172191619873047
batch i:1122
learning rate0.0001755829903978052, loss:2.9037835597991943
batch i:1123
learning rate0.0001755829903978052, loss:2.8637537956237793
batch i:1124
learning rate0.0001755829903978052, loss:2.925200939178467
batch i:1125
learning rate0.0001755829903978052, loss:2.8342761993408203
batch i:1126
learning rate0.0001755829903978052, loss:2.9095566272735596
batch i:1127
learning rate0.0001755829903978052, loss:2.871082305908203
batch i:1128
learning rate0.0001755829903978052, loss:2.811983585357666
batch i:1129
learning rate0.0001755829903978052, loss:2.889848232269287
batch i:1130
learning rate0.0001755829903978052, loss:2.9455509185791016
batch i:1131
learning rate0.0001755829903978052, loss:2.8116867542266846
batch i:1132
learning rate0.0001755829903978052, loss:2.8337721824645996
batch i:1133
learning rate0.0001755829903978052, loss:2.8329529762268066
batch i:1134
learning rate0.0001755829903978052, loss:2.8692588806152344
batch i:1135
learning rate0.0001755829903978052, loss:2.8617615699768066
batch i:1136
learning rate0.0001755829903978052, loss:2.875452995300293
batch i:1137
learning rate0.0001755829903978052, loss:2.7919225692749023
batch i:1138
learning rate0.0001755829903978052, loss:2.792252540588379
batch i:1139
learning rate0.0001755829903978052, loss:2.821051836013794
batch i:1140
learning rate0.0001755829903978052, loss:2.815035820007324
batch i:1141
learning rate0.0001755829903978052, loss:2.8043389320373535
batch i:1142
learning rate0.0001755829903978052, loss:2.851673126220703
batch i:1143
learning rate0.0001755829903978052, loss:2.7873294353485107
batch i:1144
learning rate0.0001755829903978052, loss:2.7949113845825195
batch i:1145
learning rate0.0001755829903978052, loss:2.8172874450683594
batch i:1146
learning rate0.0001755829903978052, loss:2.7917909622192383
batch i:1147
learning rate0.0001755829903978052, loss:2.8823728561401367
batch i:1148
learning rate0.0001755829903978052, loss:2.7685599327087402
batch i:1149
learning rate0.0001755829903978052, loss:2.8701910972595215
batch i:1150
learning rate0.0001755829903978052, loss:2.71372389793396
current self-play batch: 1150
num_playouts:4000, win: 4, lose: 3, tie:3
average time: 1964.510007739067
batch i:1151
learning rate0.0001755829903978052, loss:2.820838212966919
batch i:1152
learning rate0.0001755829903978052, loss:2.835139751434326
batch i:1153
learning rate0.0001755829903978052, loss:2.8732504844665527
batch i:1154
learning rate0.0001755829903978052, loss:2.8801164627075195
batch i:1155
learning rate0.0001755829903978052, loss:2.805232048034668
batch i:1156
learning rate0.0001755829903978052, loss:2.766855239868164
batch i:1157
learning rate0.0001755829903978052, loss:2.7822580337524414
batch i:1158
learning rate0.0001755829903978052, loss:2.826373338699341
batch i:1159
learning rate0.0001755829903978052, loss:2.8094191551208496
batch i:1160
learning rate0.0001755829903978052, loss:2.7546350955963135
batch i:1161
learning rate0.0001755829903978052, loss:2.817457675933838
batch i:1162
learning rate0.0001755829903978052, loss:2.7607624530792236
batch i:1163
learning rate0.0001755829903978052, loss:2.7832531929016113
batch i:1164
learning rate0.0001755829903978052, loss:2.8448803424835205
batch i:1165
learning rate0.0001755829903978052, loss:2.8510208129882812
batch i:1166
learning rate0.0001755829903978052, loss:2.8237111568450928
batch i:1167
learning rate0.0001755829903978052, loss:2.7715978622436523
batch i:1168
learning rate0.0001755829903978052, loss:2.777827739715576
batch i:1169
learning rate0.0001755829903978052, loss:2.723323106765747
batch i:1170
learning rate0.0001755829903978052, loss:2.8871376514434814
batch i:1171
learning rate0.0001755829903978052, loss:2.8174524307250977
batch i:1172
learning rate0.0001755829903978052, loss:2.845137596130371
batch i:1173
learning rate0.0002633744855967078, loss:2.8203988075256348
batch i:1174
learning rate0.0002633744855967078, loss:2.8969523906707764
batch i:1175
learning rate0.0002633744855967078, loss:2.8021185398101807
batch i:1176
learning rate0.0001755829903978052, loss:2.764697551727295
batch i:1177
learning rate0.0001755829903978052, loss:2.7221665382385254
batch i:1178
learning rate0.0001755829903978052, loss:2.757990598678589
batch i:1179
learning rate0.0001755829903978052, loss:2.823368549346924
batch i:1180
learning rate0.0001755829903978052, loss:2.801334857940674
batch i:1181
learning rate0.0001755829903978052, loss:2.7864677906036377
batch i:1182
learning rate0.0001755829903978052, loss:2.8324012756347656
batch i:1183
learning rate0.0001755829903978052, loss:2.8657479286193848
batch i:1184
learning rate0.0001755829903978052, loss:2.8333301544189453
batch i:1185
learning rate0.0001755829903978052, loss:2.7572994232177734
batch i:1186
learning rate0.0001755829903978052, loss:2.8110525608062744
batch i:1187
learning rate0.0001755829903978052, loss:2.7792484760284424
batch i:1188
learning rate0.0001755829903978052, loss:2.8332207202911377
batch i:1189
learning rate0.0001755829903978052, loss:2.7791953086853027
batch i:1190
learning rate0.0001755829903978052, loss:2.8202710151672363
batch i:1191
learning rate0.0001755829903978052, loss:2.837369441986084
batch i:1192
learning rate0.0001755829903978052, loss:2.737602472305298
batch i:1193
learning rate0.0001755829903978052, loss:2.7404751777648926
batch i:1194
learning rate0.0001755829903978052, loss:2.7815825939178467
batch i:1195
learning rate0.0001755829903978052, loss:2.668405055999756
batch i:1196
learning rate0.0001755829903978052, loss:2.7658944129943848
batch i:1197
learning rate0.0001755829903978052, loss:2.774867057800293
batch i:1198
learning rate0.0001755829903978052, loss:2.7871413230895996
batch i:1199
learning rate0.0001755829903978052, loss:2.8279576301574707
batch i:1200
learning rate0.0001755829903978052, loss:2.815080165863037
current self-play batch: 1200
num_playouts:4000, win: 7, lose: 0, tie:3
average time: 1590.2788511514664
batch i:1201
learning rate0.0001755829903978052, loss:2.6787519454956055
batch i:1202
learning rate0.0001755829903978052, loss:2.7450294494628906
batch i:1203
learning rate0.0001755829903978052, loss:2.737703323364258
batch i:1204
learning rate0.0001755829903978052, loss:2.7907533645629883
batch i:1205
learning rate0.0001755829903978052, loss:2.8224105834960938
batch i:1206
learning rate0.0001755829903978052, loss:2.6920166015625
batch i:1207
learning rate0.0001755829903978052, loss:2.80686616897583
batch i:1208
learning rate0.0001755829903978052, loss:2.7878270149230957
batch i:1209
learning rate0.0001755829903978052, loss:2.728766918182373
batch i:1210
learning rate0.0001755829903978052, loss:2.742145538330078
batch i:1211
learning rate0.0001755829903978052, loss:2.729128122329712
batch i:1212
learning rate0.0001755829903978052, loss:2.823408603668213
batch i:1213
learning rate0.0001755829903978052, loss:2.738114833831787
batch i:1214
learning rate0.0001755829903978052, loss:2.7542574405670166
batch i:1215
learning rate0.0001755829903978052, loss:2.8298158645629883
batch i:1216
learning rate0.0001755829903978052, loss:2.7298643589019775
batch i:1217
learning rate0.0001755829903978052, loss:2.7420194149017334
batch i:1218
learning rate0.0001755829903978052, loss:2.7579851150512695
batch i:1219
learning rate0.0001755829903978052, loss:2.7051234245300293
batch i:1220
learning rate0.0001755829903978052, loss:2.8240160942077637
batch i:1221
learning rate0.0001755829903978052, loss:2.826796054840088
batch i:1222
learning rate0.0001755829903978052, loss:2.7316203117370605
batch i:1223
learning rate0.0001755829903978052, loss:2.807324171066284
batch i:1224
learning rate0.0001755829903978052, loss:2.736424207687378
batch i:1225
learning rate0.0001755829903978052, loss:2.7641491889953613
batch i:1226
learning rate0.0001755829903978052, loss:2.723456382751465
batch i:1227
learning rate0.0001755829903978052, loss:2.734170436859131
batch i:1228
learning rate0.0001755829903978052, loss:2.792065382003784
batch i:1229
learning rate0.0001755829903978052, loss:2.7959835529327393
batch i:1230
learning rate0.0001755829903978052, loss:2.7247962951660156
batch i:1231
learning rate0.0001755829903978052, loss:2.6993188858032227
batch i:1232
learning rate0.0001755829903978052, loss:2.6946802139282227
batch i:1233
learning rate0.0001755829903978052, loss:2.736968517303467
batch i:1234
learning rate0.0001755829903978052, loss:2.717954635620117
batch i:1235
learning rate0.0001755829903978052, loss:2.645500898361206
batch i:1236
learning rate0.0001755829903978052, loss:2.655777931213379
batch i:1237
learning rate0.0001755829903978052, loss:2.6558523178100586
batch i:1238
learning rate0.0001755829903978052, loss:2.6519553661346436
batch i:1239
learning rate0.0001755829903978052, loss:2.668837547302246
batch i:1240
learning rate0.0001755829903978052, loss:2.72101092338562
batch i:1241
learning rate0.0001755829903978052, loss:2.6753246784210205
batch i:1242
learning rate0.0001755829903978052, loss:2.775952100753784
batch i:1243
learning rate0.0001755829903978052, loss:2.7383909225463867
batch i:1244
learning rate0.0001755829903978052, loss:2.6824254989624023
batch i:1245
learning rate0.0001755829903978052, loss:2.747213840484619
batch i:1246
learning rate0.0001755829903978052, loss:2.701612949371338
batch i:1247
learning rate0.0001755829903978052, loss:2.732555866241455
batch i:1248
learning rate0.0001755829903978052, loss:2.693319320678711
batch i:1249
learning rate0.0001755829903978052, loss:2.7606847286224365
batch i:1250
learning rate0.0001755829903978052, loss:2.7522382736206055
current self-play batch: 1250
num_playouts:4000, win: 5, lose: 1, tie:4
average time: 2075.0965320587156
batch i:1251
learning rate0.0001755829903978052, loss:2.6431703567504883
batch i:1252
learning rate0.0001755829903978052, loss:2.7794623374938965
batch i:1253
learning rate0.0001755829903978052, loss:2.6627354621887207
batch i:1254
learning rate0.0001755829903978052, loss:2.6395912170410156
batch i:1255
learning rate0.0001755829903978052, loss:2.6741175651550293
batch i:1256
learning rate0.0001755829903978052, loss:2.7801575660705566
batch i:1257
learning rate0.0001755829903978052, loss:2.7321243286132812
batch i:1258
learning rate0.0001755829903978052, loss:2.7253122329711914
batch i:1259
learning rate0.0001755829903978052, loss:2.747741222381592
batch i:1260
learning rate0.0001755829903978052, loss:2.7425315380096436
batch i:1261
learning rate0.0001755829903978052, loss:2.704108953475952
batch i:1262
learning rate0.0001755829903978052, loss:2.780884265899658
batch i:1263
learning rate0.0001755829903978052, loss:2.72184419631958
batch i:1264
learning rate0.0001755829903978052, loss:2.622514247894287
batch i:1265
learning rate0.0001755829903978052, loss:2.68154239654541
batch i:1266
learning rate0.0001755829903978052, loss:2.609133720397949
batch i:1267
learning rate0.0001755829903978052, loss:2.625547409057617
batch i:1268
learning rate0.0001755829903978052, loss:2.7290515899658203
batch i:1269
learning rate0.0001755829903978052, loss:2.7618205547332764
batch i:1270
learning rate0.0001755829903978052, loss:2.761009454727173
batch i:1271
learning rate0.0001755829903978052, loss:2.6431567668914795
batch i:1272
learning rate0.0001755829903978052, loss:2.6474814414978027
batch i:1273
learning rate0.0001755829903978052, loss:2.5812957286834717
batch i:1274
learning rate0.0001755829903978052, loss:2.677657127380371
batch i:1275
learning rate0.0001755829903978052, loss:2.6998019218444824
batch i:1276
learning rate0.0001755829903978052, loss:2.6449930667877197
batch i:1277
learning rate0.0001755829903978052, loss:2.6183972358703613
batch i:1278
learning rate0.0001755829903978052, loss:2.683846950531006
batch i:1279
learning rate0.0001755829903978052, loss:2.692758560180664
batch i:1280
learning rate0.0001755829903978052, loss:2.5857088565826416
batch i:1281
learning rate0.0001755829903978052, loss:2.6401607990264893
batch i:1282
learning rate0.0001755829903978052, loss:2.6132214069366455
batch i:1283
learning rate0.0001755829903978052, loss:2.5829851627349854
batch i:1284
learning rate0.0001755829903978052, loss:2.64622163772583
batch i:1285
learning rate0.0001755829903978052, loss:2.6557555198669434
batch i:1286
learning rate0.0001755829903978052, loss:2.7018582820892334
batch i:1287
learning rate0.0001755829903978052, loss:2.655442953109741
batch i:1288
learning rate0.0001755829903978052, loss:2.64792799949646
batch i:1289
learning rate0.0001755829903978052, loss:2.576704740524292
batch i:1290
learning rate0.0001755829903978052, loss:2.609273910522461
batch i:1291
learning rate0.0001755829903978052, loss:2.5748910903930664
batch i:1292
learning rate0.0001755829903978052, loss:2.606569766998291
batch i:1293
learning rate0.0001755829903978052, loss:2.6159377098083496
batch i:1294
learning rate0.0001755829903978052, loss:2.648608684539795
batch i:1295
learning rate0.0001755829903978052, loss:2.5385138988494873
batch i:1296
learning rate0.0001755829903978052, loss:2.5974674224853516
batch i:1297
learning rate0.0001755829903978052, loss:2.656562328338623
batch i:1298
learning rate0.0001755829903978052, loss:2.640352249145508
batch i:1299
learning rate0.0001755829903978052, loss:2.726670742034912
batch i:1300
learning rate0.0001755829903978052, loss:2.625365734100342
current self-play batch: 1300
num_playouts:4000, win: 6, lose: 2, tie:2
average time: 1646.363301038742
batch i:1301
learning rate0.0001755829903978052, loss:2.623406410217285
batch i:1302
learning rate0.0001755829903978052, loss:2.6404271125793457
batch i:1303
learning rate0.0001755829903978052, loss:2.6131129264831543
batch i:1304
learning rate0.0001755829903978052, loss:2.658146619796753
batch i:1305
learning rate0.0001755829903978052, loss:2.608394145965576
batch i:1306
learning rate0.0001755829903978052, loss:2.601485013961792
batch i:1307
learning rate0.0001755829903978052, loss:2.6959187984466553
batch i:1308
learning rate0.0001755829903978052, loss:2.6939404010772705
batch i:1309
learning rate0.0001755829903978052, loss:2.628444194793701
batch i:1310
learning rate0.0001755829903978052, loss:2.5702266693115234
batch i:1311
learning rate0.0001755829903978052, loss:2.6434154510498047
batch i:1312
learning rate0.0001755829903978052, loss:2.6082136631011963
batch i:1313
learning rate0.0001755829903978052, loss:2.5994882583618164
batch i:1314
learning rate0.0001755829903978052, loss:2.5988285541534424
batch i:1315
learning rate0.0001755829903978052, loss:2.684750556945801
batch i:1316
learning rate0.0001755829903978052, loss:2.6124534606933594
batch i:1317
learning rate0.0001755829903978052, loss:2.6300172805786133
batch i:1318
learning rate0.0001755829903978052, loss:2.636815071105957
batch i:1319
learning rate0.0001755829903978052, loss:2.7179980278015137
batch i:1320
learning rate0.0001755829903978052, loss:2.6400933265686035
batch i:1321
learning rate0.0001755829903978052, loss:2.5575480461120605
batch i:1322
learning rate0.0001755829903978052, loss:2.5987415313720703
batch i:1323
learning rate0.0001755829903978052, loss:2.6307859420776367
batch i:1324
learning rate0.0001755829903978052, loss:2.634273052215576
batch i:1325
learning rate0.0001755829903978052, loss:2.6983025074005127
batch i:1326
learning rate0.0001755829903978052, loss:2.5156662464141846
batch i:1327
learning rate0.0001755829903978052, loss:2.6211862564086914
batch i:1328
learning rate0.0001755829903978052, loss:2.6485040187835693
batch i:1329
learning rate0.0001755829903978052, loss:2.6566390991210938
batch i:1330
learning rate0.0001755829903978052, loss:2.615980863571167
batch i:1331
learning rate0.0001755829903978052, loss:2.65748929977417
batch i:1332
learning rate0.0001755829903978052, loss:2.6271157264709473
batch i:1333
learning rate0.0001755829903978052, loss:2.6510579586029053
batch i:1334
learning rate0.0001755829903978052, loss:2.6315879821777344
batch i:1335
learning rate0.0001755829903978052, loss:2.6733431816101074
batch i:1336
learning rate0.0001755829903978052, loss:2.6834044456481934
batch i:1337
learning rate0.0001755829903978052, loss:2.7044334411621094
batch i:1338
learning rate0.0001755829903978052, loss:2.627110242843628
batch i:1339
learning rate0.0001755829903978052, loss:2.632335662841797
batch i:1340
learning rate0.0001755829903978052, loss:2.55143666267395
batch i:1341
learning rate0.0001755829903978052, loss:2.6003973484039307
batch i:1342
learning rate0.0001755829903978052, loss:2.6352157592773438
batch i:1343
learning rate0.0001755829903978052, loss:2.62880802154541
batch i:1344
learning rate0.0001755829903978052, loss:2.6578807830810547
batch i:1345
learning rate0.0001755829903978052, loss:2.629789352416992
batch i:1346
learning rate0.0001755829903978052, loss:2.6952946186065674
batch i:1347
learning rate0.0001755829903978052, loss:2.700559377670288
batch i:1348
learning rate0.0001755829903978052, loss:2.729896306991577
batch i:1349
learning rate0.0001755829903978052, loss:2.670644760131836
batch i:1350
learning rate0.0001755829903978052, loss:2.76593017578125
current self-play batch: 1350
num_playouts:4000, win: 9, lose: 1, tie:0
average time: 1135.7583734989166
batch i:1351
learning rate0.0001755829903978052, loss:2.8072829246520996
batch i:1352
learning rate0.0001755829903978052, loss:2.7868003845214844
batch i:1353
learning rate0.0001755829903978052, loss:2.6984617710113525
batch i:1354
learning rate0.0001755829903978052, loss:2.7785253524780273
batch i:1355
learning rate0.0001755829903978052, loss:2.7239937782287598
batch i:1356
learning rate0.0001755829903978052, loss:2.68768310546875
batch i:1357
learning rate0.0001755829903978052, loss:2.6777334213256836
batch i:1358
learning rate0.0001755829903978052, loss:2.671128034591675
batch i:1359
learning rate0.0001755829903978052, loss:2.7195348739624023
batch i:1360
learning rate0.0001755829903978052, loss:2.6161937713623047
batch i:1361
learning rate0.0001755829903978052, loss:2.662381887435913
batch i:1362
learning rate0.0001755829903978052, loss:2.7027180194854736
batch i:1363
learning rate0.0001755829903978052, loss:2.6665966510772705
batch i:1364
learning rate0.0001755829903978052, loss:2.564727306365967
batch i:1365
learning rate0.0001755829903978052, loss:2.6326656341552734
batch i:1366
learning rate0.0001755829903978052, loss:2.630678176879883
batch i:1367
learning rate0.0001755829903978052, loss:2.637228488922119
batch i:1368
learning rate0.0001755829903978052, loss:2.7273993492126465
batch i:1369
learning rate0.0001755829903978052, loss:2.6918063163757324
batch i:1370
learning rate0.0001755829903978052, loss:2.6506452560424805
batch i:1371
learning rate0.0001755829903978052, loss:2.6608829498291016
batch i:1372
learning rate0.0001755829903978052, loss:2.7732272148132324
batch i:1373
learning rate0.0001755829903978052, loss:2.7198498249053955
batch i:1374
learning rate0.0001755829903978052, loss:2.7516016960144043
batch i:1375
learning rate0.0001755829903978052, loss:2.673760414123535
batch i:1376
learning rate0.0001755829903978052, loss:2.707393169403076
batch i:1377
learning rate0.0001755829903978052, loss:2.6961703300476074
batch i:1378
learning rate0.0001755829903978052, loss:2.7480499744415283
batch i:1379
learning rate0.0001755829903978052, loss:2.766094446182251
batch i:1380
learning rate0.0001755829903978052, loss:2.6156585216522217
batch i:1381
learning rate0.0001755829903978052, loss:2.7235658168792725
batch i:1382
learning rate0.0001755829903978052, loss:2.773709774017334
batch i:1383
learning rate0.0001755829903978052, loss:2.815441608428955
batch i:1384
learning rate0.0001755829903978052, loss:2.7302985191345215
batch i:1385
learning rate0.0001755829903978052, loss:2.730213165283203
batch i:1386
learning rate0.0001755829903978052, loss:2.711303472518921
batch i:1387
learning rate0.0001755829903978052, loss:2.774311065673828
batch i:1388
learning rate0.0001755829903978052, loss:2.749897003173828
batch i:1389
learning rate0.0001755829903978052, loss:2.7722959518432617
batch i:1390
learning rate0.0001755829903978052, loss:2.7757136821746826
batch i:1391
learning rate0.0001755829903978052, loss:2.7144558429718018
batch i:1392
learning rate0.0001755829903978052, loss:2.7628400325775146
batch i:1393
learning rate0.0001755829903978052, loss:2.776413679122925
batch i:1394
learning rate0.0001755829903978052, loss:2.741077423095703
batch i:1395
learning rate0.0001755829903978052, loss:2.7012109756469727
batch i:1396
learning rate0.0001755829903978052, loss:2.745169162750244
batch i:1397
learning rate0.0001755829903978052, loss:2.7047641277313232
batch i:1398
learning rate0.0001755829903978052, loss:2.7334296703338623
batch i:1399
learning rate0.0001755829903978052, loss:2.763701915740967
batch i:1400
learning rate0.0001755829903978052, loss:2.721672296524048
current self-play batch: 1400
num_playouts:4000, win: 5, lose: 3, tie:2
average time: 1556.4576052188872
batch i:1401
learning rate0.0001755829903978052, loss:2.7885608673095703
batch i:1402
learning rate0.0001755829903978052, loss:2.664374828338623
batch i:1403
learning rate0.0001755829903978052, loss:2.7792117595672607
batch i:1404
learning rate0.0001755829903978052, loss:2.7986416816711426
batch i:1405
learning rate0.0001755829903978052, loss:2.6737444400787354
batch i:1406
learning rate0.0001755829903978052, loss:2.7362420558929443
batch i:1407
learning rate0.0001755829903978052, loss:2.702343463897705
batch i:1408
learning rate0.0001755829903978052, loss:2.79703426361084
batch i:1409
learning rate0.0001755829903978052, loss:2.757134199142456
batch i:1410
learning rate0.0001755829903978052, loss:2.712533712387085
batch i:1411
learning rate0.0001755829903978052, loss:2.751065254211426
batch i:1412
learning rate0.0001755829903978052, loss:2.6315677165985107
batch i:1413
learning rate0.0001755829903978052, loss:2.664106845855713
batch i:1414
learning rate0.0001755829903978052, loss:2.6803336143493652
batch i:1415
learning rate0.0001755829903978052, loss:2.7048165798187256
batch i:1416
learning rate0.0001755829903978052, loss:2.7040510177612305
batch i:1417
learning rate0.0001755829903978052, loss:2.7839908599853516
batch i:1418
learning rate0.0001755829903978052, loss:2.7380495071411133
batch i:1419
learning rate0.0001755829903978052, loss:2.749452590942383
batch i:1420
learning rate0.0001755829903978052, loss:2.7942123413085938
batch i:1421
learning rate0.0001755829903978052, loss:2.78139591217041
batch i:1422
learning rate0.0001755829903978052, loss:2.7095422744750977
batch i:1423
learning rate0.0001755829903978052, loss:2.8004744052886963
batch i:1424
learning rate0.0001755829903978052, loss:2.723534107208252
batch i:1425
learning rate0.0001755829903978052, loss:2.797891616821289
batch i:1426
learning rate0.0001755829903978052, loss:2.749337673187256
batch i:1427
learning rate0.0001755829903978052, loss:2.6808743476867676
batch i:1428
learning rate0.0001755829903978052, loss:2.7010252475738525
batch i:1429
learning rate0.0001755829903978052, loss:2.7932381629943848
batch i:1430
learning rate0.0001755829903978052, loss:2.705531120300293
batch i:1431
learning rate0.0001755829903978052, loss:2.7939419746398926
batch i:1432
learning rate0.0001755829903978052, loss:2.7906763553619385
batch i:1433
learning rate0.0001755829903978052, loss:2.779020309448242
batch i:1434
learning rate0.0001755829903978052, loss:2.7271296977996826
batch i:1435
learning rate0.0001755829903978052, loss:2.719137668609619
batch i:1436
learning rate0.0001755829903978052, loss:2.7600953578948975
batch i:1437
learning rate0.0001755829903978052, loss:2.7345948219299316
batch i:1438
learning rate0.0001755829903978052, loss:2.757283926010132
batch i:1439
learning rate0.0001755829903978052, loss:2.7476699352264404
batch i:1440
learning rate0.0001755829903978052, loss:2.601451873779297
batch i:1441
learning rate0.0001755829903978052, loss:2.692981719970703
batch i:1442
learning rate0.0001755829903978052, loss:2.6518616676330566
batch i:1443
learning rate0.0001755829903978052, loss:2.728275775909424
batch i:1444
learning rate0.0001755829903978052, loss:2.742952346801758
batch i:1445
learning rate0.0001755829903978052, loss:2.726802349090576
batch i:1446
learning rate0.0001755829903978052, loss:2.6663267612457275
batch i:1447
learning rate0.0001755829903978052, loss:2.7903096675872803
batch i:1448
learning rate0.0001755829903978052, loss:2.6884632110595703
batch i:1449
learning rate0.0001755829903978052, loss:2.7261390686035156
batch i:1450
learning rate0.0001755829903978052, loss:2.7072877883911133
current self-play batch: 1450
num_playouts:4000, win: 5, lose: 3, tie:2
average time: 1651.7312955856323
batch i:1451
learning rate0.0001755829903978052, loss:2.7072701454162598
batch i:1452
learning rate0.0001755829903978052, loss:2.7329304218292236
batch i:1453
learning rate0.0001755829903978052, loss:2.6746349334716797
batch i:1454
learning rate0.0001755829903978052, loss:2.722677230834961
batch i:1455
learning rate0.0001755829903978052, loss:2.7132365703582764
batch i:1456
learning rate0.0001755829903978052, loss:2.7719244956970215
batch i:1457
learning rate0.0001755829903978052, loss:2.6747989654541016
batch i:1458
learning rate0.0001755829903978052, loss:2.6998300552368164
batch i:1459
learning rate0.0001755829903978052, loss:2.729876756668091
batch i:1460
learning rate0.0001755829903978052, loss:2.7567129135131836
batch i:1461
learning rate0.0001755829903978052, loss:2.628678321838379
batch i:1462
learning rate0.0001755829903978052, loss:2.7304904460906982
batch i:1463
learning rate0.0001755829903978052, loss:2.7274413108825684
batch i:1464
learning rate0.0001755829903978052, loss:2.767543315887451
batch i:1465
learning rate0.0001755829903978052, loss:2.6528847217559814
batch i:1466
learning rate0.0001755829903978052, loss:2.6745455265045166
batch i:1467
learning rate0.0001755829903978052, loss:2.6766772270202637
batch i:1468
learning rate0.0001755829903978052, loss:2.716818332672119
batch i:1469
learning rate0.0001755829903978052, loss:2.7387423515319824
batch i:1470
learning rate0.0001755829903978052, loss:2.730210304260254
batch i:1471
learning rate0.0001755829903978052, loss:2.7552363872528076
batch i:1472
learning rate0.0001755829903978052, loss:2.7337872982025146
batch i:1473
learning rate0.0001755829903978052, loss:2.7126240730285645
batch i:1474
learning rate0.0001755829903978052, loss:2.739895820617676
batch i:1475
learning rate0.0001755829903978052, loss:2.7304790019989014
batch i:1476
learning rate0.0001755829903978052, loss:2.68247652053833
batch i:1477
learning rate0.0001755829903978052, loss:2.6943016052246094
batch i:1478
learning rate0.0001755829903978052, loss:2.74629807472229
batch i:1479
learning rate0.0001755829903978052, loss:2.7306671142578125
batch i:1480
learning rate0.0001755829903978052, loss:2.714945077896118
batch i:1481
learning rate0.0001755829903978052, loss:2.7145211696624756
batch i:1482
learning rate0.0001755829903978052, loss:2.6809542179107666
batch i:1483
learning rate0.0001755829903978052, loss:2.6438422203063965
batch i:1484
learning rate0.0001755829903978052, loss:2.732783317565918
batch i:1485
learning rate0.0001755829903978052, loss:2.6996004581451416
batch i:1486
learning rate0.0001755829903978052, loss:2.7275428771972656
batch i:1487
learning rate0.0001755829903978052, loss:2.6736514568328857
batch i:1488
learning rate0.0001755829903978052, loss:2.7844762802124023
batch i:1489
learning rate0.0001755829903978052, loss:2.686476230621338
batch i:1490
learning rate0.0001755829903978052, loss:2.676074981689453
batch i:1491
learning rate0.0001755829903978052, loss:2.6798365116119385
batch i:1492
learning rate0.0001755829903978052, loss:2.722947120666504
batch i:1493
learning rate0.0001755829903978052, loss:2.6451327800750732
batch i:1494
learning rate0.0001755829903978052, loss:2.677064895629883
batch i:1495
learning rate0.0001755829903978052, loss:2.62703013420105
batch i:1496
learning rate0.0001755829903978052, loss:2.6572911739349365
batch i:1497
learning rate0.0001755829903978052, loss:2.703011989593506
batch i:1498
learning rate0.0001755829903978052, loss:2.737433433532715
batch i:1499
learning rate0.0001755829903978052, loss:2.635897159576416
batch i:1500
learning rate0.0001755829903978052, loss:2.717996120452881
current self-play batch: 1500
num_playouts:4000, win: 7, lose: 3, tie:0
average time: 978.779568195343
